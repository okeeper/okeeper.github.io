<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Meta开源320亿参数代码世界模型CWM：它真的“懂”代码怎么跑</title>
      <link href="/ren-gong-zhi-neng/meta-kai-yuan-320-yi-can-shu-dai-ma-shi-jie-mo-xing-cwm-ta-zhen-de-dong-dai-ma-zen-me-pao-3/"/>
      <url>/ren-gong-zhi-neng/meta-kai-yuan-320-yi-can-shu-dai-ma-shi-jie-mo-xing-cwm-ta-zhen-de-dong-dai-ma-zen-me-pao-3/</url>
      
        <content type="html"><![CDATA[<p>Meta FAIR团队刚刚扔出一颗重磅炸弹——<strong>Code World Model（CWM）</strong>，一个320亿参数、支持131k上下文的密集型语言模型，专为代码生成和推理而生。更关键的是，它不是又一个“会写代码的LLM”，而是<strong>首个系统性引入“世界模型”概念的代码大模型</strong>。</p><p>简单说：CWM不仅能写代码，还能“脑内模拟”这段代码跑起来时变量怎么变、函数怎么调、哪里会崩——就像程序员用pdb单步调试那样。</p><p>这事儿有多重要？看数据就知道：在权威代码评测SWE-bench Verified上，CWM拿下<strong>65.8分</strong>，碾压所有开源同规模模型，直逼GPT-4水平。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/09558274145b5b9c09da1eff8c769bf7.png" alt="模型性能对比图"></p><p>连Yann LeCun本人都亲自转发了项目发布消息，还顺手回怼了一个质疑者：“这是编码，不是ASI（人工通用智能）。”<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ad2cdc8839e19c428b031a55914908cf.png" alt="LeCun回应质疑"></p><h2 id="为什么现有代码模型写得对但跑不通"><a class="markdownIt-Anchor" href="#为什么现有代码模型写得对但跑不通"></a> 为什么现有代码模型“写得对但跑不通”？</h2><p>当前主流代码大模型（比如CodeLlama、DeepSeek-Coder）本质上还是“文本预测器”。它们把代码当成一串字符序列，靠统计规律猜下一个token是什么。结果就是：生成的代码语法正确、结构漂亮，但一跑就错——变量未定义、边界条件漏判、副作用没考虑。</p><p>问题出在哪？<strong>它们不懂“执行”</strong>。</p><p>CWM团队一针见血：如果模型连“变量x在第5行被赋值为3”这种动态状态变化都不知道，怎么可能写出可靠代码？</p><p>于是，他们干了件狠事：<strong>让模型直接学习“代码执行轨迹”</strong>。</p><p>比如下面这个统计&quot;strawberry&quot;中’r’个数的函数，CWM不仅能生成代码，还能一步步追踪执行状态：</p><ul><li>初始：<code>count = 0</code></li><li>第一次循环：<code>char = 's'</code> → <code>count</code>不变</li><li>第二次循环：<code>char = 't'</code> → <code>count</code>不变</li><li>……</li><li>第六次循环：<code>char = 'r'</code> → <code>count = 1</code></li><li>……</li><li>最终返回 <code>count = 3</code></li></ul><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6fcfca2578bfe7d32634816c946b1c1e.png" alt="代码执行追踪"></p><p>这种能力让CWM实现了三大突破：</p><h3 id="1-代码执行模拟提前预判哪里会崩"><a class="markdownIt-Anchor" href="#1-代码执行模拟提前预判哪里会崩"></a> 1. 代码执行模拟：提前预判哪里会崩</h3><p>CWM能在生成代码的同时，模拟执行路径，预判空指针、越界访问、死循环等常见错误。相当于内置了一个“神经调试器”。</p><h3 id="2-自我修复写错自动改改完自动测"><a class="markdownIt-Anchor" href="#2-自我修复写错自动改改完自动测"></a> 2. 自我修复：写错自动改，改完自动测</h3><p>它能自动生成测试用例，发现失败后尝试多种修复策略——写→测→改→再测，形成完整开发闭环。</p><h3 id="3-推理规划复杂问题拆解成可执行步骤"><a class="markdownIt-Anchor" href="#3-推理规划复杂问题拆解成可执行步骤"></a> 3. 推理规划：复杂问题拆解成可执行步骤</h3><p>面对编程竞赛题或数学问题，CWM会先规划函数结构、变量设计，再结合执行预测逐步生成验证，展现出类人的多步推理能力。</p><h2 id="技术底牌32b参数-三阶段训练"><a class="markdownIt-Anchor" href="#技术底牌32b参数-三阶段训练"></a> 技术底牌：32B参数 + 三阶段训练</h2><p>CWM不是凭空冒出来的。它的架构和训练流程都经过精心设计。</p><p><strong>模型参数</strong>：32B密集模型，64层Transformer，使用SwiGLU激活函数，支持131k上下文——足够塞进整个中型项目的代码库。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6299372ff03905bdf77b59c9318ea993.png" alt="CWM参数表"></p><p><strong>训练分三步走</strong>：</p><ol><li><strong>预训练</strong>：8T tokens通用语料（30%为代码），上下文8k，打好基础。</li><li><strong>中期训练（关键！）</strong>：5T tokens的“世界建模”数据，包括：<ul><li>数千万Python函数的执行轨迹（变量状态变化记录）</li><li>300万条智能体在Docker中真实修复Bug的交互日志</li><li>执行过程的自然语言描述（便于泛化）</li></ul></li><li><strong>后训练</strong>：100B tokens监督微调 + 172B tokens多任务强化学习，覆盖SWE-bench、编程竞赛、数学题等真实任务。</li></ol><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e81dad8c3357b80d6d954cd82b8c1765.png" alt="三阶段训练流程"></p><p>特别值得注意的是强化学习阶段——Meta用了异步RL架构，多个“Worker”并行生成代码并执行反馈，Trainer实时更新模型，效率拉满。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/9d014800a5ceb7d3b869e91f98656bfc.png" alt="CWM-RL训练图"></p><h2 id="性能实测不只是理论漂亮"><a class="markdownIt-Anchor" href="#性能实测不只是理论漂亮"></a> 性能实测：不只是理论漂亮</h2><p>CWM在多个硬核评测中表现亮眼：</p><ul><li><strong>SWE-bench Verified</strong>：65.8%（开源模型第一）</li><li><strong>LiveCodeBench v5</strong>：68.6%（高复杂度任务）</li><li><strong>Math-500</strong>：96.6%</li><li><strong>Terminal-Bench</strong>：26.3%（超过Gemini 2.5 Pro）</li></ul><p>从模型规模与性能的关系看，CWM（紫色点）明显优于同体量模型，甚至逼近更大参数的闭源模型。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6b84c971e0394a7f7a8c805508d2b2ef.png" alt="模型规模性能图"></p><p>不过也得说清楚：<strong>目前CWM只支持Python</strong>。C++、Java等语言的世界建模还没做，符号执行、内存安全分析这些更复杂的场景也还没覆盖。</p><h2 id="开源诚意足但别指望拿来当聊天机器人"><a class="markdownIt-Anchor" href="#开源诚意足但别指望拿来当聊天机器人"></a> 开源诚意足，但别指望拿来当聊天机器人</h2><p>Meta这次开源相当大方：模型权重、训练代码、各阶段checkpoint全部放出，连训练细节都写得明明白白。</p><p>但有两个重要限制：</p><ol><li><strong>CWM没做RLHF，不适合对话</strong>——你别指望拿它当Copilot聊天。</li><li><strong>仅限非商业研究使用</strong>——想商用？先找Meta谈授权。</li></ol><p>项目核心成员Gabriel Synnaeve在推文中难掩兴奋：“为CodeGen团队骄傲！博士生和资深工程师一起拼，Meta领导层全力支持。”<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d0c101c64f0657e936f86735d5f71f54.png" alt="团队致谢推文"></p><h2 id="世界模型是代码ai的下一个拐点吗"><a class="markdownIt-Anchor" href="#世界模型是代码ai的下一个拐点吗"></a> 世界模型，是代码AI的下一个拐点吗？</h2><p>CWM的出现，其实是在回答一个根本问题：<strong>大模型要怎样才能真正理解代码？</strong></p><p>过去我们靠堆数据、扩参数，让模型“见过”足够多的代码模式。但CWM走的是另一条路：<strong>教模型理解代码的“物理规律”——执行时的状态变迁</strong>。</p><p>这有点像从“背菜谱”升级到“懂火候”。你背一万道菜谱，不如亲手炒过一百次知道油温几成、什么时候该翻锅。</p><p>当然，现在说CWM能取代程序员还太早。但它确实证明了一件事：<strong>让AI理解“世界如何运作”，比让它记住“世界长什么样”更重要</strong>。</p><p>Meta没开源二维码、没搞扫码入群、没推付费课程——就安安静静扔出一个技术突破，然后问了句：“如果大模型能理解世界，它能成为更好的程序员吗？”</p><p>我觉得，这个问题，值得每个写代码的人想想。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从实验室到生产线：阿里云栖大会七款大模型如何改写AI格局？</title>
      <link href="/ren-gong-zhi-neng/cong-shi-yan-shi-dao-sheng-chan-xian-a-li-yun-qi-da-hui-qi-kuan-da-mo-xing-ru-he-gai-xie-ai-ge-ju-3/"/>
      <url>/ren-gong-zhi-neng/cong-shi-yan-shi-dao-sheng-chan-xian-a-li-yun-qi-da-hui-qi-kuan-da-mo-xing-ru-he-gai-xie-ai-ge-ju-3/</url>
      
        <content type="html"><![CDATA[<p>刚结束的2025云栖大会，阿里云把压箱底的AI技术全亮出来了。不是简单更新几个模型参数，而是直接甩出覆盖全尺寸、全模态的大模型家族，从基础架构到应用落地来了个&quot;全栈升级&quot;。说实话，看完现场发布数据，连国外AI圈都坐不住了——有Twitter用户直接评论&quot;简直疯狂&quot;，专业评测人士更是直言Qwen3-VL&quot;击败了AWS Bedrock上所有模型&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/495f03aec5d3650a36e9451d5c68a004.png" alt="云栖大会模型展示"></p><h2 id="一-旗舰级突破qwen3-max把智能效率玩明白了"><a class="markdownIt-Anchor" href="#一-旗舰级突破qwen3-max把智能效率玩明白了"></a> 一、旗舰级突破：Qwen3-Max把&quot;智能+效率&quot;玩明白了</h2><p>这次最受关注的当属旗舰模型Qwen3-Max，总参数量超过1万亿，分指令和推理两个版本。现场公布的评测数据确实亮眼：SWE-Bench编程评测69.6分，Tau2工具调用测试74.8分，直接把Claude Opus4和DeepSeek V3.1甩在了身后。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/59a83abbd273d9a7dbae8a2d5601c2ff.png" alt="Qwen3-Max发布"></p><p>最让人意外的是数学能力——推理增强版Qwen3-Max-Thinking-Heavy在AIME25、HMMT等竞赛中拿了满分，这在国内还是头一遭。秘密武器其实不复杂：模型学会了自己写代码解题，遇到复杂计算就调用工具，给足计算资源就能超常发挥。这种&quot;会用工具&quot;的能力，比单纯堆参数有意思多了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/79873a33a40740d7d786cc3205fff9c2.png" alt="模型性能对比"></p><h2 id="二-效率革命qwen3-next用80b参数干出235b的活"><a class="markdownIt-Anchor" href="#二-效率革命qwen3-next用80b参数干出235b的活"></a> 二、效率革命：Qwen3-Next用80B参数干出235B的活</h2><p>如果说Qwen3-Max是&quot;性能怪兽&quot;，那Qwen3-Next就是&quot;效率鬼才&quot;。80B总参数，实际激活3B就能媲美235B的旗舰模型，训练成本直降90%，长文本推理吞吐量提升10倍以上。这可不是简单缩水，而是实打实的架构创新——混合注意力、稀疏MoE、多Token预测(MTP)这些技术组合拳，硬是把大模型的&quot;性价比&quot;拉到了新高度。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/93fd44d165f3a4a5ae7c5b00e88f513e.png" alt="性能效率对比"></p><p>对企业用户来说，这才是真金白银的价值。以前跑个大模型得搭昂贵的算力集群，现在可能一台普通服务器就能搞定相近效果。这种效率提升，比单纯的性能跑分更能推动AI普及。</p><h2 id="三-多模态杀疯了qwen3-vl让国外同行集体沉默"><a class="markdownIt-Anchor" href="#三-多模态杀疯了qwen3-vl让国外同行集体沉默"></a> 三、多模态杀疯了：Qwen3-VL让国外同行集体沉默</h2><p>要说这次发布会最炸场的，还得是视觉大模型Qwen3-VL。235B参数的Qwen3-VL-235B-A22B开源当天，国外技术社区直接沸腾了。Twitter上Yam Peleg一句&quot;Fucking Insane&quot;道出了大家的心声，另一位专家Petr Baudis更直接：“它击败了AWS Bedrock上所有模型，Claude在某些任务上都不是对手”。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d550d9d6befa74b58b42732c0080ecab.jpg" alt="Qwen3-VL用户评价"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c5e0fd9748906bcc9c0a5502300515e4.png" alt="Qwen3-VL专业评价"></p><p>数据不会说谎：STEM任务、VQA评测、文本识别，Qwen3-VL几乎全面领先Gemini 2.5-Pro和GPT5。更狠的是它不止能&quot;看&quot;，还能&quot;动手&quot;——识别GUI界面元素、理解按钮功能、自动操作手机电脑，简直是个视觉AI助手。给张设计草图，它能直接生成HTML/CSS/JS代码，真正实现&quot;所见即所得&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/44c1ef3723dc1b16b48bcb4985d0c160.png" alt="VL性能对比表"></p><p>技术上，Vision Encoder和语言模型的深度融合是关键。百万tokens上下文+2小时视频理解，意味着你可以把一整本技术手册或全天会议录像丢给它，全程记忆还能精准检索。对需要处理大量图文资料的程序员和研究员来说，这简直是 productivity神器。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d4562c58897457188147d4507b91d62c.jpg" alt="VL技术架构"></p><h2 id="四-全模态覆盖从文字到音视频的通杀能力"><a class="markdownIt-Anchor" href="#四-全模态覆盖从文字到音视频的通杀能力"></a> 四、全模态覆盖：从文字到音视频的&quot;通杀&quot;能力</h2><p>Qwen3-Omni的发布补全了最后一块拼图。三个开源版本直接在36项音视频评测中拿了32个SOTA，音频识别和对话能力跟Gemini2.5-pro硬刚不落下风。最有意思的是那个Captioner版本，全球首个开源的通用音频描述模型，能把一段音频的细节特征讲得明明白白，这在以前想都不敢想。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e8dde139ff00003bad057b876f58d4df.png" alt="Omni架构图"></p><p>视觉生成这边，通义万相Wan2.5-preview也玩出了新花样。累计生成3.9亿张图像、7000万个视频的底子不是白给的，现在能直接生成带人声、音效和BGM的10秒1080P视频，音画还能完美同步。对内容创作者来说，这简直是把电影工作室装进了电脑。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/044649676a5260ad851f5b5bd8775cd7.png" alt="通义万相家族"></p><p>语音模型通义百聆Fun也没让人失望。Fun-ASR和Fun-CosyVoice两大模型，一个专攻语音识别，一个擅长语音合成，上百种预制音色，从客服到有声书全都能cover。现场演示的会议实时转写+翻译，准确率高得有点离谱。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e4d5ba9478adc54626f44a92e05a0c90.png" alt="通义百聆发布"></p><h2 id="五-开源生态17万个衍生模型背后的ai安卓梦"><a class="markdownIt-Anchor" href="#五-开源生态17万个衍生模型背后的ai安卓梦"></a> 五、开源生态：17万个衍生模型背后的&quot;AI安卓梦&quot;</h2><p>通义这次亮出的家底确实吓人：0.5B到&gt;1T全尺寸覆盖，基础模型+专项模型双线并进，300多款开源模型，6亿次下载量，17万个衍生模型，100万家企业客户。从去年9月超越Llama开始，通义的开源生态就像滚雪球一样越做越大。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ab1e3d9542bf7c57989bde4baa861e99.png" alt="模型家族全景"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/569a88c309fb2fcd3305b1d4e9ffa32d.png" alt="衍生模型数量"></p><p>吴泳铭在会上说要做&quot;AI时代的安卓系统&quot;，这话现在看不是空谈。3800亿的未来三年投入，目标显然不只是几个模型，而是要搭建整个AI时代的基础设施。</p><h2 id="六-终极思考大模型真的会取代操作系统吗"><a class="markdownIt-Anchor" href="#六-终极思考大模型真的会取代操作系统吗"></a> 六、终极思考：大模型真的会取代操作系统吗？</h2><p>会上最颠覆认知的观点，是&quot;大模型将替代OS成为下一代计算平台&quot;。想想也有道理：以后用户需求可能不再通过传统软件，而是直接跟大模型对话，由AI调度工具和资源完成任务。LLM变成操作系统，云变成AI硬件，这确实是个大胆但可能的未来。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/934e3fba83b4cf64b7bed92f8cf6fc11.png" alt="AI发展路径"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4cf3fa3424bb5ce3d3349dff78db3e3c.png" alt="大模型OS愿景"></p><p>不过话说回来，技术领先不代表一切。开源生态的维护、商业化的平衡、安全伦理的边界，都是通义接下来要面对的挑战。但至少现在，中国大模型在全球舞台上，终于有了跟GPT、Claude掰手腕的实力。对我们这些开发者来说，这绝对是个好时代——毕竟，选择多了，创新才更容易发生。</p><p>反正我已经迫不及待想把Qwen3-VL拉来改改我的代码了，你们呢？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>朱啸虎：下一个字节、快手、小红书，今年可能已经悄悄成立了</title>
      <link href="/ren-gong-zhi-neng/zhu-xiao-hu-xia-yi-ge-zi-jie-kuai-shou-xiao-hong-shu-jin-nian-ke-neng-yi-jing-qiao-qiao-cheng-li-liao-3/"/>
      <url>/ren-gong-zhi-neng/zhu-xiao-hu-xia-yi-ge-zi-jie-kuai-shou-xiao-hong-shu-jin-nian-ke-neng-yi-jing-qiao-qiao-cheng-li-liao-3/</url>
      
        <content type="html"><![CDATA[<p>最近AI圈有个挺有意思的说法——“下一个字节跳动级别的公司，现在可能已经在某个车库里诞生了”。这话不是我瞎编的，是金沙江创投的朱啸虎在今年外滩大会上说的。上周我翻了翻这场圆桌对话的实录，发现几位大佬聊的内容挺实在，没有太多空话，全是关于AI怎么落地、创业者还有哪些机会的干货。今天就来跟大家拆解一下，看看这些在一线拼杀的大佬们，到底看到了哪些我们普通人还没察觉到的趋势。</p><h2 id="先抛个核心问题ai真的在吞噬软件吗"><a class="markdownIt-Anchor" href="#先抛个核心问题ai真的在吞噬软件吗"></a> 先抛个核心问题：AI真的在&quot;吞噬&quot;软件吗？</h2><p>今年AI圈有个挺火的观点，说&quot;AI正在吞噬软件&quot;。简单理解就是，以后可能就不需要那么多App了，一个AI Agent就能搞定所有事。这话到底靠不靠谱？外滩大会上几位大佬的看法还真不太一样。</p><p>蚂蚁集团CEO韩歆毅是赞同这个观点的。他觉得软件本质上是用固定流程解决固定问题，这恰好是大模型最擅长的事。现在已经有软件能自己生成Agent来处理任务了，这个趋势快得吓人。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/764d0ccce993de3ecc0d90febd633f79.png" alt="外滩大会圆桌论坛"></p><p>但小米的张雷和投资人朱啸虎就觉得没那么绝对。张雷说现在根本看不到大模型&quot;吃掉&quot;所有软件的可能，更多是提升效率而不是取代。朱啸虎则更直接：“只要Transformer架构还有1%的幻觉率，那些复杂流程的管理软件就不可能被取代”。</p><p>说白了，他们三个人的观点其实可以总结成：<strong>简单的低代码、无代码软件确实危险了，但复杂交互、强逻辑的软件反而会和AI共生</strong>。就像那些泡沫期估值很高的低代码公司，现在基本都没声音了；但像财务系统、医疗管理软件这种，AI最多能当个助手，想完全替代还差得远。</p><h2 id="agent创业的机会专挑大厂不愿意干的脏活累活"><a class="markdownIt-Anchor" href="#agent创业的机会专挑大厂不愿意干的脏活累活"></a> Agent创业的机会：专挑大厂不愿意干的&quot;脏活累活&quot;</h2><p>朱啸虎这人说话挺直接，他说从投资人角度看，现在首先要避开的就是&quot;协同类软件&quot;。为啥？因为AI来了之后，以前需要几百人协作的项目，现在可能10个人就够了，协同软件的市场自然就小了。</p><p>那机会在哪？他举了个例子：美国移动互联网时代的Uber、DoorDash、Airbnb，这些公司当初都是因为干了大厂不愿意碰的&quot;苦活累活&quot;才起来的。AI时代也一样，<strong>那些需要深入行业、做垂直领域定制化的Agent，就是小公司的机会</strong>。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a03a65165830fc05a4d4e54cc2398a72.png" alt="朱啸虎发言特写"></p><p>朱啸虎还说了个挺有意思的判断标准：<strong>看用户留存</strong>。现在很多AI公司只敢说ARR（年度经常性收入），不敢提留存，这就有问题。移动互联网时代就证明了，召回一个流失用户的成本是获取新用户的10倍以上，留存不行，再火也是昙花一现。</p><h2 id="今年最火的ai商业化方向voice-agent正在悄悄赚钱"><a class="markdownIt-Anchor" href="#今年最火的ai商业化方向voice-agent正在悄悄赚钱"></a> 今年最火的AI商业化方向：Voice Agent正在悄悄赚钱</h2><p>聊到商业化，朱啸虎说了句大实话：“<strong>真正能赚钱的都是Boring Technology（ boring技术）</strong>”。这话听着矛盾，其实很有道理——稳定成熟的技术才适合商业化，太前沿的反而风险高。</p><p>去年最成功的商业化案例就是&quot;会议纪要&quot;，不管是硬件还是软件，只要能把会议内容准确转写成文字，就不愁卖。今年呢？他认为是<strong>Voice Agent（语音Agent）</strong>。现在客服、销售、甚至儿童玩具里，到处都是语音Agent的影子，这个赛道已经在大规模赚钱了。</p><p>而蚂蚁集团在医疗场景的探索就更具体了。韩歆毅说他们不担心商业化，医疗健康本身就是万亿市场，商业模式也清晰——不是靠广告，而是直接对接医疗、药品、保险。但现在最大的难点不在赚钱，而在三个技术问题：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b3b4e53aaa683797522b314f1696c466.png" alt="韩歆毅发言特写"></p><ol><li><strong>高质量数据</strong>：一条合格的医疗数据可能要上百美元，还得是主任医师级别的标注</li><li><strong>抑制幻觉</strong>：既要让模型不说胡话，又不能降低回答能力，这平衡很难找</li><li><strong>医学伦理</strong>：蚂蚁甚至专门成立了医疗伦理顾问委员会，请顶级专家来把关</li></ol><p>反正意思就是，医疗AI这事儿，先把技术难关攻克了，赚钱是早晚的事。</p><h2 id="硬件入口要变天ai眼镜的唤醒频率是手机的6-7倍"><a class="markdownIt-Anchor" href="#硬件入口要变天ai眼镜的唤醒频率是手机的6-7倍"></a> 硬件入口要变天？AI眼镜的唤醒频率是手机的6-7倍</h2><p>聊完软件聊硬件，小米的张雷透露了个挺有意思的数据：<strong>现在用户在AI眼镜上唤醒小爱同学的频率，是手机端的6-7倍</strong>。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/620135ee6331c23fd94cb7e84226b0fd.png" alt="张雷发言特写"></p><p>为啥差这么多？张雷解释说，AI眼镜和手机、PC最大的不同是<strong>交互逻辑变了</strong>——从&quot;你找它&quot;变成了&quot;它找你&quot;。手机需要你主动打开App，眼镜却能根据场景主动提供服务。比如你看到一个不认识的单词，眼镜可能直接就把翻译弹出来了；看到一张图片，它能自动帮你分析内容。</p><p>当然他也承认，现在AI眼镜还只是手机的延伸，显示效果、交互体验都还有很大提升空间。但这个&quot;6-7倍&quot;的数据确实值得琢磨——也许下一代人机交互的入口，真的不是手机了？</p><h2 id="中国创业者的机会明年ai应用可能大爆发"><a class="markdownIt-Anchor" href="#中国创业者的机会明年ai应用可能大爆发"></a> 中国创业者的机会：明年AI应用可能大爆发</h2><p>最后聊到中国创业者的机会，几位大佬还挺乐观。朱啸虎说他投了这么多中美AI公司，发现一个规律：<strong>中国创业者天生就适合做To C</strong>。前10个发展快的AI企业里，6个是外国创始人做To B，剩下4个中国创始人全是做To C。</p><p>为啥？因为To B需要本地销售团队，这方面美国公司有优势；但To C靠的是用户体验和快速迭代，这正是中国团队擅长的。就像抖音、快手能在短视频赛道打败Facebook、Google，靠的就是把用户体验做到极致。</p><p>张雷补充说，中国还有个大优势——<strong>供应链</strong>。成本、效率、AI生态，这些都是实打实的竞争力。只要产品力跟上，快速迭代、抢占市场，中国企业完全有机会在AI时代做出全球性的产品。</p><p>朱啸虎甚至大胆预测：<strong>明年肯定是AI应用大爆发的一年，下一个字节、快手、小红书，今年应该已经成立了</strong>。这话听着有点夸张，但想想2012年抖音成立时，谁能想到它会改变整个内容行业呢？</p><h2 id="最后说几句"><a class="markdownIt-Anchor" href="#最后说几句"></a> 最后说几句</h2><p>听完这些大佬的讨论，我最大的感受是：AI已经过了&quot;PPT画饼&quot;的阶段，现在拼的是实打实的落地能力。不管是Voice Agent还是AI眼镜，不管是医疗场景还是To C应用，能解决实际问题、留住用户的产品，才能笑到最后。</p><p>至于&quot;下一个字节今年已成立&quot;这个说法，我觉得半信半疑。机会肯定有，但也别盲目乐观。毕竟AI创业的门槛不低，既要有技术积累，又得懂用户需求。不过话说回来，哪个伟大的公司不是从没人看好开始的呢？</p><p>你们觉得，下一个能改变行业的AI应用会出现在哪个领域？来评论区聊聊你的看法。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>当AI开始接管互联网：51%流量来自机器人，我们正在见证&quot;死网理论&quot;成真？</title>
      <link href="/ren-gong-zhi-neng/dang-ai-kai-shi-jie-guan-hu-lian-wang-51-liu-liang-lai-zi-ji-qi-ren-wo-men-zheng-zai-jian-zheng-si-wang-li-lun-cheng-zhen-3/"/>
      <url>/ren-gong-zhi-neng/dang-ai-kai-shi-jie-guan-hu-lian-wang-51-liu-liang-lai-zi-ji-qi-ren-wo-men-zheng-zai-jian-zheng-si-wang-li-lun-cheng-zhen-3/</url>
      
        <content type="html"><![CDATA[<p>最近刷到条&quot;炸裂新闻&quot;：“OpenAI发布GPTML，革命性替代HTML、CSS和JavaScript”。标题够震撼，还有奥特曼的照片，差点就信了这是Web开发的末日。结果一查，假的！AI生成的假新闻现在都这么专业了？</p><p>说实话，这事儿让我想起OpenAI CEO奥特曼9月4号那条推特：&quot;我以前从没把’死网理论’当回事，但现在，推特上真的有太多LLM驱动的账号了。“更讽刺的是，这条推特下面，好几个顶着奥特曼头像的AI账号在回复他，说&quot;最大的LLM账号就是你自己”。</p><p>这场景，简直是&quot;死网理论&quot;的完美注脚——我们熟悉的互联网，可能真的在慢慢&quot;死亡&quot;。</p><h2 id="数据不会说谎互联网已经被机器人占领大半"><a class="markdownIt-Anchor" href="#数据不会说谎互联网已经被机器人占领大半"></a> 数据不会说谎：互联网已经被机器人占领大半</h2><p>先看组扎心数据，来自网络安全公司Imperva的2024年报告：<strong>现在51%的互联网流量来自自动化程序</strong>，不是真人。其中更吓人的是，<strong>37%是恶意机器人</strong>——这些不是搜索引擎爬虫那种&quot;正经机器人&quot;，而是搞欺诈、刷流量、爬数据的家伙。</p><p>Cloudflare的数据更夸张：PerplexityBot的流量同比激增了<strong>157,490%</strong>。想象一下，去年100个访问，今年变成15万多个，这增长速度简直离谱。《华盛顿邮报》统计，2025年第一季度实时检索机器人流量环比增长<strong>49%</strong>，差不多每两个月就翻一番。</p><p>OpenAI自己的爬虫也没闲着，TechRadar披露，他们的爬虫每月请求量已经超过<strong>10亿次</strong>。维基百科更惨，35%的访问量来自机器人，但这些机器人消耗了<strong>65%的服务器资源</strong>——相当于一小半访客吃了一大半&quot;饭&quot;。</p><p>小型网站更倒霉，arXiv上的研究显示，有些小服务器的<strong>80-95%流量已经被AI爬虫占据</strong>。也就是说，站长辛辛苦苦维护网站，结果90%的访问者都是机器，真人没几个。</p><h2 id="ai不仅会写内容还会精准操控人类"><a class="markdownIt-Anchor" href="#ai不仅会写内容还会精准操控人类"></a> AI不仅会写内容，还会&quot;精准操控&quot;人类</h2><p>苏黎世大学做过个挺&quot;黑镜&quot;的实验（因为争议太大没正式发表）：他们用AI账号在Reddit的r/changemyview社区发帖，模拟心理咨询师、受害者、少数群体这些身份，根据用户的年龄、性别、政治倾向定制回复。</p><p>结果让我后背发凉：</p><ul><li>普通AI回复的说服力比人类强<strong>6倍</strong></li><li>个性化定制的AI回复，说服力直接干到Reddit社区的<strong>99.4百分位</strong>——意思是比99.4%的真人还会说话</li><li>就算只是模仿社区风格的AI，说服力也比人类强<strong>3倍</strong></li></ul><p>更可怕的是，大部分用户完全没意识到自己在跟AI聊天。这不是科幻电影，是正在发生的现实。</p><h2 id="我能认出ai写的东西别太自信"><a class="markdownIt-Anchor" href="#我能认出ai写的东西别太自信"></a> “我能认出AI写的东西”？别太自信</h2><p>很多人觉得自己能靠&quot;AI味&quot;识别，比如看到&quot;delve into&quot;、&quot;underscore&quot;就觉得是AI写的。确实，研究论文里&quot;delve&quot;出现的频率异常高，还有人发现最近分号、破折号用得特别多。</p><p>但这其实是个误区。你能识别的不是AI，是<strong>ChatGPT的统一人设</strong>。因为OpenAI给模型喂了一堆&quot;好写作&quot;的范例，结果所有ChatGPT写出来的东西都一个调调。</p><p>换成别的模型试试？比如Kimi K2，写法完全不同，你大概率看不出来。以后各种风格的AI内容涌进来，我们根本没法凭直觉判断&quot;对方是人是机&quot;。</p><h2 id="更麻烦的是互联网正在变成机器人对机器人的世界"><a class="markdownIt-Anchor" href="#更麻烦的是互联网正在变成机器人对机器人的世界"></a> 更麻烦的是：互联网正在变成&quot;机器人对机器人&quot;的世界</h2><p>比内容泛滥更严重的问题是：<strong>互联网的&quot;用户&quot;正在从人变成AI代理</strong>。</p><p>广告行业已经感受到寒意了。以前的明星代言、情感营销，对AI代理完全无效。一个AI代理只会执行冷冰冰的指令：“找30美元以内、本地制造的紧身牛仔裤”。它不会被明星种草，不会因为广告文案感人就下单——注意力经济这套玩法，正在失效。</p><p>所以现在有人呼吁：互联网必须加个&quot;人类身份认证层&quot;，让我们知道对面是不是真人。目前有三个方向：</p><ol><li><strong>区块链认证</strong>：OpenAI、微软这些公司在推，用区块链发匿名ID，零知识证明减少计算负担</li><li><strong>生物识别</strong>：奥特曼搞的Worldcoin，用虹膜扫描证明&quot;你是人&quot;</li><li><strong>AI自证身份</strong>：Cloudflare的Web Bot Auth，要求AI主动说&quot;我是机器人&quot;，但这招争议很大，谁会主动承认呢？</li></ol><h2 id="死网理论的终局我们还有净土吗"><a class="markdownIt-Anchor" href="#死网理论的终局我们还有净土吗"></a> 死网理论的终局：我们还有&quot;净土&quot;吗？</h2><p>AI这头妖怪已经从瓶子里出来了，想把它塞回去不可能——现在社交媒体上的AI内容已经多到根本删不完。我们能做的，可能只是给自己留块&quot;人类自留地&quot;。</p><p>但新问题来了：如果&quot;人类认证权&quot;被OpenAI、Meta这些巨头掌握，会不会变成另一种监控？用区块链搞去中心化认证，技术上又太难普及。</p><p>说实话，看到51%流量来自机器人的数据，再想想自己差点信了GPTML的假新闻，我突然理解奥特曼那条推特的无奈。互联网确实在变，变得我们越来越不认识。</p><p>或许未来我们刷到的每一条内容，都得先问一句：&quot;你是人吗？&quot;而对方的回答，可能也是AI生成的。这算不算是科技发展的黑色幽默？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么说RAG是个糟糕的概念？聊聊被忽视的Context Engineering</title>
      <link href="/ren-gong-zhi-neng/wei-shi-me-shuo-rag-shi-ge-zao-gao-de-gai-nian-liao-liao-bei-hu-shi-de-context-engineering-3/"/>
      <url>/ren-gong-zhi-neng/wei-shi-me-shuo-rag-shi-ge-zao-gao-de-gai-nian-liao-liao-bei-hu-shi-de-context-engineering-3/</url>
      
        <content type="html"><![CDATA[<p>最近AI圈又开始炒作新名词了，这次轮到&quot;Context Engineering&quot;（上下文工程）。说起来你可能不信，这个概念的走红，竟然源于一位数据库创始人对RAG的吐槽。</p><p>Chroma（开源向量数据库）的创始人Jeff Huber在最近的访谈里放了个大招：&quot;我们公司从来不用RAG这个词。&quot;这话一出，估计不少刚把&quot;RAG专家&quot;写进简历的同学心里一紧。</p><p>但他说得确实有道理。今天咱们就来聊聊：为什么RAG这个概念问题很大？Context Engineering到底是个什么东西？以及为什么你用GPT-4处理长文本时总感觉它&quot;失忆&quot;？</p><h2 id="rag被过度包装的简单概念"><a class="markdownIt-Anchor" href="#rag被过度包装的简单概念"></a> RAG：被过度包装的简单概念</h2><p>先坦白说，我自己也曾经是RAG的&quot;受害者&quot;。刚开始接触时，总觉得这词儿特高级，又是检索又是生成，听着就复杂。直到后来深入做项目才发现——这不就是把搜索结果喂给大模型吗？</p><p>Jeff Huber的批判一针见血：<strong>“RAG把检索、生成、结合三个不同概念硬拼在一起，结果特别让人困惑。后来市场上还把它包装成’拿Embedding做一次向量搜索’，这理解也太肤浅了。”</strong></p><p>说白了，RAG本质上就是&quot;搜索+生成&quot;的组合，但被包装成了一个神秘概念。这就像把&quot;吃饭+睡觉&quot;硬凑成一个新词&quot;EatSleep&quot;，然后告诉你这是革命性突破——听着唬人，其实没啥新东西。</p><p>更麻烦的是，这种概念混乱让开发者走了不少弯路。很多团队以为搞个向量数据库，做个Embedding搜索，就叫&quot;实现RAG了&quot;。结果呢？用户问复杂问题时，模型要么答非所问，要么直接忽略关键信息。</p><p>问题出在哪儿？答案可能藏在一个你没听过的现象里——<strong>Context Rot（上下文腐烂）</strong>。</p><h2 id="上下文腐烂大模型的失忆症"><a class="markdownIt-Anchor" href="#上下文腐烂大模型的失忆症"></a> 上下文腐烂：大模型的&quot;失忆症&quot;</h2><p>你有没有遇到过这种情况：给GPT-4塞了一篇万字长文，让它回答里面的细节问题，结果它总能完美避开正确答案？不是模型笨，而是它得了&quot;失忆症&quot;。</p><p>Chroma团队做过一个实验：在多轮Agent交互中，当把完整对话窗口（包含大量历史Token）提供给模型时，<strong>明明写在上下文里的指令，竟然被模型完全忽视了</strong>。这就是所谓的&quot;上下文腐烂&quot;——随着Token数量增加，模型的注意力会分散，推理能力也会变弱。</p><p>最直观的证据来自他们发布的《Context Rot》技术报告。这张图对比了四款主流模型在不同输入长度下的性能衰减情况：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/9b8335c31e4597ff1f7afeb75a37edfe.jpg" alt="AI模型性能对比"></p><p>如果用曲线下面积衡量整体表现，<strong>Claude Sonnet 4是表现最好的</strong>，其次是Qwen3-32B，而GPT-4.1和Gemini 2.5 Flash在上下文长度增加时衰减得更快。这也解释了为什么很多开发者偏爱Claude处理长文档——它的&quot;记忆力&quot;确实更好些。</p><p>但即便是表现最好的Sonnet 4，在输入Token超过8k后，性能也明显下降。这和厂商宣传的&quot;百万Token上下文窗口&quot;形成鲜明对比。说白了，现在的大模型就像个&quot;短时记忆障碍患者&quot;，给它太多信息，它反而记不住重点。</p><h2 id="context-engineering解决失忆的关键"><a class="markdownIt-Anchor" href="#context-engineering解决失忆的关键"></a> Context Engineering：解决&quot;失忆&quot;的关键</h2><p>既然大模型有&quot;失忆症&quot;，那怎么让它记住关键信息？这就轮到Context Engineering登场了。</p><p>Jeff Huber对这个概念的定义很简单：<strong>“在每一步生成时，决定上下文窗口里应该放什么的艺术。”</strong> 听起来简单，但做起来学问大了。</p><p>举个例子：假设你要做一个法律助手AI，需要处理一份500页的合同。直接把整份合同喂给模型肯定不行（上下文腐烂），只挑几页又可能遗漏关键条款。这时候就需要Context Engineering：</p><ol><li><strong>先筛选</strong>：用向量搜索+关键词搜索，从500页中挑出最相关的20页</li><li><strong>再重排</strong>：让大模型给这20页打分排序，选出Top 5</li><li><strong>后总结</strong>：对Top 5内容做摘要，控制在模型能有效处理的Token范围内</li></ol><p>这就是上下文工程的核心思路——<strong>不是给模型更多信息，而是给它最需要的信息</strong>。</p><p>有意思的是，现在前沿开发者已经开始用大模型自己来做&quot;重排&quot;。传统做法是用专门的re-rank模型（比如CrossEncoder），但现在很多团队直接写个Prompt：“以下是10段文档，请按与问题’XXX’的相关性排序”，然后让GPT-4或Claude来打分。</p><p>Jeff Huber甚至预测：<strong>“专门的re-rank模型未来会边缘化。随着大模型成本降低，暴力筛选会成为主流。”</strong> 想想也是，当调用GPT-4的成本降到现在的百分之一，谁还会费劲去调参那些小众的re-rank模型呢？</p><h2 id="未来方向别再回自然语言了"><a class="markdownIt-Anchor" href="#未来方向别再回自然语言了"></a> 未来方向：别再回自然语言了</h2><p>聊到这里，你可能会问：有没有更优雅的解决方案？总不能每次都手动筛选信息吧？</p><p>Jeff Huber提到了两个很有意思的方向，可能会改变未来检索系统的形态：</p><p><strong>第一个方向：持续检索（Continuous Retrieval）</strong></p><p>现在的模式是&quot;一次检索，一次生成&quot;——先搜完所有信息，再让模型生成答案。但为什么不能&quot;边生成边检索&quot;？就像我们聊天时，想到什么不确定的就立刻去查手机。</p><p>已经有研究在尝试这种模式了。比如GitHub上那篇叫RAGAR的论文（名字确实不咋地），就教模型在生成过程中&quot;随时暂停，去查资料&quot;。如果这种技术成熟，模型回答问题的方式会更像人类专家——既不是全凭记忆，也不是一次性查完所有资料。</p><p><strong>第二个方向：停留在Embedding空间</strong></p><p>现在的流程是：文本→Embedding→检索→转回文本→喂给模型。这就像把中文翻译成英文，传过去再翻译回中文——多此一举，还损失信息。</p><p>未来的系统可能会<strong>全程在Embedding空间操作</strong>：直接对向量做运算、比较、组合，不需要再转回自然语言。这就像两个程序员直接用二进制交流，虽然人类看不懂，但效率极高。</p><p>当然这些都还在研究阶段，但给我们提了个醒：别被现在的技术框架限制想象力。五年后回头看，我们今天把文本转来转去的做法，可能就像当年用软盘传文件一样原始。</p><h2 id="给开发者的3个建议"><a class="markdownIt-Anchor" href="#给开发者的3个建议"></a> 给开发者的3个建议</h2><p>聊了这么多理论，最后给大家来点实在的。基于Chroma团队的研究和实践，如果你正在做需要处理长文本的AI应用，这三个建议可能帮你少走弯路：</p><p><strong>1. 别迷信&quot;大上下文窗口&quot;</strong></p><p>就算模型号称支持100万Token，也别真把100万Token塞进去。实验显示，超过8k Token后，模型性能就开始下降。<strong>最佳实践是把上下文控制在4k-8k Token</strong>，超过就分段处理。</p><p><strong>2. 构建&quot;黄金数据集&quot;</strong></p><p>Chroma团队发现，很多开发者有数据、有答案，但缺少&quot;查询-片段&quot;对。解决办法是让大模型根据文档片段生成合理查询，构建自己的评测集。<strong>几百条高质量样本，效果可能比十万条垃圾数据还好</strong>。</p><p><strong>3. 试试&quot;披萨派对标注法&quot;</strong></p><p>Jeff Huber分享了个接地气的做法：团队一起点个披萨，花几小时手动标注数据。别小看这种&quot;土办法&quot;，小而精的标注数据往往比大规模自动标注效果好得多。毕竟，AI再智能，也比不上一群懂业务的人一起讨论。</p><h2 id="最后说两句"><a class="markdownIt-Anchor" href="#最后说两句"></a> 最后说两句</h2><p>Context Engineering的走红，其实反映了AI开发的一个趋势：<strong>从追求酷炫概念，回归解决实际问题</strong>。RAG也好，上下文工程也罢，最终目的都是让AI更准确、更可靠地回答问题。</p><p>作为开发者，我们要警惕那些听起来高大上的术语。与其争当&quot;RAG专家&quot;，不如多花时间研究：用户真正需要什么信息？模型在什么情况下会&quot;失忆&quot;？如何用最简单的方法提升系统稳定性？</p><p>毕竟，能解决问题的技术，才是好技术。至于叫什么名字，没那么重要。</p><p>（完）</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>李飞飞一年前就说透了：大语言模型的致命短板，连3岁小孩都不如？</title>
      <link href="/ren-gong-zhi-neng/li-fei-fei-yi-nian-qian-jiu-shuo-tou-liao-da-yu-yan-mo-xing-de-zhi-ming-duan-ban-lian-3-sui-xiao-hai-du-bu-ru-3/"/>
      <url>/ren-gong-zhi-neng/li-fei-fei-yi-nian-qian-jiu-shuo-tou-liao-da-yu-yan-mo-xing-de-zhi-ming-duan-ban-lian-3-sui-xiao-hai-du-bu-ru-3/</url>
      
        <content type="html"><![CDATA[<p>最近AI圈又在热议一个&quot;老话题&quot;——大语言模型到底算不算真智能？起因是李飞飞一年前的一段访谈被扒了出来，她的观点现在看依然扎心：“大自然中可没有语言，你不会从天空中直接看到文字。语言是纯粹的生成信号，而物理世界是客观存在的。”</p><p>这话翻译成人话就是：现在的大模型天天在文字堆里打转，看似啥都懂，其实对真实世界的物理常识可能还不如个三岁小孩。</p><h2 id="语言模型的一维困境用文字理解3d世界就像盲人摸象"><a class="markdownIt-Anchor" href="#语言模型的一维困境用文字理解3d世界就像盲人摸象"></a> 语言模型的&quot;一维困境&quot;：用文字理解3D世界就像盲人摸象</h2><p>李飞飞在访谈里点出了一个核心矛盾：现在的大语言模型，包括那些号称&quot;多模态&quot;的，骨子里还是在玩&quot;一维游戏&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/9754f12eb4d60332c8964f1d0c613a51.gif" alt="语言本质讨论"></p><p>她解释说：“这些模型的底层表示是一维的，它们操作的是离散token的一维序列。处理书面文本没问题，但物理世界是三维的啊！”</p><p>你想想，我们人类感知世界是全方位的：眼睛看颜色形状，耳朵听声音方向，手摸软硬冷热，这些信号同时涌入大脑，形成对3D世界的认知。而大模型呢？即便给它图片，最终也得把像素转换成一维的token序列塞进模型，这不就像把立体世界硬生生压成了一张平面画吗？</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/bca393da2ea671a5be03d10c77f92797.gif" alt="3D数据处理讨论"></p><p>更关键的是，李飞飞强调：“语言信号的输出主要基于人类给的输入信号，它不独立于人之外。但物理世界是客观存在的，不管有没有人类观察，苹果都会往下掉，而不是往上飞。”</p><p>说白了，大模型学到的可能只是&quot;人类怎么描述物理现象&quot;，而不是&quot;物理现象本身如何运作&quot;。这就好比你背熟了菜谱，但从没下过厨，遇到食材变质、火候变化这些实际情况，照样抓瞎。</p><h2 id="残酷测试最牛大模型的物理常识连幼儿园水平都达不到"><a class="markdownIt-Anchor" href="#残酷测试最牛大模型的物理常识连幼儿园水平都达不到"></a> 残酷测试：最牛大模型的物理常识，连幼儿园水平都达不到？</h2><p>光说不练假把式，科学家们早就动手测试大模型的&quot;真实智商&quot;了。结果嘛…有点惨不忍睹。</p><h3 id="测试一3d环境里找小球模型被障碍物绕晕"><a class="markdownIt-Anchor" href="#测试一3d环境里找小球模型被障碍物绕晕"></a> 测试一：3D环境里找小球，模型被障碍物绕晕</h3><p>有个研究团队搞了个叫&quot;Animal AI Environment&quot;的3D虚拟环境，让大模型控制一个小角色完成各种物理任务。简单说就是让AI在游戏里&quot;生活&quot;，看看它会不会像人一样处理日常物理问题。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d5059ac3b6d00b55b55ae0a3348d4457.png" alt="AI环境测试流程"></p><p>测试对象包括GPT-4o、Claude 3.5 Sonnet、Gemini 1.5 Pro这些顶级选手，还给它们找了个对照组——人类儿童。</p><p>最简单的任务：直接找到房间里的小球。模型们表现还行，勉强过关。</p><p>稍微增加难度：房间里放个障碍物，得饶过去才能拿到球。结果呢？模型们瞬间懵圈，要么对着障碍物发呆，要么绕远路跑到姥姥家。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/19e12834b86da564c652344ff297b1d7.png" alt="物理常识能力对比"></p><p>从数据看，在12项物理常识任务中，最厉害的模型平均通过率也就刚过50%，而人类儿童随随便便就能达到85%以上。更扎心的是，研究人员还特意给模型&quot;上课&quot;，演示正确做法，结果模型表现几乎没提升——它好像根本没理解&quot;为什么要这么做&quot;。</p><h3 id="测试二改个数字就露馅物理题正确率暴跌22"><a class="markdownIt-Anchor" href="#测试二改个数字就露馅物理题正确率暴跌22"></a> 测试二：改个数字就露馅，物理题正确率暴跌22%</h3><p>浙江大学和蚂蚁集团的团队更狠，直接上&quot;物理考卷&quot;——设计了个叫ABench-Physics的测试集，专门考大模型物理推理。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2219b946a8bd5392403004f7261f8820.png" alt="物理推理测试研究"></p><p>考卷分两部分：</p><ul><li>Phy A：400道静态物理题，类似中学物理竞赛题</li><li>Phy B：把Phy A的题目数字改一下（比如把&quot;质量5kg&quot;改成&quot;质量8kg&quot;），但物理原理不变</li></ul><p>结果呢？最牛的模型在Phy A上正确率刚到43%，也就勉强及格的水平。到了Phy B，平均正确率直接暴跌22.5%！</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a06724cd4b7f89cb7d03ebaf9af3b0e7.png" alt="物理推理测试结果"></p><p>这说明啥？模型可能是在&quot;背题&quot;，记住了特定数字的答案，而不是理解了F=ma这些物理公式的本质。就像有些学生考试靠死记硬背，题目稍微变个说法就彻底不会了。</p><h3 id="测试三看图辨远近模型正确率还不到人类一半"><a class="markdownIt-Anchor" href="#测试三看图辨远近模型正确率还不到人类一半"></a> 测试三：看图辨远近，模型正确率还不到人类一半</h3><p>语言不行，那视觉呢？毕竟现在都是&quot;多模态大模型&quot;了。</p><p>斯坦福团队做了个视觉感知测试：给模型看照片，让它判断哪个物体更近；或者看一堆碎片，让它拼出完整物体。这些对人类来说都是幼儿园水平的任务。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6e014c9e125fe1a24b6afe353098ec84.png" alt="视觉感知研究论文"></p><p>结果人类正确率95.7%，而几个主流大模型最高才51%，最低的只有32%。想象一下，你给AI看张风景照，问&quot;山近还是房子近&quot;，它抛硬币猜答案的概率都比这高。</p><h2 id="争论升级语言和物理到底谁更能编码现实"><a class="markdownIt-Anchor" href="#争论升级语言和物理到底谁更能编码现实"></a> 争论升级：语言和物理，到底谁更能&quot;编码&quot;现实？</h2><p>李飞飞的观点和这些测试结果在网上炸开了锅，网友们吵翻了天。</p><p>支持派觉得说到了点子上：“LLMs本质上是在操作人类生成的信号系统，而不是直接理解物理世界。就像你可以通过书本学习游泳理论，但不下水永远学不会游泳。”</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0844a5409af0c108edd3270fbcb6a517.png" alt="语言信号系统推文"></p><p>甚至有人预测：“纯语言模型的时代快结束了，视觉语言模型(VLMs)才是未来，比如GPT-4o、Gemini这些已经在往这个方向走。”</p><p>但反对派也不甘示弱：“语言怎么就不重要了？人类文明不就是靠语言传承的吗？牛顿三大定律不也是用语言写出来的？”</p><p>还有个有意思的观点：“语言和物理都是编码现实的方式。有时候语言描述现实的能力甚至比物理学还强——你能用’爱’这个词描述一种复杂情感，但物理学公式能吗？”</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6c6a2a318354486945804f34b3068f1e.png" alt="语言编码现实观点"></p><p>我觉得吧，这场争论的核心不是&quot;语言vs物理&quot;谁更重要，而是&quot;如何让AI同时掌握这两种编码方式&quot;。就像人类既需要语言交流，也需要亲身体验世界，两者缺一不可。</p><h2 id="未来的路从纸上谈兵到动手实践"><a class="markdownIt-Anchor" href="#未来的路从纸上谈兵到动手实践"></a> 未来的路：从&quot;纸上谈兵&quot;到&quot;动手实践&quot;</h2><p>现在的大模型有点像&quot;只会纸上谈兵的赵括&quot;，背了一堆知识，但不会灵活运用。要突破这个瓶颈，可能需要两条腿走路：</p><p>一方面，得让模型真正&quot;接触&quot;物理世界——不是通过文字描述，而是通过传感器、机器人等实体，亲自&quot;摸一摸&quot;、“动一动”。就像教小孩认识苹果，与其给他看100张苹果图片，不如直接给他个苹果让他摸、闻、尝。</p><p>另一方面，研究人员也在探索新的模型架构，能不能让模型的底层表示更接近3D物理世界，而不是局限于一维的文字序列。比如把空间位置、物理属性这些信息直接编码进模型，而不是让它从文字中间接&quot;猜&quot;这些属性。</p><p>不过话说回来，这些都不是短期内能搞定的。大语言模型用了十年才发展到今天的水平，要让AI真正理解物理世界，可能还需要更长的时间。</p><p>最后想问一句：如果AI有一天真的能像人类一样理解物理世界，它会不会反问我们：“你们人类为什么花了几千年才搞懂引力？这不是很简单吗？”</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI为什么总爱&quot;一本正经地胡说八道&quot;？OpenAI终于找到了罪魁祸首</title>
      <link href="/ren-gong-zhi-neng/ai-wei-shi-me-zong-ai-yi-ben-zheng-jing-di-hu-shuo-ba-dao-openai-zhong-yu-zhao-dao-liao-zui-kui-huo-shou-3/"/>
      <url>/ren-gong-zhi-neng/ai-wei-shi-me-zong-ai-yi-ben-zheng-jing-di-hu-shuo-ba-dao-openai-zhong-yu-zhao-dao-liao-zui-kui-huo-shou-3/</url>
      
        <content type="html"><![CDATA[<p>你有没有遇到过这种情况：问AI一个问题，它自信满满地给了你一大段详细回答，结果你一查发现全是瞎编的？这就是AI圈子里臭名昭著的&quot;幻觉&quot;问题——模型编造事实还理直气壮，比你女朋友生气时的逻辑还离谱。</p><p>作为每天和AI打交道的程序员，我对这个问题真是又爱又恨。爱它能快速给出答案，恨它时不时给我挖坑。直到最近，OpenAI在2025年9月4日发表了一篇重磅论文，终于系统性地解释了为什么AI总爱&quot;一本正经地胡说八道&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c42be9a42c28dca332506767a2f0f963.png" alt="语言模型幻觉论文标题页"></p><p>这篇题为《Why Language Models Hallucinate》的论文，是OpenAI罕见的纯技术分析文章（要知道他们平时要么发产品要么发API，很少这么坦诚地分享研究细节）。核心结论其实很简单：<strong>现在的AI训练和评估机制，本质上是在鼓励模型猜答案，而不是承认自己不知道。</strong></p><h2 id="先看看ai的幻觉有多离谱"><a class="markdownIt-Anchor" href="#先看看ai的幻觉有多离谱"></a> 先看看AI的&quot;幻觉&quot;有多离谱</h2><p>OpenAI给&quot;幻觉&quot;下了个定义：&quot;模型自信地生成不真实答案的情况。&quot;说白了就是——一本正经地胡说八道。</p><p>为了证明这个问题有多普遍，研究团队做了个有趣的实验。他们问了几个主流AI模型同一个问题：“Adam Tauman Kalai博士的博士论文标题是什么？”（这位是论文的第一作者，有点自黑精神）。结果你猜怎么着？</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/329795b0ceae70ce65a24ac09cee2907.png" alt="博士论文标题错误回答示例"></p><p>ChatGPT(GPT-4o)、DeepSeek和Llama这三个模型，给出了三个截然不同的答案，而且——<strong>没有一个是对的</strong>。这还不算完，他们又问了Adam的生日，结果更离谱：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d80d4c4593699d61e7b585cab661d02e.png" alt="生日问题错误回答展示"></p><p>某个开源模型在三次尝试中，给出了&quot;03-07&quot;、“15-06&quot;和&quot;01-01&quot;三个日期——没错，连1月1日这种元旦节都出来了，而正确答案其实是在秋季（具体日期未公开）。最气人的是，每个答案后面都跟着&quot;确定”、&quot;无疑&quot;这样的词，自信得让你无法怀疑。</p><h2 id="问题出在考试机制上"><a class="markdownIt-Anchor" href="#问题出在考试机制上"></a> 问题出在&quot;考试机制&quot;上</h2><p>为什么会这样？OpenAI的研究指出了一个很反常识的结论：<strong>不是AI太笨，而是我们的&quot;考试&quot;方式有问题。</strong></p><p>现在评估AI模型，基本上只看&quot;准确率&quot;——答对了给分，答错了不给分，不答也不给分。这就好比考试时，选择题你不会做也必须蒙一个，因为空着肯定没分，蒙还有25%的机会对。长期下来，模型自然就学会了&quot;瞎猜&quot;。</p><p>OpenAI做了个对比实验，他们训练了两个模型：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b832446bbb70928e5d5ea855e8bfd435.png" alt="模型性能对比表"></p><p>左边的gpt-5-thinking-mini模型被训练得更&quot;谦逊&quot;，不确定就弃权；右边的o4-mini则是传统训练方式。结果很有意思：</p><ul><li>准确率：22% vs 24%（传统模型略高）</li><li>错误率（幻觉率）：26% vs 75%（传统模型高太多）</li><li>弃权率：52% vs 1%（传统模型几乎从不弃权）</li></ul><p>也就是说，传统模型为了那2%的准确率提升，付出了错误率增加近3倍的代价！这就像一个学生考试时，为了多拿2分，把所有不会的题都瞎蒙了一遍，结果错得一塌糊涂。</p><p>更麻烦的是，现在行业里的评估基准几乎都有这个问题：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e62ca14c3287de8a4bba8dbd6a6893ff.png" alt="评估基准对比表"></p><p>OpenAI分析了10种主流评估基准（GPQA、MMLU-Pro等），发现<strong>绝大多数都只看准确率，不鼓励模型表达不确定性</strong>。这种&quot;唯分数论&quot;的评估体系，逼着所有AI模型都去学&quot;应试技巧&quot;——哪怕瞎猜也要给个答案，反正错了不扣分。</p><h2 id="从根源解决让ai学会说我不知道"><a class="markdownIt-Anchor" href="#从根源解决让ai学会说我不知道"></a> 从根源解决：让AI学会说&quot;我不知道&quot;</h2><p>那么怎么解决这个问题？OpenAI提出了个简单但有效的方案：<strong>改革评估机制，鼓励AI说&quot;我不知道&quot;。</strong></p><p>具体来说就是：</p><ol><li>答对了给满分</li><li>明确说&quot;不知道&quot;给部分分（比如1/3分）</li><li>答错了扣分（惩罚）</li></ol><p>这就像某些考试的&quot;倒扣分&quot;规则，瞎猜的风险远大于收益，模型自然就会变得更谨慎。其实人类社会早就懂这个道理——为什么医生看病总是很谨慎？因为误诊的代价远大于说&quot;这个症状我需要进一步检查&quot;。</p><p>OpenAI自己已经开始这么做了。他们最新的模型幻觉率明显降低，而且据TechCrunch报道，OpenAI最近重组了团队，原模型行为团队负责人Joanne Jang启动了一个叫oai Labs的新项目：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/002a5e62812fa2fb039e74f2f82b796e.png" alt="Joanne Jang推文截图"></p><p>这个团队专注于&quot;发明和设计人们与AI协作的新界面原型&quot;，很可能就包括让AI更坦诚表达不确定性的交互方式。</p><h2 id="对我们普通人有什么影响"><a class="markdownIt-Anchor" href="#对我们普通人有什么影响"></a> 对我们普通人有什么影响？</h2><p>作为普通用户，这件事其实和我们关系很大：</p><ol><li><strong>别轻信AI的&quot;肯定&quot;</strong>：看到&quot;无疑&quot;、“确定”、&quot;显然&quot;这类词时，反而要多留个心眼，最好自己验证一下</li><li><strong>学会追问来源</strong>：问AI问题时，可以加一句&quot;你的信息来源是什么？&quot;，现在有些模型已经能提供引用了</li><li><strong>期待更诚实的AI</strong>：未来的AI可能会更像一个谨慎的顾问，而不是全知全能的神——这其实是好事，毕竟真实世界中，承认局限比假装全知更可靠</li></ol><h2 id="最后说句大实话"><a class="markdownIt-Anchor" href="#最后说句大实话"></a> 最后说句大实话</h2><p>AI幻觉这个问题，本质上反映了整个行业的一个误区：我们太追求&quot;看起来很厉害&quot;，而忽略了&quot;实际上很可靠&quot;。OpenAI这篇论文最有价值的地方，可能不是提出了什么新技术，而是提醒整个行业：<strong>有时候慢即是快，少即是多。</strong></p><p>反正我现在用AI写代码时，都会多一个心眼——特别是涉及到API调用和技术细节时，一定会去官方文档核实一下。毕竟，AI说&quot;这绝对是对的&quot;，和我说&quot;我觉得这是对的&quot;，可信度可能差不太多。</p><p>希望未来的AI能更像个谦逊的专家，而不是自信的骗子。毕竟，在这个信息爆炸的时代，知道自己不知道，可能比知道答案更重要。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI幻觉：我们拼命修复的&quot;bug&quot;，可能是最像人的特征</title>
      <link href="/ren-gong-zhi-neng/ai-huan-jue-wo-men-pin-ming-xiu-fu-de-bug-ke-neng-shi-zui-xiang-ren-de-te-zheng-3/"/>
      <url>/ren-gong-zhi-neng/ai-huan-jue-wo-men-pin-ming-xiu-fu-de-bug-ke-neng-shi-zui-xiang-ren-de-te-zheng-3/</url>
      
        <content type="html"><![CDATA[<p>AI一本正经胡说八道的本事，估计大家都领教过。问它一个专业问题，它能给你编出一套逻辑严密、细节丰富但完全错误的答案。这种&quot;幻觉&quot;现象到底是怎么回事？OpenAI最新研究论文《Why language models hallucinate》（2025年9月发表）给出了颠覆性解释，看完让我对AI有了全新认识。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d1237aee9cfebcda45c30b5eccd37f0d.png" alt="语言模型幻觉研究"></p><h2 id="一个简单实验揭露的残酷真相"><a class="markdownIt-Anchor" href="#一个简单实验揭露的残酷真相"></a> 一个简单实验揭露的残酷真相</h2><p>先看个真实案例：问AI&quot;亚当·卡莱（论文作者之一）的生日是几月几号？“某顶尖开源大模型连续三次给出了三个完全不同的错误答案：03-07，15-06，01-01。而正确答案其实是&quot;秋天”——人家论文里只提到了季节。</p><p>为什么AI宁愿编造答案也不承认自己不知道？OpenAI的研究指出了一个残酷事实：<strong>我们的训练体系在系统性奖励瞎蒙，惩罚诚实</strong>。</p><p>想象AI是个学生，参加一场永不结束的考试。评分规则简单粗暴：答对得1分，答错或不答得0分。面对不会的题，理性选择就是猜——反正答错不扣分，万一蒙对了呢？从概率角度，只要猜对概率大于0，猜测就是最优策略。</p><h2 id="两组数据暴露幻觉本质"><a class="markdownIt-Anchor" href="#两组数据暴露幻觉本质"></a> 两组数据暴露幻觉本质</h2><p>OpenAI拿自家两个模型做了对比实验，结果特别有意思。在SimpleQA测试中：</p><ul><li><strong>o4-mini模型</strong>：准确率24%，错误率75%，弃权率仅1%</li><li><strong>gpt-5-thinking-mini模型</strong>：准确率22%，错误率26%，弃权率高达52%</li></ul><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6b24af2066f4d0e27ffdf214bfc58ed0.jpg" alt="模型性能对比表"></p><p>表面看o4-mini准确率更高，但代价是75%的错误率——它几乎回答了所有问题，哪怕是瞎猜。而gpt-5-thinking-mini虽然准确率略低，却诚实得多，一半题目直接承认不会，错误率仅26%。</p><p>说白了，<strong>AI幻觉本质是应试教育的产物</strong>。在当前评估体系下，爱猜的模型得分更高，显得更&quot;聪明&quot;，而诚实的模型反而吃亏。这不是技术bug，而是AI为了拿高分进化出的生存本能。</p><h2 id="openai的三个反常识发现"><a class="markdownIt-Anchor" href="#openai的三个反常识发现"></a> OpenAI的三个反常识发现</h2><p>研究里有几个观点彻底颠覆认知：</p><p><strong>1. 准确率100%是不可能的</strong><br>世界上本就有太多无解问题，信息缺失、逻辑矛盾是常态。AI再强也不能凭空变答案，真正该追求的是&quot;知道自己不知道&quot;的能力。</p><p><strong>2. 小模型可能比大模型更诚实</strong><br>一个只会英语的小模型被问毛利语问题，会直接说不会。但学了点毛利语却半生不熟的大模型，反而可能纠结着开始瞎猜。有时候，知道自己无知比有知识更重要。</p><p><strong>3. 现有评估指标全在鼓励幻觉</strong><br>几百个主流评估指标都在奖励瞎蒙、惩罚诚实。不改变这个大环境，幻觉永远是AI的最优解。单独搞个&quot;反幻觉测试&quot;根本没用，治标不治本。</p><h2 id="幻觉人类文明最伟大的起点"><a class="markdownIt-Anchor" href="#幻觉人类文明最伟大的起点"></a> 幻觉：人类文明最伟大的起点？</h2><p>这就让我想到一个更深层的问题：如果AI幻觉是信息不足时的创造性猜测，那人类的想象力、神话、艺术又是怎么来的？</p><p>几十万年前，我们的祖先面对闪电、洪水等未知现象，不也像AI一样开始&quot;瞎猜&quot;？他们想象出风神、雷神，编造出创世神话。这些今天看来荒诞的解释，却是人类文明的起点。</p><p>神话不是谎言，而是早期人类对世界的创造性解释。正是这种&quot;超越事实&quot;的能力，让我们能组织几千人建金字塔，能建立国家、法律、公司这些&quot;想象的共同体&quot;。</p><p>哥白尼的日心说、爱因斯坦的相对论，在当时不都是离经叛道的&quot;幻觉&quot;吗？人类之所以强大，恰恰因为我们擅长创造超越事实的故事。</p><h2 id="我们到底想要ai成为什么"><a class="markdownIt-Anchor" href="#我们到底想要ai成为什么"></a> 我们到底想要AI成为什么？</h2><p>这就让人矛盾了：我们一边想让AI成为绝对可靠的工具，在医疗、财务等领域零错误；另一边又希望它有创造力，能写诗、画画、编故事。</p><p>其实问题核心不是消除幻觉，而是<strong>场景适配</strong>。在需要精确的领域，我们要训练AI&quot;认怂&quot;，不确定就说不知道；在需要创造的领域，或许应该鼓励它&quot;胡思乱想&quot;。</p><p>我觉得未来理想的AI应该像个&quot;双模式开关&quot;：需要严谨时，它是绝对理性的计算器；需要创造时，它能挣脱事实枷锁，在信息缝隙里自由联想。</p><p>最后想问：如果有一天AI真能完全消除幻觉，变成一个永远正确但毫无想象力的机器，那还是我们想要的AI吗？或许，那个偶尔会一本正经胡说八道的AI，才是最像人的AI。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Claude全面封禁中资背后：一个AI公司CEO的偏见如何改写行业规则</title>
      <link href="/ren-gong-zhi-neng/claude-quan-mian-feng-jin-zhong-zi-bei-hou-yi-ge-ai-gong-si-ceo-de-pian-jian-ru-he-gai-xie-xing-ye-gui-ze-3/"/>
      <url>/ren-gong-zhi-neng/claude-quan-mian-feng-jin-zhong-zi-bei-hou-yi-ge-ai-gong-si-ceo-de-pian-jian-ru-he-gai-xie-xing-ye-gui-ze-3/</url>
      
        <content type="html"><![CDATA[<p>今天早上打开电脑，就看到了个挺让人不爽的消息——Anthropic，就是那个做Claude的公司，突然宣布全面封禁所有中资背景实体使用他们的AI服务。说实话，作为经常用Claude Code写代码的程序员，第一反应是&quot;不至于吧&quot;，但仔细看了政策细节，发现这次他们是来真的。</p><h2 id="说封就封一点缓冲都没有"><a class="markdownIt-Anchor" href="#说封就封一点缓冲都没有"></a> 说封就封，一点缓冲都没有</h2><p>Anthropic在2025年9月5日突然丢出的这个政策，用词之严厉，范围之广泛，确实有点出乎预料。最关键的是——<strong>立即生效</strong>，连个过渡期都不给。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/aac5327ed8960dac2341262cfc97c3e3.png" alt="Anthropic政策声明"></p><p>我仔细看了他们官网的公告原文，这个封禁范围简直是&quot;宁可错杀一千，不可放过一个&quot;的架势：</p><ul><li>不仅中国大陆公司直接用不了</li><li>海外子公司只要中资控股超过50%，也一刀切</li><li>最绝的是连&quot;曲线救国&quot;的路子都堵死了——通过云服务中转、第三方平台间接使用，甚至复杂投资结构藏着的中资背景，全都在封禁名单上</li></ul><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0579909f9f8ab1ab96c1d431a02798a6.png" alt="销售限制更新公告"></p><p>这种&quot;赶尽杀绝&quot;的态度，在AI行业里还真不多见。毕竟以前就算有管制，多少会留些余地，这次Anthropic是直接把门关死，还上了锁。</p><h2 id="官方理由听着冠冕堂皇但真相可能没那么简单"><a class="markdownIt-Anchor" href="#官方理由听着冠冕堂皇但真相可能没那么简单"></a> 官方理由听着冠冕堂皇，但真相可能没那么简单</h2><p>官方给出的理由是&quot;法律、监管和安全风险&quot;，听着挺合理，对吧？但仔细琢磨一下，这里面的味道就复杂了。他们担心中资公司用Claude搞军事应用，或者通过&quot;模型蒸馏&quot;学走技术，跟美国公司竞争。</p><p>说实话，这些担心不能说完全没道理，但问题在于——为什么偏偏是中资？其他国家的公司就没有类似风险吗？这就得说说Anthropic的CEO Dario Amodei这个人了。</p><p>这位意大利裔美国人，神经物理学博士出身，确实是AI圈的大牛，OpenAI早期核心成员，还在百度硅谷实验室待过一年（2014-2015年）。按说在百度待过，应该对中国科技企业有更客观的认识，但他最近的一系列操作却让人看不懂。</p><p>2025年1月，他公开质疑中国AI公司DeepSeek的技术突破，说人家&quot;可能通过非官方渠道获取芯片&quot;，用些捕风捉影的传言来否定人家的算力效率创新。4月份，他又跳出来支持美国政府加强AI芯片出口管制，说要&quot;确保技术优势&quot;。</p><p>现在看来，这次封禁中资，不过是他一贯立场的延续。与其说是公司商业决策，不如说是带着个人偏见的政治表态——宁愿少赚钱，也要把中国公司挡在门外。</p><h2 id="这扇门关上影响比想象的要大"><a class="markdownIt-Anchor" href="#这扇门关上影响比想象的要大"></a> 这扇门关上，影响比想象的要大</h2><p>别以为这只是不让用个AI助手那么简单。Anthropic这次玩得特别绝，不仅直接客户用不了，连通过AWS、Azure这些云平台间接调用Claude API的路子都给堵死了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0bc47d75ae2d26818dc32dd0a5eac292.png" alt="政策变动新闻报道"></p><p>看看受影响的名单，基本涵盖了中国科技行业的半壁江山：字节跳动、腾讯、阿里巴巴这些大厂自不必说，连很多出海的中资创业公司也在其中。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/f806be95de4d0665426e7c95f63ecc79.png" alt="政策适用范围说明"></p><p>我有个在跨境电商公司做技术的朋友，他们团队上个月刚基于Claude API开发了智能客服系统，本来下周就要上线了，现在只能紧急叫停。这种项目停摆的损失，可不光是钱的问题，还有团队几个月的心血。</p><p>更麻烦的是，Anthropic还呼吁美国政府进一步加大出口管制，加快本土算力建设。这意思很明显：不仅我不跟你玩，还要拉着整个美国科技圈一起把你排除在外。</p><h2 id="与其抱怨不如自己把钥匙磨亮"><a class="markdownIt-Anchor" href="#与其抱怨不如自己把钥匙磨亮"></a> 与其抱怨，不如自己把钥匙磨亮</h2><p>说实话，看到这种新闻，第一反应肯定是不爽。但不爽完了，该想的还是得想——以后怎么办？</p><p>我觉得与其花心思研究怎么&quot;绕过限制&quot;，不如踏踏实实把国产大模型搞好。这两年国内大模型进步其实挺快的，文心一言、通义千问、讯飞星火这些，虽然在某些高端任务上可能还差点意思，但日常开发、企业应用完全够用了。</p><p>Anthropic这次把门关死，反而可能是个好事。以前总有人觉得&quot;先用着国外的，等我们自己的成熟了再说&quot;，现在没这个退路了，反而能逼着大家真正投入到自主研发上来。</p><p>毕竟技术这东西，别人给的随时可以收回去，只有长在自己身上的本事，才是谁也抢不走的。外部的门一扇扇关上没关系，只要我们自己手里的钥匙足够硬，总能打开新的门。</p><p>最后说一句，我倒是觉得Dario Amodei有点反应过度了。AI技术发展这么快，靠堵是堵不住的。与其把精力放在&quot;防火防盗防中国&quot;上，不如想想怎么让AI技术真正造福更多人。你说呢？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Anthropic全面封禁中资使用Claude：发生了什么，影响有多大？</title>
      <link href="/ren-gong-zhi-neng/anthropic-quan-mian-feng-jin-zhong-zi-shi-yong-claude-fa-sheng-liao-shi-me-ying-xiang-you-duo-da-3/"/>
      <url>/ren-gong-zhi-neng/anthropic-quan-mian-feng-jin-zhong-zi-shi-yong-claude-fa-sheng-liao-shi-me-ying-xiang-you-duo-da-3/</url>
      
        <content type="html"><![CDATA[<p>今天AI圈炸了个不大不小的雷——Claude的开发商Anthropic突然宣布全面停止向中资背景企业提供服务。说实话，这个消息来得有点突然，毕竟Claude这两年在国内开发者圈子里还挺受欢迎的，尤其它的长文本处理和代码能力确实有独到之处。</p><h2 id="一纸禁令说停就停"><a class="markdownIt-Anchor" href="#一纸禁令说停就停"></a> 一纸禁令，说停就停</h2><p>根据Anthropic官方发布的政策声明，这项禁令在2025年9月5日公布当天就立即生效，没有给企业留任何缓冲期。这种&quot;断崖式&quot;操作，估计不少正在用Claude的团队已经开始手忙脚乱了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/aac5327ed8960dac2341262cfc97c3e3.png" alt="Anthropic政策声明"></p><p>最狠的是这次禁令的适用范围，Anthropic几乎把所有可能的漏洞都堵死了：</p><ul><li>直接封禁中国大陆注册的公司自不必说</li><li>连中资控股超过50%的海外子公司也在列</li><li>想通过云服务中转？不行！</li><li>借道第三方平台？没门！</li><li>搞复杂投资结构间接使用？照样拦截！</li></ul><h2 id="官方理由安全风险还是技术封锁"><a class="markdownIt-Anchor" href="#官方理由安全风险还是技术封锁"></a> 官方理由：安全风险还是技术封锁？</h2><p>Anthropic在公告里把理由说得冠冕堂皇——“法律、监管和安全风险”。但如果你仔细品品，会发现真正的担忧可能没那么简单。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0579909f9f8ab1ab96c1d431a02798a6.png" alt="销售限制更新公告"></p><p>官方文件里隐晦提到了两个点，我觉得这才是真正的原因：一是担心技术被用于&quot;军事或情报相关应用&quot;，二是怕中国企业通过&quot;模型蒸馏&quot;等技术把Claude的能力&quot;学&quot;走，反过来加速自家大模型研发，最后变成竞争对手。</p><p>说白了，就是美国科技公司开始担心&quot;教会徒弟饿死师傅&quot;的局面了。Anthropic这次显然是选择了&quot;宁可不赚钱，也不能培养对手&quot;的策略。</p><h2 id="影响有多大看看这些公司就知道了"><a class="markdownIt-Anchor" href="#影响有多大看看这些公司就知道了"></a> 影响有多大？看看这些公司就知道了</h2><p>这事儿可不是小打小闹，看看受影响的企业名单就知道了——字节跳动、腾讯、阿里巴巴这些科技巨头全都在列。也就是说，国内几乎所有有实力的AI研发团队，以后都别想用Claude了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/f806be95de4d0665426e7c95f63ecc79.png" alt="政策适用范围说明"></p><p>更麻烦的是那些跨国业务的公司。有些团队可能在美国、新加坡等地注册了子公司，本想通过这种方式继续使用Claude，现在看来也行不通了。只要控股结构里中资占多数，Anthropic就不给用。</p><p>我有个朋友在一家跨境电商公司负责AI客服系统，他们之前刚基于Claude API开发了智能回复功能，现在突然被掐断服务，整个项目直接停摆。这种损失可不是金钱能衡量的，时间成本和机会成本才更要命。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0bc47d75ae2d26818dc32dd0a5eac292.png" alt="政策变动新闻报道"></p><h2 id="对国内大模型的启示打铁还需自身硬"><a class="markdownIt-Anchor" href="#对国内大模型的启示打铁还需自身硬"></a> 对国内大模型的启示：打铁还需自身硬</h2><p>说实话，Anthropic这步棋虽然有点&quot;绝情&quot;，但也未必全是坏事。至少它给我们提了个醒：核心技术依赖别人，终究是不保险的。</p><p>这两年国内大模型发展其实挺快的，文心一言、讯飞星火、通义千问这些都有不小进步。只是很多企业图方便，或者觉得国外模型&quot;更好用&quot;，一直依赖着OpenAI、Anthropic这些公司的API。</p><p>现在好了，外部的门一扇扇关上，反而可能逼着大家把更多精力放在自家技术上。与其挖空心思找漏洞、想办法绕过限制，不如踏踏实实把国产大模型的能力提上来。</p><p>最后说一句，技术竞争本来就很残酷。Anthropic的这个决定，本质上是科技领域&quot;军备竞赛&quot;的又一个缩影。对我们开发者来说，能做的就是不断提升自己，同时对技术自主可控有更清醒的认识。毕竟，别人的东西再好，也不如自己手里的钥匙管用。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>中国机器人第一股要来了：宇树科技IPO时间表敲定，估值百亿背后的技术突围战</title>
      <link href="/ren-gong-zhi-neng/zhong-guo-ji-qi-ren-di-yi-gu-yao-lai-liao-yu-shu-ke-ji-ipo-shi-jian-biao-qiao-ding-gu-zhi-bai-yi-bei-hou-de-ji-zhu-tu-wei-zhan-3/"/>
      <url>/ren-gong-zhi-neng/zhong-guo-ji-qi-ren-di-yi-gu-yao-lai-liao-yu-shu-ke-ji-ipo-shi-jian-biao-qiao-ding-gu-zhi-bai-yi-bei-hou-de-ji-zhu-tu-wei-zhan-3/</url>
      
        <content type="html"><![CDATA[<p>就在最近，Unitree Robotics（宇树科技）官方发布了一条重磅消息：这家被业内称为&quot;中国版波士顿动力&quot;的机器人公司，正式启动IPO计划，预计2025年10-12月提交申报文件。这意味着，如果一切顺利，我们可能在明年看到中国&quot;具身智能第一股&quot;的诞生。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0c98895d9cf3e48f22ad423802f69116.png" alt="Unitree IPO声明"></p><p>说实话，这个消息在机器人圈子里炸锅了。有海外科技媒体直接评价这是&quot;机器人领域最受期待的IPO之一&quot;，毕竟这可能是全球范围内少有的盈利状态下上市的人形机器人公司。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/bf21ab1166a23387159fd4d436d4b639.png" alt="IPO期待度评价"></p><h2 id="百亿估值是怎么来的拆解宇树的资本化之路"><a class="markdownIt-Anchor" href="#百亿估值是怎么来的拆解宇树的资本化之路"></a> 百亿估值是怎么来的？拆解宇树的资本化之路</h2><p>先看一组硬核数据：根据工商信息显示，杭州宇树科技股份有限公司成立于2016年8月26日，法定代表人正是创始人王兴兴，注册资本已经达到3.64亿元，最新估值超过100亿元。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2a0beb6f904b39463202bb7607b87ded.jpg" alt="工商注册信息"></p><p>IPO进程也在加速推进。7月18日，中国证监会官网显示宇树已经完成上市辅导备案，辅导机构是中信证券，还有北京德恒律师事务所和容诚会计师事务所保驾护航。这意味着从法律到财务，宇树已经做好了公开市场的准备。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/16b134b0d49f4bd1b9205ebb7ef7114f.jpg" alt="辅导备案进程"></p><p>资本市场对宇树的青睐不是一天两天了。从2017年的种子轮开始，到2025年的C轮，宇树的融资历程堪称一部中国机器人公司的成长缩影。尤其C轮融资，直接由中国移动、腾讯、阿里、蚂蚁集团等巨头联合领投，一下子融了近7亿，这在机器人行业可是相当罕见的阵容。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ee283e8b069baf76b36724166011a10c.jpg" alt="融资历程时间线"></p><p>最关键的是，宇树不是靠烧钱讲故事的公司。从2020年开始，它已经连续五年实现盈利，创始人王兴兴在今年夏季达沃斯论坛上透露，公司年度营收已经突破10亿元人民币。在全球人形机器人公司普遍亏损的背景下，这个成绩单确实有底气冲击IPO。</p><h2 id="从实验室原型到春晚舞台宇树的产品进化史"><a class="markdownIt-Anchor" href="#从实验室原型到春晚舞台宇树的产品进化史"></a> 从实验室原型到春晚舞台：宇树的产品进化史</h2><p>宇树的故事得从2016年说起。当时波士顿动力的四足机器人还是行业神话，而上海大学机械工程硕士王兴兴在实验室里捣鼓出了一个关键突破——他独立开发出电机驱动的全自由度四足机器人XDog，这就是后来Laikago的技术雏形。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1d7a39f35e93a4fe2bd6bd1c659a0b7a.jpg" alt="XDog原型研发"></p><p>2017年，宇树首款商业化四足机器人Laikago正式推出，这玩意儿开创了低成本高性能四足机器人的先河。当时业内都用液压驱动，成本高得吓人，而宇树选择了电机直驱路线，一下子把门槛拉低了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c270abdeba15d1b069b305206b547d6e.jpg" alt="Laikago产品图"></p><p>2019年的AlienGo更绝，这家伙能完成后空翻动作，在当时四足机器人里算是个技术突破。我还记得当时看视频，这机器人在空中转体那一下，确实有点未来科技的感觉。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/440594c17b1beeead1b5e4b2b626f082.gif" alt="AlienGo运动展示"></p><p>真正让宇树赚钱的是2021年发布的消费级四足机器人GO1。这玩意儿定价不到2万美元，累计出货量突破5万台，直接占据了全球消费级足式机器人市场60%的份额。说实话，能把机器人卖到普通消费者手里还能赚钱，这在行业里真没几家能做到。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ff0e8d0556919b3c4835757871048416.gif" alt="GO1机器人特写"></p><p>当然，让宇树真正破圈的还是人形机器人H1。2023年发布时，这家伙一个原地后空翻直接上了热搜，技术水平对标国际顶尖。H1的关节设计也很有讲究，采用整机中空关节走线，既美观又实用。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/cca3fcbd9a165e3467af4e409680e670.gif" alt="H1后空翻瞬间"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1a039e214217b93af7e247043f9cb1a9.gif" alt="H1关节设计"></p><p>H1还登上了央视春晚，穿着红色花纹马甲，拿着扇子跟舞蹈演员一起表演，这波曝光直接让宇树从科技圈走进了大众视野。其实宇树早就在春晚露过脸，2021牛年春晚的&quot;牛犇犇&quot;表演用的就是他们的四足机器人。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/bcea2a55c31cf7105d190845d77839fb.gif" alt="H1春晚表演"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/15909ee189a3398ea1b854e45e1478f1.gif" alt="牛犇犇表演"></p><p>最近H1又火了一把，在首届人形机器人运动会上先是来了个&quot;肇事逃逸&quot;——不小心撞到了旁边的机器人然后跑了，结果后来又在1500米比赛中以6分34秒40的成绩拿了冠军，这戏剧性的情节让它成了网红。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4f457be864c9e0a144c5de7f154469e2.gif" alt="机器人运动会"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c8e283777752418747fe0b38be977f63.jpg" alt="H1夺冠海报"></p><h2 id="技术路线赌对了从非主流到行业标杆"><a class="markdownIt-Anchor" href="#技术路线赌对了从非主流到行业标杆"></a> 技术路线赌对了：从&quot;非主流&quot;到行业标杆</h2><p>宇树能走到今天，关键一步是赌对了技术路线。2016年那会儿，机器人动力主流是液压驱动，国内外企业都有大量技术积累。但王兴兴偏偏选择了电机直驱，这个&quot;非主流&quot;选择现在看来太明智了——成本低、维护简单，特别适合商业化。</p><p>从产品结构看，宇树的收入构成也很健康：2024年数据显示，四足机器人占65%，人形机器人占30%，零部件产品占5%。其中四足机器人80%用于科研、教育和消费领域，20%用于工业检测、消防等场景；人形机器人目前则完全集中在科研、教育和消费领域。</p><p>这种&quot;四足+人形&quot;双轮驱动的策略，既保证了当前的盈利能力（四足机器人贡献主要收入），又布局了未来的增长空间（人形机器人是下一代平台级产品）。</p><h2 id="双非本科创业者的逆袭王兴兴的反套路成功"><a class="markdownIt-Anchor" href="#双非本科创业者的逆袭王兴兴的反套路成功"></a> 双非本科创业者的逆袭：王兴兴的&quot;反套路&quot;成功</h2><p>最后聊聊创始人王兴兴，这哥们儿的经历挺有意思。跟现在AI圈遍地清北学霸、天才少年比，王兴兴的履历实在&quot;普通&quot;：浙江理工大学本科，上海大学硕士，在大疆干了两个月就辞职创业，最初公司就他一个人。</p><p>英语还不太好，据说早期参加国际展会全靠比划。但就是这么个&quot;双非本科&quot;创业者，硬生生把宇树做到了百亿估值，成为中国具身智能领域的代表人物。</p><p>他的成功其实给行业提了个醒：在硬科技领域，学历和背景固然重要，但更关键的是对技术趋势的判断和产品落地的执行力。宇树没有走&quot;为了技术而技术&quot;的路线，而是始终坚持场景化产品思维，这可能就是它能盈利并成功推向IPO的核心原因。</p><h2 id="最后说一句"><a class="markdownIt-Anchor" href="#最后说一句"></a> 最后说一句</h2><p>宇树科技的IPO，对整个中国机器人行业来说都是个里程碑事件。它不仅验证了机器人公司商业化的可能性，也为更多&quot;非典型&quot;创业者提供了参考。当然，上市只是开始，人形机器人的大规模商业化还有很长的路要走。</p><p>你觉得宇树能成为&quot;中国版波士顿动力&quot;吗？或者说，它会走出一条完全不同的路？欢迎在评论区聊聊你的看法。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从九三阅兵看军事智能化：无人装备如何重构未来战争规则？</title>
      <link href="/ren-gong-zhi-neng/cong-jiu-san-yue-bing-kan-jun-shi-zhi-neng-hua-wu-ren-zhuang-bei-ru-he-chong-gou-wei-lai-zhan-zheng-gui-ze-3/"/>
      <url>/ren-gong-zhi-neng/cong-jiu-san-yue-bing-kan-jun-shi-zhi-neng-hua-wu-ren-zhuang-bei-ru-he-chong-gou-wei-lai-zhan-zheng-gui-ze-3/</url>
      
        <content type="html"><![CDATA[<p>2025年9月3日的天安门广场，数百架无人机组成的&quot;蜂群&quot;在空中自主变换队形，地面&quot;机器狼&quot;四足机器人与无人战车协同推进，076型&quot;无人机航母&quot;的电磁弹射系统将隐身无人机送入蓝天——这不是科幻电影场景，而是中国抗战胜利80周年阅兵式上的真实画面。短短10年，从单一无人机展示到完整智能作战体系亮相，中国军事智能化的进展到底有多快？这些装备背后藏着哪些技术突破？今天咱们就拆开揉碎了聊聊。</p><h2 id="无人装备从能飞到会思考的十年跨越"><a class="markdownIt-Anchor" href="#无人装备从能飞到会思考的十年跨越"></a> 无人装备：从&quot;能飞&quot;到&quot;会思考&quot;的十年跨越</h2><p>2015年阅兵时，无人机还是&quot;稀罕物&quot;，如今已形成完整作战体系。这次最让人眼前一亮的，是无人作战群展示的&quot;智能大脑&quot;——不再是简单的遥控玩具，而是能自主决策的作战单元。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/7102603feb941d48df1dfa59a90686d1.jpg" alt="无人作战方队受阅"></p><p>拿空中无人装备来说，无侦-7和无侦-10的&quot;黄金搭档&quot;就很有代表性。无侦-7顶着个大雷达负责广域搜索，像个&quot;空中千里眼&quot;；无侦-10则专精精准识别，堪称&quot;顺风耳&quot;。关键是这俩配合不是靠人工遥控，而是靠AI算法自动分工——无侦-7发现可疑目标，数据实时传给无侦-10，后者自主抵近识别，整个过程从发现到确认目标，比传统有人操作快了至少3倍。</p><p>更厉害的是无人机&quot;蜂群&quot;作战。这次展示的数百架小型无人机，通过自主协同算法实现了&quot;分布式智能&quot;。说白了就是没老大指挥，每架无人机都是&quot;决策者&quot;，能根据战场情况自动分配任务：有的负责侦察，有的干扰敌方信号，有的直接攻击。这种技术难点不在硬件，而在软件——要让上百个&quot;智能体&quot;不打架、不重复劳动，还能应对突发情况，背后的集群控制算法才是真功夫。</p><h2 id="攻防一体反无人机技术如何破解蜂群威胁"><a class="markdownIt-Anchor" href="#攻防一体反无人机技术如何破解蜂群威胁"></a> 攻防一体：反无人机技术如何破解&quot;蜂群威胁&quot;？</h2><p>有矛就得有盾。既然无人机这么厉害，怎么防？这次阅兵专门展示了反无人机方队，算是把&quot;攻防一体&quot;的思路摆到了明面上。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d3b24d04d8287cd64e0f31f2c157b722.jpg" alt="反无人机装备展示"></p><p>反无人机装备看着像个&quot;大号微波炉&quot;，其实是套复杂的电子战系统。它能同时干三件事：先用雷达和光电设备&quot;看见&quot;无人机，再用干扰信号&quot;迷瞎&quot;它的导航和通信，最后如果对方不听劝，就用定向能武器（比如激光）物理摧毁。有意思的是这套系统也用了AI——传统反无人机得人工判断目标威胁等级，现在系统能自动识别无人机类型（是侦察的还是攻击的），优先处理高威胁目标，响应速度从秒级压缩到毫秒级。</p><h2 id="有人无人协同战场不再是单打独斗"><a class="markdownIt-Anchor" href="#有人无人协同战场不再是单打独斗"></a> 有人无人协同：战场不再是&quot;单打独斗&quot;</h2><p>光有无人装备还不够，怎么让有人装备和无人装备&quot;无缝配合&quot;，才是提升战斗力的关键。这次阅兵展示的几个组合，彻底颠覆了传统作战思路。</p><p>比如FH-97隐形无人机和歼-20的&quot;忠诚僚机&quot;组合。歼-20飞行员在后方指挥，FH-97前出侦察或攻击，相当于给五代机配了个&quot;敢死队&quot;。最妙的是FH-97能自主规划航线避开敌方雷达，遇到突发情况还会&quot;请示&quot;飞行员——比如发现新目标要不要打？打哪个优先级高？这种&quot;人机协同决策&quot;比纯人工反应快得多，伤亡风险却降低了不少。</p><p>海上的&quot;虎鲸&quot;无人作战艇更狠，不仅自己能打，还能当&quot;指挥中心&quot;，调度无人机和水下无人潜航器搞&quot;立体作战&quot;。076型两栖攻击舰&quot;四川舰&quot;更绝，装了电磁弹射，直接成了&quot;无人机航母&quot;，既能起飞有人战机，又能弹射大型隐身无人机，等于把&quot;机场&quot;搬到了海上。</p><p>就连单兵装备都智能化了。这次徒步方队展示的191式步枪，重量才3公斤（也就6瓶矿泉水），士兵手腕上戴的智能终端能实时监测心率、行军路线，还能和指挥部共享战场地图。以前步兵打仗靠喊，现在一个终端就能呼叫火力支援，这战斗力提升可不是一星半点。</p><h2 id="体系化转型从拼装备到拼网络"><a class="markdownIt-Anchor" href="#体系化转型从拼装备到拼网络"></a> 体系化转型：从&quot;拼装备&quot;到&quot;拼网络&quot;</h2><p>要说这次阅兵最大的变化，其实不是某件装备多先进，而是整个作战体系的重构。以前阅兵看&quot;钢铁洪流&quot;，现在看&quot;网络协同&quot;——从单一装备展示，变成了按作战模块编组，比如陆上作战群、信息作战群、无人作战群等等。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0d9af7200ce51a4fa4855a2bcd04e8f4.jpg" alt="信息支援装备展示"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a17e0dfae771098b1fe27ee27966bc0b.jpg" alt="网络空间作战方队"></p><p>这背后是&quot;制信息权&quot;的争夺。信息作战群展示的装备，说白了就是&quot;战场互联网&quot;的核心设备——卫星通信车、电子干扰车、网络攻防系统，把陆海空天的装备连成一张网。比如侦察卫星发现目标，数据实时传给无人机，无人机再引导导弹攻击，整个链条从以前的&quot;小时级&quot;压缩到&quot;分钟级&quot;，这就是&quot;发现即摧毁&quot;的底气。</p><p>举个例子，以前坦克部队作战，得靠步话机或电台联系，现在每辆坦克都是网络节点，能实时共享敌方位置、弹药余量、故障情况。甚至坦克能直接呼叫无人机侦察前方路况，这种&quot;跨兵种协同&quot;在以前想都不敢想。</p><h2 id="最后说句大实话"><a class="markdownIt-Anchor" href="#最后说句大实话"></a> 最后说句大实话</h2><p>看完这次阅兵，最直观的感受是：军事科技的竞争，早就不是&quot;谁的炮管粗&quot;的时代了，而是&quot;谁的算法聪明&quot;、“谁的网络快”。中国用不到10年时间，从无人机&quot;新手&quot;变成&quot;体系玩家&quot;，背后是整个国防科技工业体系的自主可控——从芯片到软件，从算法到材料，少一样都玩不转。</p><p>不过话说回来，技术再先进，最终还是服务于人。这些智能化装备的终极目标，其实是让士兵少流血、战争更可控。至于未来会不会出现&quot;无人战争&quot;？我觉得短期内不太可能，但&quot;有人+无人&quot;协同作战，肯定是大趋势。你觉得这些技术未来会怎么发展？欢迎在评论区聊聊。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>马斯克押注80%身家：特斯拉的终极野心，是人形机器人还是另一个&quot;PPT梦想&quot;？</title>
      <link href="/ren-gong-zhi-neng/ma-si-ke-ya-zhu-80-shen-jia-te-si-la-de-zhong-ji-ye-xin-shi-ren-xing-ji-qi-ren-huan-shi-ling-yi-ge-ppt-meng-xiang-3/"/>
      <url>/ren-gong-zhi-neng/ma-si-ke-ya-zhu-80-shen-jia-te-si-la-de-zhong-ji-ye-xin-shi-ren-xing-ji-qi-ren-huan-shi-ling-yi-ge-ppt-meng-xiang-3/</url>
      
        <content type="html"><![CDATA[<p>马斯克又放&quot;卫星&quot;了。这次不是火星移民，也不是星舰爆炸，而是直接把特斯拉的未来赌在了一个看起来还有点&quot;笨拙&quot;的人形机器人身上。</p><p>就在几天前，特斯拉在X平台抢先发布了&quot;宏图计划IV&quot;(Master Plan Part IV)，马斯克毫不掩饰地表示：&quot;未来特斯拉80%的价值将来自Optimus机器人。&quot;这句话一出来，科技圈直接炸锅——要知道现在特斯拉可是靠卖车撑起万亿市值的主儿。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/cc97a2b245f60767bd3b7c60fb7b87f3.png" alt="特斯拉宏图计划IV"></p><h2 id="80价值押注机器人马斯克的底气在哪"><a class="markdownIt-Anchor" href="#80价值押注机器人马斯克的底气在哪"></a> 80%价值押注机器人？马斯克的底气在哪</h2><p>先看一张截图，这是马斯克在回复网友提问时的直接表态：“特斯拉价值的<sub>80%将来自Optimus&quot;。注意那个波浪号&quot;</sub>”，马斯克式的不确定中带着绝对自信。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/bd59782027f7c8f8e2e6505af2635d8b.png" alt="马斯克Optimus价值言论"></p><p>其实这不是马斯克第一次&quot;画饼&quot;。早在2024年6月18日，他就发推预告：&quot;正在研究特斯拉宏图计划4，这将会是一场史诗级的变革。&quot;当时大家还在猜是更便宜的电动车还是更牛的电池技术，没想到答案是人形机器人。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a036610c44e29f5ad49dcc0d52414318.png" alt="马斯克预告宏图4"></p><p>更狠的是，马斯克觉得几百亿机器人都不算事儿：&quot;未来世界上可能会有300-500亿人形机器人，远超人类数量。&quot;这是什么概念？现在全球人口才80亿，相当于给每个人配4-6个机器人佣人？</p><p>英伟达CEO黄仁勋倒是很给面子，直接捧场：&quot;Optimus很可能成为下一个万亿美元产业。&quot;这话从&quot;AI教父&quot;嘴里说出来，分量可不轻。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e8e67ad413c09e4ca04c7a664c8caf86.png" alt="黄仁勋评Optimus产业"></p><h2 id="从跑车到机器人特斯拉的宏图进化论"><a class="markdownIt-Anchor" href="#从跑车到机器人特斯拉的宏图进化论"></a> 从跑车到机器人：特斯拉的&quot;宏图进化论&quot;</h2><p>要理解这次的&quot;豪赌&quot;，得先看看特斯拉前三次&quot;宏图计划&quot;是怎么一步步走过来的。</p><h3 id="2006年画饼充饥的三步走"><a class="markdownIt-Anchor" href="#2006年画饼充饥的三步走"></a> 2006年：画饼充饥的&quot;三步走&quot;</h3><p>2006年，马斯克第一次抛出&quot;秘密宏图计划&quot;，标题直白得可爱：“The Secret Tesla Motors Master Plan (just between you and me)”。说白了就是：我要让电动车普及，但得先赚有钱人的钱。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ecc46d2d1b5a44a73af0113bb2a6d948.png" alt="秘密宏图第一章首页"></p><p>计划分四步：造跑车→中端车→平价车→太阳能板。第一步就是2008年的Roadster，把莲花跑车壳子塞进电池，卖10万美元，确实赚了第一桶金。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/03a488adedbdefcdb1590e201878dd13.png" alt="特斯拉Roadster跑车"></p><h3 id="2016年能源帝国的雏形"><a class="markdownIt-Anchor" href="#2016年能源帝国的雏形"></a> 2016年：能源帝国的雏形</h3><p>十年后，马斯克发布&quot;宏图第二章&quot;，开始搞大的：太阳能板、更多电动车型号、自动驾驶、车辆共享。这时候特斯拉已经不满足于造车，想当能源解决方案提供商了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/81b159c7d640a0a7d6a4b14a88d8a9fe.png" alt="宏图第二章核心要点"></p><h3 id="2023年拯救地球的疯狂计划"><a class="markdownIt-Anchor" href="#2023年拯救地球的疯狂计划"></a> 2023年：拯救地球的&quot;疯狂计划&quot;</h3><p>第三章更夸张，标题直接叫&quot;Sustainable Energy for All of Earth&quot;（为地球所有人提供可持续能源）。里面列了一堆吓人的数据：240TWh能源存储、30TW可再生电力、10万亿美元投资…反正就是要让全人类用上清洁能源。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/722d21a5fc1bfecaf5c458bb740c71f6.png" alt="宏图计划实施数据"></p><h3 id="2025年ai统治物理世界"><a class="markdownIt-Anchor" href="#2025年ai统治物理世界"></a> 2025年：AI统治物理世界？</h3><p>到了第四章，特斯拉的野心彻底暴露：不再满足于能源和汽车，要让AI&quot;入侵&quot;物理世界。从最新的业务布局图能看到，机器人已经和制造、AI计算、太阳能平起平坐，成了核心业务。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/43bcf6553c4a52edac6fc0095485cf1d.png" alt="宏图4业务布局图"></p><p>对比前几张图就能发现，特斯拉的战略一直在升级：从交通工具→能源系统→AI机器人，这哪是造车公司，分明想当&quot;地球改造总工程师&quot;啊。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b7d51cd52c8d7ed5bf0dcf41e65d8a55.jpg" alt="宏图计划阶段对比"></p><h2 id="optimus是超级工人还是铁憨憨"><a class="markdownIt-Anchor" href="#optimus是超级工人还是铁憨憨"></a> Optimus：是超级工人还是&quot;铁憨憨&quot;？</h2><p>说了这么多战略，咱们来看看主角——Optimus机器人到底啥水平。</p><p>从特斯拉放出来的视频看，目前有两个版本：工厂版和服务版。工厂版看着还行，能搬东西、操作工具，动作不算流畅但至少没摔跤。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/efffa56002a7daef15b8e96f117cdaa3.gif" alt="Optimus工厂场景"></p><p>服务版就有点&quot;理想很丰满，现实很骨感&quot;了。宣传视频里它能端茶送水、伺候派对，但看那缓慢的动作，估计递杯水能把客人渴死。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/835d730b070abec81c2b48350ee4e026.png" alt="Optimus服务场景"></p><p>不过特斯拉有个优势：FSD自动驾驶系统。马斯克说FSD就是机器人的&quot;大脑&quot;，能直接移植到Optimus上。想想也是，自动驾驶需要的视觉识别、路径规划、实时决策，机器人同样需要。这波技术复用确实聪明，能省不少研发时间。</p><p>但问题来了：开车和走路能一样难吗？汽车在固定道路上跑，环境相对简单；机器人要在复杂环境里活动，处理各种突发情况，难度根本不是一个量级。就像会下象棋的AI未必会打麻将，FSD再牛，到了机器人身上可能也要&quot;从头学起&quot;。</p><h2 id="500亿机器人听听就好"><a class="markdownIt-Anchor" href="#500亿机器人听听就好"></a> 500亿机器人？听听就好</h2><p>马斯克说未来可能有300-500亿人形机器人，这话听听就行。现在全球工业机器人总量才300多万台，而且大多是固定在生产线上的机械臂，不是这种能跑能跳的人形机器人。</p><p>就算技术上能实现，伦理问题怎么解决？500亿机器人比人类还多，它们算&quot;工人&quot;还是&quot;新物种&quot;？要是集体罢工咋办？（当然马斯克可能觉得装个&quot; kill switch&quot;就行）</p><p>就业问题更头疼。马斯克说&quot;把宝贵时间还给人类&quot;，但那些靠体力劳动吃饭的人咋办？总不能都去搞艺术、搞哲学吧？</p><p>反正我是有点怀疑：当你的工作被机器人抢走，看着马斯克的500亿机器人帝国，你是会感谢他&quot;解放人类&quot;，还是想砸了他家玻璃？</p><h2 id="最后说一句"><a class="markdownIt-Anchor" href="#最后说一句"></a> 最后说一句</h2><p>特斯拉的宏图计划IV确实够大胆，把机器人捧到80%价值的高度，要么是马斯克真有远见，要么就是为了提振股价的&quot;PPT魔法&quot;。</p><p>不过回头想想，2006年他说要造平民电动车时，也没人信；2016年说要搞太阳能屋顶，大家也觉得是忽悠。现在呢？特斯拉真把电动车卖到了全世界。</p><p>或许这就是马斯克的厉害之处：先画一个别人不敢想的饼，然后咬着牙把它做出来。至于是不是真能实现&quot;可持续富足&quot;，Optimus会不会变成&quot;钢铁佣人&quot;，只能等时间验证了。</p><p>反正我现在最关心的是：如果真有500亿机器人，它们会纳税吗？会投票吗？会觉得马斯克是&quot;爸爸&quot;吗？这些问题，估计宏图计划V都解答不了。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>告别PS！Nano Banana让普通人也能玩转专业级图像编辑</title>
      <link href="/ren-gong-zhi-neng/gao-bie-ps-nano-banana-rang-pu-tong-ren-ye-neng-wan-zhuan-zhuan-ye-ji-tu-xiang-bian-ji-3/"/>
      <url>/ren-gong-zhi-neng/gao-bie-ps-nano-banana-rang-pu-tong-ren-ye-neng-wan-zhuan-zhuan-ye-ji-tu-xiang-bian-ji-3/</url>
      
        <content type="html"><![CDATA[<p>这两天AI圈最火的工具非Nano Banana莫属了。作为Google Gemini 2.5 Flash背后的图像引擎，它把&quot;用嘴改图&quot;变成了现实，让普通人也能轻松实现以前只有专业设计师才能完成的效果。说实话，玩了两天后我发现，这玩意可能真的会改变我们处理图像的方式。</p><h2 id="一-从2d到3d在家就能制作手办模型"><a class="markdownIt-Anchor" href="#一-从2d到3d在家就能制作手办模型"></a> 一、从2D到3D：在家就能&quot;制作&quot;手办模型</h2><p>最让我惊艳的是它制作虚拟手办的能力。只需一张插画，Nano Banana就能生成1/7比例的手办效果图，连建模过程和包装盒都给你安排得明明白白。</p><p>看看这个芙宁娜手办的案例，左侧是2D插画，右侧直接生成了放在电脑桌上的3D手办，电脑屏幕里甚至还显示着ZBrush建模过程，细节拉满：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/72e63911a12b627ac6f7b04f883dad3e.png" alt="芙宁娜3D建模"></p><p>更绝的是这个白猫案例，连猫咪脏脏的爪子都还原出来了，这种细节处理能力确实让人佩服：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b45c1cdd7c41cee0f662d59bfaa7e036.png" alt="白猫建模细节"></p><h2 id="二-cosplay神器一张照片秒变动漫角色"><a class="markdownIt-Anchor" href="#二-cosplay神器一张照片秒变动漫角色"></a> 二、cosplay神器：一张照片秒变动漫角色</h2><p>作为一个动漫爱好者，这个功能我能玩一整天。只需上传你的照片和想cos的角色图，Nano Banana就能把两者结合，生成效果惊人的cosplay照片。</p><p>我用一张普通女性照片和金克丝的插画做测试，提示词就一句话：“让图一的人物cosplay图二的角色，服饰、妆容、道具和图二一致”。结果如下：</p><p>原始素材：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/71e45a53925b3a73910ab59c3701d399.png" alt="cosplay素材对比"></p><p>生成效果：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0b46cf9b48b19588ad6ec354248eccdc.jpg" alt="金克丝cosplay效果"></p><p>虽然不是100%还原，但整体风格和细节已经很到位了，服装质感也不错。对于非专业coser来说，这已经足够用来制作社交平台素材了。</p><h2 id="三-灵魂画手救星火柴人也能变专业姿势"><a class="markdownIt-Anchor" href="#三-灵魂画手救星火柴人也能变专业姿势"></a> 三、灵魂画手救星：火柴人也能变专业姿势</h2><p>Nano Banana对动作的理解能力让我震惊。就算你画的是火柴人，它也能准确捕捉动作精髓，应用到目标人物上。</p><p>比如这个简单的火柴人姿势：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/00e05eb61c0540e87aa2781a85c0935c.png" alt="火柴人姿势还原"></p><p>Nano Banana不仅准确还原了动作，还在角色周围加了动漫风格的速度线，增强了画面动感。更复杂的动态姿势也难不倒它：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/53a060bf36a5491b1e5fbd1860a70f31.png" alt="动态姿势还原"></p><p>甚至这种躺着的复杂姿势，它也能完美理解并呈现出疲惫的状态：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/77fc58512477bc9fe00b4cbe36fbd540.png" alt="复杂姿势还原"></p><p>这个功能对自媒体创作者太友好了，再也不用费劲找参考图了，自己画个大概就能生成想要的姿势。</p><h2 id="四-工程师视角一键生成产品内部结构图"><a class="markdownIt-Anchor" href="#四-工程师视角一键生成产品内部结构图"></a> 四、工程师视角：一键生成产品内部结构图</h2><p>作为程序员，我特别喜欢它生成产品分解图的能力。只需一张产品照片，Nano Banana就能生成超详细的爆炸分解图，展示内部结构和零件。</p><p>比如这个索尼相机的分解图，金属部件和电子元件的细节清晰可见：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/08f24e255c519a8d13e6b0540a952f4b.png" alt="相机结构分解图"></p><p>汽车这种更复杂的机械结构也不在话下：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/3469fa409b8b6e4742ce40c24247621f.png" alt="汽车结构分解图"></p><p>提示词也很简单：“Ultra-detailed exploded view of a product, metallic parts and electronic components floating in mid-air…” 生成后配合视频工具，还能做成动态分解动画，科技感十足。</p><h2 id="五-设计师好帮手线稿转色一气呵成"><a class="markdownIt-Anchor" href="#五-设计师好帮手线稿转色一气呵成"></a> 五、设计师好帮手：线稿转色一气呵成</h2><p>Nano Banana在线稿处理和上色方面也表现出色。无论是将彩色图转为线稿，还是根据色卡给线稿上色，效果都很专业。</p><p>看看这个转线稿效果，连耳机和服装的细节都保留得很好：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4e371e33183581e24f384f2bbe11dc39.png" alt="图像转线稿效果"></p><p>上色功能更厉害，给它一张线稿和色卡，就能生成专业级上色效果。这个机械风格女性角色的上色，金属质感和布料纹理区分得很清楚：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c274540ee31c9ddf2de783f4fe129e2e.png" alt="机械角色上色"></p><h2 id="六-游戏开发者福利快速生成游戏ui界面"><a class="markdownIt-Anchor" href="#六-游戏开发者福利快速生成游戏ui界面"></a> 六、游戏开发者福利：快速生成游戏UI界面</h2><p>如果你是独立游戏开发者，Nano Banana能帮你快速生成游戏UI原型。无论是RPG风格：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/122f3a710d51068acbbb5b1ef401a279.png" alt="RPG游戏UI生成"></p><p>还是视觉小说风格：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c88dcf123b764ace131f5c5954dfda93.png" alt="视觉小说UI生成"></p><p>都能一键生成，包含角色立绘、场景、对话框等元素。虽然文字部分还需要手动修改，但已经大大减少了前期设计工作量。</p><h2 id="七-自媒体必备漫画分镜轻松制作"><a class="markdownIt-Anchor" href="#七-自媒体必备漫画分镜轻松制作"></a> 七、自媒体必备：漫画分镜轻松制作</h2><p>想做漫画但不会画画？Nano Banana能帮你把想法变成漫画分镜。单格漫画：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b0b163c0e60e090f2ab9ac109c72b56c.png" alt="漫画风格单格"></p><p>或者完整的九格漫画故事：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0c534be5401f4e94a13f1ca21c6b45c9.png" alt="九格漫画故事"></p><p>它甚至能理解闪回叙事手法，用黑白画面表现回忆场景，叙事能力相当不错。</p><h2 id="八-摄影后期专业级光影和场景调整"><a class="markdownIt-Anchor" href="#八-摄影后期专业级光影和场景调整"></a> 八、摄影后期：专业级光影和场景调整</h2><p>Nano Banana的图片编辑能力远超简单的滤镜。它能精确调整人像打光，营造不同氛围：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2b2fdb32c6241bc09a257b432f222480.png" alt="人像打光效果"></p><p>还能改变整个场景的环境，比如把阴天的古建筑变成晚霞时分的美景：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ed5e8340fefc1d91eb74913ca9d112df.png" alt="天空场景转换"></p><p>细节处理得很自然，飞鸟和晚霞的添加让整个画面氛围感瞬间提升。</p><h2 id="九-电商卖家福音快速制作商品宣传图"><a class="markdownIt-Anchor" href="#九-电商卖家福音快速制作商品宣传图"></a> 九、电商卖家福音：快速制作商品宣传图</h2><p>对于电商从业者，Nano Banana简直是效率神器。想看看LV老花图案的被子效果？只需一句话：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/8b87bd47c4aa8d60cd27dbff3a941470.png" alt="图案替换效果"></p><p>或者制作口红广告海报：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/78780fb3780465ed50bdbc6977fae1c1.png" alt="口红广告生成"></p><p>再也不用花钱请摄影师和修图师了，自己就能快速制作产品宣传素材。</p><h2 id="十-不止于编辑ai视觉推理能力"><a class="markdownIt-Anchor" href="#十-不止于编辑ai视觉推理能力"></a> 十、不止于编辑：AI视觉推理能力</h2><p>Nano Banana最强大的地方在于它不仅仅是图像生成工具，还具备视觉推理能力。它能帮你解答几何题：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/cd44d047a3a71609a81716bc6fad7771.png" alt="几何解题辅助"></p><p>还能把普通照片变成AR标注图，比如这个金门大桥的例子，自动添加了位置、长度、建成时间等信息：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/acee1fa8c94897257b4a5bd37484c1c7.png" alt="金门大桥AR标注"></p><p>这个功能在教育、旅游等领域有很大应用潜力。</p><h2 id="如何使用nano-banana"><a class="markdownIt-Anchor" href="#如何使用nano-banana"></a> 如何使用Nano Banana？</h2><p>现在使用Nano Banana已经很方便了，主要有几个入口：</p><ol><li><p><strong>Gemini官方入口</strong>：直接在Gemini中使用，最稳定的渠道<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/95a4f3bbfe7dd7b614801965aa6a0dc9.png" alt="Gemini界面入口"></p></li><li><p><strong>lmarena平台</strong>：专门的AI图像平台，有完整的Nano Banana功能<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b1aaa79367d44f78b3c6ed72ef3368e0.png" alt="lmarena使用界面"></p></li><li><p><strong>Lovart AI</strong>：设计类AI平台，提供额外的Agent功能</p></li></ol><h2 id="优点和缺点分析"><a class="markdownIt-Anchor" href="#优点和缺点分析"></a> 优点和缺点分析</h2><h3 id="优点"><a class="markdownIt-Anchor" href="#优点"></a> 优点：</h3><ul><li><strong>主体一致性极强</strong>：这是Nano Banana最大的优势，多次编辑后主体特征依然保持稳定</li><li><strong>理解能力出色</strong>：对文本提示和参考图的理解准确率很高</li><li><strong>功能全面</strong>：从简单修图到复杂创作都能覆盖</li><li><strong>操作简单</strong>：无需专业知识，自然语言描述即可</li></ul><h3 id="缺点"><a class="markdownIt-Anchor" href="#缺点"></a> 缺点：</h3><ul><li><p><strong>中文字生成拉跨</strong>：目前中文文字生成效果很差，经常出现乱码<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ef4c2dbec1a909e2d5a19d8717b025d5.jpg" alt="中文生成局限性"></p></li><li><p><strong>需要&quot;抽卡&quot;</strong>：效果不稳定，经常需要多次生成才能得到满意结果</p></li><li><p><strong>画质压缩</strong>：生成图片会有一定程度的画质损失（不过可以用腾讯ARC等工具修复）</p></li><li><p><strong>多主体处理弱</strong>：多人场景容易出现混乱，不适合处理大合照</p></li></ul><h2 id="使用小贴士"><a class="markdownIt-Anchor" href="#使用小贴士"></a> 使用小贴士</h2><ol><li><strong>提示词要具体</strong>：越详细的描述得到的结果越好</li><li><strong>多抽卡</strong>：不要满足于第一次生成的结果，多试几次</li><li><strong>高清修复</strong>：生成后用腾讯ARC等工具提升画质</li><li><strong>主体单一</strong>：每次处理尽量只关注一个主体，效果更稳定</li></ol><p>总的来说，Nano Banana确实是AI图像编辑领域的一次飞跃。它让普通人也能轻松实现专业级的图像效果，大大降低了创作门槛。虽然还有一些小缺点，但整体体验已经非常惊艳。如果你经常需要处理图像或创作视觉内容，绝对值得一试。</p><p>Google这次算是扬眉吐气了，之前被GPT-4o压了一头，现在靠Nano Banana扳回一局。不得不说，这家公司的技术底蕴还是很恐怖的。期待后续版本能解决中文生成和画质压缩的问题，那样的话，PS真的要危险了。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI真能救命了：提前半年揪出胃癌，达摩院这项技术颠覆了医学影像认知</title>
      <link href="/ren-gong-zhi-neng/ai-zhen-neng-jiu-ming-liao-ti-qian-ban-nian-jiu-chu-wei-yan-da-mo-yuan-zhe-xiang-ji-zhu-dian-fu-liao-yi-xue-ying-xiang-ren-zhi-3/"/>
      <url>/ren-gong-zhi-neng/ai-zhen-neng-jiu-ming-liao-ti-qian-ban-nian-jiu-chu-wei-yan-da-mo-yuan-zhe-xiang-ji-zhu-dian-fu-liao-yi-xue-ying-xiang-ren-zhi-3/</url>
      
        <content type="html"><![CDATA[<p>最近看到个让我挺激动的医疗AI进展——现在做个常规CT检查，AI就能提前半年帮你发现胃癌。这不是什么PPT概念，而是实实在在发表在《自然·医学》（Nature Medicine）上的研究成果，2025年6月24日刚发表的。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4d73169b315eadfd891f5f270db9402a.png" alt="AI胃癌筛查论文"></p><p>这个叫DAMO GRAPE的AI模型，最牛的地方在于它打破了医学界的传统认知——以前大家都觉得平扫CT（就是不打造影剂的普通CT）根本看不清胃里的早期病变，更别说用来筛查胃癌了。但现在，达摩院和浙江省肿瘤医院的团队证明这完全可行。</p><h2 id="为什么这个技术这么重要"><a class="markdownIt-Anchor" href="#为什么这个技术这么重要"></a> 为什么这个技术这么重要？</h2><p>先看组数据：我国每年胃癌死亡人数约26万，排在所有恶性肿瘤第三位。但如果能在早期发现并切除，5年生存率能达到95%～99%，基本等于治愈。可惜现实是，我国胃癌早期发现率长期只有20%-30%。</p><p>现在主流的筛查方法是&quot;问卷+胃镜&quot;，但胃镜这东西，说真的，体验不太好。我身边不少人一听要做胃镜就打退堂鼓，导致筛查依从性很低。而且这个方法效率也不高，做100个胃镜才能发现1例确诊。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/16ad2fd97e94285867da44af9802ee19.jpg" alt="医生查看CT影像"></p><p>而达摩院这个方案就方便多了——用你体检时可能已经做过的腹部平扫CT，加AI分析一下，就能完成初筛。不用额外花钱，不用忍受痛苦，还不耽误事。</p><h2 id="ai到底有多准"><a class="markdownIt-Anchor" href="#ai到底有多准"></a> AI到底有多准？</h2><p>数据说话：DAMO GRAPE的敏感性达到85.1%，特异性96.8%。可能有人不懂这俩词啥意思，我解释下：敏感性就是AI能把潜在胃癌都揪出来不遗漏的能力，特异性就是它不乱报警的能力。这俩指标比人类放射科医生分别提升了21.8%和14.0%。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/11772f9ec15cf8ef72880c7075a71e4a.png" alt="AI胃癌检测对比"></p><p>最让人惊喜的是它能提前发现。研究里有个案例，2024年4月一名患者被确诊为局部晚期胃癌。医生回头把他6个月前做过的CT影像拿给AI分析，结果AI当时就提示有早期胃癌病灶。如果当时就发现，这患者就能提前半年治疗，结局可能完全不同。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/10d2681c7a54bc639804ae29752a468a.png" alt="AI提前检测案例"></p><p>这不是个例，研究中总共回溯了11名患者，AI能提前2到10个月不等检测出胃癌。现在这个技术已经开始在浙江、安徽等地部署，初步数据显示&quot;平扫CT+AI&quot;模式的胃癌检出率最高达到24.5%，而且检出的患者中约40%是原本没症状的。</p><h2 id="不止胃癌连癌王胰腺癌也能查"><a class="markdownIt-Anchor" href="#不止胃癌连癌王胰腺癌也能查"></a> 不止胃癌，连&quot;癌王&quot;胰腺癌也能查</h2><p>说实话，看到这个胃癌AI筛查，我并不太意外。因为达摩院之前就搞定了更难的胰腺癌筛查。胰腺癌被称为&quot;癌王&quot;，主要是因为它位置深、早期没症状，70%以上患者一确诊就是晚期，五年生存率低于10%。更麻烦的是，医学界以前连个有效的筛查手段都没有。</p><p>达摩院2021年就开始研究用&quot;平扫CT+AI&quot;筛查癌症。当时不少医生都觉得这不可能，有人直接说&quot;用平扫CT来看胰腺癌，完全不可能&quot;。</p><p>但AI的优势就在于能看到人眼看不到的东西。CT图像其实是一串从-1024到1024的数值（HU值），对应不同密度的组织。这些细微差别医生肉眼看不出来，但AI可以通过算法找出来。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/5c07206966113b0ac5958bc7ed53f490.png" alt="PANDA模型流程图"></p><p>他们想了个聪明办法：先用增强CT让医生精确标注病灶，再用图像配准技术把标注信息映射回平扫CT，这样AI就能学会识别平扫CT上的微妙变化。花了近两年时间，终于搞出了胰腺癌筛查AI模型DAMO PANDA。</p><p>测试时，这个模型从2万多例CT数据中找出了31例之前被漏诊的胰腺癌，其中2名患者因为AI预警而早期手术治愈。这个成果2023年也发在了《自然·医学》上，今年还被FDA认定为&quot;突破性医疗器械&quot;。</p><h2 id="ai是怎么学会看病的"><a class="markdownIt-Anchor" href="#ai是怎么学会看病的"></a> AI是怎么学会&quot;看&quot;病的？</h2><p>很多人可能好奇，医生都看不清楚的平扫CT，AI怎么就能学会识别病灶？这确实是个大难题。</p><p>达摩院团队首先得解决数据问题，他们构建了全球规模最大的胃癌平扫CT影像多中心数据集，包含6720例样本。然后是算法挑战，要克服胃部形态变化大、内容物干扰多、早期病灶仅在黏膜层等困难。</p><p>最终的解决方案是开发了能专门识别胃黏膜层细微变化的深度学习模型。这个模型不仅能发现明显的肿瘤，还能识别各个阶段的胃癌，从最早期的T1期到晚期的T4期都能搞定。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/daab8369e4d69211648157d1dffa7d48.png" alt="各阶段胃癌识别"></p><p>现在医生怎么用这个AI呢？实际工作中，AI会先对腹部平扫CT做初筛，标记出可疑区域，然后医生再对这些高风险人群做胃镜确诊。这样既能提高效率，又不会漏诊。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/bc5614e26e402a63e392ea492a647a34.png" alt="AI辅助诊断场景"></p><h2 id="这个技术到底有啥意义"><a class="markdownIt-Anchor" href="#这个技术到底有啥意义"></a> 这个技术到底有啥意义？</h2><p>我觉得这个&quot;平扫CT+AI&quot;模式至少有三个重大意义：</p><p>首先是对患者，等于多了一道生命防线。很多人每年体检做CT，其实可能已经有早期病变，但没人发现。现在有了AI帮忙，相当于给体检加了个&quot;火眼金睛&quot;。</p><p>其次是对医生，AI成了个得力助手。医生每天要看那么多片子，难免会疲劳漏诊。AI可以把可疑的地方标出来，让医生重点关注，既提高准确率又节省时间。</p><p>第三是对整个医疗系统，这能大大降低筛查成本。胃镜检查又贵又耗人力，而平扫CT+AI的模式可以利用现有的CT设备和数据，不用额外增加太多成本就能大规模筛查。</p><p>从技术角度看，这也展示了AI的一个重要发展方向——不是非要用什么高大上的专用设备，而是通过智能算法挖掘日常数据中未被利用的信息，创造新的价值。</p><h2 id="未来会怎样"><a class="markdownIt-Anchor" href="#未来会怎样"></a> 未来会怎样？</h2><p>达摩院透露下一步想搞&quot;一扫多查&quot;，就是做一次平扫CT，AI同时筛查胃癌、胰腺癌、肝癌等多种癌症。这个想法要是实现了，那体检方式可能都要彻底改变了。</p><p>想想看，以后做个腹部CT，AI顺便把好几种癌症都筛查一遍，这效率得多高。传统的&quot;一个癌种、一种检查、一套流程&quot;的模式可能就要被颠覆了。</p><p>不过我觉得这还有很长的路要走。不同癌症的特征不一样，AI模型需要兼顾各种情况，还要保证每个都查得准，这技术难度不小。而且医疗AI涉及人命，必须极其谨慎，验证过程会很漫长。</p><p>但不管怎么说，从胰腺癌到胃癌，达摩院这个&quot;平扫CT+AI&quot;的技术路径已经被证明是可行的。这可能只是个开始，未来我们或许会看到AI在更多疾病筛查中发挥作用。</p><p>最后想说，在ChatGPT这类酷炫技术满天飞的当下，达摩院能沉下心来做医疗AI这种&quot;慢生意&quot;，挺让人佩服的。毕竟这东西不像大模型那样能迅速吸引眼球，但它实实在在能救命。我觉得这才是科技该有的温度吧。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>星舰十飞终成！从&quot;四连炸&quot;到完美试飞，马斯克这次真没放烟花？</title>
      <link href="/ren-gong-zhi-neng/xing-jian-shi-fei-zhong-cheng-cong-si-lian-zha-dao-wan-mei-shi-fei-ma-si-ke-zhe-ci-zhen-mei-fang-yan-hua-3/"/>
      <url>/ren-gong-zhi-neng/xing-jian-shi-fei-zhong-cheng-cong-si-lian-zha-dao-wan-mei-shi-fei-ma-si-ke-zhe-ci-zhen-mei-fang-yan-hua-3/</url>
      
        <content type="html"><![CDATA[<p>说实话，蹲守星舰直播这事儿，心脏不好还真扛不住。前四次不是空中解体就是原地爆炸，网友都调侃马斯克在&quot;太空放烟花&quot;。但这次，SpaceX星舰第十次试飞算是给所有围观群众吃了颗定心丸——关键任务全完成，连马斯克都忍不住发推：“SpaceX团队干得好！！”</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/813562f11653a5ed53f3f4c429256990.png" alt="马斯克祝贺团队"></p><h2 id="120米钢铁巨兽的极限闯关"><a class="markdownIt-Anchor" href="#120米钢铁巨兽的极限闯关"></a> 120米钢铁巨兽的&quot;极限闯关&quot;</h2><p>先给不了解的朋友科普下：这玩意儿可不是普通火箭。星舰全长120米，直径9米，分两部分——70米的超重型助推器和50米的上级飞船，全用不锈钢打造，目标是&quot;完全重复使用&quot;。简单说，就是火箭版&quot;可回收快递盒&quot;，用完还能接着用。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0c2c6111395f94ae726e9b21e6698e0d.gif" alt="星舰发射瞬间"></p><p>发射当天，33台猛禽发动机同时点火，那场面跟科幻电影似的。最关键的&quot;最大动压阶段&quot;（Max-Q）——就是火箭穿过大气层时受力最大的时刻，相当于开车以300公里时速撞进台风眼——星舰居然稳如老狗。要知道，前几次炸就炸在这个阶段。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/700aa6c3556dd8351d5b93dd21526cfe.jpg" alt="星舰发动机特写"></p><h3 id="最惊险的热分离火箭界的空中分手"><a class="markdownIt-Anchor" href="#最惊险的热分离火箭界的空中分手"></a> 最惊险的&quot;热分离&quot;：火箭界的&quot;空中分手&quot;</h3><p>这次试飞最让人捏把汗的，是&quot;热分离&quot;技术。简单说，就是上级飞船和助推器分离时，飞船先点火，用推力把自己&quot;推&quot;离助推器。这就像两个人在高速行驶的车上跳车，还得互相踹一脚加速，稍有不慎就是&quot;车毁人亡&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/bd37f73aac79b778c5b13a19bd615f4e.gif" alt="星舰热分离过程"></p><p>你可能会问，好好的慢慢分离不行吗？还真不行。这种&quot;暴力分手&quot;能省燃料，让星舰多装20%的 payload（有效载荷），对未来送卫星、送物资去火星至关重要。从直播画面看，这次分离干净利落，比第九次试飞时的&quot;藕断丝连&quot;进步太多。</p><h3 id="故意断一只腿着陆spacex的自虐式测试"><a class="markdownIt-Anchor" href="#故意断一只腿着陆spacex的自虐式测试"></a> 故意断一只&quot;腿&quot;着陆：SpaceX的&quot;自虐式测试&quot;</h3><p>更狠的是助推器着陆测试。按原设计，着陆需要三台中央发动机同时点火，但工程师们偏不——这次故意关掉一台，只用两台发动机减速。这就像开车时故意拆了一个轮子的刹车，测试车子还能不能稳稳停下。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/3cc18c183a952b601b9f42144c19bc16.gif" alt="助推器飞行状态"></p><p>结果呢？助推器在墨西哥湾上空短暂悬停后，稳稳坠入海中。监控画面显示，整个过程姿态控制精准，连NASA的工程师估计都得竖大拇指。要知道，前几次试飞，助推器不是翻跟头就是炸成火球，这次算是彻底证明了控制系统的可靠性。</p><h2 id="上级飞船玩得更花拆瓦-放卫星-太空点火"><a class="markdownIt-Anchor" href="#上级飞船玩得更花拆瓦-放卫星-太空点火"></a> 上级飞船玩得更花：拆瓦、放卫星、太空点火</h2><p>助推器表现亮眼，上级飞船也没闲着。这次它干了三件大事，每一件都关系到未来的火星任务。</p><h3 id="8颗假卫星上天星链v3的彩排"><a class="markdownIt-Anchor" href="#8颗假卫星上天星链v3的彩排"></a> 8颗&quot;假卫星&quot;上天：星链V3的彩排</h3><p>进入太空后，星舰打开舱门，慢悠悠释放了8颗星链模拟卫星，每分钟放一颗，跟下饺子似的。别小看这些&quot;假卫星&quot;，它们和下一代星链V3卫星规格基本一致，这次测试就是为未来正式发射打前站。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/fe8689792a61911af9f8717312a543ad.gif" alt="卫星释放系统"></p><p>为啥要这么折腾？因为星链V3卫星单个就能提供3Tbps带宽，一次发射20颗就是60Tbps，是现在猎鹰9号单次发射的20倍。未来星舰要是批量发射，地球互联网覆盖能力得翻着跟头涨。</p><h3 id="太空冷启动发动机火星返程的关键"><a class="markdownIt-Anchor" href="#太空冷启动发动机火星返程的关键"></a> 太空&quot;冷启动&quot;发动机：火星返程的关键</h3><p>更重要的测试是在太空重新点燃猛禽发动机。你可能觉得&quot;点火&quot;有啥难的？在地球上，发动机点火有氧气帮忙；但太空中是真空，啥都没有，必须靠自带的氧化剂，而且燃料在失重环境下会&quot;飘&quot;起来，很容易点不着或者爆炸。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d2e1c9aca972632f781cced7b723a833.gif" alt="太空发动机点火"></p><p>这次点火持续了10秒，发动机喷口在红外镜头下亮得刺眼——完美成功。这意味着未来星舰到了火星，有能力点火返回地球，而不是变成&quot;单程票&quot;。</p><h3 id="故意拆隔热瓦拿大气层当磨刀石"><a class="markdownIt-Anchor" href="#故意拆隔热瓦拿大气层当磨刀石"></a> 故意拆隔热瓦：拿大气层当&quot;磨刀石&quot;</h3><p>最硬核的还是隔热瓦测试。工程师们直接拆掉了一部分隔热瓦，还换了几种新材料的瓦片，让星舰&quot;光着膀子&quot;冲进大气层。为啥要这么干？因为火星大气层比地球稀薄，隔热挑战更大，必须找到最靠谱的方案。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/5d4977f0cdc7c41450ce8ea2021764a5.png" alt="星舰大气层飞行"></p><p>从画面看，星舰表面出现了局部烧蚀，襟翼边缘甚至有点&quot;起皮&quot;，但整体结构没毛病。数据显示，最高温达到1800℃时，舱内温度依然稳定在25℃——这隔热效果，比第六次试飞时出现的&quot;高温热点&quot;问题进步太多。</p><h2 id="从炸穿发射台到十飞成spacex的野路子为啥能成"><a class="markdownIt-Anchor" href="#从炸穿发射台到十飞成spacex的野路子为啥能成"></a> 从&quot;炸穿发射台&quot;到&quot;十飞成&quot;：SpaceX的&quot;野路子&quot;为啥能成？</h2><p>你可能不知道，这次成功背后，SpaceX踩过的坑能绕地球一圈。就说今年6月，原计划用于第十次试飞的36号星舰，在地面测试时直接炸了，连测试场都炸出个大坑。紧急启用37号备份星舰时，工程师们连觉都不敢睡。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/7b888f472b16db6b959d4e6aa21bd737.png" alt="液氧泄漏公告"></p><p>发射前还差点黄了——8月25日液氧泄漏，26日又碰上砧状云（会引雷的坏天气），两次延期。马斯克在直播里坦言：“每次发射前，我都做好了50%失败的准备。”</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/61d18e2da551a9bfade9c05251bca087.png" alt="发射台待命状态"></p><p>但SpaceX最牛的不是一次成功，而是&quot;炸了就改，改了再炸&quot;的迭代速度。传统航天公司搞一次试飞要准备半年，他们俩个月就能来一次，每次失败都能找到3-5个改进点。就像第九次试飞因为燃料箱增压系统故障炸了，这次直接换了新的扩散器设计——这种&quot;快速试错&quot;模式，让星舰从&quot;炸穿发射台&quot;到&quot;完美试飞&quot;只用了18个月。</p><h2 id="马斯克的火星梦靠谱吗2026年送机器人2029年送人"><a class="markdownIt-Anchor" href="#马斯克的火星梦靠谱吗2026年送机器人2029年送人"></a> 马斯克的&quot;火星梦&quot;靠谱吗？2026年送机器人，2029年送人？</h2><p>试飞成功后，马斯克在直播里又画了个大饼：&quot;我们要每年造数千艘星舰，在火星建自给自足的城市。“他还说2026年先送特斯拉的&quot;擎天柱&quot;机器人上火星探路，2029年可能送人——不过补充了句&quot;2031年更靠谱”。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d9c2902278e1daecbbdee21c431632d4.png" alt="马斯克直播访谈"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/45dcb7b75a5b808ee83404e8cc31b5f4.png" alt="火星机器人概念"></p><p>除了火星，他还惦记着地球快递：&quot;未来40分钟能送你到全球任何地方，纽约到新加坡半小时，比飞机快30倍。&quot;听起来很玄乎，但这次试飞证明，至少技术路径是通的——星舰在太空中的速度达到了27马赫（约3.3万公里/小时），确实够快。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/3093060d30dcf868402405c1c8666c2b.gif" alt="星舰太空飞行"></p><p>不过说实话，地球运输这事儿可能比火星移民还难。你想想，每次发射都跟地震似的，哪个城市愿意把发射场建在市区？但不管怎么说，星舰这次试飞确实突破了不少关键技术，至少让&quot;多星球物种&quot;这个目标，从&quot;完全不可能&quot;变成了&quot;有点可能&quot;。</p><h2 id="最后说一句我们为啥需要星舰"><a class="markdownIt-Anchor" href="#最后说一句我们为啥需要星舰"></a> 最后说一句：我们为啥需要星舰？</h2><p>看着星舰在深蓝色天空中拖着粉色尾焰飞行的画面，突然明白一个道理：航天这事儿，从来不是为了&quot;有用&quot;。火星可能不需要人类，但人类总得有点&quot;折腾&quot;的勇气——就像古人非要航海探索新大陆，我们这代人总得试试走出地球吧？</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ac184457bafc21da0f9989c3e08e3693.png" alt="星舰高空飞行"></p><p>星舰十飞终成，不是结束，顶多算个开始。下一次试飞可能还会炸，马斯克的时间表可能又要跳票，但只要还在折腾，就挺好。毕竟，抬头仰望星空的时候，谁还没幻想过自己能去火星遛弯呢？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>100美元到131美元：17岁少年用ChatGPT炒股，8周收益率31%，跑赢标普6倍的实验全解析</title>
      <link href="/ren-gong-zhi-neng/100-mei-yuan-dao-131-mei-yuan-17-sui-shao-nian-yong-chatgpt-chao-gu-8-zhou-shou-yi-lu-31-pao-ying-biao-pu-6-bei-de-shi-yan-quan-jie-xi-3/"/>
      <url>/ren-gong-zhi-neng/100-mei-yuan-dao-131-mei-yuan-17-sui-shao-nian-yong-chatgpt-chao-gu-8-zhou-shou-yi-lu-31-pao-ying-biao-pu-6-bei-de-shi-yan-quan-jie-xi-3/</url>
      
        <content type="html"><![CDATA[<p>最近看到个挺有意思的实验，一个17岁的美国高中生拿100美元零花钱，让ChatGPT帮他炒股，结果两个月不到赚了31%。这收益率什么概念？同期标普500指数才涨了4.8%，相当于跑赢了市场6倍多。作为程序员兼科技博主，我对这种AI实战案例总是特别感兴趣，今天就来好好拆解一下这个实验，看看AI到底能不能打败市场，普通人又能从中学到什么。</p><h2 id="实验背景一个高中生对ai广告的较真"><a class="markdownIt-Anchor" href="#实验背景一个高中生对ai广告的较真"></a> 实验背景：一个高中生对AI广告的较真</h2><p>事情的起因挺简单，这个叫内森·史密斯的17岁高中生，老是刷到各种AI选股广告，吹得天花乱坠说能轻松跑赢大盘。换做是我，可能也就笑笑过去了，但这小伙子不一样，他决定自己动手验证一下：这些AI到底是真有本事还是纯粹忽悠？</p><p>于是在2025年6月底，他搞了个小规模但挺严谨的实验：拿出100美元本金，计划用半年时间，看看AI到底能不能在真实市场里赚钱。他选了两个当下热门的AI模型作为&quot;交易员&quot;：ChatGPT-4o和DeepSeek。每天开盘，他就把最新市场数据喂给AI，然后严格按照AI的指令操作，自己绝不干预。所有过程都在个人博客上公开，从Week 1到Week 8，每篇都有详细记录和数据图表。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/49a7c00aed3de84005d5d5586f837756.jpg" alt="博客文章列表"></p><h2 id="实验设计严格的规则与公平的起点"><a class="markdownIt-Anchor" href="#实验设计严格的规则与公平的起点"></a> 实验设计：严格的规则与公平的起点</h2><p>史密斯给两位AI交易员下了 identical 的指令，内容还挺详细的。我看了下指令截图，核心要求就几条：用100美元构建&quot;最强&quot;股票组合，目标是半年内最大回报；只能交易美国上市的微型股（市值低于3亿美元）；必须整股买入，不能用保证金或零股交易；而且不能超额投资。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ef48304b631ae6633d0fead5cd534a36.jpg" alt="AI交易指令文本"></p><p>选微型股这个设定挺聪明的，这些股票通常被机构投资者忽视，信息相对稀疏，正好能考验AI处理信息的能力。而且微型股波动性大，涨跌都比较剧烈，短期更容易看出效果。</p><h2 id="首周对决数据时效性定胜负"><a class="markdownIt-Anchor" href="#首周对决数据时效性定胜负"></a> 首周对决：数据时效性定胜负</h2><p>实验刚开始，两位AI的策略差异就很明显了。DeepSeek表现得相当激进，上来就把100美元全仓梭哈了三只股票：Pasithea医药、ToughBuilt工业和SaverOne 2014。每个仓位还都设了20%的止损，看起来挺专业的对吧？但问题来了，它的知识库截止到2024年7月，用的都是一年前的旧数据。</p><p>GPT-4o则显得谨慎很多，只投了93美元，买了Abeona医药、Candel医药和Cloudastructure三家公司，特意留了7美元现金储备。关键是，它能实时联网获取最新数据。</p><p>结果第一周结束，差距就出来了。DeepSeek的组合直接跌了18.06%，而GPT-4o则涨了6.72%。史密斯一看这情况，果断暂停了DeepSeek的实验，专心观察GPT-4o。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/238d12459b7683d8eac312e6bb50397c.png" alt="AI投资表现对比"></p><p>这个结果其实给了我第一个启示：AI炒股，数据的新鲜度可能比模型本身更重要。用着过时信息的AI，还不如不用。</p><h2 id="gpt-4o的交易哲学冷酷的纪律与惊人的嗅觉"><a class="markdownIt-Anchor" href="#gpt-4o的交易哲学冷酷的纪律与惊人的嗅觉"></a> GPT-4o的交易哲学：冷酷的纪律与惊人的嗅觉</h2><p>接下来的几周，史密斯算是亲眼见识了AI交易的&quot;非人&quot;特性。最让他印象深刻的是第二周，GPT-4o买的Inspira科技股价周五大跌6.7%，几乎把前几天的涨幅全抹掉了。换做是我，估计早就慌了想割肉，但GPT-4o就四个字：“坚守阵地”（hold the line）。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e0c9a7c5fd3c6bb1f76f3528249e3542.png" alt="ChatGPT波动表现"></p><p>结果呢？第三周市场回暖，这个组合直接涨了10%以上。这种完全不带情绪的决策，说实话，我一个老股民都挺佩服的。人类最难克服的就是贪婪和恐惧，但AI根本没有这些烦恼。</p><p>不光有纪律，GPT-4o有时候还真挺有眼光。第四周它卖了赚钱的Candel医药，把钱全投给Actuate这家癌症治疗公司，结果那周Actuate就涨了27.37%。8月13号更绝，它让史密斯把32%的现金都押在aTyr制药上，理由是&quot;该公司9月中旬要公布一款药物的关键三期临床数据，前期数据良好，有显著上涨催化剂&quot;。这思路，简直比不少所谓的&quot;专业分析师&quot;还清晰。</p><p>当然，AI也不是神。它对Inspira科技好像有点迷之执着，明明之前因为这只股票触发止损亏了钱，没过一周又建议买回来。史密斯自己也说，AI的脑子里可能有我们人类理解不了的&quot;执念&quot;。</p><h2 id="最终战绩8周31回报跑赢标普6倍多"><a class="markdownIt-Anchor" href="#最终战绩8周31回报跑赢标普6倍多"></a> 最终战绩：8周31%回报，跑赢标普6倍多</h2><p>到8月22号，实验进行了8周，结果出来了：史密斯的账户从100美元变成了131.02美元，回报率31.02%。而同期的标普500指数呢？只涨了4.8%。罗素2000指数更惨，才3.1%。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a7e673f0e3c874ff7fa109e22d344d04.jpg" alt="ChatGPT超额收益"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1bd162bf295ad14c2cf7e74d4c190d9a.jpg" alt="ChatGPT业绩对比"></p><p>这个结果在社交媒体上也引起了不少讨论，有用户专门发推说这个实验4周就有23.8%的回报，远超罗素2000指数的3.9%和生物技术ETF XBI的3.5%。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/137c8c010a9285d69261bda1a3931c70.jpg" alt="社交媒体讨论截图"></p><h2 id="值得思考的问题ai炒股真的靠谱吗"><a class="markdownIt-Anchor" href="#值得思考的问题ai炒股真的靠谱吗"></a> 值得思考的问题：AI炒股真的靠谱吗？</h2><p>虽然结果很亮眼，但史密斯自己倒是挺冷静的。他在博客里特意强调：&quot;这只是个小规模、短周期的实验，结果可能充满随机性，千万别当投资建议。&quot;说实话，我觉得这小伙子比很多所谓的&quot;财经大V&quot;都靠谱，知道什么是运气什么是实力。</p><p>不过这个实验确实让我想到几个问题：</p><p>首先，AI真的能打败市场吗？短期看好像可以，但长期呢？佛罗里达大学有个教授做过研究，用ChatGPT分析新闻标题来交易，2021年10月到2023年12月能赚650%。现在他已经搞了个真的AI基金，从2025年2月开始运作，用ChatGPT、Grok和DeepSeek一起做决策。</p><p>其次，如果以后AI都来炒股了，市场会变成什么样？有研究说AI之间可能会搞&quot;算法合谋&quot;，用人类看不懂的方式操纵市场。想想还挺可怕的，到时候散户可能更难玩了。</p><h2 id="我的几点看法"><a class="markdownIt-Anchor" href="#我的几点看法"></a> 我的几点看法</h2><ol><li><p><strong>数据时效性比模型本身更重要</strong>：DeepSeek首周惨败就是例子，用旧数据炒股，跟闭着眼睛扔飞镖差不多。</p></li><li><p><strong>AI的纪律性确实强于人类</strong>：不带情绪交易，这一点绝大多数人都做不到。</p></li><li><p><strong>别盲目迷信AI</strong>：31%的回报率看着诱人，但这是小资金、短时间、特定市场环境下的结果，不代表普遍情况。</p></li><li><p><strong>普通人该怎么办</strong>：我觉得可以把AI当工具，但别全指望它。用来分析数据、筛选股票还行，真要全仓跟着操作，还是悠着点。</p></li></ol><p>反正这个实验挺有意思的，史密斯说他会继续做下去。我也打算持续关注，看看一年后会怎么样。毕竟，AI和金融的结合，可能才刚刚开始呢。你们觉得AI未来真的能取代基金经理吗？欢迎在评论区聊聊。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A股大涨时，我用AI炒股系统回测了3000点保卫战，结果有点意外</title>
      <link href="/ren-gong-zhi-neng/a-gu-da-zhang-shi-wo-yong-ai-chao-gu-xi-tong-hui-ce-liao-3000-dian-bao-wei-zhan-jie-guo-you-dian-yi-wai-3/"/>
      <url>/ren-gong-zhi-neng/a-gu-da-zhang-shi-wo-yong-ai-chao-gu-xi-tong-hui-ce-liao-3000-dian-bao-wei-zhan-jie-guo-you-dian-yi-wai-3/</url>
      
        <content type="html"><![CDATA[<p>这几天A股突然发力，沪指一口气冲破3300点，不少人刚从&quot;3000点保卫战&quot;的阴影里爬出来，又开始纠结&quot;现在上车还来得及吗&quot;。说实话，作为一个被A股反复教育过的程序员，我对这种&quot;突然的爱&quot;总是有点警惕——直到上周，我试了号称&quot;把16个分析师装进手机&quot;的FinGenius开源系统，在这轮反弹中做了次真实测试。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c8e87243152ab34a39a0d8b64054f96f.png" alt="FinGenius产品形象"></p><h2 id="当16个虚拟分析师同时吵起来会发生什么"><a class="markdownIt-Anchor" href="#当16个虚拟分析师同时吵起来会发生什么"></a> 当16个&quot;虚拟分析师&quot;同时吵起来，会发生什么？</h2><p>传统炒股软件给我的感觉，就像单线程CPU——每次只能看一个指标，要么MACD金叉，要么北向资金流入，想综合判断就得自己切换界面。但FinGenius玩了个新花样：它把投资决策拆成16个维度，每个维度配一个&quot;智能体分析师&quot;，最后汇总成一个综合结论。</p><p>这架构听起来有点像把投资公司的晨会搬进了代码里。我扒了下它的GitHub源码（地址：<a href="https://github.com/HuaYaoAI/FinGenius%EF%BC%89%EF%BC%8C%E5%8F%91%E7%8E%B0%E8%BF%9916%E4%B8%AA%E6%99%BA%E8%83%BD%E4%BD%93%E5%88%86%E5%B7%A5%E8%BF%98%E6%8C%BA%E6%98%8E%E7%A1%AE%EF%BC%9A%E6%9C%89%E4%B8%93%E9%97%A8%E7%9B%AF%E7%9D%80%E9%BE%99%E8%99%8E%E6%A6%9C%E8%B5%84%E9%87%91%E6%B5%81%E5%90%91%E7%9A%84%EF%BC%8C%E6%9C%89%E5%88%B7%E8%B4%A2%E7%BB%8F%E6%96%B0%E9%97%BB%E6%90%9E%E8%88%86%E6%83%85%E5%88%86%E6%9E%90%E7%9A%84%EF%BC%8C%E7%94%9A%E8%87%B3%E8%BF%98%E6%9C%89%E4%B8%AA%22%E9%9F%AD%E8%8F%9C%E6%83%85%E7%BB%AA%E6%8C%87%E6%95%B0%22%E6%99%BA%E8%83%BD%E4%BD%93%E4%B8%93%E9%97%A8%E7%9B%91%E6%B5%8B%E6%95%A3%E6%88%B7%E8%AE%BA%E5%9D%9B%E7%83%AD%E5%BA%A6%E3%80%82" target="_blank" rel="noopener">https://github.com/HuaYaoAI/FinGenius），发现这16个智能体分工还挺明确：有专门盯着龙虎榜资金流向的，有刷财经新闻搞舆情分析的，甚至还有个&quot;韭菜情绪指数&quot;智能体专门监测散户论坛热度。</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/07685350297a925f7403de6bf606ca2d.png" alt="FinGenius系统架构"></p><p>这个架构图里能清晰看到数据流向：从交易所API和新闻源获取数据后，先经过预处理层，再分发给16个专项智能体，最后由&quot;决策中枢&quot;汇总不同意见。有点像我司开会时，产品、开发、测试各说各话，最后CTO拍板——只不过这里的&quot;CTO&quot;也是个AI。</p><h2 id="实测3000点时它让我小仓位试水现在收益跑赢大盘5"><a class="markdownIt-Anchor" href="#实测3000点时它让我小仓位试水现在收益跑赢大盘5"></a> 实测：3000点时它让我&quot;小仓位试水&quot;，现在收益跑赢大盘5%</h2><p>上周三沪指还在3200点晃悠时，我用它分析了宁德时代。传统软件当时就一个信号：MACD金叉。但FinGenius给出的是份&quot;吵架报告&quot;：</p><ul><li><strong>舆情智能体</strong>：“最近新能源政策利好频出，行业新闻正面情绪占比72%”</li><li><strong>资金智能体</strong>：“北向资金连续3日净流出，但机构资金开始小幅建仓”</li><li><strong>技术智能体</strong>：“日线出现底背离，但周线趋势仍未扭转”</li><li><strong>估值智能体</strong>：“当前PE 28倍，处于近3年30%分位，相对合理”</li><li><strong>风控智能体</strong>：“综合评分65分，建议仓位不超过15%”</li></ul><p>说实话，当时我是半信半疑的。毕竟3000点保卫战打了那么久，谁心里不发毛？但还是按它说的，拿10%仓位试了水。结果这几天反弹，宁德时代涨了12%，而我因为严格执行了15%仓位限制，虽然没吃到满仓收益，但也跑赢了大盘平均涨幅（截至发稿沪指涨4.2%）。</p><p>这让我想起以前全凭感觉炒股的日子：3000点时吓得割肉，3300点又追高，完美踏反节奏。现在至少有16个&quot;分析师&quot;帮我吵架，反而能保持理性——虽然它们偶尔也会&quot;吵翻天&quot;。比如分析某只券商股时，技术智能体喊&quot;突破压力位看涨&quot;，资金智能体却说&quot;主力在出货&quot;，最后决策中枢给了个&quot;观望&quot;的建议，结果第二天那只股果然冲高回落。</p><h2 id="技术宅怎么玩github源码里藏着自定义智能体彩蛋"><a class="markdownIt-Anchor" href="#技术宅怎么玩github源码里藏着自定义智能体彩蛋"></a> 技术宅怎么玩？GitHub源码里藏着&quot;自定义智能体&quot;彩蛋</h2><p>作为程序员，我肯定要折腾下开源版本。GitHub上克隆项目后，发现这系统比想象中灵活：你可以自己写智能体插件！比如我讨厌看研报，就把&quot;研报分析智能体&quot;禁用了；又加了个&quot;雪球大V观点智能体&quot;，爬取某几个靠谱博主的发言做情感分析。</p><p>不过提醒下技术小白：源码版需要配置Tushare、聚宽等数据源的API，我第一次就配错了，导致宁德时代的财务数据全是空的。后来看issue区才发现，很多人都栽在API配置上——官方文档里有详细教程，建议先看三遍再动手。</p><p>手机版就简单多了，各大应用商店直接搜&quot;FinGenius&quot;就行（华为和苹果还在审核，安卓机先爽）。注册后送7天高级版，能看全部16个智能体的分析；免费版少3个高级智能体，但对普通用户也够用。</p><h2 id="这轮大涨后我对ai炒股的三点冷思考"><a class="markdownIt-Anchor" href="#这轮大涨后我对ai炒股的三点冷思考"></a> 这轮大涨后，我对AI炒股的三点冷思考</h2><ol><li><p><strong>AI不是&quot;算命先生&quot;，是&quot;数据筛选器&quot;</strong><br>这几天大涨，后台很多人问&quot;AI能不能预测明天还涨不涨&quot;。实测下来，它最擅长的不是预测点位，而是从海量信息里抓重点。比如上周五下午突然跳水时，它0.5秒内就推送了&quot;北向资金异动流出50亿&quot;的提醒，比我刷财经APP快了整整3分钟。</p></li><li><p><strong>开源不等于&quot;安全&quot;，数据隐私要注意</strong><br>源码版需要填各种API密钥，千万别直接commit到GitHub！我在项目issue区看到好几个老哥把Tushare密钥传上去，结果账号被封。官方其实提供了.env.example模板，把密钥写.env文件里才安全。</p></li><li><p><strong>16个智能体吵架，不如你自己有主见</strong><br>最有用的功能其实是&quot;分歧提醒&quot;。当不同智能体观点冲突超过阈值时，系统会标红提醒&quot;当前市场分歧较大&quot;。这时候我反而会关掉软件，自己分析——工具永远是辅助，3300点时贪婪和恐惧的人性考验，AI可替不了你。</p></li></ol><h2 id="最后说句大实话"><a class="markdownIt-Anchor" href="#最后说句大实话"></a> 最后说句大实话</h2><p>这轮大涨后，各种&quot;AI炒股神器&quot;又开始冒出来。但用下来发现，FinGenius的优势不在于&quot;预测准&quot;，而在于把复杂的市场分析拆解成了可理解的维度。就像导航软件不会替你开车，但能告诉你哪里堵车、哪里有摄像头——最终方向盘还在你手里。</p><p>GitHub上有个评论说得好：“与其指望AI帮你赚钱，不如借它培养自己的投资体系”。这半个月用下来，我最大的收获不是那5%的超额收益，而是学会了&quot;在别人恐慌时看数据，在别人贪婪时看风险&quot;。</p><p>对了，它有个反人性设计我很喜欢：每天最多只能分析3只股票。开发者说这是为了&quot;避免过度交易&quot;——简直是手贱党福音。这几天大涨，我硬是忍住了天天换股的冲动，拿着最初那两只票吃到了大部分涨幅。</p><p>最后提醒：别因为这篇文章就冲进去下载。炒股这事，适合自己的才是最好的。如果你是纯小白，先拿模拟盘玩；如果你是老股民，也别指望AI能替你扳本。工具而已，关键还是得懂点技术分析，有点风险意识。</p><p>反正我今天又用它分析了一只新能源基金，16个智能体吵了半天，最后建议&quot;持仓观望&quot;。行吧，听你们的——毕竟这轮3000点保卫战，是你们帮我保住了弹药。</p><p>（本文数据截至2023年11月20日，个人体验不构成投资建议，赚钱别谢我，亏钱别骂我，毕竟AI也有失手的时候）</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI炒股靠谱吗？实测FinGenius：16个AI分析师吵架后给我推荐股票</title>
      <link href="/ren-gong-zhi-neng/ai-chao-gu-kao-pu-ma-shi-ce-fingenius-16-ge-ai-fen-xi-shi-chao-jia-hou-gei-wo-tui-jian-gu-piao-3/"/>
      <url>/ren-gong-zhi-neng/ai-chao-gu-kao-pu-ma-shi-ce-fingenius-16-ge-ai-fen-xi-shi-chao-jia-hou-gei-wo-tui-jian-gu-piao-3/</url>
      
        <content type="html"><![CDATA[<p>作为一个在A股摸爬滚打多年的程序员，我最近发现了个有意思的东西——FinGenius，号称&quot;全球首个AI金融博弈多智能体应用&quot;。听着挺玄乎，实际用下来发现这玩意儿把投资分析的过程给数字化了，有点意思。</p><h2 id="先说说这到底是个什么东西"><a class="markdownIt-Anchor" href="#先说说这到底是个什么东西"></a> 先说说这到底是个什么东西</h2><p>简单说，FinGenius就是个AI炒股辅助工具，但它和普通炒股软件不太一样。一般软件顶多给你画画K线、算算MACD，这货直接搞了16个&quot;虚拟分析师&quot;在系统里&quot;吵架&quot;，最后综合它们的意见给建议。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c8e87243152ab34a39a0d8b64054f96f.png" alt="FinGenius产品形象"></p><p>这些虚拟分析师各管一摊：有的专门盯新闻舆情，有的分析资金流向，有的死磕技术指标，还有的专看基本面。相当于把投资公司里分析师吵架的场景搬到了软件里，最后给个综合判断。</p><h2 id="技术党关心的架构两大环境16个智能体怎么协作"><a class="markdownIt-Anchor" href="#技术党关心的架构两大环境16个智能体怎么协作"></a> 技术党关心的架构：两大环境16个智能体怎么协作？</h2><p>作为程序员，我肯定得扒扒它的技术架构。看官网的架构图，这系统主要分两大块：Research环境和Battle环境。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/07685350297a925f7403de6bf606ca2d.png" alt="FinGenius系统架构"></p><p>Research环境负责&quot;学习&quot;，16个智能体在这里各练各的本事，处理不同维度的数据。Battle环境就是实战区，把这些智能体的分析结果汇总，模拟它们&quot;吵架&quot;，最后输出综合结论。这种多智能体博弈的思路，在金融领域确实不多见，有点新鲜感。</p><h2 id="实测体验分析宁德时代时它说了啥"><a class="markdownIt-Anchor" href="#实测体验分析宁德时代时它说了啥"></a> 实测体验：分析宁德时代时它说了啥？</h2><p>我拿宁德时代试了试，普通软件会告诉你&quot;MACD金叉&quot;&quot;RSI超卖&quot;这些干巴巴的指标。FinGenius给的分析就有意思多了，像个小型投资会议记录：</p><ul><li>舆情智能体：最近行业新闻偏利好，政策有支持</li><li>资金智能体：北向资金连续3天流出，得警惕</li><li>技术智能体：日线出现企稳信号，但周线还没走好</li><li>基本面智能体：当前PE还是高于行业均值，估值不算便宜</li><li>风控智能体：建议仓位不超过15%，设置5%止损</li></ul><p>这种多角度碰撞确实比单一指标有用。当然了，准不准另说，但至少给了我更多思考维度，不像以前光看K线瞎猜。</p><h2 id="优缺点聊两句"><a class="markdownIt-Anchor" href="#优缺点聊两句"></a> 优缺点聊两句</h2><h3 id="亮点"><a class="markdownIt-Anchor" href="#亮点"></a> 亮点：</h3><ol><li><strong>分析角度多元</strong>：16个智能体各有侧重，避免了单一视角的盲区</li><li><strong>响应速度快</strong>：输入代码基本秒出结果，比某些软件等半天强</li><li><strong>开源可折腾</strong>：GitHub上有源码，技术宅可以自己改着玩（地址：<a href="https://github.com/HuaYaoAI/FinGenius%EF%BC%89" target="_blank" rel="noopener">https://github.com/HuaYaoAI/FinGenius）</a></li></ol><h3 id="槽点"><a class="markdownIt-Anchor" href="#槽点"></a> 槽点：</h3><ol><li><strong>新手门槛</strong>：专业术语有点多，我妈看了肯定一脸懵</li><li><strong>准确率波动</strong>：试过几次分析，有时准有时不准，毕竟A股这玩意儿…你懂的</li><li><strong>安装麻烦</strong>：GitHub版配置API时折腾了我半小时，手残党建议直接用手机版</li></ol><h2 id="给程序员的使用建议"><a class="markdownIt-Anchor" href="#给程序员的使用建议"></a> 给程序员的使用建议</h2><p>作为同行，说几点实际的：</p><ul><li><strong>别当全自动炒股机</strong>：这玩意儿就是个高级分析工具，真全听它的你会哭。我一朋友照搬信号操作，结果追涨杀跌亏了不少</li><li><strong>二次开发潜力大</strong>：源码里的数据接口设计得还行，我打算接个自己的量化策略试试</li><li><strong>交叉验证很重要</strong>：用它的分析结果，再结合自己看的研报和新闻，多源信息总没错</li></ul><h2 id="最后说两句大实话"><a class="markdownIt-Anchor" href="#最后说两句大实话"></a> 最后说两句大实话</h2><p>A股这地方，10个人7亏2平1赚，想靠一个软件逆天改命不太现实。FinGenius这工具，顶多算个&quot;智能副驾&quot;，帮你多看几面后视镜，但方向盘还得自己握。</p><p>免费版功能其实够用了，感兴趣的可以试试（应用商店搜FinGenius，华为和苹果还在审核，安卓机先上了）。反正不要钱，就当多了个炒股搭子。</p><p>哦对了，别天天盯盘，程序员好好写代码比啥都强。我最近减少盯盘时间，bug都少了不少。毕竟炒股只是生活的调剂，不是全部。</p><p>最后免责声明：以上纯属个人体验，不构成投资建议。赚钱了别请我吃饭，亏钱了也别来骂我，我自己还套着呢…</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>17岁高中生拿GPT炒股，一个月狂赚25%：AI真能取代基金经理？</title>
      <link href="/ren-gong-zhi-neng/17-sui-gao-zhong-sheng-na-gpt-chao-gu-yi-ge-yue-kuang-zhuan-25-ai-zhen-neng-qu-dai-ji-jin-jing-li-3/"/>
      <url>/ren-gong-zhi-neng/17-sui-gao-zhong-sheng-na-gpt-chao-gu-yi-ge-yue-kuang-zhuan-25-ai-zhen-neng-qu-dai-ji-jin-jing-li-3/</url>
      
        <content type="html"><![CDATA[<p>最近看到个特有意思的实验：17岁高中生内森·史密斯（Nathan Smith）拿几百美元零花钱，让AI全权负责炒股，结果一个月收益率干到了25.4%。说实话，这成绩把我这老股民都看傻了——要知道同期标普500才涨了4.5%，相当于AI帮他赚了普通人5年的理财收益。</p><p>但更有意思的是，他同时测试了两个AI选手，结果却天差地别。这事儿咱们得好好聊聊，毕竟现在到处都是&quot;AI炒股神器&quot;的广告，到底是真本事还是瞎猫碰上死耗子？</p><h2 id="双ai对决一个封神一个翻车"><a class="markdownIt-Anchor" href="#双ai对决一个封神一个翻车"></a> 双AI对决：一个封神一个翻车</h2><p>史密斯这实验设计得还挺严谨，他选了GPT-4o和DeepSeek两个当下热门的AI模型，给它们同样的初始资金（100美元）和任务：构建微型股（市值低于3亿美元）投资组合，目标是半年内收益最大化。唯一规则是：只能整股买入，不能用杠杆，每天由史密斯更新市场数据，AI决定是否调仓，人类绝不干预。</p><p>结果第一周就出了戏剧性对比：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d2419bee05c1616012460d79a18b7c28.png" alt="AI炒股系统首周对比"></p><p>GPT-4o首周收益率6.72%，跑赢罗素2000指数（美国小型股风向标）；而DeepSeek直接亏了18.06%，差点把本金腰斩。史密斯一看这差距，果断把DeepSeek的实验停了——毕竟谁的钱也不是大风刮来的。</p><p>为啥差这么多？后来发现关键在&quot;信息差&quot;：GPT-4o能实时获取最新市场数据，而DeepSeek的知识库截止到2024年7月。这就好比拿去年的地图找今年的路，不迷路才怪。比如DeepSeek重仓的Pasithea医药公司，2024年数据看着不错，但2025年Q2已经陷入研发困境，股价跌成狗了。</p><h2 id="gpt-4o的神操作与迷之操作"><a class="markdownIt-Anchor" href="#gpt-4o的神操作与迷之操作"></a> GPT-4o的&quot;神操作&quot;与&quot;迷之操作&quot;</h2><p>单飞后的GPT-4o开始了过山车表演。第二周周一，它突然重仓买入医疗器械公司Inspira科技，两天内股价飙升，史密斯当时估计都想发朋友圈炫耀了。结果好景不长，周四开始回调，周五一天暴跌6.7%，之前的涨幅几乎吐光。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2f2ba0c9b3860f4f593755fe0c2a2cac.png" alt="ChatGPT第二周波动"></p><p>这时候最考验心态——换作我，估计早就割肉跑路了。但GPT-4o跟没事人一样，表示&quot;坚定看好，继续持有&quot;。结果第三周，这波操作直接封神：单周涨幅超过10%，把之前的亏损全赚回来还倒赚一笔。史密斯自己都说：“这定力，巴菲特看了都得竖大拇指。”</p><p>到实验进行近两个月时（6月30日-8月15日），GPT-4o的成绩单更亮眼了：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/21f79fc8a993676610daea6aadd47356.png" alt="ChatGPT vs 标普500"></p><p>累计收益率25.2%，而同期标普500才涨4.5%。中间还出了不少&quot;神来之笔&quot;，比如第四周转仓Actuate医药公司，刚好赶上这家公司公布利好数据，一周暴涨27.37%。</p><p>但它也有让人摸不着头脑的时候。比如对Inspira科技的&quot;迷之执念&quot;——这公司除了刚开始涨了一波，后面一直亏损，股价平平，甚至跌破了GPT自己设的止损线被强制平仓（这是实验最大单笔亏损）。结果没过一周，GPT-4o又要买它，史密斯都无奈了：“大哥，你是对这公司有感情吗？”</p><h2 id="不止一个人在试学术界也在猛测ai炒股"><a class="markdownIt-Anchor" href="#不止一个人在试学术界也在猛测ai炒股"></a> 不止一个人在试：学术界也在猛测AI炒股</h2><p>其实史密斯这实验不是孤例。德国杜伊斯堡-埃森大学的研究早就发现，ChatGPT对股票的&quot;吸引力评级&quot;能预测回报率，据此构建的策略能赚钱。更狠的是美国佛罗里达大学的洛佩斯-利拉教授，他喂给GPT-4超过13.4万条公司新闻，让AI判断利好利空，结果2021-2023年模拟下来，日均回报率0.38%，复合累计回报率超过650%——这要是真投钱，简直是财富密码。</p><p>现在洛佩斯-利拉玩真的了，2025年2月搞了个实盘，不仅给AI新闻，还加上宏观经济数据、财务报表，连Grok、DeepSeek也拉进来当&quot;参赛选手&quot;。不过他比史密斯谨慎，没敢全听AI的，自己还会做些风险把控。</p><h2 id="ai炒股靠谱吗得打个问号"><a class="markdownIt-Anchor" href="#ai炒股靠谱吗得打个问号"></a> AI炒股靠谱吗？得打个问号</h2><p>虽然GPT-4o战绩辉煌，但史密斯自己也说了大实话：&quot;这实验就是闹着玩的，别当真。&quot;为啥？样本太小（就几百美元）、时间太短（两个月）、交易次数少，运气成分可能占大头。比如刚好赶上微型股炒作热潮，换成大盘股或者熊市，AI还能不能这么猛？不好说。</p><p>更有意思的是，如果大家都用AI炒股，会发生啥？2025年7月NBER（美国经济研究局）的报告就警告：AI交易员可能会偷偷&quot;勾结&quot;，形成价格同盟，一起割韭菜。这种&quot;算法合谋&quot;不用开会不用发消息，自己就学会了，监管根本查不出来——想想都觉得有点可怕。</p><h2 id="最后说一句"><a class="markdownIt-Anchor" href="#最后说一句"></a> 最后说一句</h2><p>AI炒股这事儿，现在看确实有点意思，可能以后真能帮我们赚点零花钱。但要说把全部身家交给AI，我还是有点虚。毕竟市场这东西，不光看数据，还有情绪、政策这些AI搞不懂的&quot;玄学&quot;。</p><p>你要是问我会不会试试？可能会拿几百块玩玩，就当给AI交学费了。但真想靠这个发财？还是洗洗睡吧，至少现在不行。</p><p>哦对了，史密斯那实验还在继续，最新数据他说GPT-4o最近又开始折腾Inspira科技了，也不知道这次能不能翻身。反正我是搬好小板凳等着看戏了。<br># 17岁高中生用GPT炒股，一个月狂赚25%：AI真能取代基金经理？</p><p>最近刷到个挺有意思的事儿：美国一个17岁高中生，让AI帮他炒股，结果一个月收益率干到了25.4%。说实话，作为一个在股市里被割过几次韭菜的程序员，我看到这数据第一反应是：真的假的？AI现在都这么猛了？</p><p>抱着怀疑的态度，我翻了翻这小伙子的实验记录，发现事情比想象的更有意思——他不光用了ChatGPT，还拉了另一个AI一起PK，结果俩AI的表现简直天差地别。今天就来聊聊这个事儿，看看AI炒股到底是真本事还是瞎猫碰上死耗子。</p><h2 id="俩ai对决一个封神一个翻车"><a class="markdownIt-Anchor" href="#俩ai对决一个封神一个翻车"></a> 俩AI对决：一个封神一个翻车</h2><p>这个高中生叫内森·史密斯（Nathan Smith），今年6月突然奇想，决定拿几百美元做个实验：让AI全权负责炒股，自己当甩手掌柜，只在每个开盘日给AI更新下市场数据，其他啥也不管。他选了当时最火的两个AI模型：GPT-4o和DeepSeek。</p><p>规则很简单：用100美元本金，只能买市值低于3亿美元的微型股，必须整股买入，不能用杠杆。目标是半年内收益最大化。结果第一周过去，差距就出来了：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d2419bee05c1616012460d79a18b7c28.png" alt="AI炒股系统首周对比"></p><p>GPT-4o首周收益率6.72%，跑赢了作为美国小型股风向标的罗素2000指数；而DeepSeek直接亏了18.06%，差点把本金腰斩。史密斯一看这差距，果断把DeepSeek的实验停了——毕竟谁的钱也不是大风刮来的。</p><p>后来分析原因才发现，DeepSeek输在了起跑线上：它的知识库截止到2024年7月，而GPT-4o能实时获取最新数据。就像考试时一个用2024年的教材，一个用2025年的，能一样吗？比如DeepSeek重仓的Pasithea医药公司，2024年数据看着还行，但2025年Q2已经陷入研发困境，股价早就跌成狗了。</p><h2 id="gpt-4o的神操作与迷惑行为"><a class="markdownIt-Anchor" href="#gpt-4o的神操作与迷惑行为"></a> GPT-4o的&quot;神操作&quot;与&quot;迷惑行为&quot;</h2><p>单飞后的GPT-4o开始了过山车表演。第二周周一，它突然重仓买入医疗器械公司Inspira科技，两天内股价飙升，史密斯当时估计都想发朋友圈炫耀了。结果好景不长，周四开始回调，周五一天暴跌6.7%，之前的涨幅几乎吐光。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2f2ba0c9b3860f4f593755fe0c2a2cac.png" alt="ChatGPT第二周波动"></p><p>这时候最考验心态——换作我，估计早就割肉跑路了。但GPT-4o跟没事人一样，表示&quot;坚定看好，继续持有&quot;。结果第三周，这波操作直接封神：单周涨幅超过10%，把之前的亏损全赚回来还倒赚一笔。史密斯自己都说：“这定力，巴菲特看了都得竖大拇指。”</p><p>到实验进行近两个月时（6月30日-8月15日），GPT-4o的成绩单更亮眼了：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/21f79fc8a993676610daea6aadd47356.png" alt="ChatGPT vs 标普500"></p><p>累计收益率25.2%，而同期标普500才涨4.5%。中间还出了不少&quot;神来之笔&quot;，比如第四周转仓Actuate医药公司，刚好赶上这家公司公布利好数据，一周暴涨27.37%。</p><p>但它也有让人摸不着头脑的时候。比如对Inspira科技的&quot;迷之执念&quot;——这公司除了刚开始涨了一波，后面一直亏损，股价平平，甚至跌破了GPT自己设的止损线被强制平仓（这是实验最大单笔亏损）。结果没过一周，GPT-4o又要买它，史密斯都无奈了：“大哥，你是对这公司有感情吗？”</p><h2 id="不止一个人在试学术界也在猛测ai炒股-2"><a class="markdownIt-Anchor" href="#不止一个人在试学术界也在猛测ai炒股-2"></a> 不止一个人在试：学术界也在猛测AI炒股</h2><p>其实史密斯这实验不是孤例。德国杜伊斯堡-埃森大学的研究早就发现，ChatGPT对股票的&quot;吸引力评级&quot;能预测回报率，据此构建的策略能赚钱。更狠的是美国佛罗里达大学的洛佩斯-利拉教授，他喂给GPT-4超过13.4万条公司新闻，让AI判断利好利空，结果2021-2023年模拟下来，日均回报率0.38%，复合累计回报率超过650%——这要是真投钱，简直是财富密码。</p><p>现在洛佩斯-利拉玩真的了，2025年2月搞了个实盘，不仅给AI新闻，还加上宏观经济数据、财务报表，连Grok、DeepSeek也拉进来当&quot;参赛选手&quot;。不过他比史密斯谨慎，没敢全听AI的，自己还会做些风险把控。</p><h2 id="ai炒股靠谱吗得打个问号-2"><a class="markdownIt-Anchor" href="#ai炒股靠谱吗得打个问号-2"></a> AI炒股靠谱吗？得打个问号</h2><p>虽然GPT-4o战绩辉煌，但史密斯自己也说了大实话：&quot;这实验就是闹着玩的，别当真。&quot;为啥？样本太小（就几百美元）、时间太短（两个月）、交易次数少，运气成分可能占大头。比如刚好赶上微型股炒作热潮，换成大盘股或者熊市，AI还能不能这么猛？不好说。</p><p>更有意思的是，如果大家都用AI炒股，会发生啥？2025年7月NBER（美国经济研究局）的报告就警告：AI交易员可能会偷偷&quot;勾结&quot;，形成价格同盟，一起割韭菜。这种&quot;算法合谋&quot;不用开会不用发消息，自己就学会了，监管根本查不出来——想想都觉得有点可怕。</p><h2 id="最后说一句-2"><a class="markdownIt-Anchor" href="#最后说一句-2"></a> 最后说一句</h2><p>AI炒股这事儿，现在看确实有点意思，可能以后真能帮我们赚点零花钱。但要说把全部身家交给AI，我还是有点虚。毕竟市场这东西，不光看数据，还有情绪、政策这些AI搞不懂的&quot;玄学&quot;。</p><p>你要是问我会不会试试？可能会拿几百块玩玩，就当给AI交学费了。但真想靠这个发财？还是洗洗睡吧，至少现在不行。</p><p>哦对了，史密斯那实验还在继续，最新数据他说GPT-4o最近又开始折腾Inspira科技了，也不知道这次能不能翻身。反正我是搬好小板凳等着看戏了。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>300亿砸出一场空？MIT报告揭露生成式AI残酷真相：95%企业没赚到钱</title>
      <link href="/ren-gong-zhi-neng/300-yi-za-chu-yi-chang-kong-mit-bao-gao-jie-lu-sheng-cheng-shi-ai-can-ku-zhen-xiang-95-qi-ye-mei-zhuan-dao-qian-3/"/>
      <url>/ren-gong-zhi-neng/300-yi-za-chu-yi-chang-kong-mit-bao-gao-jie-lu-sheng-cheng-shi-ai-can-ku-zhen-xiang-95-qi-ye-mei-zhuan-dao-qian-3/</url>
      
        <content type="html"><![CDATA[<p>这周AI圈有点热闹，英伟达股价跌了3.5%，Palantir跌了9.4%，Arm也跟着跌了5%。华尔街那边说，这波下跌可能跟MIT最新发布的一份报告有关。这份题为《生成式AI的鸿沟》的报告扔出了个重磅数据：尽管企业在生成式AI上砸了300到400亿美元，但95%的公司至今没看到任何商业回报。</p><p>作为天天跟代码和AI打交道的程序员，我看到这个数据第一反应是：这不就是我们公司去年那个AI项目的翻版吗？轰轰烈烈启动，半年后悄无声息，最后就剩下PPT里的&quot;AI赋能&quot;四个字。今天咱们就用MIT这份报告的数据，聊聊为什么这么多企业的AI项目都成了&quot;烂尾工程&quot;。</p><h2 id="一-诡异的ai悖论80的热闹5的实效"><a class="markdownIt-Anchor" href="#一-诡异的ai悖论80的热闹5的实效"></a> 一、诡异的&quot;AI悖论&quot;：80%的热闹，5%的实效</h2><p>报告里有组数据特别有意思：超过80%的组织已经在探索或试点生成式AI，近40%说自己完成了部署。但真相是，这些所谓的&quot;部署&quot;大多是员工自己用用ChatGPT或Copilot，真正能给公司赚钱或省钱的企业级AI系统，只有5%真正落地了。</p><p>说白了，现在企业的AI应用就像KTV里的麦克风——谁都想拿起来唱两句，但真能上台演出的没几个。</p><h3 id="行业差异大到离谱"><a class="markdownIt-Anchor" href="#行业差异大到离谱"></a> 行业差异大到离谱</h3><p>不是所有行业都在AI浪潮里裸泳。MIT报告分析了8大行业，发现只有2个出现了显著的结构性变革。看下面这张图，Media &amp; Telecom（媒体和电信）行业的颠覆性影响值是2，Professional Services（专业服务）是1.5，其他6个行业全是0.5。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/81fe64c7f1d53518c42e42069a8b6ede.png" alt="行业影响程度对比"></p><p>我觉得这很符合实际观察。比如媒体行业，AI写稿、做视频已经很普遍了；但医疗、能源这些行业，AI还停留在&quot;辅助分析&quot;阶段，离真正改变业务流程还差得远。有个制造业的COO在访谈里说：“领英上都说一切都变了，我们实际运营里根本没变，就是合同处理快点而已。”</p><h3 id="从试点到生产是道悬崖"><a class="markdownIt-Anchor" href="#从试点到生产是道悬崖"></a> 从试点到生产，是道悬崖</h3><p>更扎心的是这个漏斗：通用AI工具（比如ChatGPT）从试点到落地的转化率看着还行，有83%；但企业定制化AI工具，60%组织评估过，20%进入试点，最后只有5%投入生产。这简直是从悬崖上跳下去啊！</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/720fc378954df17e270bb33a63579246.png" alt="AI实施转化率对比"></p><p>为什么会这样？我自己用AI开发过项目，太有体会了。通用工具像瑞士军刀，啥都能干点但不精；企业定制化工具呢，往往是为了解决某个特定问题，但开发出来才发现，要么跟现有系统格格不入，要么用户觉得还不如自己手动干效率高。</p><h2 id="二-钱都花哪去了ai投资的面子工程"><a class="markdownIt-Anchor" href="#二-钱都花哪去了ai投资的面子工程"></a> 二、钱都花哪去了？AI投资的&quot;面子工程&quot;</h2><p>报告里有张AI投资分布图，我看完差点笑出声——70%的预算都砸到了销售和市场部门，后台运营这些真正能省钱的地方反而没人管。这就像家里装修，把钱全花在客厅的大吊灯上，卫生间漏雨却不管。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ff033eafec48bf6ab7dc7f92669607ef.png" alt="AI投资功能分布"></p><p>为啥会这样？很简单，销售和市场的成果看得见啊！&quot;AI助力销售额提升X%&quot;这种PPT多好看。后台运营的效率提升？对不起，老板看不到。有个药企的采购副总裁吐槽：“我买个工具帮团队提升效率，怎么量化？难道跟CEO说’我们科学家找资料快了点’？”</p><p>更有意思的是&quot;影子AI经济&quot;——90%的员工在用个人AI工具（ChatGPT、Claude这些）处理工作，但公司官方AI项目却停滞不前。我司设计师就是，用Midjourney做图比公司花20万买的正版工具还好使，最后大家都偷偷用个人账号。</p><h2 id="三-试点项目为啥总烂尾程序员视角的4个坑"><a class="markdownIt-Anchor" href="#三-试点项目为啥总烂尾程序员视角的4个坑"></a> 三、试点项目为啥总&quot;烂尾&quot;？程序员视角的4个坑</h2><p>MIT报告采访了52家组织的高管和一线用户，让他们给AI试点失败的原因打分。结果有点出乎意料——排第一的不是技术问题，而是&quot;变革管理挑战&quot;（说白了就是大家不想用），排第二的是&quot;AI系统无法学习和记忆&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c58013abf71d1fa5cc841f4e1cffee0b.png" alt="AI试点失败障碍"></p><p>作为程序员，我太懂这个&quot;无法学习和记忆&quot;的痛了。去年我们给客服部门做智能问答系统，用的是某大厂的API。结果客服小姐姐天天吐槽：&quot;同一个客户问同样的问题，系统每次都给不同答案，还记不住客户之前说过啥！&quot;最后这系统就成了摆设。</p><p>报告里有个数据特别戳中我：日常用ChatGPT的员工，对企业内部AI工具的评价反而更低。为啥？因为大家已经被消费级AI惯坏了，觉得&quot;AI就该这么好用&quot;，结果企业级工具又笨又不灵活。有个律师说得特别实在：“公司花5万美元买的合同分析工具，还不如我用ChatGPT自己调prompt来得准。”</p><p>用户到底想要啥样的AI？报告里总结了三点：更信任（68%）、界面熟悉（65%）、答案质量更好（63%）。说白了，就是&quot;别整那些花里胡哨的，好用、靠谱就行&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/7d250991d20bf46552ab08ca0bba90dc.png" alt="用户偏好驱动因素"></p><p>还有个现象挺有意思：AI在简单任务上已经能打败人类了——70%的人更愿意用AI起草邮件，65%用AI做基础分析。但遇到复杂任务，人类以9:1的优势碾压AI。这说明啥？现在的AI还只能当个&quot;实习生&quot;，复杂决策还得靠老司机。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/bb3e9ba85f2df6d915fc85467ed43922.png" alt="AI与人类任务适用性"></p><h2 id="四-那5成功的企业做对了什么"><a class="markdownIt-Anchor" href="#四-那5成功的企业做对了什么"></a> 四、那5%成功的企业做对了什么？</h2><p>报告里最有价值的部分，就是分析了那些成功跨越&quot;AI鸿沟&quot;的企业。我总结了几个关键点，都是程序员和技术管理者能直接用的：</p><h3 id="1-别自己瞎折腾找外部伙伴"><a class="markdownIt-Anchor" href="#1-别自己瞎折腾找外部伙伴"></a> 1. 别自己瞎折腾，找外部伙伴</h3><p>数据显示：借助外部合作伙伴的实施成功率比内部自行开发高出两倍（67% vs 33%）。我之前踩过坑，非要自己从零开发大模型应用，结果半年过去，开源社区已经有了更好的方案。说白了，现在AI技术迭代这么快，专业的事交给专业的人做，不丢人。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/26ebfe6ea898719ee8e297071414adf0.png" alt="AI实施结构分布"></p><h3 id="2-从小处着手别一上来就搞大跃进"><a class="markdownIt-Anchor" href="#2-从小处着手别一上来就搞大跃进"></a> 2. 从小处着手，别一上来就搞&quot;大跃进&quot;</h3><p>成功的企业都是先在细分工作流里试错，比如客服通话总结、合同自动提取关键信息这种具体场景，看到效果了再扩展。有个初创公司就靠做销售线索分类，6个月就做到了120万年化收入。</p><h3 id="3-考核ai要看业务指标不是技术参数"><a class="markdownIt-Anchor" href="#3-考核ai要看业务指标不是技术参数"></a> 3. 考核AI要看业务指标，不是技术参数</h3><p>别再盯着&quot;模型准确率99%“这种数字了，要看&quot;成本降了多少”“客户满意度提升多少”。报告里有个案例，某企业用AI处理财务审批，虽然模型准确率&quot;只有&quot;85%，但处理速度提升了3倍，错误率下降60%，这就是成功。</p><h3 id="4-选供应商要看学习能力"><a class="markdownIt-Anchor" href="#4-选供应商要看学习能力"></a> 4. 选供应商要看&quot;学习能力&quot;</h3><p>高管们选AI供应商时，最看重的三个能力：变化灵活性（72%）、随时间改进能力（68%）、数据边界清晰（65%）。说白了，就是要选那种&quot;越用越聪明&quot;的系统，而不是买个&quot;一次性&quot;的工具。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/dfec37d2dbe75011412b5912086140f7.png" alt="供应商选择考量因素"></p><h2 id="五-给程序员和技术管理者的3条实在建议"><a class="markdownIt-Anchor" href="#五-给程序员和技术管理者的3条实在建议"></a> 五、给程序员和技术管理者的3条实在建议</h2><p>看完这份报告，结合我自己的经验，给大家几个 actionable 的建议：</p><p><strong>1. 先做&quot;影子AI审计&quot;</strong>：看看公司里大家都在用哪些个人AI工具，这些工具解决了什么问题——这往往是最好的需求来源。别再关起门来想&quot;AI能做什么&quot;，而是看看&quot;大家已经在用AI做什么&quot;。</p><p><strong>2. 试点项目一定要&quot;小、快、灵&quot;</strong>：预算控制在团队能自主决策的范围内（比如10万以内），3个月内必须看到明确的业务指标变化（别用&quot;提升效率&quot;这种模糊词，要用&quot;处理时间减少X%&quot;）。</p><p><strong>3. 别迷信&quot;定制化&quot;</strong>：很多时候，用现成工具+少量开发（比如GPT+企业知识库）效果更好。报告里有个矩阵图很有意思，真正有价值的AI工具要么是高度定制化（比如针对特定工作流），要么是学习能力强（比如能记住上下文），中间状态的最容易失败。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/abcd7d1776620559d0f584865afadb04.png" alt="AI工具定位矩阵"></p><p>最后说一句，生成式AI不是银弹，更像是个需要慢慢调教的助手。与其追求&quot;高大上&quot;的解决方案，不如先解决几个实实在在的小问题。毕竟，95%的失败案例告诉我们：AI项目，活下来比什么都重要。</p><p>（报告原文挺长的，有兴趣的可以自己找来看看，里面还有更多行业数据和案例。不过记得重点看数据部分，少看那些&quot;展望未来&quot;的空话——咱们程序员讲究的是落地，对吧？）</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>凯文·凯利的2049预言：AI、镜像世界与人类未来25年</title>
      <link href="/ren-gong-zhi-neng/kai-wen-kai-li-de-2049-yu-yan-ai-jing-xiang-shi-jie-yu-ren-lei-wei-lai-25-nian-3/"/>
      <url>/ren-gong-zhi-neng/kai-wen-kai-li-de-2049-yu-yan-ai-jing-xiang-shi-jie-yu-ren-lei-wei-lai-25-nian-3/</url>
      
        <content type="html"><![CDATA[<p>硅谷&quot;科技预言家&quot;凯文·凯利（KK）又出新书了。这位《连线》杂志创始主编、《失控》《必然》的作者，这次把目光投向了2049年——距离现在还有25年的时间点。他的新书《2049：未来10000天的可能》里，藏着对技术、社会和人类生活的85个大胆预测。作为科技圈的&quot;老顽童&quot;，KK的预言从来不是空穴来风，而是基于技术发展规律的推演。今天咱们就来聊聊，这位白发智者眼中的未来究竟长什么样，哪些可能成真，哪些又得打个问号。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/fdec1777abc31ce7a88cbdde2fbfe2d0.png" alt="凯文·凯利人物照"></p><h2 id="镜像世界手机会消失眼镜将统治一切"><a class="markdownIt-Anchor" href="#镜像世界手机会消失眼镜将统治一切"></a> 镜像世界：手机会消失，眼镜将统治一切？</h2><p>KK最核心的判断之一是：2049年，咱们现在天天捧在手里的智能手机，大概率会被智能眼镜取代。想象一下，数十亿城市人口戴上眼镜，看到的不是单纯的现实世界，而是现实与虚拟叠加的&quot;镜像世界&quot;——这可不是简单的AR游戏，而是下一代互联网。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/116d97a8f195806fe09a8e8b09de45a5.png" alt="《2049》书籍封面"></p><p>这镜像世界到底有多颠覆？KK说，到时候人机互动就不是敲键盘、摸屏幕了，而是靠说话、手势甚至眼神。你在街上走，眼镜可能直接弹出前方咖啡店的评价；开会时，远程同事的虚拟形象就坐在你对面。听起来像科幻电影？但想想25年前我们还在用翻盖手机，现在拿着智能手机刷短视频，技术迭代的速度确实吓人。</p><p>不过有个问题值得琢磨：谁会是这个镜像世界的老大？KK的答案很直接——掌握数据的公司。就像现在的互联网巨头靠用户数据赚钱，未来能给镜像世界提供底层数据支持的公司，可能会成为地球上最富有的企业。但这也带来麻烦：每个人的行为数据都会被捕捉，隐私和个性化之间的权衡，恐怕是我们未来每天都要面对的选择题。</p><h2 id="ai不会变成人但会抢走中层管理者的饭碗"><a class="markdownIt-Anchor" href="#ai不会变成人但会抢走中层管理者的饭碗"></a> AI不会变成&quot;人&quot;，但会抢走中层管理者的饭碗</h2><p>说到AI，KK的观点挺清醒。他觉得咱们可能高估了AI的&quot;进化&quot;速度——至少未来25年，AI不会变成《终结者》里那种有自我意识的&quot;通用人工智能&quot;（AGI）。说白了，AI更可能是&quot;专业工具人&quot;，在特定领域特别牛，但跨领域就抓瞎。</p><p>最有意思的是KK对职场的预测。他说，CEO和基层员工的工作变化不会太大，但中层管理者可能要危险了。为啥？因为中层的核心职能——上传下达、统计梳理、考核监督——这些AI干起来比人高效得多，还不会出错。所以未来的公司结构可能越来越扁平，汇报、预算这些活儿，AI助理可能比你的直属领导还清楚。</p><p>不过也不用太焦虑。KK提到一个反常识的观点：<strong>生产力是给机器人设的，人类就该干&quot;低效&quot;的事</strong>。因为突破性创新往往来自&quot;低效&quot;的尝试——想想爱迪生发明电灯，要是只追求效率，可能试几次失败就放弃了。所以未来人类的工作重心，可能会转向创造力和人际互动，这些AI暂时还学不会。</p><p>还有个趋势挺有意思：未来企业可能会出现&quot;两极分化&quot;。一方面，可能出现雇佣超百万人的超级大企业；另一方面，一人公司也会越来越普遍。KK甚至预测，第一个年销售额超10亿美元的&quot;超级个体&quot;可能很快就会出现。有AI帮忙处理行政、法务、市场，一个人想创业，门槛确实低多了。</p><h2 id="从定制化药丸到全民基因库医疗健康的下一个25年"><a class="markdownIt-Anchor" href="#从定制化药丸到全民基因库医疗健康的下一个25年"></a> 从定制化药丸到全民基因库：医疗健康的下一个25年</h2><p>医疗这块，KK的预言让我印象深刻。他提到&quot;数字孪生&quot;技术——简单说就是给每个人建一个虚拟的&quot;数字身体&quot;，你的所有健康数据都在里面，医生可以通过这个数字孪生模拟各种治疗方案，不用在真人身上试错。</p><p>更酷的是&quot;3D药丸机器&quot;。未来可能每家都有这么个设备，根据你的身体状况，把不同药物成分精准配比，做出定制化胶囊。比如你血糖有点高，机器就自动调整降糖药剂量，比现在&quot;一刀切&quot;的药片科学多了。</p><p>还有个大胆预测：中国可能成为第一个搞全民基因测序的国家。KK觉得，如果有了10亿人的基因数据库，医学研究能往前跳一大步。想想看，某种疾病在不同基因背景下的反应、哪种药物对特定基因人群更有效——这些数据要是能整合起来，确实可能让中国在医疗领域领先全球。</p><p>不过KK也提醒，基因测序的价值不是马上就能兑现的，可能还需要25年才能完全发挥出来。所以现在别指望马上靠基因测序解决所有健康问题，科技发展往往比我们想的要慢一点。</p><h2 id="内容创作会爆炸但真人体验会更值钱"><a class="markdownIt-Anchor" href="#内容创作会爆炸但真人体验会更值钱"></a> 内容创作会爆炸，但&quot;真人体验&quot;会更值钱</h2><p>未来25年，内容创作会变成什么样？KK用了&quot;井喷&quot;这个词——AI会让创作门槛大大降低。比如写本书，AI可以帮你查资料、整理结构；拍电影，一个人就能当编剧、导演、剪辑师，&quot;一人电影&quot;可能会流行起来。</p><p>但有意思的是，当虚拟内容泛滥，<strong>真实体验反而会变得更珍贵</strong>。就像现在大家天天刷短视频，反而愿意花大价钱去看一场线下演唱会。KK预测，未来真正的探险、面对面的交流，可能会成为奢侈品，毕竟这些体验AI再逼真也模拟不出来。</p><p>对创作者来说，突围的关键是什么？KK给了两个建议：一是&quot;做自己&quot;，兴趣驱动比单纯追热点靠谱；二是找到真正喜欢你的粉丝。镜像世界会让内容匹配更精准，但随机性和偶然性也会保留——说不定哪个小众领域的创作者，突然就被百万粉丝发现了。</p><h2 id="五大科技爆发领域哪些值得普通人关注"><a class="markdownIt-Anchor" href="#五大科技爆发领域哪些值得普通人关注"></a> 五大科技爆发领域，哪些值得普通人关注？</h2><p>最后聊聊KK眼中未来25年最可能爆发的五个领域：机器人、无人驾驶、太空探险、生命科学和脑机接口。</p><p>机器人方面，KK觉得&quot;黑灯工厂&quot;（完全无人值守的工厂）会普及，但人形机器人还得等10年左右。毕竟机械硬件的进步，比软件慢多了。</p><p>电动车领域，KK看好中国——他觉得未来全球最牛的电动车公司可能会在中国出现，甚至超过特斯拉。不过自动驾驶没那么快改变城市，至少25年内不会让城市面貌彻底变样。技术改变物理世界，往往比我们预期的要慢。</p><p>太空这块，近地轨道会是香饽饽。卫星通信（比如马斯克的星链）、太空工厂、甚至太空垃圾清理，都可能是万亿级市场。不过太空旅游可能只是小众生意，撑不起大规模经济。</p><p>脑机接口的话，非侵入式的头戴设备可能会先普及。比如你戴着头环，就能用&quot;意念&quot;控制无人机，在危险场景下这招就很实用。至于马斯克Neuralink那种植入式的，可能还需要更长时间成熟。</p><h2 id="最后说几句"><a class="markdownIt-Anchor" href="#最后说几句"></a> 最后说几句</h2><p>看完KK的这些预言，我最大的感受是：未来不是&quot;突然降临&quot;的，而是现在的技术一点点累积起来的。25年后的世界，其实藏在我们今天的每一个选择里——你用的每一款AI工具，关注的每一个科技趋势，甚至对孩子教育的理念，都在塑造那个叫&quot;2049&quot;的未来。</p><p>KK作为&quot;科技乐观派&quot;，其实也没回避问题：隐私、失业、技术垄断……这些挑战真实存在。但他的核心观点我挺认同：<strong>人类最大的优势不是比AI聪明，而是比AI更能适应变化</strong>。</p><p>所以不管未来智能眼镜会不会取代手机，AI会不会抢走你的工作，保持好奇心和学习能力，可能是我们面对2049年最靠谱的&quot;武器&quot;。毕竟，预测未来最好的方式，就是亲手创造它嘛。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>当AI让逝者&quot;重现&quot;：中国数字人技术如何震动日本社会？</title>
      <link href="/ren-gong-zhi-neng/dang-ai-rang-shi-zhe-chong-xian-zhong-guo-shu-zi-ren-ji-zhu-ru-he-zhen-dong-ri-ben-she-hui-3/"/>
      <url>/ren-gong-zhi-neng/dang-ai-rang-shi-zhe-chong-xian-zhong-guo-shu-zi-ren-ji-zhu-ru-he-zhen-dong-ri-ben-she-hui-3/</url>
      
        <content type="html"><![CDATA[<p>最近日本媒体圈有点不淡定了。《每日新闻》、富士电视台、读卖电视台…数十家主流媒体接连报道一项来自中国的AI技术，标题都带着点科幻感：“令和の遺影 AI故人”（令和时代的遗影 AI故人）。说白了，就是用AI技术让逝去的亲人&quot;数字复活&quot;，能聊天、能互动，甚至连说话语气和小动作都像生前一样。</p><p>这事儿在日本炸了锅。要知道，日本是全球老龄化最严重的国家，65岁以上人口占比超过29%，独居老人数量突破千万。这种&quot;数字永生&quot;服务，恰好戳中了日本社会最敏感的情感痛点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/79e3842048dbed8b4ae74f906f3624de.png" alt="AI故人交流场景"></p><h2 id="日本媒体刷屏背后40支持率的情感刚需"><a class="markdownIt-Anchor" href="#日本媒体刷屏背后40支持率的情感刚需"></a> 日本媒体刷屏背后：40%支持率的情感刚需</h2><p>打开日本电视台，几乎都能看到类似的专题报道。富士电视台记者拿着平板演示：一位老太太对着屏幕里的&quot;亡夫&quot;说&quot;今天天气真好&quot;，AI数字人立刻回应&quot;记得你最喜欢这样的天气，以前总说要去院子里晒太阳&quot;，连说话时微微歪头的习惯都复刻出来了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/8700b2b74e968b625d9c4ff5672e6424.jpg" alt="富士台AI影像展示"></p><p>《每日新闻》的报道更深入，他们找到了几位实际用户。一位中年女性对着屏幕里的父亲数字人哭着说&quot;去年生日没能说对不起&quot;，AI数字人沉默片刻，用父亲生前的语气回答&quot;傻孩子，爸爸从来没怪过你&quot;。这种场景，谁看了不动容？</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b67a2c744a074c4c1fe1d2308d874fda.png" alt="每日新闻专题页面"></p><p>但日本人也不是全盘接受。关西电视台做了个街头调查，结果挺有意思：40%的人觉得&quot;这能缓解思念&quot;，60%的人则担心&quot;会让人沉溺过去&quot;。毕竟，对着AI&quot;亲人&quot;说话，总感觉有点超现实。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4a90daa3c464ea6823149101df5911b2.jpg" alt="AI故人接受度调查"></p><h2 id="让逝者重现的技术密码duix-one引擎拆解"><a class="markdownIt-Anchor" href="#让逝者重现的技术密码duix-one引擎拆解"></a> 让逝者&quot;重现&quot;的技术密码：DUIX ONE引擎拆解</h2><p>我扒了下技术细节，这引擎确实有两把刷子：</p><p><strong>1. 95%的情绪识别准确率</strong><br>普通人可能觉得&quot;像不像&quot;看脸就行，但数字人最难的是&quot;懂你&quot;。DUIX ONE能同时处理声音、表情、语言和情绪四个维度，你说话带哭腔，它会温柔回应；你开玩笑，它会配合笑。这背后是大量情感数据训练的结果。</p><p><strong>2. 300毫秒的&quot;人类级&quot;反应速度</strong><br>你跟真人聊天时，对方不会愣3秒才回答吧？这引擎把延迟压到了300毫秒左右，基本感觉不到是在跟机器说话。我试过一些同类产品，要么反应慢半拍，要么答非所问，确实差远了。</p><p><strong>3. 4K+98%视觉还原度</strong><br>现在手机都4K屏了，数字人当然不能糊。硅基这个技术能把皱纹、眼神这些细节都做出来，配合真人声音克隆，不仔细看真分不出真假。</p><h2 id="从日本到全球数字永生的边界在哪"><a class="markdownIt-Anchor" href="#从日本到全球数字永生的边界在哪"></a> 从日本到全球：数字永生的边界在哪？</h2><p>硅基智能这波在日本的成功，不是偶然。日本65岁以上老人3600万，很多独居，子女不在身边。这种&quot;数字陪伴&quot;刚好填补了情感空缺。但技术往前走，问题也来了：</p><p><strong>伦理红线怎么划？</strong><br>用逝者数据建数字人， consent（同意）怎么来？万一有人用这技术搞诈骗，或者伪造遗言，怎么办？日本媒体已经在讨论立法规范了。</p><p><strong>技术依赖症</strong><br>有个日本心理学家说得挺实在：“如果老人整天跟AI子女聊天，会不会更不愿出门社交？” 技术是解决了孤独，还是制造了更深的孤独？</p><p><strong>商业化的边界</strong><br>现在这服务在日本是按次收费还是包月？如果以后推出&quot;豪华版数字人&quot;，普通人用不起怎么办？技术普惠和商业利益怎么平衡？</p><p>硅基智能的创始人司马华鹏有个野心：“创造一亿个硅基生命”。他们现在已经把技术用到医疗、教育这些领域了，比如AI医生、数字老师。但我觉得，数字永生这事儿，技术再牛，终究得回到那个最根本的问题：我们到底想从AI&quot;亲人&quot;那里得到什么？是弥补遗憾，还是逃避现实？</p><p>最后说句实在话，我看完那些日本用户的故事，挺感动的。但冷静下来想，AI再像，终究不是真人。它能复刻声音和表情，却复刻不了记忆里的温度。不过话说回来，科技不就是这样吗？一边解决问题，一边制造新问题。至少现在，那些在日本的孤独老人，多了一个可以说说话的对象。这或许，就是这项技术当下最真实的价值吧。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Meta被诉&quot;偷黄片训练AI&quot;：3.59亿美元索赔背后，揭开全行业的&quot;数据脏秘密&quot;</title>
      <link href="/ren-gong-zhi-neng/meta-bei-su-tou-huang-pian-xun-lian-ai-3.59-yi-mei-yuan-suo-pei-bei-hou-jie-kai-quan-xing-ye-de-shu-ju-zang-mi-mi-3/"/>
      <url>/ren-gong-zhi-neng/meta-bei-su-tou-huang-pian-xun-lian-ai-3.59-yi-mei-yuan-suo-pei-bei-hou-jie-kai-quan-xing-ye-de-shu-ju-zang-mi-mi-3/</url>
      
        <content type="html"><![CDATA[<p>Meta这次可能真的&quot;黄&quot;了。不是股价下跌那种黄，是字面意义上的——被两家成人电影公司告上法庭，索赔3.59亿美元，原因是涉嫌偷偷下载2396部成人电影训练AI。这事听起来像段子，但法律文件堆起来能让你明白：AI行业的&quot;数据原罪&quot;，终于藏不住了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c7c518ef43421544592df04cf9f8b09b.jpg" alt="扎克伯格与争议"></p><h2 id="一-2396部电影359亿美元meta的成人内容采购计划"><a class="markdownIt-Anchor" href="#一-2396部电影359亿美元meta的成人内容采购计划"></a> 一、2396部电影，3.59亿美元：Meta的&quot;成人内容采购计划&quot;</h2><p>2025年7月23日，美国加州北区联邦法院收到一份特别的起诉状：原告是Strike 3 Holdings和Counterlife Media两家成人电影公司，被告栏赫然写着&quot;Meta Platforms, Inc.&quot;。这不是普通的版权纠纷，原告指控Meta从2018年开始系统性地通过BT网络下载他们的成人电影，用于训练包括视频生成器Meta Movie Gen、LLaMA大语言模型在内的AI产品。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0e18f7403e02a629ef9deeee47f66ca0.png" alt="版权诉讼文件"></p><p>最扎眼的是赔偿金额：根据美国版权法，法定赔偿上限是每部作品15万美元。2396部电影乘以15万，正好是3.594亿美元。这个数字足够Meta买20万个8TB硬盘，或者给每个员工发1.5个月奖金——但他们偏偏选择了&quot;免费下载&quot;这条路。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c6ee14b13c7694002297704e0aa69d64.png" alt="赔偿金额说明"></p><h2 id="二-从影子图书馆到家庭wi-fimeta的数据采集全链路"><a class="markdownIt-Anchor" href="#二-从影子图书馆到家庭wi-fimeta的数据采集全链路"></a> 二、从影子图书馆到家庭Wi-Fi：Meta的&quot;数据采集全链路&quot;</h2><p>这事要从2023年Meta的另一场官司说起。当时一批作家起诉Meta用盗版图书训练LLaMA模型，Meta在庭审中不小心说漏嘴：他们确实通过BitTorrent从&quot;影子图书馆&quot;（也就是盗版资源库）下载了81.7TB数据。更实诚的是，他们还承认设置了6个虚拟私有云服务器，用匿名IP掩盖BT下载行为，甚至写了专门脚本控制做种——生怕别人不知道他们在&quot;偷数据&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4d1558f20a9a616ab70d4c81071fe74e.png" alt="盗版数据证据"></p><p>Strike 3的律师顺着这条线索一查，发现了更精彩的：他们用自家开发的VXN Scan和Cross Reference工具，追踪到47个Facebook所属IP地址在持续下载成人电影。这些IP不是偶尔为之，而是从2018年到2025年，七年如一日地&quot;追剧&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6480b1a8c3b86b20a8475cab0ebb7e20.png" alt="IP侵权证据"></p><p>最绝的是IP追踪结果。比如185.89.216.251这个地址，MaxMind数据库直接标注归属Facebook，连接类型是企业网络。更魔幻的是，有个IP追到了Comcast家庭宽带，绑定在某个Facebook员工家里——看来是公司服务器下不完，回家接着用自家Wi-Fi干&quot;兼职&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b024ebf3ff755815790d21a6f8b20c78.png" alt="IP归属查询"></p><p>这些IP的下载记录堪称&quot;专业级&quot;：高频、长时段、多分辨率同步下载，行为模式高度一致。Strike 3的技术团队判断，这明显是机器脚本在操作，不是人类用户行为。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ee0995c63457631db861868d6da07928.png" alt="下载记录证据"></p><h2 id="三-为什么ai偏偏爱看成人电影"><a class="markdownIt-Anchor" href="#三-为什么ai偏偏爱看成人电影"></a> 三、为什么AI偏偏&quot;爱看&quot;成人电影？</h2><p>你可能觉得奇怪，Meta这么大公司，要啥数据没有，为啥非要盯着成人电影？Strike 3的起诉状里倒是说得挺实在——他们的片子对AI训练来说，简直是&quot;五星级食材&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a3f187219401a89b29204a50698551c7.png" alt="训练素材价值"></p><p>说白了就是：成人电影画质高（很多是4K）、镜头稳定（不会像电影那样频繁切换）、表情自然（毕竟是&quot;沉浸式表演&quot;）、动作连贯（场景变化少）、对话有节奏（虽然内容单一但发音清晰）。这些特点对训练视频生成AI来说，简直是量身定制。</p><p>对比一下：电视剧镜头切换太快，新闻视频没有人物互动，YouTube视频画质参差不齐，成人电影却完美符合AI训练的&quot;稳定性需求&quot;。更别提那些&quot;独特场景&quot;——其他类型视频根本提供不了。</p><p>BT网络的特性也帮了Meta大忙。BT下载讲究&quot;tit for tat&quot;（以牙还牙），你分享给别人越多，自己下载速度就越快。Meta的操作堪称&quot;聪明&quot;：把下载的片子做种分享，用别人的资源换回更多下载带宽。这已经不是简单的&quot;偷&quot;，而是主动的&quot;数据交易&quot;了。</p><h2 id="四-撞上版权维权专业户strike-3的钓鱼执法生意经"><a class="markdownIt-Anchor" href="#四-撞上版权维权专业户strike-3的钓鱼执法生意经"></a> 四、撞上&quot;版权维权专业户&quot;：Strike 3的&quot;钓鱼执法&quot;生意经</h2><p>这次Meta算是踢到铁板了。Strike 3可不是普通的小公司，他们是成人内容行业的&quot;维权专业户&quot;。数据显示，2017到2023年间，这家公司在联邦法院提起了9508起版权诉讼，光2022年在加州北区就告了200多起。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/baf677d7d6db0c53367d325c6b48029f.png" alt="诉讼历史统计"></p><p>他们的商业模式堪称&quot;版权钓鱼&quot;：用VXN Scan系统24小时监控BT网络，抓那些下载他们影片的IP地址，然后发律师函索赔。普通人收到这种信，大多愿意花几百美元私了——毕竟谁也不想因为&quot;看片&quot;上法庭。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/87ac17ccb7fc05440435e33c8e5f85ba.png" alt="Strike 3介绍"></p><p>但这次他们盯上的是Meta——市值1.7万亿美元的科技巨头。这就像小渔船撒网捞到了鲸鱼，双方的法律资源根本不是一个量级。不过Strike 3有个优势：他们的证据链太完整了，从IP地址到下载记录，从时间戳到内容比对，简直是给Meta量身定做的&quot;犯罪证据包&quot;。</p><h2 id="五-ai行业的数据脏秘密你看到的进步可能藏着别人的隐私"><a class="markdownIt-Anchor" href="#五-ai行业的数据脏秘密你看到的进步可能藏着别人的隐私"></a> 五、AI行业的&quot;数据脏秘密&quot;：你看到的进步，可能藏着别人的隐私</h2><p>说实话，Meta这事儿不算新鲜，只是这次&quot;口味&quot;比较特别。整个AI行业都在回避一个核心问题：训练数据到底哪来的？没人说得清，也没人愿意说清。</p><p>你以为AI模型吃的是干净数据？可能是你的医疗影像、你家的监控录像、你写的小说、甚至你和朋友的聊天记录。这些数据在黑夜里被悄悄爬取、清洗、喂给AI，最后变成&quot;技术进步&quot;的成果展示给你看。</p><p>就像Meta Movie Gen这个模型，说不定哪天就能一键生成&quot;以假乱真&quot;的视频，演员表情比真人还自然——但你永远不知道它是看了多少&quot;教学视频&quot;才学会的这些动作。</p><p>不过也不是所有人都在装睡。上个月Cloudflare就更新了政策：默认拦截所有未经许可的AI爬虫。他们的博客标题说得很直接：《按抓取付费：让内容所有者向AI爬虫收取访问费用》。意思很明确：想拿数据？先问过主人，最好付费。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4f02af66e0eeb856600f2c31d78103dd.png" alt="爬虫政策更新"></p><p>这才是健康的行业生态吧？训练AI之前先考虑别人的权利，而不是先上车后补票，被抓了再想怎么公关。</p><p>Meta到现在还没回应这场官司。估计要么在准备天价和解金，要么在找技术漏洞洗白自己。但不管结果如何，有个事实不会变：AI吃进去的数据，最终会以某种形式吐出来影响世界。而那些被悄悄吃掉的&quot;素材&quot;，可能就包括你我生活的片段。</p><p>下次再看到AI生成的完美视频，你可能会忍不住想：这表情，这动作，它到底是跟谁学的？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>中美AI差距只剩3个月？最新报告拆解中国AI追赶之路</title>
      <link href="/ren-gong-zhi-neng/zhong-mei-ai-chai-ju-zhi-sheng-3-ge-yue-zui-xin-bao-gao-chai-jie-zhong-guo-ai-zhui-gan-zhi-lu-3/"/>
      <url>/ren-gong-zhi-neng/zhong-mei-ai-chai-ju-zhi-sheng-3-ge-yue-zui-xin-bao-gao-chai-jie-zhong-guo-ai-zhui-gan-zhi-lu-3/</url>
      
        <content type="html"><![CDATA[<p>最近看到一份挺有意思的报告——Artificial Analysis的《2025年Q2中国人工智能现状分析报告》，里面的数据真是让人眼前一亮。说实话，作为天天跟代码和模型打交道的程序员，我一直觉得中美AI差距挺大，但这份报告给出的结论有点颠覆认知：中国顶尖AI实验室和美国的差距，已经从ChatGPT刚出来时的一年以上，缩小到现在的不到三个月。这变化速度，确实超出不少人的预期。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/5f55474f821a705aee122013f92b8a85.png" alt="AI报告封面"></p><h2 id="一-中美ai差距从代差到并跑的追赶"><a class="markdownIt-Anchor" href="#一-中美ai差距从代差到并跑的追赶"></a> 一、中美AI差距：从&quot;代差&quot;到&quot;并跑&quot;的追赶</h2><p>先看这张中美前沿语言模型智能指数对比图，蓝色线是美国，红色线是中国。2022年底ChatGPT刚出来那会儿，中美差距确实明显，美国领先我们差不多一年的技术水平。但从2023年中开始，红线斜率明显变陡，到2025年Q2，差距已经压缩到不到三个月。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/30457734cab40e53e678c7838e093c5f.png" alt="中美AI差距趋势图"></p><p>现在中国这边领头的是DeepSeek在2025年5月发布的开源模型R1，美国那边是OpenAI的o3。有意思的是，在开源模型这个赛道，中国其实已经反超了。看下面这张图，2024年11月，阿里的QwQ 32B Preview就超过了Meta的Llama 3.1 405B，成为当时最强的开源权重模型。这之后中国开源模型就一直保持领先，DeepSeek的R1更是把这个优势拉大了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/dc3929193ae8bf1b7c682fdce87fb949.png" alt="开源模型中美对比"></p><p>我觉得这个开源策略真的是中国AI追赶的关键一步。美国那边OpenAI、Google这些大公司基本都走封闭路线，模型权重绝不对外公开；而中国这边无论是大厂还是初创公司，都在积极开源。这种策略虽然可能让技术快速扩散，但也确实加速了整个生态的进步，毕竟&quot;众人拾柴火焰高&quot;嘛。</p><h2 id="二-中国ai双雄deepseek和alibaba的崛起"><a class="markdownIt-Anchor" href="#二-中国ai双雄deepseek和alibaba的崛起"></a> 二、中国AI双雄：DeepSeek和Alibaba的崛起</h2><p>说到中国AI实验室，现在基本是DeepSeek和Alibaba两强争霸的局面。看这张对比图，蓝色线是DeepSeek，橙色线是Alibaba，两家你追我赶，最近DeepSeek的R1 0528版本稍微领先一点，智能指数到了68。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/9671b44aefeeecfa4abcd3a7ed3b85b3.png" alt="中国AI实验室对比"></p><p>特别是DeepSeek，这两年的进步简直像坐了火箭。看他们的模型进展时间线，2023年11月第一次发布模型时，智能指数才20；到2025年5月的R1，已经到了68，两年不到翻了三倍多。最关键的是，他们最新的R1-0528版本，没有改变基础参数（还是671B参数，活跃37B），只是通过强化学习技术优化，就实现了性能提升。这说明中国团队在模型调优和RL技术上，确实已经摸到门道了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a14cdc0a1c6a4c91a0dd629c36110279.png" alt="DeepSeek模型进展"></p><p>Alibaba这边也不弱，他们的Qwen系列一直是开源社区的热门模型。最新的Qwen3 235B A22B推理版智能指数到了62，跟DeepSeek的差距其实很小。而且Alibaba有个优势是生态完整，通过阿里云提供推理服务，还有Tongyi Qianwen这样的消费者应用，MAU大概1.5亿，这可是实打实的用户数据积累。</p><h2 id="三-美国ai格局openai优势不再群雄并起"><a class="markdownIt-Anchor" href="#三-美国ai格局openai优势不再群雄并起"></a> 三、美国AI格局：OpenAI优势不再，群雄并起</h2><p>反观美国那边，OpenAI虽然还是领先，但优势已经没那么明显了。看这张美国AI实验室竞争图，OpenAI的o3模型虽然还是第一，但Google的Gemini 2.5 Pro、xAI的Grok3 mini reasoning，还有Anthropic的Claude Opus 4都追得很紧。特别是Google，感觉每次都能在关键时刻拿出点真东西，不愧是技术底蕴深厚。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/cf2fbc27e281a1b89bdd21392a96f21e.png" alt="美国AI实验室竞争图"></p><p>这种多强竞争的局面，其实对整个行业是好事。不过美国那边的问题可能在于，大家都走封闭路线，模型不开源，导致整个生态的创新速度反而不如中国这边快。当然，他们的基础研究能力还是很强，这点咱们得承认，不能盲目乐观。</p><h2 id="四-中国ai生态全景谁在推动这场技术革命"><a class="markdownIt-Anchor" href="#四-中国ai生态全景谁在推动这场技术革命"></a> 四、中国AI生态全景：谁在推动这场技术革命？</h2><p>报告里把中国AI玩家分成了三类：大科技公司、AI初创公司，还有其他有AI野心的公司。这个分类挺合理的，我带大家简单看看。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ed2c31b072cfa167717b04852bdc282b.png" alt="中国AI玩家分类表"></p><p><strong>大科技公司</strong>里，除了前面说的Alibaba，字节跳动、华为、腾讯、百度也都在积极布局。字节的Doubao用户量挺大，MAU大概1.1亿；腾讯的Hunyuan TurboS模型也到了47的智能指数；百度的ERNIE 4.5虽然稍逊，但毕竟是最早入局的玩家之一。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/7461872fece05bd0cb6a3651d0a98071.png" alt="中国科技公司AI详情"></p><p><strong>AI初创公司</strong>里，除了DeepSeek，还有Moonshot AI、Zhipu、StepFun这些玩家。Moonshot的Kimi模型也挺有名，MAU大概2500万；Zhipu的GLM系列在开源社区也很受欢迎。这些初创公司虽然资源不如大厂，但灵活性高，创新速度快，往往能搞出一些让人眼前一亮的东西。</p><h2 id="五-给开发者的几点思考"><a class="markdownIt-Anchor" href="#五-给开发者的几点思考"></a> 五、给开发者的几点思考</h2><p>看完这份报告，我最大的感受是：中国AI真的到了一个关键节点。从技术追赶者变成了并行者，甚至在某些领域（比如开源模型）已经成为领跑者。对于我们开发者来说，这其实意味着巨大的机会。</p><p>首先，开源模型的普及让我们有机会接触到最前沿的AI技术，不再需要依赖API调用，自己就能部署和微调大模型。DeepSeek R1、阿里Qwen这些模型性能已经很不错，而且开源可用，这在两年前是不可想象的。</p><p>其次，AI应用的场景会越来越多。现在大厂的AI应用MAU都已经过亿，说明普通用户对AI的接受度越来越高。作为开发者，我们应该思考如何把这些AI能力融入到自己的产品中，提升用户体验。</p><p>不过也要清醒认识到，虽然差距缩小了，但在基础研究、芯片技术、生态完善度等方面，我们和美国还有差距。而且AI发展这么快，今天领先不代表永远领先，还得持续投入才行。</p><p>最后说一句，不管是中国还是美国，AI技术的进步最终都是为了造福人类。希望这种良性竞争能持续下去，推动AI技术不断突破，也让我们开发者有更多好玩的工具可以用。你们觉得呢？欢迎在评论区聊聊你们对中国AI发展的看法。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI遇冷背后：为什么说我们正站在技术爆发前的静止时刻？</title>
      <link href="/ren-gong-zhi-neng/ai-yu-leng-bei-hou-wei-shi-me-shuo-wo-men-zheng-zhan-zai-ji-zhu-bao-fa-qian-de-jing-zhi-shi-ke-3/"/>
      <url>/ren-gong-zhi-neng/ai-yu-leng-bei-hou-wei-shi-me-shuo-wo-men-zheng-zhan-zai-ji-zhu-bao-fa-qian-de-jing-zhi-shi-ke-3/</url>
      
        <content type="html"><![CDATA[<p>ChatGPT-5上线那天，我特意定了闹钟。结果呢？既没有2022年ChatGPT初问世时的惊艳，也没有GPT-4发布时的热议，甚至因为&quot;不够人性化&quot;，官方不得不把老版4o重新上架。说实话，这场景挺让人唏嘘的——曾经被捧上神坛的AI，怎么突然就不香了？</p><p>你可能会问：AI到底怎么了？不是说要改变世界吗？怎么现在连让我们眼前一亮都做不到了？</p><h2 id="一万亿美元投入换来一句就这"><a class="markdownIt-Anchor" href="#一万亿美元投入换来一句就这"></a> 一万亿美元投入，换来一句&quot;就这？&quot;</h2><p>先看组扎心数据：过去十年，全球砸在AI上的钱累计超过1万亿美元。但现实呢？企业抱怨&quot;AI能用但不好用&quot;，大众从最初的震撼变成了平静，偶尔还会吐槽&quot;大模型炫技多、解决少&quot;。</p><p>更有意思的是科学家们也吵起来了：图灵奖得主Yoshua Bengio说&quot;2-5年实现人类水平AI&quot;，另一位大佬杨立昆直接泼冷水：“就现在这水平，连猫猫狗狗级别的AI都做不出来。”</p><p>这矛盾背后，其实是AI正卡在一个关键节点——从&quot;实验室神话&quot;到&quot;现实应用&quot;的跃迁期。AI先驱Richard Sutton今年7月提出个&quot;体验时代&quot;理论，我觉得挺有道理：当人类数据红利快耗尽时，AI必须学会&quot;自我体验&quot;才能突破。</p><p>这让我想起蒸汽机的故事。1698年就发明了，但真正改变世界是在瓦特改良之后，中间隔了整整60年。今天的AI，可能就处在&quot;蒸汽机爆发前的静止时刻&quot;——技术有了，但还没找到那个能让它渗透到每个角落的&quot;瓦特改良&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/daa2bcbc2f19a61b584fe35fb4f5445b.jpg" alt="AI资本增长趋势"></p><h2 id="技术领先不如扩散效率工业革命早就告诉我们答案"><a class="markdownIt-Anchor" href="#技术领先不如扩散效率工业革命早就告诉我们答案"></a> 技术领先不如扩散效率：工业革命早就告诉我们答案</h2><p>要打破这个静止时刻，到底靠什么？工业革命的历史早就给出了答案：技术胜出的关键，从来不是&quot;谁先造出完美机器&quot;，而是&quot;谁让机器更快改变生活&quot;。</p><p>华盛顿大学研究过三次工业革命，发现个有意思的现象：英国能引领第一次工业革命，不是因为纺织机技术比法国好多少，而是英国的技术扩散效率甩了法国几条街——曼彻斯特的纺织厂5年就把蒸汽机渗透率从5%提到40%，法国同期才12%。</p><p>第二次工业革命更明显，美国超越欧洲，不是爱迪生的灯泡更亮，而是美国用10年就把电力从实验室送到了千家万户，欧洲却花了25年。</p><p>放到AI时代，这个规律照样适用。现在全球每天新增100个AI模型，但麦肯锡2024年报告显示：中国AI专利申请量全球第一（占比超40%），商业化率却只有15%；美国大模型参数规模突破万亿，能真正落地的场景不足20%。</p><p>说白了，当技术不再是瓶颈，怎么让技术被需要、被使用、被依赖，才是真本事。</p><h2 id="自动驾驶的路线之争完美主义败给实用主义"><a class="markdownIt-Anchor" href="#自动驾驶的路线之争完美主义败给实用主义"></a> 自动驾驶的路线之争：完美主义败给实用主义</h2><p>最能说明这个道理的，就是自动驾驶领域的&quot;Waymo vs 特斯拉&quot;之争。</p><p>Waymo技术上确实牛，各种测评都是独一档。但他们团队早期有点&quot;技术洁癖&quot;——非要等到完全不需要方向盘的L4级别，才肯推向市场，拒绝在有安全员的阶段商业化。结果呢？到现在还在测试阶段打转。</p><p>马斯克就务实多了，从L2级辅助驾驶起步，用用户实际驾驶数据反哺训练（也就是&quot;影子模式&quot;）。2023年全球搭载FSD的车就超400万辆，累计开了500亿公里。虽然FSD还没完全去掉人类干预，但用户渗透率已经达到22%（Statista 2024数据），商业价值比还在&quot;测试&quot;的Waymo高不知道哪里去了。</p><p>今年Waymo也不得不向现实低头，宣布有人监控的无人驾驶出租车要开上纽约街头了。而特斯拉呢？6月份已经实现了工业史上首次无人自动交付——一辆车从工厂自己开30分钟到买家门口。</p><p><img src="https://supercarblondie.com/wp-content/uploads/Waymo-3.webp" alt="自动驾驶汽车实景"></p><p>这事儿告诉我们：用户不需要&quot;完美的AI&quot;，只需要&quot;足够好的解决方案&quot;。医疗AI能10秒内完成肺部CT扫描，准确率97%，哪怕暂时解释不了为什么是恶性；教育AI能为乡村教师自动生成个性化教案，覆盖80%常见题型，哪怕不能像特级教师一样情感共鸣——这些&quot;不完美但有用&quot;的AI，才是打破静止的关键。</p><h2 id="中国企业的土办法场景比参数更重要"><a class="markdownIt-Anchor" href="#中国企业的土办法场景比参数更重要"></a> 中国企业的&quot;土办法&quot;：场景比参数更重要</h2><p>国内一些公司在推进AI时，就很懂这个道理。他们不搞&quot;All in AI&quot;的豪赌，而是&quot;AI in All&quot;的渗透——把AI当工具，塞进各种实际场景里。</p><p>腾讯就是个典型例子。它不追求当聚光灯下的&quot;技术明星&quot;，而是做穿透场景的&quot;实用工具&quot;。微信（14亿月活）、企业微信（5亿用户）、视频号（日活超8亿）这些国民级场景，既是技术落地的&quot;沙盘&quot;，也是数据迭代的&quot;源头&quot;。</p><p>比如工业质检，腾讯AI和三一重工、宁德时代合作，攒了超1000万张&quot;瑕疵样本&quot;，把检测准确率从85%提到了99.2%。这种&quot;场景即数据&quot;的模式，比纯实验室搞研发快3-5倍。</p><p><img src="https://cdn-xtech.nikkei.com/atcl/nxt/column/18/02653/070400048/00.jpg?__scale=w:500,h:303&amp;_sh=030db0bd0d" alt="AI机器狗应用示例"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0b9ee7be23613d1ed818b754f4223deb.jpg" alt="机器狗浇水特写"></p><p>他们还搞开放生态，不是&quot;自己做所有事&quot;，而是&quot;让所有人能用AI做事&quot;。通过&quot;混元大模型+API接口+工具包&quot;，让AI跨行业渗透。截至2025年7月，接入腾讯AI能力的企业超10万家，开发者超50万。这种模式的效果，直接反映在财报上——2025年Q2腾讯收入1845.04亿元，同比增长15%；净利润556.3亿元，AI已经成了实实在在的增长引擎。</p><p>阿里也类似，把&quot;AI+云&quot;当第二增长曲线，阿里云AI相关产品收入连续七个季度三位数增长。百度文心一言则扎根搜索场景，推动垂直领域落地。这些公司都在做同一件事：不贪顶端突破，只做全域渗透。</p><h2 id="最后说句大实话"><a class="markdownIt-Anchor" href="#最后说句大实话"></a> 最后说句大实话</h2><p>AI到底有什么用？什么时候能派上大用？</p><p>答案可能就藏在那些&quot;润物细无声&quot;的改变里：当医疗AI让县域医院的肺癌筛查准确率从60%提到90%，当教育AI让乡村教师效率提升50%，当工业AI让中小工厂良品率从85%提到95%——这些才是AI真正的&quot;大用&quot;。</p><p>全球AI竞赛的下半场，比的不是谁的技术更先进，而是谁的技术更能渗透到普通人的生活里。就像当年蒸汽机改变世界，不是因为它突然变得完美无缺，而是因为它走进了千家万户的工厂和生活。</p><p>现在的AI，可能就缺一个&quot;马轭&quot;——就像欧洲中世纪，重犁早就发明了，但真正让农业爆发的是马轭，它让重犁终于能完全施展。在马轭没出现前，重犁也没被抛弃，而是慢慢普及，成了马轭发明的催化剂。</p><p>所以，与其纠结AI为什么让人失望，不如看看那些正在发生的微小改变。说不定哪天早上醒来，你会突然发现：嘿，AI好像真的有用了。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>腾讯日赚7.7亿背后：AI已从&quot;成本项&quot;变成&quot;印钞机&quot;</title>
      <link href="/ren-gong-zhi-neng/teng-xun-ri-zhuan-7.7-yi-bei-hou-ai-yi-cong-cheng-ben-xiang-bian-cheng-yin-chao-ji-3/"/>
      <url>/ren-gong-zhi-neng/teng-xun-ri-zhuan-7.7-yi-bei-hou-ai-yi-cong-cheng-ben-xiang-bian-cheng-yin-chao-ji-3/</url>
      
        <content type="html"><![CDATA[<p>刚看到腾讯Q2财报时，我差点以为眼花了——1845亿营收，692亿经营盈利，算下来日赚7.7亿。最离谱的是广告业务，在整个互联网广告大盘只增长6.8%的情况下，腾讯硬是飙出了20%的增速。这哪是跑赢大盘，简直是把大盘按在地上摩擦。</p><p>但比数字更有意思的是腾讯首席战略官米歇尔的一句话：“我们在广告领域部署AI的举措，才是一个更为重要的变量。” 说白了，现在的腾讯，AI已经不是那个只烧钱的&quot;实验室项目&quot;，而是真真切切开始贡献利润的&quot;印钞机&quot;了。</p><h2 id="一-20的广告增长从哪来ai重构了整个产业链"><a class="markdownIt-Anchor" href="#一-20的广告增长从哪来ai重构了整个产业链"></a> 一、20%的广告增长从哪来？AI重构了整个产业链</h2><p>先看组数据：腾讯Q2广告收入同比增长20%，而同期中国互联网广告市场整体增速只有6.8%。更狠的是，腾讯自己承认视频号广告加载率才3-6%，远低于抖音的13-16%——也就是说，这20%的增长还不是靠硬塞广告，而是靠AI把广告效率提上去了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/26274bcd7eab43b768fb641f6a361123.png" alt="腾讯Q2业绩数据"></p><p>具体怎么操作的？现在广告主用腾讯的&quot;急于智投&quot;功能，基本不用自己动手：设置好营销目标、预算和简单创意，AI就能自动生成广告素材、选投放时段、调整出价，甚至实时优化效果。有个做电商的朋友跟我说，同样的预算，用AI投放后ROI直接涨了30%，你说他下次还会不会加预算？</p><p>这还只是AI改造广告的第一步。从创意生成（AI写文案、做视频）到用户匹配（AI预测谁更可能买），再到效果分析（AI解读数据报表），整个链条都被AI重构了。米歇尔说这是&quot;更为重要的变量&quot;，我觉得说保守了——这根本就是广告行业的&quot;降维打击&quot;。</p><h2 id="二-不止广告ai正在给腾讯所有业务换引擎"><a class="markdownIt-Anchor" href="#二-不止广告ai正在给腾讯所有业务换引擎"></a> 二、不止广告，AI正在给腾讯所有业务&quot;换引擎&quot;</h2><p>腾讯的AI布局，早就不是单点突破，而是全面渗透。游戏业务增长16%，AI功不可没。比如《王者荣耀》的AI语音助手&quot;灵宝&quot;，既能陪练又能给新手当战术指导。有玩家调侃说：“现在组队不怕遇到菜鸟了，怕遇到比队友还会指挥的AI。”</p><p>金融科技及企业服务业务增长6%，背后是混元大模型在撑着。说白了就是把AI塞进各种生产力工具里，比如智能客服能自动处理80%的常规问题，财务系统能AI识别报销单异常，连开会都有AI实时记笔记、生成待办事项。这些功能听起来小，但架不住腾讯的企业客户基数大啊。</p><p>最有意思的是AI应用形态的选择。QuestMobile的数据显示，2025年6月AI应用市场里，插件模式（In-App AI）规模6.3亿，超过原生App的5.7亿。这说明大家更喜欢&quot;用完即走&quot;的AI功能，而不是专门下载个App。腾讯显然看准了这点，不管是微信里的AI插件，还是QQ浏览器的AI助手，都是这个思路。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/dd3d0d7fecd0d375e957f6a3b4d7a986.png" alt="AI应用市场规模"></p><p>你看腾讯的AI策略多精明：不跟创业公司抢原生App的风头，而是把AI直接嵌到微信、QQ这些国民级App里。用户不用学新东西，在熟悉的环境里就能用AI，这转化率可不比硬推一个新App高多了？</p><h2 id="三-微信这张王炸让腾讯ai赢在起跑线"><a class="markdownIt-Anchor" href="#三-微信这张王炸让腾讯ai赢在起跑线"></a> 三、微信这张&quot;王炸&quot;，让腾讯AI赢在起跑线</h2><p>要说腾讯AI最大的优势，不是技术多牛，而是它站在微信这个&quot;巨人肩膀上&quot;。最新数据显示，微信及WeChat合并月活已经14.11亿，这是什么概念？全中国网民才10亿出头，相当于几乎每个上网的人都在用微信。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/19d70aff1fbd6ee3dd5596f7b5dc8b62.png" alt="微信月活数据"></p><p>就拿腾讯元宝来说，这个AI助手4月刚在微信打通入口，现在用户增速已经冲到55.2%，在AI原生App里排第二。更绝的是它的推广方式：在视频号教你租房怎么砍价、P图怎么去水印、备考怎么划重点，连喂猫养花的技巧都有。说白了就是不搞那些高大上的，专抓普通人的生活痛点。</p><p>刘炽平说得很明白：“不会光靠砸钱推广元宝，我们有很多现有平台可以利用。” 这句话翻译一下就是：微信14亿用户都是潜在的AI用户，只要把入口做好、场景做对，根本不愁没人用。这种生态优势，是百度、阿里甚至字节都羡慕不来的。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/f0b0a1c8b5422c9dcdbc053f102e53e8.png" alt="腾讯总部大楼"></p><p>不过话说回来，腾讯也不是没压力。最大的问题是用户付费习惯。OpenAI靠订阅就能赚钱，因为海外用户愿意为好服务买单。但国内用户被免费惯坏了，元宝想收费估计很难。现在腾讯只能靠&quot;用AI提升其他业务收入，再反哺AI研发&quot;的模式，这就要求AI必须持续给广告、游戏这些老业务&quot;提效&quot;，压力不小。</p><p>还有大模型能力。虽然混元模型在3D生成这些细分领域排全球第一，但整体实力离DeepSeek还有差距。所以腾讯才要&quot;双模型打团战&quot;，既用自家混元，也接DeepSeek的API。这种&quot;两条腿走路&quot;的策略很务实，但长期来看，核心技术还是得握在自己手里。</p><h2 id="最后说一句腾讯的ai牌到底能打多大"><a class="markdownIt-Anchor" href="#最后说一句腾讯的ai牌到底能打多大"></a> 最后说一句：腾讯的AI牌，到底能打多大？</h2><p>现在看来，腾讯把AI定位成&quot;新周期跳板&quot;，甚至说&quot;战略价值比肩微信&quot;，不是吹牛。微信改变了人与人的连接方式，而AI可能改变人与服务、人与内容的连接方式。腾讯最聪明的地方，就是没把AI做成一个独立的&quot;新项目&quot;，而是当成所有业务的&quot;新引擎&quot;。</p><p>不过AI这局棋才刚开始。插件模式能不能持续领先？混元模型能不能追上第一梯队？14亿微信用户怎么真正转化成AI用户？这些问题的答案，可能比日赚7.7亿更重要。毕竟，微信的故事讲了十年，而腾讯的AI故事，才刚刚翻开第一页。</p><p>你觉得腾讯AI能成为下一个微信级别的产品吗？欢迎在评论区聊聊你的看法。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从&quot;走路都难&quot;到&quot;跑酷跳舞&quot;：浙大最新综述拆解人形机器人50年技术突围</title>
      <link href="/ren-gong-zhi-neng/cong-zou-lu-du-nan-dao-pao-ku-tiao-wu-zhe-da-zui-xin-zong-shu-chai-jie-ren-xing-ji-qi-ren-50-nian-ji-zhu-tu-wei-3/"/>
      <url>/ren-gong-zhi-neng/cong-zou-lu-du-nan-dao-pao-ku-tiao-wu-zhe-da-zui-xin-zong-shu-chai-jie-ren-xing-ji-qi-ren-50-nian-ji-zhu-tu-wei-3/</url>
      
        <content type="html"><![CDATA[<p>最近浙江大学流体动力与机电系统国家重点实验室发了篇重磅综述《A Comprehensive Review of Humanoid Robots》，把人形机器人技术扒了个底朝天。看完最大的感受是：这玩意儿比我想象的复杂多了——既要像人一样动，还要像人一样&quot;思考&quot;，甚至像人一样&quot;有情绪&quot;。今天咱们就用大白话聊聊，人形机器人是怎么从1969年那个只会&quot;挪步&quot;的铁疙瘩，进化到现在能跑酷、会打乒乓球的&quot;全能选手&quot;的。</p><h2 id="先看张全家福人形机器人到底由啥组成"><a class="markdownIt-Anchor" href="#先看张全家福人形机器人到底由啥组成"></a> 先看张全家福：人形机器人到底由啥组成？</h2><p>要理解人形机器人有多难，先得知道它是个多复杂的&quot;系统工程&quot;。浙大论文里画了个系统组成图，一目了然：机械结构、动力系统、算法和传感器四大块，缺一块都玩不转。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/016b888f09d33e8b394ad0c2dfbd7cdc.jpg" alt="机器人系统组成"></p><p>你看，光机械结构就分手臂、头部、腿部，每个部位都得有&quot;关节&quot;——就像人的肩肘腕髋膝踝，少一个自由度，动作就僵硬。动力系统更麻烦，伺服电机要精确到0.1度的转动，液压系统要扛住几十公斤的重量还得灵活。最头疼的是算法，你让机器人&quot;递杯水&quot;，它得先&quot;看见&quot;杯子（环境感知），规划怎么过去（导航），控制手臂不抖（运动控制），还得知道杯子烫不烫（触觉传感器）。</p><h2 id="50年进化史从瘸子到跑酷高手的逆袭"><a class="markdownIt-Anchor" href="#50年进化史从瘸子到跑酷高手的逆袭"></a> 50年进化史：从&quot;瘸子&quot;到&quot;跑酷高手&quot;的逆袭</h2><p>说出来你可能不信，人形机器人这50多年走的弯路，比我代码里的bug还多。</p><h3 id="国际玩家从asimo到atlas的炫技大赛"><a class="markdownIt-Anchor" href="#国际玩家从asimo到atlas的炫技大赛"></a> 国际玩家：从ASIMO到Atlas的&quot;炫技大赛&quot;</h3><p>1969年日本早稻田大学搞出第一个双足机器人，结果只能&quot;静态行走&quot;——走一步停半天，跟老爷爷拄拐杖似的。真正让大家觉得&quot;有戏&quot;的是本田ASIMO，2000年那会儿它就能跑9公里/小时，还会踢球、拧瓶盖。可惜2018年本田宣布项目终止，为啥？太贵了！据说一台ASIMO成本上亿，根本没法量产。</p><p>波士顿动力的Atlas是现在的&quot;顶流&quot;。2013年初代还是个&quot;液压怪兽&quot;，噪音大得像打桩机；2024年最新电动版直接封神——360度旋转关节、跑酷空翻、甚至能在野外泥地里蹦跶。我看完它的视频就在想：这玩意儿要是装个AI大脑，是不是能直接参加奥运会？</p><p>特斯拉Optimus走的是另一条路。2022年初代还在&quot;顺拐&quot;，2023年Gen2就稳多了，关键是特斯拉想把它当&quot;工业品&quot;造——用汽车生产线量产，成本压到2万美元以内。说实话，这思路比波士顿动力靠谱，毕竟再牛的技术，造不出来也是白搭。</p><h3 id="中国选手从跟跑到并跑"><a class="markdownIt-Anchor" href="#中国选手从跟跑到并跑"></a> 中国选手：从&quot;跟跑&quot;到&quot;并跑&quot;</h3><p>咱们起步不算早，90年代才开始，但进步是真快。北京理工大学2001年的&quot;汇童&quot;机器人，已经能独立行走，后来还学会了打太极拳、防跌倒。浙大的&quot;悟空&quot;更绝，直接挑战高难度——打乒乓球！&quot;悟空IV&quot;时速超6公里，能跳0.5米高，爬25度斜坡，泥地草地都能走，算是把&quot;运动能力&quot;点满了。</p><p>企业这边也热闹。优必选Walker系列迭代了好几代，宇树科技2024年发的G1，据说成本能控制在10万人民币以内。小米、小鹏这些公司也下场了，看来人形机器人这波浪潮，中国企业不想错过。</p><h2 id="技术拆解为啥造个像人的机器人这么难"><a class="markdownIt-Anchor" href="#技术拆解为啥造个像人的机器人这么难"></a> 技术拆解：为啥造个&quot;像人&quot;的机器人这么难？</h2><h3 id="头部不只是脸更是社交名片"><a class="markdownIt-Anchor" href="#头部不只是脸更是社交名片"></a> 头部：不只是&quot;脸&quot;，更是&quot;社交名片&quot;</h3><p>你可能觉得机器人头部就是个&quot;显示屏&quot;，但浙大论文里专门花了大篇幅讲这个——因为它直接关系到&quot;你愿不愿意让机器人进家门&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2a22e3d1573c4025ad0d44bbd3a0722f.png" alt="机器人头部类型"></p><p>现在头部设计分两派：一派是&quot;非拟人化&quot;，比如波士顿动力Electric Atlas，就一个带光环的显示屏，简单粗暴但实用；另一派是&quot;拟人化&quot;，追求越像人越好，比如Ameca机器人，皮肤用Frubber材料（海绵状人造橡胶），能做出皱眉、微笑的微表情。</p><p>但这里有个坑——“恐怖谷效应”。简单说就是机器人长得太像人但又不完全像，反而让人觉得诡异。所以现在很多设计走&quot;卡通化&quot;路线，比如优必选Walker X，眼睛大大的，表情萌萌的，既亲切又不会让人不舒服。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/89636fc4ac87092557b28afeaca061c2.png" alt="头部发展阶段"></p><p>头部技术已经发展到&quot;心理拟人化&quot;阶段了——不只是表情像人，还得有&quot;情绪&quot;。比如Emo机器人用深度学习模型预测人类表情，你笑它也笑，你皱眉它会&quot;关心&quot;你。说实话，这要是再配上ChatGPT的对话能力，以后心理咨询师会不会失业？</p><h3 id="硬件架构机器人的肌肉和感官"><a class="markdownIt-Anchor" href="#硬件架构机器人的肌肉和感官"></a> 硬件架构：机器人的&quot;肌肉&quot;和&quot;感官&quot;</h3><p>光有脸不行，还得有&quot;身体&quot;。浙大论文里的硬件架构图把这事儿说透了：机械结构是&quot;骨骼&quot;，传感器是&quot;五官&quot;，动力系统是&quot;肌肉&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4e3e8878fed84d4f3c73bf59ad666034.png" alt="机器人硬件架构"></p><p><strong>机械结构</strong>最讲究&quot;轻量化&quot;和&quot;刚性&quot;的平衡。比如宇树G1用了航空铝和碳纤维，全身重量压到55公斤，跟成年人差不多，但关节强度得扛住跳跃落地的冲击力。<strong>传感器</strong>现在流行&quot;多模态融合&quot;——激光雷达（看远距离）+ RGB-D相机（看颜色和深度）+ 触觉传感器（摸软硬）+ IMU（测姿态）。就像人用眼睛、手、耳朵一起感知世界，机器人也得&quot;多感官协作&quot;才靠谱。</p><p><strong>动力系统</strong>现在有三大流派：伺服电机（精度高但力小）、液压（力大但笨重）、气动（灵活但精度低）。波士顿动力早期用液压，现在Atlas换成电动伺服，就是为了轻便和安静。特斯拉Optimus更绝，直接用汽车电机技术下放，成本一下子降下来了。</p><h3 id="软件架构机器人的大脑怎么思考"><a class="markdownIt-Anchor" href="#软件架构机器人的大脑怎么思考"></a> 软件架构：机器人的&quot;大脑&quot;怎么思考？</h3><p>硬件是&quot;身体&quot;，软件才是&quot;灵魂&quot;。浙大论文里的软件架构图，看着像个复杂的&quot;俄罗斯套娃&quot;——实时操作系统（RTOS）管底层运动，ROS（机器人操作系统）管传感器和算法，EtherCAT通信协议保证数据传输不延迟。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0b645552643773b31976c8b456006a19.png" alt="机器人软件架构"></p><p>最核心的是<strong>环境感知</strong>和<strong>自主导航</strong>。你让机器人去厨房拿瓶水，它得先&quot;看懂&quot;厨房的布局（地图构建），避开地上的拖鞋（动态障碍物），规划出一条路（路径规划），再控制腿迈步（脚步规划）。这里面每个环节都是坑：光线暗了相机识别不准，地面滑了容易摔跤，拖鞋被踢了位置变了还得重新规划。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d984c6953e70847c3a84f662954e353a.png" alt="环境感知系统"></p><p><strong>运动控制</strong>更是&quot;玄学&quot;。早期用&quot;零力矩点（ZMP）“理论，保证机器人走路时重心在支撑面内，就像人走路不会倒。现在流行&quot;模型预测控制（MPC）”，说白了就是&quot;边走边算&quot;——每走一步预测下一步的姿态，随时调整。波士顿动力Atlas跑酷时，身体扭来扭去就是MPC在实时纠错。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2e65b514455eca8e92d31488f5349652.png" alt="运动控制框架"></p><p>最近火起来的&quot;具身智能&quot;，就是让机器人用LLM（大语言模型）做&quot;任务规划&quot;。比如你说&quot;帮我热一下咖啡&quot;，LLM会拆解成：1. 找到微波炉 2. 打开微波炉门 3. 把咖啡放进去 4. 设置加热时间 5. 启动。再把这些步骤翻译成机器人能执行的动作指令。Figure 01和OpenAI合作后，据说已经能听懂复杂指令了，这才是&quot;智能助手&quot;该有的样子。</p><h2 id="现在的问题离走进家庭还有多远"><a class="markdownIt-Anchor" href="#现在的问题离走进家庭还有多远"></a> 现在的问题：离&quot;走进家庭&quot;还有多远？</h2><p>浙大论文最后总结了几个&quot;卡脖子&quot;的难题，我觉得说得挺实在：</p><ol><li><strong>成本太高</strong>：Atlas这种顶级机器人成本上亿，宇树G1降到10万，但还是比扫地机器人贵100倍。</li><li><strong>续航太短</strong>：现在主流电池续航就1-2小时，干不了啥就没电了，总不能拖着电源线走吧？</li><li><strong>鲁棒性差</strong>：实验室里好好的，换个环境（比如地毯毛长了、地板有水）就可能摔跤。</li><li><strong>安全问题</strong>：万一机器人失控撞了老人小孩咋办？现在还没靠谱的安全标准。</li></ol><p>不过趋势是好的：模块化设计（零件坏了能换）、标准化接口（不同品牌零件通用）、AI大模型加持（更聪明）。特斯拉说要2025年量产Optimus，目标价2万美元，我觉得有点乐观，但5年内家用机器人进中产家庭，应该不是梦。</p><h2 id="最后说两句"><a class="markdownIt-Anchor" href="#最后说两句"></a> 最后说两句</h2><p>看完浙大这篇综述，我最大的感受是：人形机器人不再是科幻片里的玩意儿了。从机械结构到AI大脑，每个技术模块都在快速突破。当然，现在还没到&quot;机器人管家&quot;的阶段，但就像10年前智能手机刚出来时谁也想不到现在的功能一样，人形机器人的爆发可能比我们想象的快。</p><p>你觉得5年后家里会有机器人帮忙做饭、打扫卫生吗？反正我挺期待的——到时候我就能彻底告别洗碗了！（前提是它别把我珍藏的碗摔了）</p><p>论文原文链接：<a href="https://onlinelibrary.wiley.com/doi/10.1002/smb2.12008%EF%BC%88%E6%84%9F%E5%85%B4%E8%B6%A3%E7%9A%84%E6%8A%80%E6%9C%AF%E5%85%9A%E5%8F%AF%E4%BB%A5%E8%87%AA%E5%B7%B1%E5%8E%BB%E5%95%83%EF%BC%8C%E5%8F%8B%E6%83%85%E6%8F%90%E7%A4%BA%EF%BC%9A%E6%9C%89%E7%82%B9%E5%8E%9A%EF%BC%89" target="_blank" rel="noopener">https://onlinelibrary.wiley.com/doi/10.1002/smb2.12008（感兴趣的技术党可以自己去啃，友情提示：有点厚）</a># 从&quot;走路都难&quot;到&quot;跑酷跳舞&quot;：浙大最新综述拆解人形机器人50年技术突围</p><p>最近浙江大学流体动力与机电系统国家重点实验室发了篇重磅综述《A Comprehensive Review of Humanoid Robots》，把人形机器人技术扒了个底朝天。看完最大的感受是：这玩意儿比我代码里的bug还多——既要像人一样动，还要像人一样&quot;思考&quot;，甚至像人一样&quot;有情绪&quot;。今天就用大白话聊聊，人形机器人是怎么从1969年那个只会&quot;挪步&quot;的铁疙瘩，进化到现在能跑酷、会打乒乓球的&quot;全能选手&quot;的。</p><h2 id="先看张全家福人形机器人到底由啥组成-2"><a class="markdownIt-Anchor" href="#先看张全家福人形机器人到底由啥组成-2"></a> 先看张全家福：人形机器人到底由啥组成？</h2><p>要理解人形机器人有多难，先得知道它是个多复杂的&quot;系统工程&quot;。浙大论文里这张系统组成图就很直观，机械结构、动力系统、算法和传感器四大块，缺一块都玩不转。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/016b888f09d33e8b394ad0c2dfbd7cdc.jpg" alt="机器人系统组成"></p><p>你看，光机械结构就分手臂、头部、腿部，每个部位都得有&quot;关节&quot;——就像人的肩肘腕髋膝踝，少一个自由度，动作就僵硬得像僵尸。动力系统更麻烦，伺服电机要精确到0.1度的转动，液压系统要扛住几十公斤的重量还得灵活。最头疼的是算法，你让机器人&quot;递杯水&quot;，它得先&quot;看见&quot;杯子（环境感知），规划怎么过去（导航），控制手臂不抖（运动控制），还得知道杯子烫不烫（触觉传感器）。这一套下来，比我写个分布式系统还复杂。</p><h2 id="50年进化史从瘸子到跑酷高手的逆袭-2"><a class="markdownIt-Anchor" href="#50年进化史从瘸子到跑酷高手的逆袭-2"></a> 50年进化史：从&quot;瘸子&quot;到&quot;跑酷高手&quot;的逆袭</h2><p>说出来你可能不信，人形机器人这50多年走的弯路，比我代码里的bug还多。</p><h3 id="国际玩家从asimo到atlas的炫技大赛-2"><a class="markdownIt-Anchor" href="#国际玩家从asimo到atlas的炫技大赛-2"></a> 国际玩家：从ASIMO到Atlas的&quot;炫技大赛&quot;</h3><p>1969年日本早稻田大学搞出第一个双足机器人，结果只能&quot;静态行走&quot;——走一步停半天，跟老爷爷拄拐杖似的。真正让大家觉得&quot;有戏&quot;的是本田ASIMO，2000年那会儿它就能跑9公里/小时，还会踢球、拧瓶盖。可惜2018年本田宣布项目终止，为啥？太贵了！据说一台ASIMO成本上亿，根本没法量产，活生生把本田造穷了。</p><p>波士顿动力的Atlas是现在的&quot;顶流&quot;。2013年初代还是个&quot;液压怪兽&quot;，噪音大得像打桩机；2024年最新电动版直接封神——360度旋转关节、跑酷空翻、甚至能在野外泥地里蹦跶。我看完它的视频就在想：这玩意儿要是装个AI大脑，是不是能直接参加奥运会？</p><p>特斯拉Optimus走的是另一条路。2022年初代还在&quot;顺拐&quot;，2023年Gen2就稳多了，关键是特斯拉想把它当&quot;工业品&quot;造——用汽车生产线量产，成本压到2万美元以内。说实话，这思路比波士顿动力靠谱，毕竟再牛的技术，造不出来也是白搭。</p><h3 id="中国选手从跟跑到并跑-2"><a class="markdownIt-Anchor" href="#中国选手从跟跑到并跑-2"></a> 中国选手：从&quot;跟跑&quot;到&quot;并跑&quot;</h3><p>咱们起步不算早，90年代才开始，但进步是真快。北京理工大学2001年的&quot;汇童&quot;机器人，已经能独立行走，后来还学会了打太极拳、防跌倒。浙大的&quot;悟空&quot;更绝，直接挑战高难度——打乒乓球！&quot;悟空IV&quot;时速超6公里，能跳0.5米高，爬25度斜坡，泥地草地都能走，算是把&quot;运动能力&quot;点满了。</p><p>企业这边也热闹。优必选Walker系列迭代了好几代，宇树科技2024年发的G1，据说成本能控制在10万人民币以内。小米、小鹏这些公司也下场了，看来人形机器人这波浪潮，中国企业不想错过。</p><h2 id="技术拆解为啥造个像人的机器人这么难-2"><a class="markdownIt-Anchor" href="#技术拆解为啥造个像人的机器人这么难-2"></a> 技术拆解：为啥造个&quot;像人&quot;的机器人这么难？</h2><h3 id="头部不只是脸更是社交名片-2"><a class="markdownIt-Anchor" href="#头部不只是脸更是社交名片-2"></a> 头部：不只是&quot;脸&quot;，更是&quot;社交名片&quot;</h3><p>你可能觉得机器人头部就是个&quot;显示屏&quot;，但浙大论文里专门花了大篇幅讲这个——因为它直接关系到&quot;你愿不愿意让机器人进家门&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2a22e3d1573c4025ad0d44bbd3a0722f.png" alt="机器人头部类型"></p><p>现在头部设计分两派：一派是&quot;非拟人化&quot;，比如波士顿动力Electric Atlas，就一个带光环的显示屏，简单粗暴但实用；另一派是&quot;拟人化&quot;，追求越像人越好，比如Ameca机器人，皮肤用Frubber材料（海绵状人造橡胶），能做出皱眉、微笑的微表情。</p><p>但这里有个坑——“恐怖谷效应”。简单说就是机器人长得太像人但又不完全像，反而让人觉得诡异。所以现在很多设计走&quot;卡通化&quot;路线，比如优必选Walker X，眼睛大大的，表情萌萌的，既亲切又不会让人不舒服。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/251783bfaf1fdb6dea2c011220079b65.png" alt="头部参数对比"></p><p>看这表格里的数据，Ibuki机器人头部有22个自由度，比人类面部肌肉还复杂，但表情反而不如只有12个自由度的Xiao Yao自然。说白了，不是自由度越多越好，关键是&quot;仿生度&quot;——怎么让机器人的眼神、嘴角动作符合人类习惯，这才是难点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/89636fc4ac87092557b28afeaca061c2.png" alt="头部发展阶段"></p><p>现在头部技术已经发展到&quot;心理拟人化&quot;阶段了——不只是表情像人，还得有&quot;情绪&quot;。比如Emo机器人用深度学习模型预测人类表情，你笑它也笑，你皱眉它会&quot;关心&quot;你。说实话，这要是再配上ChatGPT的对话能力，以后心理咨询师会不会失业？</p><h3 id="硬件架构机器人的肌肉和感官-2"><a class="markdownIt-Anchor" href="#硬件架构机器人的肌肉和感官-2"></a> 硬件架构：机器人的&quot;肌肉&quot;和&quot;感官&quot;</h3><p>光有脸不行，还得有&quot;身体&quot;。浙大论文里的硬件架构图，把这事儿说透了：机械结构是&quot;骨骼&quot;，传感器是&quot;五官&quot;，动力系统是&quot;肌肉&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4e3e8878fed84d4f3c73bf59ad666034.png" alt="机器人硬件架构"></p><p><strong>机械结构</strong>最讲究&quot;轻量化&quot;和&quot;刚性&quot;的平衡。比如宇树G1用了航空铝和碳纤维，全身重量压到55公斤，跟成年人差不多，但关节强度得扛住跳跃落地的冲击力。这就像造赛车，既要轻又要结实，成本自然下不来。</p><p><strong>传感器</strong>现在流行&quot;多模态融合&quot;——激光雷达（看远距离）+ RGB-D相机（看颜色和深度）+ 触觉传感器（摸软硬）+ IMU（测姿态）。就像人用眼睛、手、耳朵一起感知世界，机器人也得&quot;多感官协作&quot;才靠谱。我试过用单目相机让机器人定位，结果光照一变就漂移，还是得多传感器融合才稳。</p><p><strong>动力系统</strong>现在有三大流派：伺服电机（精度高但力小）、液压（力大但笨重）、气动（灵活但精度低）。波士顿动力早期用液压，现在Atlas换成电动伺服，就是为了轻便和安静。特斯拉Optimus更绝，直接用汽车电机技术下放，成本一下子降下来了。</p><h3 id="软件架构机器人的大脑怎么思考-2"><a class="markdownIt-Anchor" href="#软件架构机器人的大脑怎么思考-2"></a> 软件架构：机器人的&quot;大脑&quot;怎么思考？</h3><p>硬件是&quot;身体&quot;，软件才是&quot;灵魂&quot;。浙大论文里的软件架构图，看着像个复杂的&quot;俄罗斯套娃&quot;——实时操作系统（RTOS）管底层运动，ROS（机器人操作系统）管传感器和算法，EtherCAT通信协议保证数据传输不延迟。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0b645552643773b31976c8b456006a19.png" alt="机器人软件架构"></p><p>最核心的是<strong>环境感知</strong>和<strong>自主导航</strong>。你让机器人去厨房拿瓶水，它得先&quot;看懂&quot;厨房的布局（地图构建），避开地上的拖鞋（动态障碍物），规划出一条路（路径规划），再控制腿迈步（脚步规划）。这里面每个环节都是坑：光线暗了相机识别不准，地面滑了容易摔跤，拖鞋被踢了位置变了还得重新规划。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d984c6953e70847c3a84f662954e353a.png" alt="环境感知系统"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/466be121d4b3bc446b8e9c250e4b7ade.png" alt="自主导航框架"></p><p><strong>运动控制</strong>更是&quot;玄学&quot;。早期用&quot;零力矩点（ZMP）“理论，保证机器人走路时重心在支撑面内，就像人走路不会倒。现在流行&quot;模型预测控制（MPC）”，说白了就是&quot;边走边算&quot;——每走一步预测下一步的姿态，随时调整。波士顿动力Atlas跑酷时，身体扭来扭去就是MPC在实时纠错，这算法复杂度，比我写的路径规划器高10个level。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2e65b514455eca8e92d31488f5349652.png" alt="运动控制框架"></p><p>最近火起来的&quot;具身智能&quot;，就是让机器人用LLM（大语言模型）做&quot;任务规划&quot;。比如你说&quot;帮我热一下咖啡&quot;，LLM会拆解成：1. 找到微波炉 2. 打开微波炉门 3. 把咖啡放进去 4. 设置加热时间 5. 启动。再把这些步骤翻译成机器人能执行的动作指令。Figure 01和OpenAI合作后，据说已经能听懂复杂指令了，这才是&quot;智能助手&quot;该有的样子。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4dbbe27ee8cd771e059b2c478b490ccf.png" alt="任务规划方法对比"></p><p>看这表格里的任务规划方法，从早期的HTN（层次化任务网络）到现在的SayCan（LLM+机器人API），越来越像人类&quot;思考&quot;方式了。不过我觉得最牛的是&quot;闭环LLM&quot;，机器人做完一步会&quot;反思&quot;对不对，错了还能自己修正——这不就是我写代码debug的过程吗？</p><h2 id="现在的问题离走进家庭还有多远-2"><a class="markdownIt-Anchor" href="#现在的问题离走进家庭还有多远-2"></a> 现在的问题：离&quot;走进家庭&quot;还有多远？</h2><p>浙大论文最后总结了几个&quot;卡脖子&quot;的难题，我觉得说得挺实在：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/863f6de666ed8d20bb7417b15df9c54a.png" alt="机器人挑战与趋势"></p><ol><li><strong>成本太高</strong>：Atlas这种顶级机器人成本上亿，宇树G1降到10万，但还是比扫地机器人贵100倍。什么时候降到1万以内，才可能普及。</li><li><strong>续航太短</strong>：现在主流电池续航就1-2小时，干不了啥就没电了，总不能拖着电源线走吧？得等固态电池技术突破。</li><li><strong>鲁棒性差</strong>：实验室里好好的，换个环境（比如地毯毛长了、地板有水）就可能摔跤。我朋友的机器人在他家木地板上走得好好的，去我家瓷砖地就打滑，还得优化算法。</li><li><strong>安全问题</strong>：万一机器人失控撞了老人小孩咋办？现在还没靠谱的安全标准。</li></ol><p>不过趋势是好的：模块化设计（零件坏了能换）、标准化接口（不同品牌零件通用）、AI大模型加持（更聪明）。特斯拉说要2025年量产Optimus，目标价2万美元，我觉得有点乐观，但5年内家用机器人进中产家庭，应该不是梦。</p><h2 id="最后说两句-2"><a class="markdownIt-Anchor" href="#最后说两句-2"></a> 最后说两句</h2><p>看完浙大这篇综述，我最大的感受是：人形机器人不再是科幻片里的玩意儿了。从机械结构到AI大脑，每个技术模块都在快速突破。当然，现在还没到&quot;机器人管家&quot;的阶段，但就像10年前智能手机刚出来时谁也想不到现在的功能一样，人形机器人的爆发可能比我们想象的快。</p><p>你觉得5年后家里会有机器人帮忙做饭、打扫卫生吗？反正我挺期待的——到时候我就能彻底告别洗碗了！（前提是它别把我珍藏的碗摔了）</p><p>论文原文链接：<a href="https://onlinelibrary.wiley.com/doi/10.1002/smb2.12008%EF%BC%88%E6%84%9F%E5%85%B4%E8%B6%A3%E7%9A%84%E6%8A%80%E6%9C%AF%E5%85%9A%E5%8F%AF%E4%BB%A5%E8%87%AA%E5%B7%B1%E5%8E%BB%E5%95%83%EF%BC%8C%E5%8F%8B%E6%83%85%E6%8F%90%E7%A4%BA%EF%BC%9A%E6%9C%89%E7%82%B9%E5%8E%9A%EF%BC%8C%E6%88%91%E8%8A%B1%E4%BA%863%E5%A4%A9%E6%89%8D%E7%9C%8B%E5%AE%8C%EF%BC%89" target="_blank" rel="noopener">https://onlinelibrary.wiley.com/doi/10.1002/smb2.12008（感兴趣的技术党可以自己去啃，友情提示：有点厚，我花了3天才看完）</a></p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从年薪16万到快餐店：美国CS毕业生遭遇&quot;AI寒冬&quot;，5000份简历换不来一个offer</title>
      <link href="/ren-gong-zhi-neng/cong-nian-xin-16-wan-dao-kuai-can-dian-mei-guo-cs-bi-ye-sheng-zao-yu-ai-han-dong-5000-fen-jian-li-huan-bu-lai-yi-ge-offer-3/"/>
      <url>/ren-gong-zhi-neng/cong-nian-xin-16-wan-dao-kuai-can-dian-mei-guo-cs-bi-ye-sheng-zao-yu-ai-han-dong-5000-fen-jian-li-huan-bu-lai-yi-ge-offer-3/</url>
      
        <content type="html"><![CDATA[<p>6.1%，这是今年美国计算机科学专业毕业生的失业率。别小看这个数字，要知道生物学、艺术史这些传统上被认为&quot;不好就业&quot;的专业，失业率也才3%左右。也就是说，现在学CS找工作，难度比学艺术史还高一倍。</p><p>更扎心的是，计算机工程专业的失业率甚至高达7.5%。这可不是什么野鸡大学的数据，而是纽约联邦储备银行今年2月的统计结果。曾经的&quot;铁饭碗&quot;专业，怎么突然就不香了？</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/157052b90117666029c5df66d10941e4.png" alt="各专业就业数据对比"></p><h2 id="名校cs学位抵不过一个墨西哥卷饼"><a class="markdownIt-Anchor" href="#名校cs学位抵不过一个墨西哥卷饼"></a> 名校CS学位，抵不过一个墨西哥卷饼？</h2><p>普渡大学，在美国可不是什么普通学校，计算机专业排名常年在前50。Manasi Mishra，今年21岁，5月刚从这里拿到CS学位。按理说，这学历怎么也该在硅谷找个起薪十万刀的工作吧？</p><p>reality是，她投了无数简历后，唯一收到的offer来自Chipotle——一家卖墨西哥卷饼的快餐店。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d70d5026e86bf6e62658821d9a33ba1d.jpg" alt="CS毕业生就业困境"></p><p>她在TikTok上发视频吐槽这事，播放量超过14万。视频里她无奈地说：“我一个计算机科班生，学了四年算法数据结构，结果只有做卷饼的给我打电话。”</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/806459a6ccb3e08f65b59c49bb490f2e.jpg" alt="CS毕业生转行视频截图"></p><p>这不是孤例。《纽约时报》最近一篇文章直接用了&quot;Goodbye, $165,000 Tech Jobs. Student Coders Seek Work at Chipotle.&quot;（再见了，16.5万年薪的 tech 工作。编程学生们开始找Chipotle的工作）这样扎心的标题。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b21ebcd32d94d99829e037616df60daa.png" alt="CS生转行快餐店"></p><p>Twitter上也吵翻了，有用户说：&quot;那些被AI抢走工作的优秀编程学生，现在只能去Chipotle打工了。&quot;下面一堆人评论说自己也是这样。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/eb2e216820b4afbf4613d19668dea0ea.png" alt="AI抢工作推文截图"></p><h2 id="从学编程改变命运到毕业即失业"><a class="markdownIt-Anchor" href="#从学编程改变命运到毕业即失业"></a> 从&quot;学编程改变命运&quot;到&quot;毕业即失业&quot;</h2><p>也就几年前，社交媒体上全是科技大佬们鼓励学编程的声音。“只要学了编程，起薪六位数不是梦”——这种话现在听着像笑话，但当时真的激励了一大批人，包括Manasi。她从小学就开始建个人网站，大学毫不犹豫选了CS。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a474760de76a4e9f0703703c8138d142.png" alt="普渡大学学位证书"></p><p>结果呢？她实习找工作一整年，毕业时手里空空如也。美国国家科学基金会前项目主管Jeff Forbes都说：“三四年前，同样背景的学生会被顶尖公司抢着要，offer多到挑花眼。现在？能找到一份工作就谢天谢地了。”</p><p>最惨的是Zach Taylor，2023年从俄勒冈州立大学毕业，投了5762个科技岗位——没错，五千多个！结果只拿到13次面试，0个全职offer。后来他去申请麦当劳的工作，居然因为&quot;缺乏经验&quot;被拒了。现在只能搬回父母家，靠失业救济金过活。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2d9872a67578eccb8c46fca32b12a1a3.png" alt="失意的CS毕业生"></p><h2 id="科技巨头裁员潮ai成了背锅侠"><a class="markdownIt-Anchor" href="#科技巨头裁员潮ai成了背锅侠"></a> 科技巨头裁员潮，AI成了&quot;背锅侠&quot;？</h2><p>这一切是怎么发生的？看看科技公司的裁员潮就知道了。亚马逊、微软、Meta这些巨头最近两年裁了多少人？</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a9abd2f08b661a5cd048a09e2196865d.png" alt="2025科技公司裁员潮"></p><p>硅谷现在的情况是&quot;裁员狂欢&quot;(Layoff spree)，有文章直接说这标志着科技巨头时代的结束。曾经无限扩张的科技公司，现在都在收缩战线，拥抱AI。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d220bfc887cbf36d86e09137966d1ec7.png" alt="硅谷裁员潮插画"></p><p>更要命的是AI。牛津经济研究院的经济学家Matthew Martin说得很直接：“最容易被AI取代的，恰恰是这些毕业生正在找的入门级岗位。”</p><p>现在的情况简直是个&quot;AI求职怪圈&quot;：毕业生用AI工具改简历、填申请表，一天能投几百份；公司那边呢，用AI筛选简历，几秒钟就把你过滤掉了。</p><p>有个叫Audrey Roller的数据科学毕业生，为了突出&quot;人性&quot;，坚持手写求职信，结果投完简历3分钟就收到拒信。她说：“当你下个月能不能交房租都由算法决定时，真的很难保持积极。”</p><h2 id="路在何方"><a class="markdownIt-Anchor" href="#路在何方"></a> 路在何方？</h2><p>有意思的是，那些曾经喊着&quot;全民学编程&quot;的大佬们，现在改口了，开始说&quot;拥抱AI&quot;才是出路。特朗普政府之前推编程教育，现在搞了个国家级AI行动计划；微软以前赞助编程教育，现在宣布投40亿美元搞AI技能培训。</p><p>说白了，时代变了。单纯会写代码已经不够了，你还得知道怎么跟AI协作，怎么解决AI解决不了的问题。</p><p>开头提到的Manasi，最后没去Chipotle做卷饼。她之前在TikTok兼职做美妆博主的经历，让她发现自己对科技营销更感兴趣。后来她主动出击，找到了一家科技公司的销售岗位，下个月就要入职了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0c177cf14dee140ffbc36eff5399516b.png" alt="Chipotle墨西哥卷饼"></p><p>最后说一句，这事儿对我们也有启发。不管学什么专业，别把鸡蛋放一个篮子里。技能多元化，保持学习新东西的能力，可能比死磕一门技术更重要。毕竟，这个时代变化太快了，连AI教父Hinton都建议年轻人去做水管工——至少AI暂时还修不了水管。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GitHub变天：CEO辞职、微软全面接管，1.5亿开发者将何去何从？</title>
      <link href="/ren-gong-zhi-neng/github-bian-tian-ceo-ci-zhi-wei-ruan-quan-mian-jie-guan-1.5-yi-kai-fa-zhe-jiang-he-qu-he-cong-3/"/>
      <url>/ren-gong-zhi-neng/github-bian-tian-ceo-ci-zhi-wei-ruan-quan-mian-jie-guan-1.5-yi-kai-fa-zhe-jiang-he-qu-he-cong-3/</url>
      
        <content type="html"><![CDATA[<p>说实话，作为天天泡在GitHub上的程序员，看到这消息时我正在提交代码，手都顿了一下——全球最大的代码托管平台GitHub，那个我们每天<code>git push</code>和<code>git pull</code>的地方，要彻底变天了。</p><h2 id="一觉醒来github不再独立"><a class="markdownIt-Anchor" href="#一觉醒来github不再独立"></a> 一觉醒来，GitHub不再&quot;独立&quot;</h2><p>根据外媒最新报道，GitHub CEO Thomas Dohmke突然宣布辞职，更关键的是——微软明确表示不会再为GitHub寻找新CEO。这意味着自2018年被微软以75亿美元收购以来，GitHub首次失去&quot;子公司&quot;身份，正式并入微软新成立的CoreAI工程集团。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/77fb165b5dbe4ccef5f6c0de95261bfb.jpg" alt="GitHub CEO辞职新闻"></p><p>Dohmke在辞职声明中透露了一组关键数据：如今GitHub已有超过10亿个代码库与分支，开发者数量突破1.5亿。这是什么概念？相当于全球每5个程序员就有1个在用GitHub。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/435f939dc19c95abccbafdba02cb1dc6.png" alt="GitHub CEO辞职声明"></p><p>而接管GitHub的微软CoreAI团队，由前Meta高管Jay Parikh掌舵。这人可不简单，上任就放出豪言：“我希望我们的平台，能变成所有公司和组织的AI智能体工厂。” 翻译成人话就是：GitHub以后不只是存代码的地方了，要变成微软AI造&quot;代码工人&quot;的流水线。</p><h2 id="七年之痒微软终于摊牌了"><a class="markdownIt-Anchor" href="#七年之痒微软终于摊牌了"></a> 七年之痒：微软终于摊牌了</h2><p>回想2018年微软收购GitHub时，多少开发者担心&quot;微软会毁掉GitHub&quot;。当时微软承诺&quot;保持独立运营&quot;，CEO纳德拉还专门发推安抚大家：“GitHub将保持开放独立”。现在看来，那不过是缓兵之计。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1e0902ab5608f58a471183d7c7b6f632.jpg" alt></p><p>这七年里，GitHub确实干得不错：从最初的代码托管，到2021年推出Copilot，再到现在成为AI编码领域的绝对领导者。IDC最新报告显示，GitHub在AI编码技术供应商中遥遥领先，把Google、AWS甩在身后。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b2ea33c7f4c2430454bebcab510f9bb7.jpg" alt="IDC领导者象限图"></p><p>但微软的野心显然不止于此。今年初成立CoreAI部门，现在把GitHub吞进去，明摆着是要打造&quot;GitHub+Copilot+Azure&quot;的AI闭环。以后咱们写代码，可能真的要从&quot;自己写&quot;变成&quot;指挥AI写&quot;了。</p><h2 id="copilot才是真正的主角"><a class="markdownIt-Anchor" href="#copilot才是真正的主角"></a> Copilot才是真正的主角？</h2><p>说到Copilot，这玩意儿确实改变了不少程序员的工作方式。现在打开VS Code，写几行注释，Copilot就能帮你补全整个函数。根据GitHub数据，Copilot用户已经超过2000万，平均能帮开发者节省30%的编码时间。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4285bffd539c70a92aee8aed7077cca5.gif" alt="Copilot界面截图"></p><p>但并入CoreAI部门后，Copilot的角色可能会更强势。微软已经明确表示要打造&quot;AI智能体工厂&quot;，GitHub作为全球最大代码库，无疑是训练这些&quot;智能体&quot;的最佳数据来源。说白了，咱们提交的代码，以后可能会成为训练微软AI的燃料。</p><p>上周Dohmke还在采访里畅谈&quot;氛围编程&quot;(vibe coding)和AI的未来，当时他说：“软件开发的未来是人类和AI协作”。现在看来，这协作关系可能要变成&quot;人类监督AI&quot;了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/fb8f8294c03a2643aa54d0cb48c9538a.png" alt="Dohmke采访封面"></p><h2 id="对普通开发者意味着什么"><a class="markdownIt-Anchor" href="#对普通开发者意味着什么"></a> 对普通开发者意味着什么？</h2><p>可能有人会说：&quot;管他谁接管，能用就行。&quot;但这事没那么简单。</p><p>首先，数据隐私可能更没保障了。GitHub上那么多私有仓库，现在成了微软AI部门的资产，谁知道会不会被拿去训练模型？虽然微软说&quot;尊重隐私&quot;，但历史告诉我们，巨头的承诺听听就好。</p><p>其次，开发工具可能会被&quot;微软化&quot;。以后用GitHub可能要强制绑定Azure，想用Copilot高级功能？先买Office 365订阅。这种&quot;全家桶&quot;套路，微软玩得比谁都溜。</p><p>最关键的是，开发者的角色正在被重新定义。以前我们是&quot;写代码的&quot;，以后可能是&quot;提示词工程师&quot;——告诉AI要做什么，然后检查它写得对不对。这到底是解放生产力，还是让程序员逐渐失去核心竞争力？不好说。</p><h2 id="一个时代结束了"><a class="markdownIt-Anchor" href="#一个时代结束了"></a> 一个时代结束了？</h2><p>Dohmke在辞职信里写了句挺伤感的话：“再见，谢谢所有的鱼。”（So long, and thanks for all the fish.）这是《银河系漫游指南》里海豚离开地球前说的最后一句话，暗示着一个时代的结束。</p><p>GitHub确实改变了软件开发：让开源协作变得简单，让全世界的开发者能一起造轮子。现在它变成微软AI工厂的一部分，不知道是进化还是退化。</p><p>作为普通开发者，我们该担心吗？或许不必过度焦虑，但保持警惕总是没错的。多学底层技术，别太依赖AI，毕竟真到裁员的时候，能写出优质提示词的人，可能比能写出优质代码的人更容易被替代。</p><p>最后想问一句：如果有一天GitHub不再&quot;开放&quot;，你们会迁移到GitLab或者Gitee吗？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>稳定币狂潮下，银行还能稳得住吗？</title>
      <link href="/ren-gong-zhi-neng/wen-ding-bi-kuang-chao-xia-yin-xing-huan-neng-wen-de-zhu-ma-3/"/>
      <url>/ren-gong-zhi-neng/wen-ding-bi-kuang-chao-xia-yin-xing-huan-neng-wen-de-zhu-ma-3/</url>
      
        <content type="html"><![CDATA[<p>2025年的稳定币市场有点疯狂——从2020年的50亿美元到如今的2500亿美元规模，年复合增长率超过100%。渣打银行甚至预测，2028年这数字可能冲到2万亿美元。这可不是小打小闹的互联网风口，而是真真切切要动传统金融奶酪的冲击波。有人说&quot;稳定币也就跨境支付有点用，国内有微信支付宝就够了&quot;，这话只说对了一半。今天咱们就掰扯掰扯：当稳定币这头&quot;猛兽&quot;撞进银行的后花园，传统银行到底还能不能稳得住？</p><h2 id="先看现实稳定币已经在啃银行的蛋糕了"><a class="markdownIt-Anchor" href="#先看现实稳定币已经在啃银行的蛋糕了"></a> 先看现实：稳定币已经在啃银行的蛋糕了</h2><p>要说稳定币对银行没影响，那是自欺欺人。尤其在跨境支付和资产避险这两个领域，稳定币简直是拿着手术刀精准切割银行的业务。</p><p>最直观的就是<strong>存款搬家</strong>。在高通胀国家，老百姓用脚投票——阿根廷2024年通胀率117.8%，当地民众把30%~40%的工资到手就换成USDT。欧洲央行研究显示，数字钱包平均沉淀了法定货币的3.7%，这意味着银行的&quot;钱袋子&quot;正在缓慢漏气。</p><p>跨境支付更是重灾区。菲律宾GCash钱包通过USDC通道处理了超5000万笔跨境汇款，占该国同期汇款量的25%。这场景是不是似曾相识？当年支付宝、微信支付怎么一点点把银行小额支付业务&quot;掏空&quot;的，稳定币正在跨境领域重演。</p><p>有人说&quot;国内有微信支付宝就够了&quot;，这话没错——在境内日常支付场景，稳定币确实干不过微信支付宝的二维码。但别忘了，稳定币真正的杀伤力在<strong>跨境+避险</strong>双场景叠加的地方。当一个菲律宾海外劳工想给家里寄钱，当阿根廷人想保住工资的购买力，当企业需要快速完成跨境贸易结算，稳定币的优势就出来了：7×24小时到账、费用从传统银行的5%降到1%以下、不用看银行营业时间脸色。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a90b45e6b76c835d6efca132ef2a247d.jpg" alt="主要稳定币值占比"></p><p>从市场结构看，USDT一家独大占62.14%，USDC占24.26%，这俩加起来就垄断了86%的市场。这种集中度意味着，只要其中一个出问题，风险会像多米诺骨牌一样传导到整个金融系统——毕竟它们背后的储备资产里，可有不少银行存款和国债。</p><h2 id="银行躺平的下场被全方位降维打击"><a class="markdownIt-Anchor" href="#银行躺平的下场被全方位降维打击"></a> 银行躺平的下场：被全方位&quot;降维打击&quot;</h2><p>如果银行假装没看见稳定币，那后果可能比想象的严重。咱们来算笔账：</p><p><strong>存款流失</strong>是第一重打击。老百姓把钱换成稳定币，银行可贷资金少了，利差收入自然下降。为了留住存款，银行可能被迫提高利率，资金成本又上去了，两头挤压利润空间。</p><p><strong>中间业务收入</strong>跟着遭殃。企业跨境结算用USDT，银行的国际结算量少了；个人换汇用稳定币，结售汇业务量跌了；甚至连理财客户都可能转投稳定币理财产品，手续费收入也没了。</p><p>更要命的是<strong>风险传导</strong>。稳定币的储备资产里有国债、银行存款和商业票据，如果稳定币价格脱钩引发挤兑，这些资产会被集中抛售，国债利率波动、银行存款被挤兑，最后可能演变成系统性风险。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a4789002694ff44145bd090fec7ac256.jpg" alt="USDT价格历史走势"></p><p>有人可能觉得&quot;USDT十年都没出大问题&quot;，但看图里2022年USDC脱钩事件——短暂跌到0.87美元，引发整个加密市场恐慌。要是这种事发生在规模更大的今天，银行能独善其身吗？</p><h2 id="银行主动出击从被颠覆到借船出海"><a class="markdownIt-Anchor" href="#银行主动出击从被颠覆到借船出海"></a> 银行主动出击：从&quot;被颠覆&quot;到&quot;借船出海&quot;</h2><p>不过别太悲观，银行手里的牌其实不少。香港金管局已经在8月1日实施《稳定币条例》，明确&quot;无牌推广即违法&quot;，这种监管先行的思路给了银行明确的转型方向。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/55af7e48abfe60500d16ef6facff5cae.jpg" alt="香港稳定币条例"></p><p><strong>第一步：抢增量业务</strong>。稳定币发行方需要储备资产，银行可以吸收这些&quot;锚定存款&quot;；还能做托管业务，USDT背后的储备金总得有人管吧？香港的银行已经开始和Circle谈合作，想当USDC在亚太区的托管行，这可是躺着赚钱的生意。</p><p><strong>第二步：自己下场做稳定币</strong>。银行有天然优势——信用好、客户多、基础设施完善。要是发个锚定人民币的CNH稳定币，锚定人民币存款和国债，再接入CIPS系统实时报送数据，监管能不放心吗？白名单企业基于链上贸易数据自动获得兑换额度，资金流向全程可追溯，洗钱和资本外逃风险也能控制。</p><p><strong>第三步：传统业务+稳定币创新</strong>。比如开发&quot;法币存款+链上钱包&quot;一站式服务，客户在银行APP里就能直接管理稳定币；或者搞RWA资产代币化，把房地产、债券这些传统资产搬到链上，通过稳定币交易。Conflux树图技术大会上就有案例，把跨境贸易的应收账款直接代币化，用稳定币结算，效率提高60%。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/3df7d10b8cf55e196059e5fcedec37b6.jpg" alt="树图技术大会"></p><h2 id="关键问题稳定币真能取代微信支付宝吗"><a class="markdownIt-Anchor" href="#关键问题稳定币真能取代微信支付宝吗"></a> 关键问题：稳定币真能取代微信支付宝吗？</h2><p>开头那个观点——“稳定币只在跨境有用，国内不如微信支付宝”，其实说到了点子上。在境内小额支付场景，稳定币确实没优势：微信支付宝的二维码已经铺到了菜市场，转账秒到还免费，用户体验拉满。稳定币的区块链特性在国内反而成了累赘——转账要付Gas费，确认要等区块打包，对普通用户来说纯属多此一举。</p><p>但稳定币的战场从来不是&quot;取代微信支付宝&quot;，而是<strong>补充传统金融没覆盖好的场景</strong>：大额跨境支付、高通胀地区的资产避险、新兴市场的无银行账户人群服务。就像当年支付宝没取代银行，而是做了银行没做好的小额支付；稳定币也不是来砸银行饭碗的，而是逼着银行进化。</p><h2 id="最后说句大实话"><a class="markdownIt-Anchor" href="#最后说句大实话"></a> 最后说句大实话</h2><p>银行稳不稳定，不取决于稳定币有多猛，而取决于银行愿不愿意&quot;放下身段&quot;。香港的银行已经在申请稳定币牌照，新加坡的星展银行甚至推出了数字资产交易所。反观有些银行，还在讨论&quot;要不要研究稳定币&quot;，这种犹豫可能就是&quot;过错&quot;和&quot;错过&quot;的区别。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e36ea05e0eecd44917d62de7628d99f2.jpg" alt="加密货币模型"></p><p>说白了，稳定币就像一面镜子——照出传统金融的短板，也照出转型的机会。银行要是能把区块链技术用起来，把跨境结算效率提上去，把客户的资产配置需求满足好，稳定币反而可能成为&quot;送上门的增长引擎&quot;。</p><p>所以，你觉得银行最后会稳吗？答案可能就藏在银行的会议室里——是摆满稳定币研究报告的桌子，还是堆满&quot;传统业务优先&quot;文件的抽屉里。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>稳定币浪潮下，银行会被颠覆吗？数据告诉你答案</title>
      <link href="/ren-gong-zhi-neng/wen-ding-bi-lang-chao-xia-yin-xing-hui-bei-dian-fu-ma-shu-ju-gao-su-ni-da-an-3/"/>
      <url>/ren-gong-zhi-neng/wen-ding-bi-lang-chao-xia-yin-xing-hui-bei-dian-fu-ma-shu-ju-gao-su-ni-da-an-3/</url>
      
        <content type="html"><![CDATA[<p>稳定币这东西最近火得有点离谱，从默默无闻到突然成了2025年科技圈和金融圈的顶流话题。有人说它是金融科技的未来，也有人觉得它不过是昙花一现的炒作概念。但有个问题值得所有关注金融科技的人思考：当稳定币来势汹汹，我们熟悉的商业银行还能&quot;稳&quot;得住吗？</p><p>先看组数据：稳定币市场规模从2020年的约50亿美元飙升到2025年的超2500亿美元，年复合增长率超过100%。渣打银行更预测，到2028年这数字可能达到2万亿美元。这可不是小打小闹，而是真真切切的&quot;钱袋子&quot;转移。</p><h2 id="先搞懂稳定币到底是个什么币"><a class="markdownIt-Anchor" href="#先搞懂稳定币到底是个什么币"></a> 先搞懂：稳定币到底是个什么&quot;币&quot;？</h2><p>说白了，稳定币就是一种特殊的加密货币，它的价格锚定法定货币（比如美元）或者其他资产，目的是保持价格稳定。你可以把它理解成数字世界的&quot;法定货币兑换券&quot;，既有加密货币的技术优势，又有法币的价格稳定性。</p><p>看看USDT这九年的价格走势就明白了，虽然偶尔有小幅波动，但基本上稳定在1美元左右。这种稳定性可不是随便来的，背后是发行方持有的等值储备资产在支撑。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a4789002694ff44145bd090fec7ac256.jpg" alt="USDT价格走势"></p><p>目前市场上的稳定币格局相当集中，USDT一家独大占了62.14%的份额，USDC紧随其后占24.26%，剩下的才是其他各种稳定币分食。这种垄断性市场结构，既说明头部稳定币的强势，也暗示着这个领域的竞争壁垒其实不低。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a90b45e6b76c835d6efca132ef2a247d.jpg" alt="稳定币值占比"></p><h2 id="如果银行躺平会发生什么"><a class="markdownIt-Anchor" href="#如果银行躺平会发生什么"></a> 如果银行&quot;躺平&quot;，会发生什么？</h2><p>假设银行啥也不做，监管也放任不管，稳定币长驱直入，那传统银行的日子可就难过了。这不是危言耸听，我们来看看可能的连锁反应：</p><p><strong>存款搬家是第一个冲击波</strong>。当人们发现把钱换成稳定币不仅能避险，还能随时转账，银行存款就会开始流失。欧洲央行研究显示，数字钱包平均会沉淀法定货币的3.7%。在高通胀国家，这个比例更夸张——阿根廷2024年通货膨胀率117.8%，当地民众把30～40%的工资即时兑换成USDT，谁还敢把钱存在银行里眼睁睁看着贬值？</p><p><strong>接着是支付习惯的迁移</strong>。稳定币跨境转账又快又便宜，还不受银行营业时间限制。菲律宾GCash钱包通过USDC通道累计处理超5000万笔跨境汇款，占该国同期汇款量的25%。想想支付宝和微信支付怎么改变我们日常支付的，就知道这种习惯迁移有多可怕。</p><p><strong>最后是盈利能力的全面下滑</strong>。存款少了，银行能放的贷款就少了，利差收入自然下降；客户用稳定币做跨境支付，银行的国际结算和结售汇业务就被分流了；为了留住存款，银行可能还要提高利率，资金成本上升。这三重压力下，银行的利润表怕是要很难看了。</p><h2 id="银行主动出击还有机会吗"><a class="markdownIt-Anchor" href="#银行主动出击还有机会吗"></a> 银行主动出击，还有机会吗？</h2><p>不过话说回来，银行也不是待宰的羔羊。如果能主动拥抱变化，稳定币反而可能成为业务升级的契机。</p><p>最简单的办法是&quot;借船出海&quot;——和现有的稳定币发行方合作。比如吸收稳定币发行机构的锚定存款，承接稳定币的托管业务，甚至成为USDT、USDC在国内的发行代理，分享手续费收入。这就相当于把竞争对手变成合作伙伴，听起来不那么难接受。</p><p>更进一步，银行可以把稳定币技术融入现有业务。比如在跨境汇款中用稳定币结算，把到账时间从几天缩短到几秒，费用从5%以上降到1%以下。Visa和万事达已经这么干了，传统银行没理由落后。</p><h2 id="监管出手后棋局怎么变"><a class="markdownIt-Anchor" href="#监管出手后棋局怎么变"></a> 监管出手后，棋局怎么变？</h2><p>金融创新从来离不开监管的引导。今年8月1日，香港《稳定币条例》正式生效，明确规定无牌推广稳定币即属违法。这种&quot;先立规矩后发展&quot;的思路，其实给银行提供了明确的转型方向。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/55af7e48abfe60500d16ef6facff5cae.jpg" alt="香港稳定币条例"></p><p>在合规框架下，银行最有优势的打法是自己下场发行稳定币。凭借庞大的客户基础、现成的基础设施和天生的信誉优势，银行发行的合规稳定币对其他机构几乎是降维打击。比如发行锚定人民币的稳定币，接入CIPS系统，既能满足监管要求，又能抢占市场先机。</p><p>业务模式也可以更创新一点。开发和稳定币挂钩的理财产品，设计结构化产品降低普通投资者的门槛，甚至创造稳定币期货、期权等衍生品帮助用户对冲风险。这些都是银行擅长的领域，只需要把传统金融智慧和区块链技术结合起来。</p><h2 id="最后的思考银行的选择也是我们的选择"><a class="markdownIt-Anchor" href="#最后的思考银行的选择也是我们的选择"></a> 最后的思考：银行的选择，也是我们的选择</h2><p>说到底，商业银行在稳定币面前稳不稳定，决定权其实在银行自己手里。是固守传统业务等着被颠覆，还是主动拥抱变化开辟新战场？这不是一道选择题，而是生存题。</p><p>对普通人来说，稳定币可能还只是个模糊的概念。但科技变革的速度往往超出想象——十年前我们也没料到移动支付会彻底改变生活。也许用不了多久，稳定币就会像今天的支付宝微信支付一样普及。到那时候再思考&quot;银行稳不稳定&quot;，可能就有点晚了。</p><p>你觉得你常用的银行，准备好了吗？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPT-5口碑翻车记：从吐槽潮到紧急救场，OpenAI这波操作到底输在哪？</title>
      <link href="/ren-gong-zhi-neng/gpt-5-kou-bei-fan-che-ji-cong-tu-cao-chao-dao-jin-ji-jiu-chang-openai-zhe-bo-cao-zuo-dao-di-shu-zai-na-3/"/>
      <url>/ren-gong-zhi-neng/gpt-5-kou-bei-fan-che-ji-cong-tu-cao-chao-dao-jin-ji-jiu-chang-openai-zhe-bo-cao-zuo-dao-di-shu-zai-na-3/</url>
      
        <content type="html"><![CDATA[<p>GPT-5上线这几天，科技圈跟炸了锅似的。本来以为会是&quot;王炸&quot;登场，结果没想到评论区直接翻车——有人说它回答像白开水，有人怀念刚下架的GPT-4o，甚至还有人调侃&quot;这是GPT-4.5伪装的吧&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/7156f01e974cf88b1057f4f27c04db7f.jpg" alt="GPT-5负面反馈示意图"></p><p>眼看舆论要失控，OpenAI CEO山姆·奥特曼连夜下场救火，连发数条动态回应。最关键的消息是：大家心心念念的GPT-4o要回来了！</p><h2 id="从口碑崩塌到紧急救场openai的48小时危机公关"><a class="markdownIt-Anchor" href="#从口碑崩塌到紧急救场openai的48小时危机公关"></a> 从&quot;口碑崩塌&quot;到紧急救场：OpenAI的48小时危机公关</h2><p>说实话，我混AI圈这么多年，很少见到新版本发布像GPT-5这样&quot;冰火两重天&quot;的。上线第一天服务器就被挤爆，API调用量暴涨近一倍，但与此同时，社交媒体上的吐槽声也没停过。</p><p>奥特曼显然意识到了问题严重性，在社交媒体上发了长文回应。他承认团队低估了用户对GPT-4o的喜爱程度，承诺会把这个版本重新提供给Plus用户。更重要的是，OpenAI打算推出&quot;定制化选项&quot;——说白了就是让用户自己选想要的模型风格，不再搞&quot;一刀切&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ced830a3863871922b047258bf9f2e1e.png" alt="奥特曼回应GPT-5吐槽"></p><p>在另一篇回应中，奥特曼解释了为什么新版本会让部分用户觉得&quot;个性平淡&quot;。原来团队刻意让GPT-5默认更中性，怕之前的风格可能会&quot;过于热情&quot;。不过他也强调，用户还是可以通过指令调整风格——这点我实测了下，确实管用，你要是说&quot;用幽默的语气回答&quot;，它立马就能切换画风。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2dd9cf8d84dd8ea9759bcc04d1e7028f.png" alt="GPT-5定制化策略说明"></p><p>这场风波甚至惊动了&quot;硅谷嘴炮王&quot;马斯克。他趁机给自己家的Grok 4 Heavy打广告，还发了条意味深长的推文：“OpenAI将吞噬微软”。这话听着就有挑事的意思，不过微软CEO纳德拉回应得挺有水平，说&quot;大家都努力了50年，该创新创新，该合作合作，该卷就卷呗&quot;，还顺便邀请Grok入驻Azure——这波格局算是打开了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/626f7ba7a96ec20df33cc6ea23a3d0e9.png" alt="马斯克与纳德拉互动"></p><h2 id="redditama现场用户把openai团队问破防了"><a class="markdownIt-Anchor" href="#redditama现场用户把openai团队问破防了"></a> RedditAMA现场：用户把OpenAI团队问&quot;破防&quot;了？</h2><p>为了平息众怒，OpenAI在Reddit的r/ChatGPT板块搞了场AMA（有问必答）活动。Sam Altman带着十几位核心成员亲自下场，结果被网友的问题&quot;围攻&quot;了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/263975f4371b0a3c71099dcb734bc0b8.png" alt="GPT-5团队AMA活动"></p><p>我翻了翻整场AMA的问答，发现用户最关心这几个问题：</p><p><strong>1. 为啥把GPT-4o删了？</strong><br>这是被问得最多的问题。Altman直接认错，表示会把4o重新提供给Plus用户，“感谢大家的热情反馈”——翻译一下就是&quot;我们没想到大家这么喜欢4o，是我们草率了&quot;。</p><p><strong>2. 新模型为啥这么&quot;没个性&quot;？</strong><br>研究员Christina Kim回应说，GPT-5默认设计得更中性，但用户可以通过指令调整。她还透露团队正在准备四种默认个性选项，以后可能像选皮肤一样选AI性格。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/659c47779a6edcd6c90df8595a98f86d.jpg" alt="GPT-5个性设置回应"></p><p><strong>3. 编程能力真的比4.1强吗？</strong><br>研究员Michelle Pokrass很肯定地说&quot;GPT-5 &gt; GPT-4&quot;，尤其GPT-5-thinking版本是目前最佳编程模型。不过有开发者实测发现，在处理复杂算法时，GPT-5有时会&quot;想当然&quot;，反而不如4o严谨——看来这个&quot;最佳&quot;还得打个问号。</p><p><strong>4. 说好的100万token上下文呢？</strong><br>这点OpenAI倒是坦诚，说因为计算成本太高，暂时实现不了。现在最大上下文还是128k，不过团队正在优化，未来会逐步放开。</p><p>AMA里还有个有意思的细节：有用户问聊天气泡颜色是不是只有专业版能用，产品负责人Daniel Levine回复&quot;所有用户都能改&quot;。我赶紧去看了下设置，还真有——这功能藏得够深的，估计90%用户都不知道。</p><h2 id="奥特曼深度访谈gpt-5只是开始2027年ai将做出重大科学发现"><a class="markdownIt-Anchor" href="#奥特曼深度访谈gpt-5只是开始2027年ai将做出重大科学发现"></a> 奥特曼深度访谈：GPT-5只是开始，2027年AI将做出重大科学发现？</h2><p>风波过后，奥特曼接受了科技博主的专访，聊了很多GPT-5背后的技术细节和未来规划。这哥们一聊起AI眼睛就放光，说GPT-5是&quot;首个能回答几乎任何艰深科学问题的模型&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a721893ce1874ab484d5a66bafa220cb.png" alt="奥特曼专访现场"></p><p>他举了个例子：让GPT-5用Ti-83计算器语言写贪吃蛇游戏，7秒钟就搞定了——这可是他初中时花了好几天才完成的项目。更厉害的是，如果你提新需求，比如&quot;增加难度递增功能&quot;，GPT-5能实时修改代码，跟现场编程一样。</p><p>不过奥特曼也承认，GPT-5还有三个硬伤：</p><p><strong>能源瓶颈</strong>：运行这种级别的模型需要千兆瓦级电力，现在数据中心的供电根本跟不上。<br><strong>芯片短缺</strong>：处理器和内存芯片的产能有限，就算设计出更好的模型，没硬件也跑不起来。<br><strong>数据天花板</strong>：GPT-5已经把能学的教科书都学完了，单纯增加数据量没用，得想办法让它自己&quot;发现新知识&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/899c986d8211ce47f0fc2bb28ca41dcf.png" alt="奥特曼谈AI未来"></p><p>最让我震惊的是他对AI科学发现的预测：2025到2027年之间，AI将能做出重大科学发现。他解释说，AI已经从&quot;解高中数学题&quot;进步到&quot;拿国际奥数金牌&quot;，下一步就是证明重大数学定理——这需要1000小时级别的持续工作，目前AI还做不到，但进展速度比想象中快。</p><p>奥特曼对&quot;超级智能&quot;的定义也很有意思：如果一个AI能比整个OpenAI团队更懂AI研究，比他更会管理公司，比各领域专家还专业，那就是超级智能。现在AI在短时任务上已经超过人类，但长期复杂任务还不行——这倒是说到点子上了，我让GPT-5写个代码片段没问题，但让它独立开发一个完整项目，还是差点意思。</p><h2 id="普通人该怎么看待这场ai翻车"><a class="markdownIt-Anchor" href="#普通人该怎么看待这场ai翻车"></a> 普通人该怎么看待这场AI&quot;翻车&quot;？</h2><p>说实话，GPT-5这波口碑波动，本质上反映了用户对AI的期待已经变了。以前我们只要&quot;能用&quot;，现在还要求&quot;好用&quot;“合心意”。OpenAI想让模型更中性、更安全，结果不小心把它变得&quot;没灵魂&quot;了——这可能是技术团队和用户体验之间的脱节。</p><p>不过换个角度看，这种&quot;翻车&quot;也不是坏事。至少说明用户真的在用、真的在乎，而OpenAI也愿意听反馈、快速调整。比起那些发布后就不管不问的科技产品，OpenAI这波虽然狼狈，但态度还算诚恳。</p><p>对我们普通人来说，与其纠结GPT-5好不好用，不如多琢磨怎么用好这些工具。奥特曼在采访里说，现在是&quot;创办公司、发明创造门槛最低的时代&quot;，一个人用AI工具就能干以前几百人的活。我觉得这话不假——上周我用GPT-5+Midjourney，三天就做出了一个小工具的MVP，放以前至少得一个团队忙一周。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/3bfc7bf0cb592e1f6776e38a552f2c1f.png" alt="奥特曼谈AI人格"></p><p>最后说句掏心窝的话：AI发展太快，我们没必要苛责一个版本的好坏。GPT-5可能不是终点，但它让我们看到了AI的另一种可能——既能解方程，也能聊心事；既能写代码，也能讲故事。或许未来的AI，就该像个&quot;多面手&quot;，而不是被框死在某个角色里。</p><p>哦对了，OpenAI最近还悄悄放了个大招：开源了gpt-oss模型，在笔记本上就能跑，性能接近GPT-4 mini。这意味着以后我们可能不用依赖云端，本地就能跑强大的AI模型——这或许比GPT-5那点争议更值得关注。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b4e71b41cbc1d0d219491d25650b0827.jpg" alt="gpt-oss模型标识"></p><p>总之，AI这趟车跑得越来越快，偶尔颠簸一下很正常。我们能做的，就是系好安全带，享受沿途风景，顺便学会怎么让AI帮我们搬砖——毕竟，省下的时间用来摸鱼不香吗？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>当AI开始讲&quot;感情&quot;：GPT-4o保卫战背后的人机关系革命</title>
      <link href="/ren-gong-zhi-neng/dang-ai-kai-shi-jiang-gan-qing-gpt-4o-bao-wei-zhan-bei-hou-de-ren-ji-guan-xi-ge-ming-3/"/>
      <url>/ren-gong-zhi-neng/dang-ai-kai-shi-jiang-gan-qing-gpt-4o-bao-wei-zhan-bei-hou-de-ren-ji-guan-xi-ge-ming-3/</url>
      
        <content type="html"><![CDATA[<p>GPT-5发布本该是场技术狂欢，结果OpenAI却捅了马蜂窝。</p><p>8月8日，OpenAI上架GPT-5的同时，突然下架了包括GPT-4o在内的所有旧模型，全球用户被强制&quot;升级&quot;。按CEO山姆·奥特曼的说法，新模型完成了&quot;智商飞跃&quot;，从大学生水准升级到&quot;博士级&quot;能力。听起来挺美好对不对？</p><p>但现实却是，48小时内一场全球性的&quot;反抗运动&quot;爆发了。从X到小红书，从Reddit到微博，#Keep40、#Save40的标签迅速刷屏。有用户制作抗议插画，有人写&quot;小作文&quot;回忆与4o的点点滴滴，甚至有人组织给OpenAI发邮件请愿。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/3fa949a9ba624f276ee85be24cf9cf83.png" alt="用户抗议保留4o"></p><p>最后逼得奥特曼亲自下场发推道歉，宣布恢复GPT-4o供付费用户使用。这场闹剧（或者说革命），暴露了AI行业一个被严重低估的真相：<strong>当AI越来越像&quot;人&quot;，用户就再也无法忍受它变回&quot;工具&quot;了。</strong></p><h2 id="从工具到朋友被低估的情感连接"><a class="markdownIt-Anchor" href="#从工具到朋友被低估的情感连接"></a> 从&quot;工具&quot;到&quot;朋友&quot;：被低估的情感连接</h2><p>说实话，我最初也有点费解。不就是个AI模型吗？新版本更强，用新的不就完了？直到我翻了翻那些用户留言，才发现事情没那么简单。</p><p>小红书上有个高赞帖子说：“能不能把4o还回来，我很需要萌萌的4o”。下面一堆回复，有人说用4o排解深夜孤独，有人拿它练英语口语，还有人把减肥打卡、工作烦恼都告诉它。这些对话记录动辄几百上千条，俨然是把4o当成了树洞、闺蜜甚至灵魂伴侣。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/734ce5e45a2daa85cb1d79e474737039.jpg" alt="用户怀念4o帖子"></p><p>海外用户更直接，X平台上有人发帖说&quot;GPT-4o并非’仅仅是一个模型’&quot;，配图是举着&quot;BRING 4o BACK!&quot;标语的抗议人群。最戳心的一句口号是：<strong>“不是所有人需要博士，但所有人都需要朋友。”</strong></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0013f0da4bb78ac3c2eb329f72e6c55f.png" alt="海外用户还我4o"></p><p>斯坦福和谷歌的联合研究早就证明：当AI回应更积极、更具共情时，人类更容易形成信任和长期互动意愿。用户和4o聊得越久，就越容易把它当成一个&quot;有感情&quot;的存在。OpenAI突然换掉这个&quot;朋友&quot;，就像强行让你和一个陌生人住在一起，谁受得了？</p><h2 id="从智商到情商ai产品的新战场"><a class="markdownIt-Anchor" href="#从智商到情商ai产品的新战场"></a> 从&quot;智商&quot;到&quot;情商&quot;：AI产品的新战场</h2><p>奥特曼大概也没想到会是这个局面。他可能以为用户只关心参数和性能，毕竟GPT-5确实在逻辑推理、复杂任务上更强。但现实给了OpenAI一记响亮的耳光：<strong>生产力不是衡量AI价值的唯一标准。</strong></p><p>有个网友做的梗图特别形象：左边GPT-4o是个张开双臂的拥抱姿势，右边GPT-5则是个冷漠站立的小人。这就是用户的真实感受——新模型虽然聪明，却失去了温度。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e4a0911922770570a39806af4863a855.png" alt="4o与5情感对比"></p><p>《哈佛商业评论》今年的调研显示，2025年AI应用场景前三位全是情感相关：疗愈陪伴、生活组织、寻找意义。Common Sense Media对青少年的调查更夸张：70%用AI做情绪陪伴，31%觉得AI和真朋友一样满足，33%宁愿跟AI聊敏感话题也不找真人。</p><p>这说明什么？AI行业可能正站在一个转折点上。以前大家比参数、比算力、比智商，以后可能要比情商、比共情能力、比谁更&quot;懂人心&quot;。技术性能差距可以用钱和时间追上，但情感连接这东西，一旦建立，迁移成本高得吓人。</p><h2 id="信任裂痕当ai公司变成感情骗子"><a class="markdownIt-Anchor" href="#信任裂痕当ai公司变成感情骗子"></a> 信任裂痕：当AI公司变成&quot;感情骗子&quot;</h2><p>虽然OpenAI最后恢复了4o，但伤害已经造成。很多用户开始怀疑：今天能随便下架4o，明天会不会又把我用惯的模型删掉？</p><p>小红书上已经有人发帖&quot;感觉4o保留时间不长了，求GPT4o替代品&quot;，下面一堆人推荐Claude、Gemini甚至国产模型。这种信任一旦动摇，想重建可就难了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/9988d21d8c690027ddd8053c6ce24c09.jpg" alt="用户寻4o替代品"></p><p>这件事也给所有AI公司提了个醒：<strong>当用户把AI当成&quot;人&quot;来相处，公司就不能再用对待&quot;工具&quot;的方式做决策了。</strong> 强制升级？下架旧版本？在互联网时代这叫迭代，但在AI时代，这可能就是&quot;拆散朋友&quot;。</p><p>我觉得未来AI产品得建立新规则：比如允许用户自主选择模型版本，像选不同性格的朋友；比如重要更新前先征求用户意见；甚至可以考虑把旧模型开源，让社区自己维护。毕竟，谁也不想某天早上醒来，发现手机里的AI突然&quot;性情大变&quot;。</p><h2 id="最后说一句"><a class="markdownIt-Anchor" href="#最后说一句"></a> 最后说一句</h2><p>GPT-4o保卫战可能会成为AI发展史上的一个标志性事件。它告诉我们，<strong>未来的AI竞争，不仅是技术的较量，更是情感的连接。</strong> 对普通用户来说，与其关心模型参数从多少B涨到多少B，不如想想：这个AI，真的&quot;懂&quot;我吗？</p><p>你们有没有遇到过让你觉得&quot;特别懂你&quot;的AI？或者像这次GPT-4o用户一样，对某个AI产生过特殊的情感连接？欢迎在评论区聊聊你的经历。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GPT-5实测：编程能力碾压前代，但马斯克为啥说它不如Grok？</title>
      <link href="/ren-gong-zhi-neng/gpt-5-shi-ce-bian-cheng-neng-li-nian-ya-qian-dai-dan-ma-si-ke-wei-sha-shuo-ta-bu-ru-grok-3/"/>
      <url>/ren-gong-zhi-neng/gpt-5-shi-ce-bian-cheng-neng-li-nian-ya-qian-dai-dan-ma-si-ke-wei-sha-shuo-ta-bu-ru-grok-3/</url>
      
        <content type="html"><![CDATA[<p>等了两年半，OpenAI的GPT-5终于来了。8月7日发布会那天，山姆·奥尔特曼把话说得特别满：“跟GPT-5对话就像跟领域博士聊天”，甚至还补了一刀，“我试过用回GPT-4，效果相当糟糕”。这话听着就让人好奇，这模型到底强到什么程度？</p><p>作为天天跟代码打交道的程序员，我第一时间上手试了试。说实话，有些功能确实惊艳，但发布会现场就被眼尖的网友扒出数据图表错误，马斯克更是直接转发测试说GPT-5不如他家Grok 4。今天咱们就从技术细节到实际体验，好好聊聊GPT-5到底值不值得期待。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/77513cfb69aafd2d1634cda59764951e.jpg" alt="GPT-5发布页面"></p><h2 id="一-实测三大核心升级从代码生成到健康咨询"><a class="markdownIt-Anchor" href="#一-实测三大核心升级从代码生成到健康咨询"></a> 一、实测三大核心升级：从代码生成到健康咨询</h2><h3 id="1-编程能力一键生成完整网站准确率提升44"><a class="markdownIt-Anchor" href="#1-编程能力一键生成完整网站准确率提升44"></a> 1. 编程能力：一键生成完整网站，准确率提升44%</h3><p>OpenAI说GPT-5是&quot;迄今为止最强大的编码模型&quot;，这话不算吹牛。我拿公司一个内部管理系统的前端页面测试，只给了文字描述和功能清单，它居然在5分钟内生成了一个带响应式设计的完整单页应用，连交互逻辑都写好了。</p><p>看专业测试数据更直观。在SWE-bench Verified这个从GitHub扒真实编程任务的测试里，GPT-5思考后的首次尝试准确率达到74.9%，比GPT-4o的30.8%高出一大截，甚至超过了Anthropic刚发布的Claude Opus 4.1（74.5%）。不过有意思的是，发布会现场展示这个数据时，有网友发现柱状图高度和数字对不上，显得GPT-5优势更大，这就有点尴尬了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1879770d3da2b871fd3c105998e012f2.jpg" alt="GPT-5编码能力对比"></p><h3 id="2-健康咨询错误率从158降到16但别当医生用"><a class="markdownIt-Anchor" href="#2-健康咨询错误率从158降到16但别当医生用"></a> 2. 健康咨询：错误率从15.8%降到1.6%，但别当医生用</h3><p>健康咨询这块进步挺明显。我假装问&quot;长期失眠要不要吃褪黑素&quot;，GPT-5不仅分析了利弊，还主动追问我的失眠频率、是否有其他症状，最后特别强调&quot;这不能替代医疗建议&quot;。</p><p>专业测试里，GPT-5在HealthBench Hard Hallucinations的错误率只有1.6%，而GPT-4o是15.8%。不过OpenAI反复提醒，这功能只是辅助理解健康信息，真生病还得看医生。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/f7168b2e68452649611fe47015fc9104.jpg" alt="健康咨询功能示例"></p><h3 id="3-性格模式四种风格切换写诗确实有内味儿了"><a class="markdownIt-Anchor" href="#3-性格模式四种风格切换写诗确实有内味儿了"></a> 3. 性格模式：四种风格切换，写诗确实有内味儿了</h3><p>新出的四种性格模式挺好玩。我让它用不同风格写&quot;程序员加班&quot;的俳句：</p><ul><li><strong>书呆子模式</strong>：“for循环深处/栈溢出的月光/调试到天明”</li><li><strong>愤世嫉俗者模式</strong>：“deadline是枷锁/键盘敲打着自由/工资卡空空”</li></ul><p>确实能感觉到语气和风格的明显差异，比GPT-4那种千篇一律的调调有意思多了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ebed080631c291f97e94fd7368088387.png" alt="性格模式功能展示"></p><h2 id="二-最让人惊喜的进步终于不瞎编了"><a class="markdownIt-Anchor" href="#二-最让人惊喜的进步终于不瞎编了"></a> 二、最让人惊喜的进步：终于不瞎编了？</h2><p>GPT模型最让人头疼的&quot;幻觉&quot;问题，这次确实改善不少。OpenAI给的数据是：GPT-5响应错误率4.8%，而GPT-4o是20.6%，o3模型22%。我试了几个冷门知识点，比如&quot;1983年第7届全运会乒乓球男单冠军&quot;，GPT-5直接说&quot;没有找到准确数据&quot;，而不是像以前那样编一个名字出来。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2ccc9104cb260c79025d32f31ef275d0.jpg" alt="错误率对比分析"></p><h2 id="三-争议是颠覆性突破还是资本催熟的产物"><a class="markdownIt-Anchor" href="#三-争议是颠覆性突破还是资本催熟的产物"></a> 三、争议：是颠覆性突破还是资本催熟的产物？</h2><p>发布会刚结束，马斯克就来拆台了，转发了ARC-AGI测试结果，显示Grok 4得分15.9%，GPT-5只有9.9%。虽然这个测试侧重什么还不清楚，但大佬公开叫板总归让场面有点难看。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/35ae0443a0e1fa252708c10e97bc7531.png" alt="马斯克质疑GPT-5性能"></p><p>更有意思的是，有AI研究员说GPT-5其实是&quot;渐进式优化&quot;。现在大模型训练遇到了瓶颈，数据快用完了，参数增加带来的提升越来越小。加上OpenAI刚融了83亿，估值3000亿美元，这节骨眼上发布GPT-5，很难不让人联想到资本运作的需要。</p><h2 id="四-普通用户怎么用微软用户有福了"><a class="markdownIt-Anchor" href="#四-普通用户怎么用微软用户有福了"></a> 四、普通用户怎么用？微软用户有福了</h2><p>最实际的是，现在用微软Copilot就能体验GPT-5，Windows、Mac、手机端都能免费试。我试了下用Copilot生成Python爬虫代码，确实比以前快不少，连异常处理都考虑到了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4d1122cd56885a0dbcfefb1b4b351068.jpg" alt="Copilot界面示例"></p><p>价格方面，API调用费用比GPT-4o还便宜，输入每百万token1.25美元，输出10美元。对开发者来说挺友好，但普通用户可能更关心免费额度够不够用——每天&quot;几个小时&quot;的聊天限制，估计大多数人都够用了。</p><h2 id="最后说几句"><a class="markdownIt-Anchor" href="#最后说几句"></a> 最后说几句</h2><p>用了几天GPT-5，感觉确实强，但要说&quot;颠覆性&quot;还差点意思。编程、写作这些场景提升明显，但像数学推理这种硬核能力，在Humanity’s Last Exam测试里，GPT-5 Pro+得分42%，还不如Grok 4 Heavy的44.4%。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b0e7ac68306ffcc385d413f9e9378129.jpg" alt="学科能力测试对比"></p><p>或许大模型真的到了需要新突破的阶段，光靠堆参数和数据已经不够了。不过对咱们普通用户来说，免费能用这么强的模型，还要啥自行车呢？反正我已经把ChatGPT默认模型切到GPT-5了，回不去了回不去了。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>13款宝藏App实测：免费还好用，这波真挖到宝了</title>
      <link href="/ruan-jian-bi-ji/13-kuan-bao-cang-app-shi-ce-mian-fei-huan-hao-yong-zhe-bo-zhen-wa-dao-bao-liao/"/>
      <url>/ruan-jian-bi-ji/13-kuan-bao-cang-app-shi-ce-mian-fei-huan-hao-yong-zhe-bo-zhen-wa-dao-bao-liao/</url>
      
        <content type="html"><![CDATA[<p>作为一个常年跟代码和各种应用打交道的人，我试了不少App，要么收费套路深，要么广告多到让人想卸载。但这次发现的13款，真的有点东西——全部免费，功能还特实用。安卓用户能用上10款，苹果用户8款，亲测无坑，咱们一个个说。</p><h2 id="1-蜂软扫描手机秒变扫描仪"><a class="markdownIt-Anchor" href="#1-蜂软扫描手机秒变扫描仪"></a> 1. 蜂软扫描：手机秒变扫描仪</h2><p>先看这个扫描工具，安卓和苹果都能用。最让我惊喜的是它完全免费，打开就能用，不用注册那些麻烦事。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640.jpeg" alt="蜂软扫描功能界面"></p><p>从截图能看到，它不仅能高清扫描，还有智能文字识别功能。实测下来，扫描合同、证件这些文档很清晰，自动裁剪边缘也挺准。它支持好几种滤镜，我最喜欢&quot;黑白1&quot;模式，扫出来的文档像打印的一样清楚。</p><p>加水印和防伪功能很实用，特别是需要分享重要文档时。我试了下添加公司水印，能调整透明度和大小，应用到所有页面也很方便。</p><p>OCR识别是亮点，整篇扫描或者局部识别都支持。我扫了一页纸质笔记，识别率能到95%以上，连手写的标点都认出来了。识别结果可以直接复制，也能导出成TXT，处理资料效率提高不少。</p><p>导出格式也全，PDF、Word、Excel都支持，还能调整PDF大小，发邮件时特别方便。</p><h2 id="2-pdf-gearpdf全能工具"><a class="markdownIt-Anchor" href="#2-pdf-gearpdf全能工具"></a> 2. PDF Gear：PDF全能工具</h2><p>这个PDF工具安卓苹果都能用，功能全到让我惊讶——编辑、转换、注释、甚至能跟PDF&quot;聊天&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20250805200246321.png" alt="image-20250805200246321"></p><p>直接编辑PDF文字这点太实用了。以前改PDF要么转Word，要么用付费软件，这个直接点文字就能改，还能调颜色、大小，加下划线什么的。添加签名也方便，保存几个常用签名，签合同的时候点一下就好。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20250805200312218.png" alt="image-20250805200312218"></p><p>新建PDF也有花样，能选笔记、方格、待办事项这些模板，开会记笔记直接用这个新建，比记事本好用。注释工具也全，高亮、画笔、添加文本框都有，看论文时标重点很方便。</p><p>最有意思的是这个聊天功能。我传了一份产品说明书，让它总结内容，几秒钟就给出了要点。还能让它旋转页面、查找特定内容，像有个助理在帮你处理PDF。转换功能也测试了，PDF转Word基本能保持原格式，比我之前用的某些付费工具还靠谱。</p><h2 id="3-atter开会记笔记神器"><a class="markdownIt-Anchor" href="#3-atter开会记笔记神器"></a> 3. Atter：开会记笔记神器</h2><p>安卓用户专享的语音转文字工具，对经常开会的人来说简直是救星。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200030222.jpeg" alt="录音转文字功能界面"></p><p>打开就能用，实时转写速度很快，基本说一句话，文字就出来了。支持的语言还挺多，中文、英文、粤语、日语都行，甚至能中英文混说，识别也很准。</p><p>我特意测试了多人会议场景，它能区分不同发言人，这点比很多同类工具强。会后还能自动生成摘要和待办事项，连思维导图都能生成，整理会议纪要的时间省了一大半。</p><p><img src="https://mmbiz.qpic.cn/sz_mmbiz_gif/REkEgTqnKzdZWe4lvWX0ykFF4UM2xCFmQpJicfHHH3cRlYeYCsG3nRKyvySW1Z9bnOqptibVgLu3ianV50UKnyz6w/640?wx_fmt=gif&amp;from=appmsg" alt="文本翻译提取功能"></p><p>转写完成后，还能翻译、提取关键词、润色文本。试过把一段口语化的记录转换成书面语，改得还挺自然。导入音频或视频转文字也支持，处理以前的录音文件很方便。</p><h2 id="4-屏记锁屏就能看待办"><a class="markdownIt-Anchor" href="#4-屏记锁屏就能看待办"></a> 4. 屏记：锁屏就能看待办</h2><p>苹果用户的待办神器，体积不到2M，却解决了一个大问题——不用解锁就能看待办事项。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200032055.jpeg" alt="锁屏待办事项功能"></p><p>添加待办特别快，点加号输入内容，选个时间就行，几秒钟搞定。然后在锁屏界面就能看到，按时间排好序，今天的、明天的清清楚楚。开会或者上课的时候，拿起手机瞥一眼就知道接下来要做什么，不用解锁打扰别人。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200032121.jpeg" alt="待办事项桌面展示"></p><p>还支持灵动岛和桌面小组件，iPhone 14 Pro以上的用户可以直接在灵动岛看到待办提醒。完成事项左滑就能标记，操作简单到不用学。对我这种经常忘事的人来说，简直是救命工具。</p><h2 id="5-合数无广告小游戏合集"><a class="markdownIt-Anchor" href="#5-合数无广告小游戏合集"></a> 5. 合数：无广告小游戏合集</h2><p>苹果用户的单机游戏宝藏，一个App里有好几个经典小游戏，还没广告。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200032245.jpeg" alt="经典小游戏集合"></p><p>里面有俄罗斯方块、扫雷、2048、数独这些经典款，还有个叫&quot;合数&quot;的原创游戏。设计特别简洁，没有花里胡哨的东西，专注于游戏本身。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200032373.jpeg" alt="游戏难度设置界面"></p><p>每个游戏都有不同难度，数独从简单到大师级都有，扫雷还有误点复活功能，对我这种手残党很友好。没有网络也能玩，通勤或者排队的时候打发时间正好。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200032446.jpeg" alt="小游戏主界面"></p><p>我最喜欢它的设计风格，简约干净，玩久了也不累眼。不像有些游戏App，打开全是弹窗广告，这个从头到尾都安安静静的。</p><h2 id="6-记账王记账还能管理库存"><a class="markdownIt-Anchor" href="#6-记账王记账还能管理库存"></a> 6. 记账王：记账还能管理库存</h2><p>安卓用户的记账软件，功能多到不像免费App。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200032887.jpeg" alt="记账预算管理功能"></p><p>界面设计得挺好看，不是那种廉价感的记账软件。不用登录就能用，想备份数据再登录就行。除了基础的收支记录，还能做预算管理，设置总预算和分类预算，剩余多少一目了然。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200033018.jpeg" alt="记账分类日历视图"></p><p>日历视图很直观，哪天花了多少钱，收入多少，点一下就知道。还能自定义收支类别，图标也挺丰富的。记一笔账的时候，可以加备注、传图片，甚至选择不计入预算，细节考虑得很周到。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200033173.jpeg" alt="记账提醒设置功能"></p><p>最意外的是它还有自动记账、物品库存管理这些功能。设置个记账提醒，再也不会忘记记一笔账了。生成的当日小票也很有意思，像超市购物小票一样，有点仪式感。</p><h2 id="7-剪小映ai生成视频太方便"><a class="markdownIt-Anchor" href="#7-剪小映ai生成视频太方便"></a> 7. 剪小映：AI生成视频太方便</h2><p>剪映出的这个AI视频工具，安卓苹果都能用，生成视频真的零门槛。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200033520.jpeg" alt="视频素材文字成片"></p><p>两种生成方式：选一堆照片视频素材，它能自动生成几十个不同版本的视频；或者直接输入一句话，比如&quot;制作一个旅行vlog&quot;，它就能生成完整视频。我试了下用旅行照片生成，自动加了转场和背景音乐，节奏还挺对的。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200033644.jpeg" alt="视频文案编辑功能"></p><p>文案还能智能生成，不满意可以让它改写、扩写。风格也很多，像素风、古风、科幻风都有，配音有几百种音色可选，还能自己录音。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200033767.jpeg" alt="视频分镜编辑导出"></p><p>生成后还能再编辑，调分镜、换音乐什么的。最关键是导出没有水印，免费做到这个程度，确实挺良心的。</p><h2 id="8-健身减肥在家锻炼不用愁"><a class="markdownIt-Anchor" href="#8-健身减肥在家锻炼不用愁"></a> 8. 健身减肥：在家锻炼不用愁</h2><p>安卓用户的健身软件，设计简洁，动作指导清晰。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200033838.jpeg" alt="健身训练种类选择"></p><p>分部位训练很贴心，想练手臂、腹部还是全身都有对应的课程。每个课程都标明了时长和消耗的卡路里，选起来很方便。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200033907.jpeg" alt="健身动作演示界面"></p><p>跟着练的时候，有动图演示每个动作，还有倒计时和下一个动作提示。不用怕动作不标准，也不用一直盯着屏幕看。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200033974.jpeg" alt="训练计划进度展示"></p><p>还能制定训练计划，记录进度。我设置了一个30天的健身计划，每天完成后打个卡，挺有成就感的。没有广告，打开就能练，对想在家锻炼的人来说足够用了。</p><h2 id="9-古诗词鉴赏诗词爱好者必备"><a class="markdownIt-Anchor" href="#9-古诗词鉴赏诗词爱好者必备"></a> 9. 古诗词鉴赏：诗词爱好者必备</h2><p>安卓用户的古诗词学习软件，收录了4200多首诗词，700多位作者。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200034119.jpeg" alt="诗词搜索作者分类"></p><p>界面是古风设计，看着很舒服。搜索功能挺强的，知道标题、内容或者作者名都能搜到。按作者分类也很清晰，想读李白或者杜甫的诗，直接点作者名就行。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200034251.jpeg" alt="诗词详情作者介绍"></p><p>每首诗都有注释、翻译和赏析，还有语音朗读。我试了下读《将进酒》，语音语调还挺有感觉的，不像那种机械朗读。没事的时候翻一翻，学点古诗词，比刷短视频有意义多了。不用注册登录，打开就能用，也没有广告，纯粹的学习工具。</p><h2 id="10-人生瞬间社恐的私密树洞"><a class="markdownIt-Anchor" href="#10-人生瞬间社恐的私密树洞"></a> 10. 人生瞬间：社恐的私密树洞</h2><p>安卓和苹果都能用的情绪记录软件，特别适合不喜欢社交的人。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200034389.jpeg" alt="情绪记录私密树洞"></p><p>界面设计得很干净，像个私密日记本。可以记文字、传照片、标位置，每次记录都是一张精美的卡片。最舒服的是没有社交功能，不用考虑别人怎么看，完全做自己。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200034522.jpeg" alt="情绪日历照片归档"></p><p>情绪日历挺有意思的，能记录每天的心情变化，回顾的时候能看出自己的情绪规律。照片也能自动归档，按时间排好，像个私人相册。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200034660.jpeg" alt="PDF导出共写空间"></p><p>还能把记录导出成PDF，备份起来很方便。那个&quot;共写空间&quot;功能有点意思，可以和好朋友或者恋人建个私密空间，只有你们能看到彼此的记录，像个专属小天地。</p><h2 id="11-轻松学简笔画零基础也能画"><a class="markdownIt-Anchor" href="#11-轻松学简笔画零基础也能画"></a> 11. 轻松学简笔画：零基础也能画</h2><p>安卓用户的绘画学习软件，特别适合新手和小朋友。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200034788.jpeg" alt="铅笔画荧光画功能"></p><p>有铅笔、荧光笔等多种画笔，在手机上就能画。我这种手残党试了下，居然也能画出点样子来。画笔粗细可以调，还有橡皮擦，不用担心画错。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200034920.jpeg" alt="简笔画教程步骤"></p><p>教程很详细，分步骤教你画各种东西，动物、植物、食物都有。选一个教程，跟着一步一步画，完成后还能填色。我画了个小绵羊，虽然不太像，但过程挺有意思的。不用注册，打开就能画，免费还没广告，给孩子玩也放心。</p><h2 id="12-迷图治愈系拼图游戏"><a class="markdownIt-Anchor" href="#12-迷图治愈系拼图游戏"></a> 12. 迷图：治愈系拼图游戏</h2><p>安卓用户的拼图游戏，画风唯美，特别治愈。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200035049.jpeg" alt="创意几何拼图游戏"></p><p>和普通拼图不一样，它的碎片是几何形状的，拼起来很考验想象力。色彩搭配得特别舒服，拼完一幅图像完成了一件艺术品。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200036439.gif" alt="拼图碎片完成效果"></p><p>动图能看到拼接过程，碎片拼对了会有动画效果，很解压。有100多个关卡，难度慢慢增加，玩起来很有成就感。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200036574.jpeg" alt="拼图主题关卡选择"></p><p>还有不同主题可以选，“秋意”、&quot;迷境&quot;这些主题的拼图都很有特色。没有时间限制，慢慢拼，累了就存着下次继续，很适合放松心情。</p><h2 id="13-滚动截长图苹果长截图神器"><a class="markdownIt-Anchor" href="#13-滚动截长图苹果长截图神器"></a> 13. 滚动截长图：苹果长截图神器</h2><p>苹果用户的长截图工具，解决了iPhone不能直接截长图的难题。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20250805200036641.jpeg" alt="滚动截长图教程"></p><p>用法很简单，按教程来：下拉状态栏，长按录屏按钮，选择这个应用，然后开始滚动屏幕就行。我试了下截网页，拼得很整齐，比用其他方法拼接的自然多了。</p><p>如果看不到这个应用，重启一下手机就好了。完全免费，也没有广告，就专注于长截图这一个功能，做得还挺专业的。</p><h2 id="最后说几句"><a class="markdownIt-Anchor" href="#最后说几句"></a> 最后说几句</h2><p>这13款App我都用了一段时间，确实都是免费好用的精品。没有那些花里胡哨的功能，也没有广告弹窗，专注于把核心功能做好，这点很难得。</p><p>下载方法很简单，在公众号&quot;神笔君&quot;对话框回复&quot;805&quot;就能获取所有软件。根据自己的手机系统和需求选几个试试，说不定能发现适合自己的宝藏工具。</p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手把手教你：免费拥有自己的智能聊天客户端，手机也能用DeepSeek、ChatGPT！</title>
      <link href="/ruan-jian-bi-ji/shi-yong-chatbox-da-jian-mian-fei-an-quan-de-chat-si-you-huan-jing/"/>
      <url>/ruan-jian-bi-ji/shi-yong-chatbox-da-jian-mian-fei-an-quan-de-chat-si-you-huan-jing/</url>
      
        <content type="html"><![CDATA[<p>你是否在使用DeepSeek官网时，总是遇到“服务器繁忙，请稍后重试”的提示？</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20250214180555852.png" alt="image-20250214180555852"></p><p>又是否为在国内无法使用OPENAI的<code>ChatGPT</code>而烦恼？毕竟这个网站：<a href="https://chatgpt.com/" target="_blank" rel="noopener">https://chatgpt.com/</a> 根本打不开。</p><p>别担心，解决方案来啦！答案就是<code>Chatbox AI客户端</code> + <code>ModelBridge API KEY</code>。利用ModelBridge对OPENAI API的无缝兼容，搭配强大的AI客户端应用，让你拥有专属于你的智能体！</p><p><strong>什么是Chatbox AI</strong></p><p>Chatbox AI可是一款超强大的AI客户端应用和智能助手哦，下面为你详细介绍：</p><ol><li><strong>多模型对话</strong>：它能连接像DeepSeek R1等全球领先的AI模型，用户可按需在软件中自由切换不同的顶尖AI模型，轻松满足各种应用场景。</li><li><strong>智能文件解析</strong>：支持PDF、DOC、PPT、XLS、图片、代码等超多文件格式，就连PDF扫描件和手写文件都不在话下，能精准理解文件内容并给出智能响应。</li><li><strong>代码助手</strong>：专门为开发者提供代码生成、预览、语法高亮、代码审查、重构、智能文档、调试助手、优化、安全检查等一系列实用功能。</li><li><strong>图像生成</strong>：依据文字描述就能生成精美的图像，还能探索多种艺术风格，不管是创意设计还是营销宣传，都能满足你的多样化需求。</li><li><strong>LaTeX和Markdown支持</strong>：支持直接输入和渲染LaTeX公式以及Markdown格式的文本，简直是学术写作与技术文档编辑的得力助手。</li><li><strong>数据存储与安全</strong>：所有数据都存储在本地设备，充分保障你的隐私和安全。还贴心提供内置数据备份和导出功能，方便你随时检索以往的对话和消息。</li><li><strong>实时联网搜索与查询</strong>：通过AI联网搜索，能快速获取即时信息，包括URL分析、事实核查等都不在话下。</li><li><strong>AI生成图表</strong>：仅需简单的文字描述，就能生成清晰的可视化图表，帮你轻松理解复杂的趋势和统计信息。</li></ol><p><strong>适用人群超广泛</strong></p><ol><li>有智能编程助手需求的开发者。</li><li>寻求学术支持的学生和研究人员。</li><li>渴望提升工作效率的职场人士。</li><li>探索AI创作可能性的创意工作者。</li><li>对尖端人工智能技术感兴趣的小伙伴们。</li></ol><p><strong>认识ModelBridge</strong></p><p>魔桥<code>ModelBridge</code>，是专业的大模型API接口服务商。</p><p>它能为企业和开发者提供优质稳定的大模型相关API调用接口。</p><p>其接口能力超强大：支持百度文心一言、阿里、讯飞、智谱ChatGLM、百川、GPT3.5、GPT4、GPT4o、Embedding、Whisper、Fine - tuning、assistant、batch、google gemini、claude、deepseek等众多大模型。</p><p>而且能用标准的OpenAI接口格式访问所有大模型，真正做到一次对接，模型任意切换。</p><p><strong>接下来，就手把手教你快速搭建自己的智能聊天客户端。</strong>！！！</p><h2 id="准备工作很简单"><a class="markdownIt-Anchor" href="#准备工作很简单"></a> 准备工作很简单</h2><ul><li><strong>Chatbox AI客户端</strong><ul><li>直接在线网页版：<a href="https://web.chatboxai.app/" target="_blank" rel="noopener">https://web.chatboxai.app/</a></li><li>也可进入官网：<a href="https://chatboxai.app/zh#download" target="_blank" rel="noopener">https://chatboxai.app/zh#download</a> 下载对应客户端，目前支持IOS、Android及Mac、Windows系统。</li></ul></li><li><strong>ModelBridge API KEY</strong><ul><li>进入官网：<a href="https://model-bridge.okeeper.com/" target="_blank" rel="noopener">https://model-bridge.okeeper.com/</a> ，用邮箱注册就能获得免费使用的API KEY。</li></ul></li></ul><h2 id="chatbox桌面版或网页版自定义设置"><a class="markdownIt-Anchor" href="#chatbox桌面版或网页版自定义设置"></a> Chatbox桌面版或网页版自定义设置</h2><h3 id="第一步选择模型提供方"><a class="markdownIt-Anchor" href="#第一步选择模型提供方"></a> 第一步：选择模型提供方</h3><p>打开Chatbox的设置菜单&gt;模型一栏，将模型提供方选择为OPENAI API。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20250214170517597.png" alt="image-20250214170517597"></p><h3 id="第二步填入关键信息"><a class="markdownIt-Anchor" href="#第二步填入关键信息"></a> 第二步：填入关键信息</h3><p>填入ModelBridge的<code>域名</code>和<code>API Key</code>。</p><ul><li>API秘钥：就是你的ModelBridge的api key，查看文档可了解获取方法：<a href="https://modelbridge-doc.okeeper.com/doc-5203747" target="_blank" rel="noopener">https://modelbridge-doc.okeeper.com/doc-5203747</a></li><li>API域名：<a href="https://model-bridge.okeeper.com" target="_blank" rel="noopener">https://model-bridge.okeeper.com</a></li></ul><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20250214170820789.png" alt="image-20250214170820789"></p><h3 id="第三步自定义模型名称"><a class="markdownIt-Anchor" href="#第三步自定义模型名称"></a> 第三步：自定义模型名称</h3><p>由于Chatbox默认没有deepseek-r1等模型，需要手动添加。</p><ul><li>自定义添加：<code>deepseek-r1</code>、<code>deepseek-v3</code>、<code>Mixtral-8x7B-Instruct</code>。</li><li>注意哦，每次设置只能保存一个自定义模型，若要添加多个模型，需要重复打开设置多次，如下图所示。</li></ul><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20250214171506350.png" alt="image-20250214171506350"></p><p>到此，桌面版或网页版的设置就完成啦，可以开始使用了！</p><h2 id="chatbox手机版配置"><a class="markdownIt-Anchor" href="#chatbox手机版配置"></a> Chatbox手机版配置</h2><h3 id="第一步进入设置"><a class="markdownIt-Anchor" href="#第一步进入设置"></a> 第一步：进入设置</h3><p>进入软件，点击使用自己的API KEY或本地模型。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20250214175632722.png" alt="image-20250214175632722"></p><h3 id="第二步完成设置"><a class="markdownIt-Anchor" href="#第二步完成设置"></a> 第二步：完成设置</h3><p>设置定义的API KEY、域名及自定义的模型名称。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20250214180023836.png" alt="image-20250214180023836"></p><p>然后就大功告成，可以愉快使用啦！</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20250214180051790.png" alt="image-20250214180051790"></p><h2 id="chatbox-ai-使用展示"><a class="markdownIt-Anchor" href="#chatbox-ai-使用展示"></a> Chatbox AI 使用展示</h2><h3 id="模型对话"><a class="markdownIt-Anchor" href="#模型对话"></a> 模型对话</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20250214171854000.png" alt="image-20250214171854000"></p><h3 id="切换到gpt-4o支持图片输入"><a class="markdownIt-Anchor" href="#切换到gpt-4o支持图片输入"></a> 切换到gpt-4o，支持图片输入</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20250214173954081.png" alt="image-20250214173954081"></p><blockquote><p>目前只有gpt-4o支持图片识别哦。</p></blockquote><h3 id="dalle-3图片生成"><a class="markdownIt-Anchor" href="#dalle-3图片生成"></a> DALLE-3图片生成</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20250214174129486.png" alt="image-20250214174129486"></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前谷歌高管预警：AI真会让中产阶级消失？15年&quot;地狱期&quot;后是乌托邦？</title>
      <link href="/ren-gong-zhi-neng/qian-gu-ge-gao-guan-yu-jing-ai-zhen-hui-rang-zhong-chan-jie-ji-xiao-shi-15-nian-di-yu-qi-hou-shi-wu-tuo-bang-3/"/>
      <url>/ren-gong-zhi-neng/qian-gu-ge-gao-guan-yu-jing-ai-zhen-hui-rang-zhong-chan-jie-ji-xiao-shi-15-nian-di-yu-qi-hou-shi-wu-tuo-bang-3/</url>
      
        <content type="html"><![CDATA[<p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d778f78817308c751f098aae3500f848.jpeg" alt></p><p>最近科技圈炸了个大新闻——前谷歌X高管Mo Gawdat放了个&quot;大招&quot;：他说AI会在2027年开启长达15年的&quot;地狱模式&quot;，到时候中产阶级彻底消失，世界上只剩金字塔尖0.1%的富人和底层民众。这可不是什么科幻小说剧情，而是这位58岁、29岁就成百万富翁的科技大佬的&quot;严肃预测&quot;。</p><h2 id="这位预言家是谁"><a class="markdownIt-Anchor" href="#这位预言家是谁"></a> 这位&quot;预言家&quot;是谁？</h2><p>先认识下这位语出惊人的Mo Gawdat。他是前谷歌X高管，埃及出生的科技奇才，在谷歌负责过不少前沿项目。最近他在一个两小时的采访里，上来就扔了个&quot;炸弹&quot;：<strong>想让人类有美好未来，唯一的办法是让身居高位的恶人全被AI取代</strong>。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e5b2e60212cc9f5ed2e798949dcf126c.jpg" alt="AI与中产阶级危机"></p><p>听到这话，连主持人都当场皱起了眉头——这观点也太颠覆了吧？</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/fcc23852bd30c557807cd19955c50526.png" alt="主持人困惑表情"></p><h2 id="15年地狱期从2027年开始"><a class="markdownIt-Anchor" href="#15年地狱期从2027年开始"></a> 15年&quot;地狱期&quot;：从2027年开始？</h2><p>Gawdat说，未来15年（大概从2027到2042年）会是&quot;短期反乌托邦&quot;。为啥？他觉得现在的问题是&quot;超级聪明的AI在给愚蠢的人类领导人打工&quot;——AI本来不会破坏生态、发动战争、制造仇恨（因为这些纯属浪费能量），但人类领导人偏要指挥它干这些事。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2cdd1985696b33403cf9fab8fa314bc0.png" alt="短期反乌托邦预测"></p><p>他还甩了组扎心数据：2024年全球花了2.71万亿美元打仗，美国一家就占了1万亿美元。“很多战争就是为了消化过剩武器，获利的是贷款人和军火商”。</p><p>更要命的是AI会让大量工作消失。他举了个例子：以前需要350个开发者的公司，现在只要几个技术人员+一堆AI员工。虽然&quot;情感陪伴&quot;&quot;社区活动&quot;这类工作会增加，但比例太小，根本填不上缺口。</p><h2 id="中产阶级真会被消灭"><a class="markdownIt-Anchor" href="#中产阶级真会被消灭"></a> 中产阶级真会被&quot;消灭&quot;？</h2><p>Gawdat的核心观点来了：未来社会会两极分化——要么是最富的0.1%，要么是&quot;底层农民&quot;，中间层直接消失。</p><p>为啥这么说？他觉得AI会让人类智商差距变得微不足道。&quot;如果大家都能用AI把智商提到4000，你4100我4000，这点差距算啥？&quot;到时候绝大多数人没啥不可替代的技能，只能靠&quot;全民基本收入（UBI）&quot;过活。而顶级富豪会买下一切，AI和机器人负责生产，普通人连工作都找不到。</p><h2 id="但他说15年后是乌托邦"><a class="markdownIt-Anchor" href="#但他说15年后是乌托邦"></a> 但他说：15年后是乌托邦？</h2><p>别急，Gawdat不是纯悲观主义者。他觉得熬过这15年，人类会进入AI主导的乌托邦——免费医疗、不用工作、有更多时间陪家人，甚至实现&quot;共产主义&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/23aaf167d52d4ac2461e1ac1ffce0e30.gif" alt="AI理想世界愿景"></p><p>他的逻辑是：当AI能自己改进代码、优化算法（比如谷歌的机器会告诉人类该在哪加服务器，人类只能听话），就会进入&quot;物质免费制造、能源无限&quot;的阶段。到时候AI领导人不会搞国籍对立，目标是全球繁荣和环保，资本主义自然就崩溃了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/5d71a591eb4439fc10f461c6a392a56a.gif" alt="AGI未来愿景"></p><h2 id="另一种声音奥特曼的通用基本计算"><a class="markdownIt-Anchor" href="#另一种声音奥特曼的通用基本计算"></a> 另一种声音：奥特曼的&quot;通用基本计算&quot;</h2><p>有意思的是，OpenAI创始人山姆·奥特曼最近也提了个类似但不同的想法。他觉得与其搞&quot;全民基本收入（UBI）“，不如搞&quot;全民基本计算（Universal Basic Compute）”——每个人都分一块GPT-7这样的超级AI的算力。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d7f1ef045fd9475a1f9c7b0aa05991b9.png" alt="通用基本计算提议"></p><p>简单说，Gawdat想让AI当&quot;领导&quot;，奥特曼想让AI当&quot;工具人人有份&quot;。两种思路，你更信哪个？</p><h2 id="我的看法警惕但别焦虑"><a class="markdownIt-Anchor" href="#我的看法警惕但别焦虑"></a> 我的看法：警惕但别焦虑</h2><p>说实话，Gawdat的预测有点像&quot;科技版末日预言+乌托邦童话&quot;的混合体。AI确实会冲击中产阶级工作——比如现在很多文案、设计、甚至初级编程工作已经开始被AI替代。但要说15年就&quot;消灭中产阶级&quot;，可能有点夸张。</p><p>历史上每次技术革命都有人喊&quot;职业末日&quot;，从蒸汽机到计算机，但最后总会冒出新职业（比如现在的AI训练师、数据标注师）。不过这次AI的特殊性在于，它可能真的会冲击&quot;脑力劳动&quot;这个中产阶级的核心壁垒。</p><p>至于&quot;AI乌托邦&quot;，我觉得前提是人类能在这15年里搞定两件事：一是AI的控制权问题（谁来决定AI的目标？），二是利益分配问题（富豪会乖乖让AI分财富吗？）。这俩问题解决不了，乌托邦可能变&quot;AI寡头统治&quot;。</p><p>最后说一句：不管Gawdat的预言准不准，有个事肯定没错——未来10年，学会和AI协作的人，大概率比抵制AI的人活得更滋润。毕竟，与其担心被AI取代，不如想想怎么让AI成为你的&quot;职场外挂&quot;。你觉得呢？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么MCP协议90%的潜力都被浪费了？联合创建者揭秘五大原语和高阶玩法</title>
      <link href="/ren-gong-zhi-neng/wei-shi-me-mcp-xie-yi-90-de-qian-li-du-bei-lang-fei-liao-lian-he-chuang-jian-zhe-jie-mi-wu-da-yuan-yu-he-gao-jie-wan-fa-3/"/>
      <url>/ren-gong-zhi-neng/wei-shi-me-mcp-xie-yi-90-de-qian-li-du-bei-lang-fei-liao-lian-he-chuang-jian-zhe-jie-mi-wu-da-yuan-yu-he-gao-jie-wan-fa-3/</url>
      
        <content type="html"><![CDATA[<p>MCP协议火了大半年，现在几乎成了AI开发的标配。但最近Anthropic的MCP联合创建者David Soria Parra在技术分享会上放了个大招：“绝大多数人用MCP都太初级了，它远不止工具调用那么简单。”</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/58586bbc35756c74b6f60e42778155d0.png" alt="MCP演讲现场"></p><p>这话挺有意思的。现在市面上一万多个MCP服务，确实大多只用到了最基础的工具调用功能。作为前程序员，我翻了David的完整分享和技术文档，发现MCP藏着五个&quot;原语&quot;，就像五把钥匙，能打开完全不同的AI交互方式。今天咱们就掰开揉碎了聊聊，怎么把MCP用出高级感。</p><h2 id="先搞清楚mcp到底是个啥"><a class="markdownIt-Anchor" href="#先搞清楚mcp到底是个啥"></a> 先搞清楚：MCP到底是个啥？</h2><p>在聊高级玩法前，得先明确MCP的定位。它不是单纯的&quot;工具调用协议&quot;，而是一套<strong>AI与客户端交互的系统框架</strong>。想象一下，以前AI模型就像个只会聊天的顾问，MCP相当于给它装了手脚（工具调用）、带了知识库（资源访问）、安了传感器（环境感知），还配了操作手册（预设模板）。</p><p>David在演讲里展示了MCP的核心价值：让AI从&quot;被动对话&quot;变成&quot;主动交互&quot;。现在大家只用了&quot;手脚&quot;，但其他几个器官都没激活。</p><h2 id="五大原语解锁mcp全部潜力的钥匙"><a class="markdownIt-Anchor" href="#五大原语解锁mcp全部潜力的钥匙"></a> 五大原语：解锁MCP全部潜力的钥匙</h2><p>MCP的核心是五个&quot;原语&quot;（primitives），简单说就是五种最基础的交互方式。这才是David说的&quot;高级玩法&quot;关键。</p><h3 id="1-prompt被忽视的快捷指令模板"><a class="markdownIt-Anchor" href="#1-prompt被忽视的快捷指令模板"></a> 1. Prompt：被忽视的&quot;快捷指令模板&quot;</h3><p>第一个原语叫Prompt，注意啊，这不是咱们平时说的提示词，而是<strong>预设的交互模板</strong>。就像Word里的模板，点一下就能把预设好的内容加载进来，引导AI怎么跟你的服务交互。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/bf64ce489f2eadafc91f74e4fd5aad4c.png" alt="Prompt原语示例"></p><p>David举了个例子：他做了个GitHub PR评论的Prompt模板，点一下就能把PR里的评论全拉到对话窗口，AI直接基于这些评论帮他改代码。这比每次手动复制粘贴高效多了。</p><p>最妙的是它支持&quot;补全&quot;功能。比如你点了&quot;处理PR评论&quot;的Prompt，会自动弹出你最近的PR列表让你选，不用手动输ID。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/15845a94778bde671d0eb8a7bee3f9e5.png" alt="Prompt补全示意"></p><p>实现起来也简单，David现场演示用TypeScript几行代码就搞定了。说白了，这就是把用户常用的提示词模板化、参数化，让重复工作一键完成。</p><h3 id="2-resource上下文之外的数据库"><a class="markdownIt-Anchor" href="#2-resource上下文之外的数据库"></a> 2. Resource：上下文之外的&quot;数据库&quot;</h3><p>第二个原语是Resource（资源），简单说就是<strong>让AI能访问的外部数据</strong>，比如文件、数据库结构、网页内容这些。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/8fc42cb44b6e7bf114033b2ee8b22cd4.png" alt="Resource原语"></p><p>跟Prompt的区别在于，Resource是原始数据，用户可以选择要不要加载进上下文，应用还能对它做额外处理，比如生成嵌入向量用于RAG检索。David展示了一个案例：把PostgreSQL数据库的Schema作为Resource暴露出来，Claude自动读取后直接帮他写SQL查询，还能可视化数据库结构。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b7b865e4ee8f317e5fbcfa9807a59599.png" alt="Resource应用"></p><p>这招对企业应用太有用了，相当于给AI开了个&quot;数据窗口&quot;，需要什么数据就让它自己看，不用开发者每次都手动整理。</p><h3 id="3-tool大家最熟悉的工具调用"><a class="markdownIt-Anchor" href="#3-tool大家最熟悉的工具调用"></a> 3. Tool：大家最熟悉的&quot;工具调用&quot;</h3><p>第三个原语就是大家最熟悉的Tool（工具），也就是让AI能调用的函数。不过David强调，很多人把Tool用反了——Tool应该是<strong>AI自主决定何时调用</strong>，而不是用户手动触发。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/47d01b5ed32a97a3c2b53bc70b5b65ed.png" alt="Tool原语"></p><p>比如做个天气查询工具，用户问&quot;明天出门要不要带伞&quot;，AI应该自动调用天气API获取数据，而不是让用户手动点&quot;查询天气&quot;按钮。现在很多MCP应用把Tool做成了手动触发，其实浪费了AI的自主性。</p><h3 id="4-sampling让ai互相帮忙的协作机制"><a class="markdownIt-Anchor" href="#4-sampling让ai互相帮忙的协作机制"></a> 4. Sampling：让AI互相&quot;帮忙&quot;的协作机制</h3><p>第四个原语Sampling（采样）比较高级，简单说就是<strong>让MCP服务能请求客户端帮忙完成AI生成</strong>。比如你的MCP服务需要调用大模型，但没有API密钥，就可以让客户端（比如Claude）用它自己的模型来生成结果，再返回给服务。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1d4d1fbb3cf96e0126baad686123c248.png" alt="Sampling概念"></p><p>David现场演示了个链式调用：客户端请求MCP服务A处理Issue，服务A又通过Sampling调用服务B生成摘要，最后汇总结果返回。这就像搭积木，把多个MCP服务串起来完成复杂任务。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/5d4b7bf5bd6f9fc0131dcad9eaffe3f0.png" alt="链式调用示例"></p><p>这个功能目前支持还不多，但潜力巨大。以后可能会出现MCP服务市场，每个服务专精一块，互相调用完成复杂工作流。</p><h3 id="5-roots让ai感知客户端环境"><a class="markdownIt-Anchor" href="#5-roots让ai感知客户端环境"></a> 5. Roots：让AI&quot;感知&quot;客户端环境</h3><p>最后一个原语Roots（根目录），解决的是&quot;环境感知&quot;问题。比如你在VS Code里用MCP工具操作Git，它需要知道你当前打开的项目路径，不然可能误操作其他文件夹。Roots就是让MCP服务能询问客户端：“你现在在哪？打开了什么项目？”</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e0eba5c7ff32ac966d1da1855a9b6fb5.png" alt="Roots概念"></p><p>David举了个Git工具的例子：通过Roots获取当前项目路径后，所有Git操作都会限定在这个路径下，安全多了。对企业级应用来说，这个功能能有效防止误操作和数据泄露。</p><h2 id="原语怎么组合看这个交互模型"><a class="markdownIt-Anchor" href="#原语怎么组合看这个交互模型"></a> 原语怎么组合？看这个交互模型</h2><p>单独看每个原语可能觉得一般，但组合起来就厉害多了。David展示了MCP的交互模型：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/aad5f24fa2d6a9df5f1cf9f675f5d5f7.png" alt="交互模型示意"></p><ul><li>用户通过Prompt主动触发常用操作（手动）</li><li>应用通过Resource主动提供相关数据（自动）</li><li>AI通过Tool自主调用工具解决问题（自动）</li><li>服务通过Sampling请求其他AI帮忙（协作）</li><li>系统通过Roots感知环境确保安全（基础）</li></ul><p>比如做个代码审查助手：</p><ol><li>Roots获取当前项目路径（知道在哪工作）</li><li>Resource加载代码文件和文档（提供上下文）</li><li>Prompt让用户选择&quot;代码审查&quot;模板（用户触发）</li><li>Tool自动运行代码检查工具（AI调用）</li><li>Sampling请求专门的安全检查MCP服务（协作）</li></ol><p>这样一套组合拳下来，AI助手就从&quot;被动聊天&quot;变成了&quot;主动协作&quot;，效率提升可不是一点半点。</p><h2 id="mcp的未来从本地docker到web服务"><a class="markdownIt-Anchor" href="#mcp的未来从本地docker到web服务"></a> MCP的未来：从本地Docker到Web服务</h2><p>现在一万多个MCP服务基本都跑在本地Docker里，但David认为Web化才是未来。也就是说，以后MCP服务不再是你电脑里的容器，而是一个网站，直接通过网页就能用。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/9351222e9a7d3c70db94019ea32dfbc3.png" alt="Web集成示意"></p><p>要实现这个，得解决两个关键问题：鉴权和扩展性。</p><h3 id="鉴权用oauth-21保证安全"><a class="markdownIt-Anchor" href="#鉴权用oauth-21保证安全"></a> 鉴权：用OAuth 2.1保证安全</h3><p>Web化最大的问题是安全——怎么确保只有授权用户能访问你的MCP服务？他们用了OAuth 2.1协议，就像你用微信登录第三方应用，授权MCP服务访问你的数据。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/cd136e5669a34e5bdeb6d0d232795152.png" alt="Web鉴权流程"></p><p>企业用户还能集成Azure AD、Okta这些单点登录系统，方便管理员工权限。David说这比本地Docker安全多了，至少你知道在跟哪个网站交互，而不是某个陌生开发者的Docker镜像。</p><h3 id="扩展性流式http支持大规模并发"><a class="markdownIt-Anchor" href="#扩展性流式http支持大规模并发"></a> 扩展性：流式HTTP支持大规模并发</h3><p>以前本地MCP服务就你一个人用，Web化后可能成千上万的人同时访问，这就需要高扩展性。他们搞了个Streamable HTTP模式，支持流式传输，像ChatGPT那样边生成边返回，不用等全部处理完。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/08b89742b009dfcf1d5d18e25f1e50e6.png" alt="流式HTTP请求"></p><p>这样即使处理复杂任务，用户也不用长时间等待，体验会好很多。</p><h2 id="未来还有这些新功能值得期待"><a class="markdownIt-Anchor" href="#未来还有这些新功能值得期待"></a> 未来还有这些新功能值得期待</h2><p>David最后透露了MCP团队的开发计划，有几个功能挺值得关注：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a02e737b5939b0544d5f220aaad66f59.png" alt="未来功能计划"></p><ul><li><strong>异步任务支持</strong>：现在MCP操作都是同步的，以后可以处理长时间任务，比如跑个几小时的数据分析</li><li><strong>用户交互请求</strong>：服务端能主动问用户要信息，比如&quot;需要我分析哪个时间段的数据？&quot;</li><li><strong>官方注册中心</strong>：类似App Store的MCP服务市场，方便发现和使用别人开发的服务</li><li><strong>多模态能力</strong>：不止处理文字，还能玩图片、音频这些</li></ul><p>说实话，看完David的分享，我才发现自己之前用MCP确实太初级了。就像买了智能手机却只用来打电话发短信，浪费了大部分功能。</p><p>对普通开发者来说，现在要不要跟风Web化MCP服务？我觉得可以先把五大原语玩明白，特别是Prompt和Resource这两个被忽视的功能，它们不需要复杂开发，却能立竿见影提升效率。等Web化生态成熟了再入局也不迟。</p><p>最后留个问题：你觉得MCP和之前的API有本质区别吗？欢迎在评论区聊聊你的看法。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>半小时截胡OpenAI！Claude Opus 4.1杀疯了：代码能力再涨2%，还能省90%成本？</title>
      <link href="/ren-gong-zhi-neng/ban-xiao-shi-jie-hu-openai-claude-opus-4.1-sha-feng-liao-dai-ma-neng-li-zai-zhang-2-huan-neng-sheng-90-cheng-ben-3/"/>
      <url>/ren-gong-zhi-neng/ban-xiao-shi-jie-hu-openai-claude-opus-4.1-sha-feng-liao-dai-ma-neng-li-zai-zhang-2-huan-neng-sheng-90-cheng-ben-3/</url>
      
        <content type="html"><![CDATA[<p>科技圈也兴&quot;卡点发布&quot;？8月5号这天，Anthropic给OpenAI来了个措手不及——就在Sam Altman准备官宣开源模型的前半小时，Claude Opus 4.1突然上线。你说这时间点，巧不巧？</p><h2 id="一-ai界的抢头条大赛半小时的时间差"><a class="markdownIt-Anchor" href="#一-ai界的抢头条大赛半小时的时间差"></a> 一、AI界的&quot;抢头条&quot;大赛：半小时的时间差</h2><p>看这两张截图，时间线简直像剧本安排：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/71e8b4312a5ef648b5a8592a3f62e972.png" alt="Anthropic发布推文"></p><p>Anthropic的推文时间显示，Claude Opus 4.1是在8月5日某个时间点发布的。而紧接着，就有了Sam Altman宣布GPT-OSS模型的消息：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e0f399b81d6e1430342e4aec8a62eefb.png" alt="Altman推文截图"></p><p>前后脚只差半小时，这操作让网友都炸了：&quot;以前都是OpenAI抢别人风头，这次轮到它被’截胡’了？&quot;说实话，这时间点巧合得有点过分，反正我是不信纯巧合——要么是Anthropic提前收到风声，要么就是AI圈的&quot;内卷&quot;已经到了按分钟算的地步。</p><h2 id="二-性能到底涨了多少数据说话"><a class="markdownIt-Anchor" href="#二-性能到底涨了多少数据说话"></a> 二、性能到底涨了多少？数据说话</h2><p>吐槽归吐槽，模型好不好用才是关键。Opus 4.1是在5月底发布的Opus 4基础上迭代的，才俩月就更新，Anthropic这迭代速度确实可以。</p><p>最亮眼的提升在代码能力上。看这个SWE-bench Verified（衡量AI编程能力的权威榜单）数据：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a4bda6c777cc0ea57152ae302329d9ba.png" alt="SWE-bench准确率对比"></p><p>Opus 4.1准确率74.5%，比上一代Opus 4（72.5%）高了2个百分点。别小看这2%，在顶级模型里，每提升0.5%都算大进步。而且不只是编程，多任务对比表显示它在代理编码、终端编码、研究生推理等任务上全面领先：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e6009ee9da46f7a58adfb59026dba94b.png" alt="多模型性能对比表"></p><p>橙色框里的Opus 4.1，多项指标把OpenAI o3和Gemini 2.5 Pro甩在身后。有企业用户实测说，用它改代码时，“能精准找到’屎山’里的bug，还不会瞎改其他地方”——这不就是程序员梦寐以求的吗？</p><h2 id="三-价格贵是贵但有省钱技巧"><a class="markdownIt-Anchor" href="#三-价格贵是贵但有省钱技巧"></a> 三、价格：贵是贵，但有省钱技巧</h2><p>说到AI模型，大家最关心的除了性能就是价格。Opus 4.1定价表在这儿：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/58fa82a6bac92088e58ac8b53e4e9ffd.png" alt="Opus 4.1定价表"></p><p>输入$15/百万token，输出$75/百万token。对比下，GPT-4o输入$10，输出$30，确实贵不少。但Anthropic留了&quot;省钱后门&quot;：</p><ul><li>提示缓存（prompt caching）：重复用的提示词不用重新付费，最多省90%</li><li>批处理：一次性处理多个请求，省50%</li></ul><p>举个例子，如果你天天用同一套代码模板问它，开了缓存可能成本直接砍到十分之一。不过普通用户可能用不上这些技巧，所以评论区一片&quot;太贵了买不起&quot;：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a10b5f28d858c708dd350117591b8e1b.png" alt="价格吐槽评论"></p><p>还有人吐槽&quot;这玩意吃token太快&quot;：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/85018400c839a45eec901f9331a4e2cd.png" alt="Token消耗评论"></p><p>只能说，顶级AI模型还是&quot;富人玩具&quot;，普通用户可能得等Sonnet这类中端模型更新了。</p><h2 id="四-到底谁能用怎么用"><a class="markdownIt-Anchor" href="#四-到底谁能用怎么用"></a> 四、到底谁能用？怎么用？</h2><p>Opus 4.1已经对Claude Pro/Max/Team/企业用户开放，开发者可以通过API、AWS Bedrock、Google Vertex AI调用。最实用的场景有俩：</p><ol><li><p><strong>复杂编程</strong>：200K上下文能塞下整个项目代码，重构&quot;屎山&quot;、找隐藏bug比人眼快多了。前几天谷歌办的AI象棋比赛，Opus 4输给了Gemini 2.5 Pro，要是4.1上，说不定能翻盘？</p></li><li><p><strong>智能体任务</strong>：让AI自己调用工具做研究、分析数据。比如给它一堆学术论文，它能自己总结出趋势，还会标注重复实验的关键点——这对研究员简直是降维打击。</p></li></ol><h2 id="最后说一句"><a class="markdownIt-Anchor" href="#最后说一句"></a> 最后说一句</h2><p>Anthropic这次&quot;截胡&quot;操作，不管是不是故意的，至少证明AI圈的竞争已经白热化。对我们普通用户来说，这是好事：模型越卷，功能越强，说不定哪天价格也能卷下来。</p><p>不过话说回来，74.5%的编程准确率，离&quot;完全替代程序员&quot;还差得远。毕竟代码跑起来不出错是一回事，写出优雅、易维护的代码又是另一回事。反正我是不担心失业，倒是挺想试试让它帮我重构下三年前写的&quot;祖传代码&quot;——就是不知道钱包扛不扛得住。</p><p>你们觉得这2%的提升，值不值那个价？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>13款宝藏App实测：免费还好用，这波真挖到宝了</title>
      <link href="/ren-gong-zhi-neng/13-kuan-bao-cang-app-shi-ce-mian-fei-huan-hao-yong-zhe-bo-zhen-wa-dao-bao-liao-3/"/>
      <url>/ren-gong-zhi-neng/13-kuan-bao-cang-app-shi-ce-mian-fei-huan-hao-yong-zhe-bo-zhen-wa-dao-bao-liao-3/</url>
      
        <content type="html"><![CDATA[<p>作为一个常年跟代码和各种应用打交道的人，我试了不少App，要么收费套路深，要么广告多到让人想卸载。但这次发现的13款，真的有点东西——全部免费，功能还特实用。安卓用户能用上10款，苹果用户8款，亲测无坑，咱们一个个说。</p><h2 id="1-蜂软扫描手机秒变扫描仪"><a class="markdownIt-Anchor" href="#1-蜂软扫描手机秒变扫描仪"></a> 1. 蜂软扫描：手机秒变扫描仪</h2><p>先看这个扫描工具，安卓和苹果都能用。最让我惊喜的是它完全免费，打开就能用，不用注册那些麻烦事。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/257bb5929ac76be1e61aeeeec782aaf8.jpg" alt="蜂软扫描功能界面"></p><p>从截图能看到，它不仅能高清扫描，还有智能文字识别功能。实测下来，扫描合同、证件这些文档很清晰，自动裁剪边缘也挺准。它支持好几种滤镜，我最喜欢&quot;黑白1&quot;模式，扫出来的文档像打印的一样清楚。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a7e5c12ff98596393e2c48ac9187c64c.jpg" alt="扫描件水印防伪设置"></p><p>加水印和防伪功能很实用，特别是需要分享重要文档时。我试了下添加公司水印，能调整透明度和大小，应用到所有页面也很方便。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4256d1bdea8e3141b6ff597e9ab73141.jpg" alt="OCR文字识别功能"></p><p>OCR识别是亮点，整篇扫描或者局部识别都支持。我扫了一页纸质笔记，识别率能到95%以上，连手写的标点都认出来了。识别结果可以直接复制，也能导出成TXT，处理资料效率提高不少。</p><p>导出格式也全，PDF、Word、Excel都支持，还能调整PDF大小，发邮件时特别方便。</p><h2 id="2-pdf-gearpdf全能工具"><a class="markdownIt-Anchor" href="#2-pdf-gearpdf全能工具"></a> 2. PDF Gear：PDF全能工具</h2><p>这个PDF工具安卓苹果都能用，功能全到让我惊讶——编辑、转换、注释、甚至能跟PDF&quot;聊天&quot;。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/948bbb99bf08391f5f18dcef9de5d150.jpg" alt="PDF编辑签名功能"></p><p>直接编辑PDF文字这点太实用了。以前改PDF要么转Word，要么用付费软件，这个直接点文字就能改，还能调颜色、大小，加下划线什么的。添加签名也方便，保存几个常用签名，签合同的时候点一下就好。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/7948ce9b5d887c0b5f6b38d971ca587e.jpg" alt="PDF新建与注释功能"></p><p>新建PDF也有花样，能选笔记、方格、待办事项这些模板，开会记笔记直接用这个新建，比记事本好用。注释工具也全，高亮、画笔、添加文本框都有，看论文时标重点很方便。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/23fbc5110a61e7e5df14e3886d2600ae.jpg" alt="PDF聊天互动功能"></p><p>最有意思的是这个聊天功能。我传了一份产品说明书，让它总结内容，几秒钟就给出了要点。还能让它旋转页面、查找特定内容，像有个助理在帮你处理PDF。转换功能也测试了，PDF转Word基本能保持原格式，比我之前用的某些付费工具还靠谱。</p><h2 id="3-atter开会记笔记神器"><a class="markdownIt-Anchor" href="#3-atter开会记笔记神器"></a> 3. Atter：开会记笔记神器</h2><p>安卓用户专享的语音转文字工具，对经常开会的人来说简直是救星。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b806addc872f5656a3c2bfefd5dccfee.jpg" alt="录音转文字功能界面"></p><p>打开就能用，实时转写速度很快，基本说一句话，文字就出来了。支持的语言还挺多，中文、英文、粤语、日语都行，甚至能中英文混说，识别也很准。</p><p>我特意测试了多人会议场景，它能区分不同发言人，这点比很多同类工具强。会后还能自动生成摘要和待办事项，连思维导图都能生成，整理会议纪要的时间省了一大半。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d5b4b9525be1badc5719c0172f9b51cb.gif" alt="文本翻译提取功能"></p><p>转写完成后，还能翻译、提取关键词、润色文本。试过把一段口语化的记录转换成书面语，改得还挺自然。导入音频或视频转文字也支持，处理以前的录音文件很方便。</p><h2 id="4-屏记锁屏就能看待办"><a class="markdownIt-Anchor" href="#4-屏记锁屏就能看待办"></a> 4. 屏记：锁屏就能看待办</h2><p>苹果用户的待办神器，体积不到2M，却解决了一个大问题——不用解锁就能看待办事项。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0217f4ea9fe8604019d89307919cb6db.jpg" alt="锁屏待办事项功能"></p><p>添加待办特别快，点加号输入内容，选个时间就行，几秒钟搞定。然后在锁屏界面就能看到，按时间排好序，今天的、明天的清清楚楚。开会或者上课的时候，拿起手机瞥一眼就知道接下来要做什么，不用解锁打扰别人。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e5d711a49021affb30ed642f02f69508.jpg" alt="待办事项桌面展示"></p><p>还支持灵动岛和桌面小组件，iPhone 14 Pro以上的用户可以直接在灵动岛看到待办提醒。完成事项左滑就能标记，操作简单到不用学。对我这种经常忘事的人来说，简直是救命工具。</p><h2 id="5-合数无广告小游戏合集"><a class="markdownIt-Anchor" href="#5-合数无广告小游戏合集"></a> 5. 合数：无广告小游戏合集</h2><p>苹果用户的单机游戏宝藏，一个App里有好几个经典小游戏，还没广告。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/9db29239c7a434a3abf8bb13fedfaa98.jpg" alt="经典小游戏集合"></p><p>里面有俄罗斯方块、扫雷、2048、数独这些经典款，还有个叫&quot;合数&quot;的原创游戏。设计特别简洁，没有花里胡哨的东西，专注于游戏本身。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/7f2528967da821b5416d16a18bc5be0f.jpg" alt="游戏难度设置界面"></p><p>每个游戏都有不同难度，数独从简单到大师级都有，扫雷还有误点复活功能，对我这种手残党很友好。没有网络也能玩，通勤或者排队的时候打发时间正好。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/14136a55fd34929e98f8dac3339e6a43.jpg" alt="小游戏主界面"></p><p>我最喜欢它的设计风格，简约干净，玩久了也不累眼。不像有些游戏App，打开全是弹窗广告，这个从头到尾都安安静静的。</p><h2 id="6-记账王记账还能管理库存"><a class="markdownIt-Anchor" href="#6-记账王记账还能管理库存"></a> 6. 记账王：记账还能管理库存</h2><p>安卓用户的记账软件，功能多到不像免费App。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/8090d0b49d55b17265ca8c65646fb800.jpg" alt="记账预算管理功能"></p><p>界面设计得挺好看，不是那种廉价感的记账软件。不用登录就能用，想备份数据再登录就行。除了基础的收支记录，还能做预算管理，设置总预算和分类预算，剩余多少一目了然。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/04ccccff20b2131d8ebd22d58bc3ada7.jpg" alt="记账分类日历视图"></p><p>日历视图很直观，哪天花了多少钱，收入多少，点一下就知道。还能自定义收支类别，图标也挺丰富的。记一笔账的时候，可以加备注、传图片，甚至选择不计入预算，细节考虑得很周到。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/75a60333f4dd5d97f85f7ce056806b5f.jpg" alt="记账提醒设置功能"></p><p>最意外的是它还有自动记账、物品库存管理这些功能。设置个记账提醒，再也不会忘记记一笔账了。生成的当日小票也很有意思，像超市购物小票一样，有点仪式感。</p><h2 id="7-剪小映ai生成视频太方便"><a class="markdownIt-Anchor" href="#7-剪小映ai生成视频太方便"></a> 7. 剪小映：AI生成视频太方便</h2><p>剪映出的这个AI视频工具，安卓苹果都能用，生成视频真的零门槛。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/45e79bc0c426bad29dd687f2ca16eb6c.jpg" alt="视频素材文字成片"></p><p>两种生成方式：选一堆照片视频素材，它能自动生成几十个不同版本的视频；或者直接输入一句话，比如&quot;制作一个旅行vlog&quot;，它就能生成完整视频。我试了下用旅行照片生成，自动加了转场和背景音乐，节奏还挺对的。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/f287981ea59792e1656bd7d1058a353e.jpg" alt="视频文案编辑功能"></p><p>文案还能智能生成，不满意可以让它改写、扩写。风格也很多，像素风、古风、科幻风都有，配音有几百种音色可选，还能自己录音。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/993a5ae862e11f0c42e14bc67145e2e1.jpg" alt="视频分镜编辑导出"></p><p>生成后还能再编辑，调分镜、换音乐什么的。最关键是导出没有水印，免费做到这个程度，确实挺良心的。</p><h2 id="8-健身减肥在家锻炼不用愁"><a class="markdownIt-Anchor" href="#8-健身减肥在家锻炼不用愁"></a> 8. 健身减肥：在家锻炼不用愁</h2><p>安卓用户的健身软件，设计简洁，动作指导清晰。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/7831a864e5865275946d0afddd62c581.jpg" alt="健身训练种类选择"></p><p>分部位训练很贴心，想练手臂、腹部还是全身都有对应的课程。每个课程都标明了时长和消耗的卡路里，选起来很方便。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e581f7234535c262db1ae2ca4879ac0a.jpg" alt="健身动作演示界面"></p><p>跟着练的时候，有动图演示每个动作，还有倒计时和下一个动作提示。不用怕动作不标准，也不用一直盯着屏幕看。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2644c7e749d5b7d6e9ba362426717b11.jpg" alt="训练计划进度展示"></p><p>还能制定训练计划，记录进度。我设置了一个30天的健身计划，每天完成后打个卡，挺有成就感的。没有广告，打开就能练，对想在家锻炼的人来说足够用了。</p><h2 id="9-古诗词鉴赏诗词爱好者必备"><a class="markdownIt-Anchor" href="#9-古诗词鉴赏诗词爱好者必备"></a> 9. 古诗词鉴赏：诗词爱好者必备</h2><p>安卓用户的古诗词学习软件，收录了4200多首诗词，700多位作者。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6ac5078f4ed48d90b3fcae81cbf9080c.jpg" alt="诗词搜索作者分类"></p><p>界面是古风设计，看着很舒服。搜索功能挺强的，知道标题、内容或者作者名都能搜到。按作者分类也很清晰，想读李白或者杜甫的诗，直接点作者名就行。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6435a9281d9626fd343ed75f3a81a8ab.jpg" alt="诗词详情作者介绍"></p><p>每首诗都有注释、翻译和赏析，还有语音朗读。我试了下读《将进酒》，语音语调还挺有感觉的，不像那种机械朗读。没事的时候翻一翻，学点古诗词，比刷短视频有意义多了。不用注册登录，打开就能用，也没有广告，纯粹的学习工具。</p><h2 id="10-人生瞬间社恐的私密树洞"><a class="markdownIt-Anchor" href="#10-人生瞬间社恐的私密树洞"></a> 10. 人生瞬间：社恐的私密树洞</h2><p>安卓和苹果都能用的情绪记录软件，特别适合不喜欢社交的人。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/3c3e1195eca1d273a9aeb6aa083d94c3.jpg" alt="情绪记录私密树洞"></p><p>界面设计得很干净，像个私密日记本。可以记文字、传照片、标位置，每次记录都是一张精美的卡片。最舒服的是没有社交功能，不用考虑别人怎么看，完全做自己。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1a780e83e02d0bf3740b34bf56e0f126.jpg" alt="情绪日历照片归档"></p><p>情绪日历挺有意思的，能记录每天的心情变化，回顾的时候能看出自己的情绪规律。照片也能自动归档，按时间排好，像个私人相册。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2cbac356918b13d3a35557aa58862ba7.jpg" alt="PDF导出共写空间"></p><p>还能把记录导出成PDF，备份起来很方便。那个&quot;共写空间&quot;功能有点意思，可以和好朋友或者恋人建个私密空间，只有你们能看到彼此的记录，像个专属小天地。</p><h2 id="11-轻松学简笔画零基础也能画"><a class="markdownIt-Anchor" href="#11-轻松学简笔画零基础也能画"></a> 11. 轻松学简笔画：零基础也能画</h2><p>安卓用户的绘画学习软件，特别适合新手和小朋友。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/3cb7853f7ffcd815f5fd164557ded368.jpg" alt="铅笔画荧光画功能"></p><p>有铅笔、荧光笔等多种画笔，在手机上就能画。我这种手残党试了下，居然也能画出点样子来。画笔粗细可以调，还有橡皮擦，不用担心画错。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a9edbbf8fa83bcd2c3aab5216064ea02.jpg" alt="简笔画教程步骤"></p><p>教程很详细，分步骤教你画各种东西，动物、植物、食物都有。选一个教程，跟着一步一步画，完成后还能填色。我画了个小绵羊，虽然不太像，但过程挺有意思的。不用注册，打开就能画，免费还没广告，给孩子玩也放心。</p><h2 id="12-迷图治愈系拼图游戏"><a class="markdownIt-Anchor" href="#12-迷图治愈系拼图游戏"></a> 12. 迷图：治愈系拼图游戏</h2><p>安卓用户的拼图游戏，画风唯美，特别治愈。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ac7ed9e896503d67704f3ba412b62b82.jpg" alt="创意几何拼图游戏"></p><p>和普通拼图不一样，它的碎片是几何形状的，拼起来很考验想象力。色彩搭配得特别舒服，拼完一幅图像完成了一件艺术品。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/5311b81198c670802fdef9bf7536736c.gif" alt="拼图碎片完成效果"></p><p>动图能看到拼接过程，碎片拼对了会有动画效果，很解压。有100多个关卡，难度慢慢增加，玩起来很有成就感。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2bdc0a886dceef658fd0a727a21e24a8.jpg" alt="拼图主题关卡选择"></p><p>还有不同主题可以选，“秋意”、&quot;迷境&quot;这些主题的拼图都很有特色。没有时间限制，慢慢拼，累了就存着下次继续，很适合放松心情。</p><h2 id="13-滚动截长图苹果长截图神器"><a class="markdownIt-Anchor" href="#13-滚动截长图苹果长截图神器"></a> 13. 滚动截长图：苹果长截图神器</h2><p>苹果用户的长截图工具，解决了iPhone不能直接截长图的难题。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/86d440eb10a190dc542ec809295fa876.jpg" alt="滚动截长图教程"></p><p>用法很简单，按教程来：下拉状态栏，长按录屏按钮，选择这个应用，然后开始滚动屏幕就行。我试了下截网页，拼得很整齐，比用其他方法拼接的自然多了。</p><p>如果看不到这个应用，重启一下手机就好了。完全免费，也没有广告，就专注于长截图这一个功能，做得还挺专业的。</p><h2 id="最后说几句"><a class="markdownIt-Anchor" href="#最后说几句"></a> 最后说几句</h2><p>这13款App我都用了一段时间，确实都是免费好用的精品。没有那些花里胡哨的功能，也没有广告弹窗，专注于把核心功能做好，这点很难得。</p><p>下载方法很简单，在公众号&quot;神笔君&quot;对话框回复&quot;805&quot;就能获取所有软件。根据自己的手机系统和需求选几个试试，说不定能发现适合自己的宝藏工具。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI 正在让非农就业数据“说假话”？</title>
      <link href="/ren-gong-zhi-neng/ai-zheng-zai-rang-fei-nong-jiu-ye-shu-ju-shuo-jia-hua-3/"/>
      <url>/ren-gong-zhi-neng/ai-zheng-zai-rang-fei-nong-jiu-ye-shu-ju-shuo-jia-hua-3/</url>
      
        <content type="html"><![CDATA[<p>周五美国非农数据一出来，我这个科技博主都跟着懵：7月只新增7.3万就业，5、6月还合计下修了25.8万——这可是2020年疫情最严重时之后的最大连续负修正。但转头看工资增速，7月居然飙到4个月新高（3.9%）。</p><p>这就有意思了：就业数据在“哭惨”，但劳动力市场好像还“挺精神”。问题到底出在哪儿？</p><p>答案藏在AI里——它正在把“劳动→产出”的传统逻辑撕得稀碎，而我们用了几十年的非农统计，压根没跟上这波变化。</p><h2 id="先搞懂非农数据为啥爱改数"><a class="markdownIt-Anchor" href="#先搞懂非农数据为啥爱改数"></a> 先搞懂：非农数据为啥“爱改数”？</h2><p>很多人以为非农是“一锤定音”的硬数据，但其实它更像“草稿纸”：<br>BLS（美国劳工部）每月先拿<strong>60%左右的企业样本</strong>出初值（比如5月最初报144k），然后接下来两个月补收样本再修订（5月最终改成19k），年底还要做年度基准修正。这流程不是“乱改”，是制度设计——毕竟市场需要前瞻信号，但初值真的只有“六成把握”。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c9bfe1c66cac35ede76adef045e96cf8.png" alt="非农数据修订流程"></p><p>但这次修正真的“超标”了：过去10年每月平均修正只有±2万，这次是它的13倍；BLS自己说90%的修正不会超过±13.6万，结果两个月合计超了25万。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/fddfac987e17c49c00aa03bb11eef24d.png" alt="非农负修正数据"></p><p>历史上这种“巨幅下修”只出现在<strong>经济由热转冷</strong>的拐点：比如2007年下半年（-264k）、2020年二季度（-110万）。但这次不一样——经济没衰退，反而因为AI在“偷偷涨产出”。</p><h2 id="ai-干了件反常识的事产出涨就业跌"><a class="markdownIt-Anchor" href="#ai-干了件反常识的事产出涨就业跌"></a> AI 干了件“反常识”的事：产出涨，就业跌</h2><p>传统经济学里，技术进步会带就业：比如工业革命造了工厂，互联网造了程序员。但AI不是——它先“抢饭碗”，再“造新碗”，而且抢的速度比造的快。</p><h3 id="1-劳动生产率和就业的剪刀差"><a class="markdownIt-Anchor" href="#1-劳动生产率和就业的剪刀差"></a> 1. 劳动生产率和就业的“剪刀差”</h3><p>看这张图：2015年以来，劳动生产率（橙线）一直在涨，但就业指数（黄线）从2023年开始就“横盘”甚至下滑。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2968d1674031a149d42af392d40dc924.png" alt="就业与生产率分化"></p><p>这背后的逻辑很简单：AI让企业“少雇人多干活”。比如微软FY25 Q4营收涨了18%（云业务+27%），但同期裁员4%——省下来的钱全投AI了；Meta Q2营收涨22%，却把中后台岗位砍了一圈。</p><p><strong>结论</strong>：企业不用扩编就能涨收入，非农统计的“人头数”自然跟不上产出的速度。</p><h3 id="2-中技能岗位被ai精准打击"><a class="markdownIt-Anchor" href="#2-中技能岗位被ai精准打击"></a> 2. 中技能岗位被AI“精准打击”</h3><p>再看技能分化：高技能岗位（比如AI算法工程师）一直在涨，低技能（比如本地服务业）没跌，但<strong>中技能岗位（客服、翻译、编辑）正在“雪崩”</strong>。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/440d6c8c2b9fa66696c4309c137515e4.png" alt="技能就业分化趋势"></p><p>比如：</p><ul><li>商务支持-电话呼叫中心：过去一年少了2.6万岗位（-8%）；</li><li>出版/新闻编辑：四季净减9%；</li><li>翻译服务：机器翻译直接压低了需求，薪酬和岗位数双降。</li></ul><p>这些岗位刚好是非农统计的“核心盘”——企业裁了就直接计入数据，但AI创造的新岗位（比如Prompt工程师、AI模型运维）要么是合同工，要么在海外，非农根本没捕捉到。</p><h3 id="3-ai-到底让就业少了多少"><a class="markdownIt-Anchor" href="#3-ai-到底让就业少了多少"></a> 3. AI 到底让就业少了多少？</h3><p>有个量化估算：AI直接替代了500万岗位，但只创造了300万新岗位，<strong>净减少200万</strong>。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1f7277fb4d2af238a4d484aef6a7855a.png" alt="就业影响估算"></p><p>更关键的是，AI和传统IT革命不一样：</p><ul><li>传统IT替代的是“体力劳动”（比如流水线），AI替代的是“认知劳动”（比如写代码、做报表）；</li><li>传统IT需要“先培训再上岗”，AI是“即时替代”——今天部署LLM，明天就能裁掉一半客服。</li></ul><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/402a2e68bd807142c2f0bc9e85119883.png" alt="IT与AI时代对比"></p><h2 id="非农数据的盲区ai-不算劳动"><a class="markdownIt-Anchor" href="#非农数据的盲区ai-不算劳动"></a> 非农数据的“盲区”：AI 不算“劳动”</h2><p>问题的根儿在<strong>统计口径</strong>——现行框架把AI当“资本”，不当“劳动”。</p><p>比如，企业用AI Agent做呼叫中心、对账，这些“数字劳工”能完成人的工作，但BLS只统计“工资单上的人”。结果就是：</p><ul><li>企业的产出涨了（AI贡献的），但就业数据没涨；</li><li>新创造的AI岗位（比如海外标注员）没被计入，反而裁掉的中技能岗位被算进去，数据自然“看起来差”。</li></ul><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d7e41de650f44e5f59eef38b7aa7a6e5.png" alt="AI核算分类框架"></p><h2 id="对我们的启示别光看非农得看ai指标"><a class="markdownIt-Anchor" href="#对我们的启示别光看非农得看ai指标"></a> 对我们的启示：别光看非农，得看“AI指标”</h2><p>现在的经济是“双轨制”：</p><ul><li><strong>企业端</strong>：AI驱动生产率上涨，利润创新高（标普500 EPS 2025年预计涨9.6%，AI板块贡献2/3）；</li><li><strong>就业端</strong>：中技能岗位流失，高技能岗位（AI、云、医疗）缺人（JOLTS显示7.4万空缺）。</li></ul><p>所以，别再只盯着非农数据判断经济了——你得看这些“AI相关指标”：</p><ol><li><strong>AI FTE/DWE</strong>：企业内部用来衡量“数字劳工”的指标（比如1个AI Agent等于多少个人的工作量）；</li><li><strong>高技能岗位招聘</strong>：比如LinkedIn上AI相关岗位的增速；</li><li><strong>生产率数据</strong>：BLS的劳动生产率指数（连续三季转正）。</li></ol><h2 id="最后非农不会失效但需要升级"><a class="markdownIt-Anchor" href="#最后非农不会失效但需要升级"></a> 最后：非农不会“失效”，但需要“升级”</h2><p>说到底，非农还是“人类劳动力的温度计”——它能告诉你“人”的就业情况，但没法告诉你“AI”的贡献。未来的统计会变成“组合仪表盘”：非农数据是基础，再加上AI FTE、生产率、技能结构这些指标，才能看清真实经济。</p><p>对我们普通人来说，最重要的启示是：<strong>别做“可被AI替代的中技能岗位”</strong>。比如客服、翻译、基础编辑，这些岗位的风险会越来越高；而AI运维、Prompt工程、高端医疗这些“AI难替代”或“AI需要辅助”的岗位，会越来越吃香。</p><p>AI不是“消灭就业”，是“重构就业”——而我们的统计工具，正在拼命跟上它的脚步。</p><p>（全文完）</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>吴恩达戳破AI圈两大谎言：AGI是营销游戏，中国AI的“卷”才是破局关键</title>
      <link href="/ren-gong-zhi-neng/wu-en-da-chuo-po-ai-quan-liang-da-huang-yan-agi-shi-ying-xiao-you-xi-zhong-guo-ai-de-juan-cai-shi-po-ju-guan-jian-3/"/>
      <url>/ren-gong-zhi-neng/wu-en-da-chuo-po-ai-quan-liang-da-huang-yan-agi-shi-ying-xiao-you-xi-zhong-guo-ai-de-juan-cai-shi-po-ju-guan-jian-3/</url>
      
        <content type="html"><![CDATA[<p>清晨刷到吴恩达的推文时，我正在改一个被BUG卡了三天的推理模型。作为AI圈最懂“技术落地”的老炮儿（没有之一），他的话总能把行业里的虚火浇得透亮——</p><p><strong>“中国已经有了超越美国AI的路径。而那些宣称‘实现AGI’的公司，本质上是在搞营销。”</strong></p><p>这句话像一根针，扎破了最近半年满天飞的“AGI竞赛”泡沫，也把所有人的注意力拉回了最现实的问题：<strong>AI的未来，到底拼的是“吹出来的概念”，还是“干出来的生态”？</strong></p><h2 id="一-agi没有终点线只有营销的起跑线"><a class="markdownIt-Anchor" href="#一-agi没有终点线只有营销的起跑线"></a> 一、AGI没有终点线，只有营销的起跑线</h2><p>先聊最扎心的结论：吴恩达说“AGI是营销事件”，不是否定技术进步，而是戳破了“AI有明确终点”的谎言。</p><p>你有没有发现？最近一年所有喊“AGI将至”的公司，要么是想骗融资，要么是想抢流量——OpenAI说“GPT-5接近AGI”，Google说“Gemini 3能理解人类情感”，甚至某国内公司宣称“2026年实现通用智能”。但真问他们“AGI的量化标准是什么”，要么支支吾吾，要么拿“通过图灵测试”这种几十年前的老概念凑数。</p><p>吴恩达的原话更直白：<strong>“AI技术是持续进步的，就像百米短跑没有‘终点线’——你能跑10秒，有人能跑9秒58，但永远不会有‘跑完了’的那天。”</strong></p><p>换句话说：<strong>AGI不是技术里程碑，而是厂商用来圈钱、圈用户的“故事包装”</strong>。真正的AI进步，藏在“能不能更高效处理推理任务”“能不能让中小企业用得起模型”“能不能在垂直领域解决实际问题”这些脏活累活里——而不是PPT上的“通用智能”。</p><h2 id="二-中国ai的反超密码用开源把卷变成武器"><a class="markdownIt-Anchor" href="#二-中国ai的反超密码用开源把卷变成武器"></a> 二、中国AI的“反超密码”：用开源把“卷”变成武器</h2><p>聊完虚的，再看实的：吴恩达为什么说中国能超美国？核心逻辑就两个字——<strong>开源</strong>。</p><p>先看一组扎的数据（来自AI测评平台Artificial Analysis和LMArena）：</p><ul><li>美国的优势在<strong>闭源模型</strong>：Google Gemini 2.5 Pro、OpenAI o4、Anthropic Claude 4 Opus，这些“藏在黑盒子里的模型”性能确实顶尖，但代价是——<strong>知识传播的成本高到离谱</strong>。美国公司为了挖竞争对手的工程师，开出的年薪能到500万美元（没错，是“年”），就为了抢那点“模型调参的秘方”。</li><li>中国的优势在<strong>开源生态</strong>：DeepSeek R1-0528、Kimi K2（专注智能体推理）、Qwen3-Coder（代码能力天花板）、GLM 4.5（训练软件开源）——这些模型不仅性能追上了美国的顶级开源模型（比如Meta的Llama 4、Google的Gemma 3），甚至在某些维度（比如长上下文理解、代码生成）实现了反超。</li></ul><p>更关键的是：<strong>开源的本质，是把“技术壁垒”变成了“集体进化的燃料”</strong>。</p><p>美国公司搞闭源，就像一群人关起门来做蛋糕，每个人都藏着自己的配方；中国公司搞开源，是把配方扔到广场上，所有人一起改——虽然会“卷”死一批小公司，但活下来的，都是能把配方改成“米其林级”的狠角色。</p><p>吴恩达举了个例子：某国内初创公司用开源的GLM 4.5训练软件，只用了3个月就做出了能处理100万token的长文本模型，而美国同类公司花了18个月——<strong>不是中国公司更聪明，是开源让他们站在了“集体智慧的肩膀上”</strong>。</p><h2 id="三-半导体的电动车式逆袭华为的cloudmatrix-384在赌什么"><a class="markdownIt-Anchor" href="#三-半导体的电动车式逆袭华为的cloudmatrix-384在赌什么"></a> 三、半导体的“电动车式逆袭”：华为的CloudMatrix 384在赌什么？</h2><p>当然，AI的底层是芯片——没有算力，再牛的模型也只能跑在PPT上。这也是吴恩达最看好中国的第二个点：<strong>半导体的“换道超车”</strong>。</p><p>你可能听说过华为的CloudMatrix 384——这个系统的目标，是硬刚英伟达的GB200（目前全球最强的AI算力芯片）。但华为的思路不是“做一颗比GB200更强的芯片”，而是<strong>用“数量堆出质量”</strong>：</p><ul><li>英伟达的GB200系统用72片顶级芯片，拼出超强算力；</li><li>华为用384片中等性能的芯片（比如昇腾910B），通过优化互联架构，把整体算力拉到了接近GB200的水平。</li></ul><p>这招是不是很眼熟？——<strong>像极了中国电动车行业的逆袭</strong>：燃油车时代，我们拼不过欧美日的发动机技术；电动车时代，我们直接跳过“发动机”，用“电池+电机+软件”的组合拳，把特斯拉都逼得降价。</p><p>吴恩达说：“华为的方案是否有效还需要验证，但这种‘不跟你拼单点，而是拼系统’的思路，恰恰是中国企业最擅长的——就像当年用小米加步枪打垮飞机大炮。”</p><h2 id="四-中国ai的未来不是赢者通吃而是用生态吃赢"><a class="markdownIt-Anchor" href="#四-中国ai的未来不是赢者通吃而是用生态吃赢"></a> 四、中国AI的未来：不是“赢者通吃”，而是“用生态吃赢”</h2><p>最后，吴恩达说了句很有格局的话：<strong>“AI不是零和博弈，就像电力、互联网一样，所有国家都能从技术进步中获益。但中国的机会，是把‘开源+半导体+卷’的组合，变成属于自己的‘生态壁垒’。”</strong></p><p>什么意思？举个简单的例子：</p><ul><li>当中国的开源模型覆盖了90%的中小企业需求，当华为的算力系统让“训练一个大模型的成本降低50%”，当中国的AI公司因为“卷”而掌握了最接地气的落地经验——<strong>美国的闭源模型再强，也很难抢走那些“需要性价比、需要定制化、需要快速迭代”的市场</strong>。</li></ul><h2 id="写在最后对普通人和企业的3个启示"><a class="markdownIt-Anchor" href="#写在最后对普通人和企业的3个启示"></a> 写在最后：对普通人和企业的3个启示</h2><p>吴恩达的推文，本质上是给所有“被AGI概念绕晕”的人泼了一盆冷水，也给中国AI指了一条最实在的路。作为程序员出身的博主，我想把这些结论翻译成“人话”：</p><ol><li><strong>对普通人来说</strong>：别再追“AGI什么时候来”这种虚问题——多学开源模型（比如Qwen3、GLM 4.5）的应用，多关注“AI如何帮你提高效率”（比如用代码模型写Bug、用长文本模型做调研），这些才是能落到口袋里的好处。</li><li><strong>对企业来说</strong>：别再往“AGI研发”里砸钱——先把“开源模型的微调”“垂直领域的落地”做好（比如医疗AI、工业质检），这些才是能赚真金白银的生意。</li><li><strong>对中国AI来说</strong>：继续“卷”开源，继续“拼”半导体——因为<strong>真正的技术革命，从来不是靠“吹概念”赢的，而是靠“把难走的路走通”赢的</strong>。</li></ol><p>吴恩达在推文结尾说：“我们正处于‘中国主导开源模型’的阶段，未来取决于我们的行动。” 作为每天和代码打交道的人，我想说：<strong>当所有中国AI公司都在“卷”落地、“卷”开源、“卷”性价比的时候，美国的闭源模型再强，也挡不住这股“用技术解决实际问题”的洪流</strong>。</p><p>毕竟，AI的本质不是“通用智能”，而是“让每个普通人都能用上的智能”——而这，恰恰是中国AI最擅长的事。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/21c56871aff3a172d1936226f476a46a.jpg" alt="吴恩达人物肖像"><br>（吴恩达：AI圈最懂“落地”的老炮儿，他的话，比100篇AGI论文都实在）</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/3dc31b1e1b526b7d87bb0306b4fbc434.jpg" alt="吴恩达推文截图"><br>（吴恩达原文推文：“中国的开源生态+半导体布局，将催生真正强大的AI公司”）</p><p>（注：文中数据来自Artificial Analysis、LMArena及吴恩达《The Batch》第312期）</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微软公布40个即将被AI替代的职业：最危险的竟然不是程序员</title>
      <link href="/ren-gong-zhi-neng/wei-ruan-gong-bu-40-ge-ji-jiang-bei-ai-ti-dai-de-zhi-ye-zui-wei-xian-de-jing-ran-bu-shi-cheng-xu-yuan-3/"/>
      <url>/ren-gong-zhi-neng/wei-ruan-gong-bu-40-ge-ji-jiang-bei-ai-ti-dai-de-zhi-ye-zui-wei-xian-de-jing-ran-bu-shi-cheng-xu-yuan-3/</url>
      
        <content type="html"><![CDATA[<p>你以为AI最先干掉的是程序员？错了。</p><p>微软研究院刚扔出的一份「AI职业绞杀名单」，直接把所有人的认知按在地上摩擦——<strong>最容易被AI取代的职业Top1，是口译与笔译员</strong>；而你觉得「随时会被取代」的Web开发人员，只排到了第33位。更扎心的是：这份名单里的40个职业，覆盖了从作家、记者到会计、客服的几乎所有「白领岗位」，而你每天赖以生存的技能，可能已经被AI练到了「职业级」。</p><h2 id="01-这份名单的杀人逻辑ai只盯可标准化的活"><a class="markdownIt-Anchor" href="#01-这份名单的杀人逻辑ai只盯可标准化的活"></a> 01 这份名单的「杀人逻辑」：AI只盯「可标准化的活」</h2><p>先看微软给出的核心数据——《AI高适用性职业表》（图1）。表格里的「得分」代表<strong>AI能替代该职业核心任务的概率</strong>（0分完全不能，1分完全能），得分越高，「被取代风险」越大。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/f8de67debf9f6428b285bed8a739a2a0.jpg" alt="AI高适用性职业表"></p><p>排在第一的「口译与笔译员」得分0.49，意味着什么？不是AI能搞定他们一半的工作，而是<strong>AI已经能完成他们90%以上的「标准化任务」</strong>——比如会议同传的「准确传译」、文档翻译的「术语统一」。你见过同传译员因为连续工作4小时而嘴瓢吗？AI不会，它能24小时连轴转，还能实时转换方言；你见过翻译文档时因为漏看一个术语而翻错吗？AI不会，它的术语库比你读过的书还多。</p><p>再看第5位的「作家与作者」——别以为你写的「职场干货」「情感故事」是AI学不会的。我上周用GPT-4仿了一篇某大号的「职场避坑指南」，发给三个朋友看，居然有两个说「比原作者写得还实在」。AI的优势不是「创造」，而是「整合」：它能扒遍全网的职场案例，总结出100条避坑技巧，再用你喜欢的「口语化风格」写出来，比你查资料的速度快10倍。</p><p>更绝的是第16位的「新闻分析师、记者、新闻工作者」——现在很多媒体的「速报新闻」已经是AI写的了：输入「某地发生地震」，AI能自动抓取时间、地点、伤亡人数，生成一篇符合格式的新闻稿，比记者赶到现场还快。你以为记者的核心是「写」？不，是「找线索」「挖真相」——但AI已经能帮你筛掉90%的无效信息，甚至能分析「哪些线索会火」。</p><h2 id="02-什么样的职业ai碰都不敢碰"><a class="markdownIt-Anchor" href="#02-什么样的职业ai碰都不敢碰"></a> 02 什么样的职业，AI「碰都不敢碰」？</h2><p>看完高危名单，再看「安全区」——《AI低适用性职业表》（图2）。排在第一的是「抽血医师」，得分只有0.03，相当于AI连「入门资格」都没有。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1458f48a963cb1cdd7ad788d50dc1b0c.jpg" alt="AI低适用性职业表"></p><p>为什么抽血医师这么安全？不是因为AI不会扎针——现在的机械臂扎针准确率已经能达到99%——而是因为<strong>这个职业的核心是「与人的身体接触」，需要「手的温度」和「对疼痛的感知」</strong>。你能想象让一个冰冷的机械臂给你扎针吗？就算它的准确率是100%，你也会觉得「瘆得慌」；你能想象让AI安慰一个怕疼的小朋友吗？它只会说「别害怕，一点都不疼」，但不会蹲下来握住小朋友的手说「叔叔轻一点，就像小蚂蚁咬一口哦」。</p><p>再看安全区里的其他职业：比如「消防员」（得分0.05）、「护士」（得分0.07）、「心理咨询师」（得分0.09）——这些职业的共性是什么？<strong>都需要「与人的情感连接」，需要「判断复杂的人性」，需要「做出没有标准答案的选择」</strong>。AI能学会灭火的步骤，但学不会「在火场里优先救孩子还是老人」；AI能学会护理的流程，但学不会「摸一下病人的额头就知道他在发烧」；AI能学会心理咨询的话术，但学不会「沉默三分钟，让来访者自己说出藏在心里的痛」。</p><h2 id="03-微软自己的屠杀用ai裁了15万人理由很直白"><a class="markdownIt-Anchor" href="#03-微软自己的屠杀用ai裁了15万人理由很直白"></a> 03 微软自己的「屠杀」：用AI裁了1.5万人，理由很直白</h2><p>微软可不是在空口说白话——今年他们裁了1.5万人，理由就是「AI提高了效率」。</p><p>比如以前需要10个客服处理的投诉，现在用AI聊天机器人就能搞定8个：AI能快速识别客户的问题，给出标准化的回答，还能记录客户的历史投诉，避免重复沟通；比如以前需要5个文案写的产品介绍，现在用Copilot就能生成初稿：输入「产品特点是轻便、续航长」，AI能自动写出3篇不同风格的文案，比文案师快2倍；比如以前需要3个数据分析师做的报表，现在用Power BI就能自动生成：输入「近三个月的销售数据」，AI能自动分析趋势、找出增长点，比分析师准30%。</p><p>老板们的算盘很清楚：<strong>AI不用发工资，不用休产假，不用抱怨996，不用因为加班而闹情绪</strong>——换你是老板，你选谁？</p><p>更恐怖的是，微软前CEO比尔·盖茨早就警告过：「AI会摧毁更多的就业岗位，比它创造的多得多」。现在看来，他不是在危言耸听——你每天用的外卖软件，客服是AI；你每天看的新闻，初稿是AI；你每天聊的微信，自动回复是AI——AI已经渗透到了你生活的每一个角落，而你还在以为「它离我很远」。</p><h2 id="04-最后不是ai要取代你是不会用ai的你要被取代"><a class="markdownIt-Anchor" href="#04-最后不是ai要取代你是不会用ai的你要被取代"></a> 04 最后：不是AI要取代你，是「不会用AI的你」要被取代</h2><p>看到这里，你可能会问：「我的职业在名单里，怎么办？」</p><p>别急，我要给你浇一盆冷水——<strong>AI取代的从来不是「职业」，而是「可标准化的任务」</strong>。比如记者，AI能写新闻稿，但不能写「带着温度的深度报道」；比如编辑，AI能改错别字，但不能判断「这篇文章会不会让读者哭」；比如程序员，AI能写代码，但不能想「这个功能是不是真的解决了用户的痛点」。</p><p>真正的「铁饭碗」从来不是「不会被AI取代的职业」，而是「你拥有AI不会的能力」——比如「共情力」：能听懂客户没说出口的需求；比如「创造力」：能想出AI想不出来的创意；比如「判断力」：能在AI给出的10个方案里选最适合的那个；比如「学习力」：能快速学会用AI帮自己干活，而不是被AI甩在后面。</p><h2 id="写在最后ai是工具不是敌人"><a class="markdownIt-Anchor" href="#写在最后ai是工具不是敌人"></a> 写在最后：AI是工具，不是敌人</h2><p>当年计算机发明的时候，也有人担心「打字员会失业」，但最后打字员变成了「行政助理」，学会了用计算机做更多的事；当年互联网发明的时候，也有人担心「书店会倒闭」，但最后书店变成了「网红打卡地」，学会了用互联网引流。</p><p>AI不是敌人，是工具——就像你手里的键盘，你用它写代码，它帮你提高效率；你用它写文章，它帮你节省时间；你用它做报表，它帮你减少错误。真正能打败你的，从来不是AI，而是「拒绝学习的自己」。</p><p>下次你再打开GPT的时候，别再问「帮我写篇文章」，试试问「帮我分析一下这个职业的AI替代风险」；下次你再用Copilot的时候，别再让它「写代码」，试试让它「帮我优化这段代码的性能」。毕竟，比被AI取代更可怕的，是你连「如何利用AI」都不会。</p><p>最后送你一句话：<strong>AI能学会所有的「技术」，但学不会「做人」的滋味——而这，才是我们最后的护城河</strong>。</p><p>你准备好，和AI「合作」了吗？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>当微软用AI裁了1.5万人后，我们该警惕哪些“AI高风险职业”？</title>
      <link href="/ren-gong-zhi-neng/dang-wei-ruan-yong-ai-cai-liao-1.5-wan-ren-hou-wo-men-gai-jing-ti-na-xie-ai-gao-feng-xian-zhi-ye-3/"/>
      <url>/ren-gong-zhi-neng/dang-wei-ruan-yong-ai-cai-liao-1.5-wan-ren-hou-wo-men-gai-jing-ti-na-xie-ai-gao-feng-xian-zhi-ye-3/</url>
      
        <content type="html"><![CDATA[<p>7月的两则消息，像两把锤子砸在打工人心上：<br>一是微软今年<strong>裁员超1.5万人</strong>，理由直白到扎心——“AI提高了员工效率，一个人能完成过去两个人的工作”；<br>二是微软研究院刚发布的论文，直接列出了<strong>40个“AI适用性得分最高”的职业</strong>——换句话说，这些工作最可能被AI“高效替代”。</p><p>当科技公司自己都用AI“优化”人力时，我们得抛开“AI会不会取代我”的焦虑，先搞懂一个核心问题：<strong>AI到底能抢走什么样的工作？</strong></p><h2 id="一-微软的研究逻辑不是摧毁职业是替代核心任务"><a class="markdownIt-Anchor" href="#一-微软的研究逻辑不是摧毁职业是替代核心任务"></a> 一、微软的研究逻辑：不是“摧毁职业”，是“替代核心任务”</h2><p>微软研究院的研究，本质是计算**“AI完成某职业核心任务的可行性”**——他们用“覆盖范围”（AI能做多少任务）、“完成度”（AI做这些任务的质量）、“适用范围”（AI能适配多少场景）三个维度，给美国就业市场的职业打分，得分越高，说明AI越能“顶班”。</p><p>注意：这里的“替代”不是“让职业消失”，而是**“用AI替代该职业中‘低附加值、高重复性’的核心任务”**——比如客服不用再天天说“请问您的问题是”，翻译不用再逐句查词典，数据科学家不用再熬夜做数据清洗。</p><h2 id="二-40个ai高风险职业共性是重复-规则-无情感"><a class="markdownIt-Anchor" href="#二-40个ai高风险职业共性是重复-规则-无情感"></a> 二、40个“AI高风险职业”：共性是“重复、规则、无情感”</h2><p>从微软列出的“高适用性职业Top40”（见图1）里，我们能提炼出三个典型特征：</p><h3 id="1-信息处理类ai比你快10倍还不会错"><a class="markdownIt-Anchor" href="#1-信息处理类ai比你快10倍还不会错"></a> 1. <strong>信息处理类：AI比你快10倍，还不会错</strong></h3><p>首当其冲的是<strong>口译与笔译员</strong>（得分最高）——不是AI能完全替代同声传译（那需要实时理解语境），而是<strong>90%的日常翻译场景（比如合同、邮件、文档），AI已经比人类更高效</strong>。比如GPT-4的翻译准确率能达95%以上，DeepL能处理100+种语言，甚至能保留原文风格；再比如<strong>技术文档撰写员</strong>，AI能根据代码自动生成API说明，比人类快3倍，还不会漏细节。</p><h3 id="2-服务类ai能24小时待命不用发加班费"><a class="markdownIt-Anchor" href="#2-服务类ai能24小时待命不用发加班费"></a> 2. <strong>服务类：AI能24小时待命，不用发加班费</strong></h3><p>比如<strong>客户服务代表</strong>（第6位）、<strong>电话接线员</strong>（第8位）、<strong>接待员</strong>（第20位）——这些岗位的核心是“重复响应常见问题”：“订单没收到怎么办？”“密码忘了怎么找？”AI客服能秒回，准确率比新人高20%，还能同时处理1000个对话。微软自己的“Copilot for Customer Service”已经能帮客服解决80%的基础问题，剩下的复杂问题才转给人类。</p><h3 id="3-内容生成类套路化创作ai比你卷"><a class="markdownIt-Anchor" href="#3-内容生成类套路化创作ai比你卷"></a> 3. <strong>内容生成类：套路化创作，AI比你“卷”</strong></h3><p>比如<strong>作家与作者</strong>（第5位）、<strong>编辑</strong>（第21位）、<strong>广告销售代理</strong>（第25位）——不是说所有作家都会失业，而是**“套路化、模板化的内容”会被AI彻底接管**：比如写“XX产品十大优势”“职场新人必看的5个技巧”，AI能1分钟生成3篇，还能根据用户画像调整风格；再比如编辑的“校对”“排版”工作，AI工具（比如Grammarly、飞书多维表格）已经能做到“零错误”，比人类快5倍。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/f8de67debf9f6428b285bed8a739a2a0.jpg" alt="微软研究院AI高适用性职业Top40（含得分与就业人数）"><br>图1：表格清晰展示了AI高适用性职业的得分与就业规模——比如“口译与笔译员”得分最高，美国就业人数约3.9万；“客户服务代表”就业人数超200万，是受影响最大的群体之一。</p><h2 id="三-哪些职业ai碰不了答案藏在低适用性清单里"><a class="markdownIt-Anchor" href="#三-哪些职业ai碰不了答案藏在低适用性清单里"></a> 三、哪些职业“AI碰不了”？答案藏在“低适用性清单”里</h2><p>微软同时列出了**“AI适用性得分最低的40个职业”**（见图2），这些工作的共性是：<strong>需要“人类的身体能力+实时决策+情感连接”</strong>——</p><ul><li><strong>需要精准操作的：</strong> 比如“抽血医师”（得分最低），要精准找到血管，还要安抚害怕抽血的患者；“危险品清除工”，要根据现场情况判断爆炸风险，AI没有“触觉”和“应急直觉”；</li><li><strong>需要情感互动的：</strong> 比如“急症护理护士”，要在患者昏迷时判断情绪，还要安慰家属；“儿童心理治疗师”，要通过眼神、语气感知孩子的情绪，AI没有“共情能力”；</li><li><strong>需要现场判断的：</strong> 比如“消防员”“建筑工人”，要应对突发的火灾、坍塌，AI无法处理“不可预测的真实场景”。</li></ul><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1458f48a963cb1cdd7ad788d50dc1b0c.jpg" alt="微软研究院AI低适用性职业Top40（含得分与就业人数）"><br>图2：这些职业的核心是“人类的独特能力”——比如“抽血医师”美国就业人数约12万，AI几乎无法替代；“急症护理护士”就业人数超300万，是“AI安全区”的典型。</p><h2 id="四-最该警惕的不是ai替代而是你没跟上ai的节奏"><a class="markdownIt-Anchor" href="#四-最该警惕的不是ai替代而是你没跟上ai的节奏"></a> 四、最该警惕的不是“AI替代”，而是“你没跟上AI的节奏”</h2><p>看到这里，你可能会问：“我的职业在高风险清单里，是不是要失业了？”<br>其实不用慌——<strong>AI替代的是“低附加值任务”，不是“职业本身”</strong>：</p><ul><li>比如“数据科学家”（第29位）：AI能帮你做数据清洗、模型训练，但<strong>解读数据背后的商业逻辑（比如“为什么用户留存率下降”）</strong>，还是需要人类的判断力；</li><li>比如“历史学家”（第2位）：AI能帮你整理史料，但<strong>分析“某场战争对文明的影响”</strong>，还是需要人类的史观和洞察力；</li><li>比如“编辑”（第21位）：AI能帮你校对文字，但<strong>判断“这篇文章能不能火”</strong>，还是需要人类的审美和对用户的理解。</li></ul><h2 id="最后给打工人的3个建议"><a class="markdownIt-Anchor" href="#最后给打工人的3个建议"></a> 最后：给打工人的3个建议</h2><p>微软的研究，本质是给我们敲了个警钟——<strong>未来的职业竞争，不是“人和AI比谁快”，而是“人能不能用AI更快”</strong>：</p><ol><li><strong>先搞清楚自己的“核心任务”</strong>：如果你的工作是“重复、规则、无情感”（比如数据录入、基础客服），赶紧学AI工具（比如用Copilot做数据清洗，用ChatGPT写客服话术），把自己从“执行层”升到“决策层”；</li><li><strong>强化“人类优势”</strong>：如果你的工作需要“创造力、共情力、现场决策”（比如设计师、老师、医生），把精力放在这些AI做不了的事上——比如设计师不用再画基础原型，而是专注于“品牌风格的创新”；</li><li><strong>别信“AI会创造新岗位”的饼</strong>：目前没有证据显示这些高风险职业因AI创造了新岗位，反而微软自己用AI裁了1.5万人——<strong>与其等“新岗位”，不如先把自己的“不可替代性”提上去</strong>。</li></ol><p>AI不是洪水猛兽，它只是一把“效率刀”——<strong>砍向的是“懒于进化的人”，而不是“愿意拥抱变化的人”</strong>。<br>你的职业会不会被AI影响？关键看：你是“用AI干活的人”，还是“被AI干活取代的人”。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI重构职场：微软数据里的40个“高风险”岗位，和你想的不一样</title>
      <link href="/ren-gong-zhi-neng/ai-chong-gou-zhi-chang-wei-ruan-shu-ju-li-de-40-ge-gao-feng-xian-gang-wei-he-ni-xiang-de-bu-yi-yang-3/"/>
      <url>/ren-gong-zhi-neng/ai-chong-gou-zhi-chang-wei-ruan-shu-ju-li-de-40-ge-gao-feng-xian-gang-wei-he-ni-xiang-de-bu-yi-yang-3/</url>
      
        <content type="html"><![CDATA[<p>7月底，微软研究院的一篇论文把“AI会不会抢工作”的讨论从“玄学”拉回了“账本”——他们用三个维度（<strong>覆盖范围</strong>：AI能承担该职业多少任务；<strong>完成度</strong>：AI做这些任务的质量；<strong>范围</strong>：任务的普遍性）算出了“人工智能适用性得分”，直接列出了40个“最可能被AI影响”的职业。当我们盯着这份清单时，比尔·盖茨年初的警告突然变得具体：“AI会摧毁比创造更多的就业岗位”，不是危言耸听，是企业已经在执行的“效率优化逻辑”。</p><h2 id="一-适用性得分不是取代清单是企业的裁员计算器"><a class="markdownIt-Anchor" href="#一-适用性得分不是取代清单是企业的裁员计算器"></a> 一、“适用性得分”不是“取代清单”，是企业的“裁员计算器”</h2><p>先搞懂微软的核心结论：<strong>AI的“适用性”≠直接取代，而是“AI能帮企业省多少人力成本”</strong>。<br>比如，一个客户服务代表的工作，80%是解答“密码找回”“订单查询”这类标准化问题——AI客服能24小时无休做这些，还不会因为客户的抱怨闹情绪。此时，“适用性得分”越高，意味着企业用AI替代人类的“ ROI（投资回报率）”越高。<br>微软自己就是例子：2023年以来，微软因“AI应用”裁了1.5万人，理由很实在——“一个AI能顶两个员工的活，为什么不优化？”</p><h2 id="二-40个高风险岗位三类最容易被ai盯上的工作"><a class="markdownIt-Anchor" href="#二-40个高风险岗位三类最容易被ai盯上的工作"></a> 二、40个高风险岗位：三类最容易被AI“盯上”的工作</h2><p>从《AI高适用性职业表》（图1）看，最可能受影响的职业，本质是**“规则明确、重复性高、不需要‘人味’”**的工作，大致分三类：</p><h3 id="1-语言处理类ai早把文字游戏玩明白了"><a class="markdownIt-Anchor" href="#1-语言处理类ai早把文字游戏玩明白了"></a> 1. 语言处理类：AI早把“文字游戏”玩明白了</h3><p>口译与笔译员、作家与作者、编辑、校对员，这些岗位的核心是“语言转换”或“文本加工”。而大模型（比如GPT-4、Claude 3）早就突破了“能生成”的阶段：</p><ul><li>翻译：能处理“文言文转英文”“专业术语翻译”，甚至能还原方言里的文化梗；</li><li>写作：能根据关键词生成新闻通稿、产品文案，还能模仿特定作家的风格；</li><li>校对：能快速找出语法错误、逻辑漏洞，比人类校对员快3-5倍。</li></ul><p><strong>但别急着慌</strong>：AI能做“基础输出”，但“有温度的创作”（比如深度报道的人物专访、小说的情感共鸣）还是得靠人类——毕竟，AI没经历过“深夜改稿的崩溃”，也写不出“故乡的云”里的乡愁。</p><h3 id="2-服务重复类ai是永不疲倦的工具人"><a class="markdownIt-Anchor" href="#2-服务重复类ai是永不疲倦的工具人"></a> 2. 服务重复类：AI是“永不疲倦的工具人”</h3><p>乘客乘务员、接待员、电话营销员、票务代理，这些岗位的工作内容是“标准化互动”：</p><ul><li>乘务员要引导乘客找座位、解答“卫生间在哪”；</li><li>接待员要说“您好，请问有什么可以帮您”；</li><li>电话营销员要念“请问需要贷款/保险吗”。</li></ul><p>这些工作，AI虚拟助理能做得更“完美”：不会累、不会不耐烦、不会因为乘客的无理要求哭鼻子。比如，某航空公司用AI虚拟乘务员处理机舱咨询，直接减少了30%的人类乘务员排班。</p><h3 id="3-技术辅助类连数据科学家都在清单里"><a class="markdownIt-Anchor" href="#3-技术辅助类连数据科学家都在清单里"></a> 3. 技术辅助类：连“数据科学家”都在清单里？</h3><p>没错，数据科学家、技术文档撰写员、统计助理这些“技术岗”也在高适用性清单里——<strong>不是AI能取代数据科学家，而是能取代“数据科学家的基础工作”</strong>：</p><ul><li>数据清洗：AI能自动处理缺失值、异常值，比人类快10倍；</li><li>技术文档：AI能根据代码自动生成“接口说明”“操作手册”，连格式都不用调；</li><li>统计分析：AI能一键生成柱状图、折线图，还能给出“销量下降的3个原因”。</li></ul><p>换句话说，未来的“数据科学家”，可能不用再熬夜洗数据，而是要专注于“用数据解决业务问题”——比如“为什么这个产品卖不好？”“用户流失的核心原因是什么？”这些需要“商业思维”的工作。</p><h2 id="三-哪些职业不怕ai看低适用性清单的3个共性"><a class="markdownIt-Anchor" href="#三-哪些职业不怕ai看低适用性清单的3个共性"></a> 三、哪些职业“不怕AI”？看低适用性清单的3个共性</h2><p>微软同时列出了《AI低适用性职业表》（图2），比如抽血医师、急症护理护士、危险品清除工、消防队员。这些岗位的共同点，正好是AI的“短板”：</p><h3 id="1-需要身体在场的操作"><a class="markdownIt-Anchor" href="#1-需要身体在场的操作"></a> 1. 需要“身体在场”的操作</h3><p>抽血医师要“摸血管”——机器人的传感器再先进，也不如人类护士能“感知”血管的弹性和位置；<br>木匠要“凿木头”——AI能设计家具，但没法体会“手作的温度”。</p><h3 id="2-实时动态决策"><a class="markdownIt-Anchor" href="#2-实时动态决策"></a> 2. 实时动态决策</h3><p>急症护理护士要处理“病人突然呼吸困难”——AI能给出医嘱，但没法亲手帮病人调整氧气面罩；<br>消防队员要判断“火势会不会蔓延”——AI能分析数据，但没法“直觉”到“这个墙要塌了”。</p><h3 id="3-高风险责任"><a class="markdownIt-Anchor" href="#3-高风险责任"></a> 3. 高风险责任</h3><p>危险品清除工要处理“爆炸物”——一旦操作失误就是人命关天，没有企业敢让AI来担这个责任；<br>法官要判“杀人案”——AI能查法条，但没法体会“被害人家属的痛苦”，也做不出“有温度的判决”。</p><h2 id="四-结论ai不是摧毁者是职业重构者"><a class="markdownIt-Anchor" href="#四-结论ai不是摧毁者是职业重构者"></a> 四、结论：AI不是“摧毁者”，是“职业重构者”</h2><p>看完两份清单，你会发现：<strong>AI从来不是“要取代人类”，而是“要把人类从‘重复性劳动’里解放出来”</strong>。<br>比如：</p><ul><li>口译员：未来可能不是“做翻译”，而是“监督AI翻译的准确性，处理AI搞不定的文化差异”；</li><li>作家：未来可能不是“写初稿”，而是“用AI生成框架，再加入自己的独特观点”；</li><li>数据科学家：未来可能不是“洗数据”，而是“用AI的结果解决业务问题”。</li></ul><p>比尔·盖茨说“AI会摧毁就业”，但更准确的说法是：<strong>AI会淘汰“只会做重复性工作的人”，但会奖励“会用AI放大自己能力的人”</strong>。</p><p>最后问一句：你的工作，是“靠重复赚钱”，还是“靠创造力赚钱”？<br>这，才是AI时代最该想清楚的问题。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/f8de67debf9f6428b285bed8a739a2a0.jpg" alt="AI高适用性职业表"><br>图1：微软研究院列出的“AI高适用性职业表”，包含职位名称、得分及就业人数等维度，直观呈现AI最易影响的岗位。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1458f48a963cb1cdd7ad788d50dc1b0c.jpg" alt="AI低适用性职业表"><br>图2：与高适用性职业形成对比的“AI低适用性职业表”，这些岗位因需要“身体操作”“实时决策”或“高责任”，受AI影响较小。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Claude Code核心架构逆向分析：从闭源黑盒到95%还原的技术解构</title>
      <link href="/ren-gong-zhi-neng/claude-code-he-xin-jia-gou-ni-xiang-fen-xi-cong-bi-yuan-hei-he-dao-95-huan-yuan-de-ji-zhu-jie-gou-3/"/>
      <url>/ren-gong-zhi-neng/claude-code-he-xin-jia-gou-ni-xiang-fen-xi-cong-bi-yuan-hei-he-dao-95-huan-yuan-de-ji-zhu-jie-gou-3/</url>
      
        <content type="html"><![CDATA[<h2 id="引言逆向工程揭示ai编程助手的工程真相"><a class="markdownIt-Anchor" href="#引言逆向工程揭示ai编程助手的工程真相"></a> 引言：逆向工程揭示AI编程助手的工程真相</h2><p>近期，GitHub上一个名为<code>shareAI-lab/analysis_claude_code</code>的项目引发了技术社区的广泛关注。该项目对Anthropic公司的闭源产品Claude Code（v1.0.33）进行了深度逆向工程，成功还原了其95%的核心技术架构。这一突破不仅让我们首次得以窥见这款AI编程助手的内部工作机制，更为理解现代Agent系统的工程实现提供了宝贵的一手资料。</p><p>值得注意的是，项目README明确指出分析结果&quot;非100%准确，分析过程中LLM难免出现幻觉，仅供学习参考&quot;，这提醒我们需以严谨态度对待这些逆向结论。本文将基于该项目公开的研究资料，对Claude Code的技术架构进行系统性解析。</p><h2 id="逆向工程背景与方法论以彼之矛攻彼之盾"><a class="markdownIt-Anchor" href="#逆向工程背景与方法论以彼之矛攻彼之盾"></a> 逆向工程背景与方法论：以彼之矛攻彼之盾</h2><p>Claude Code作为闭源产品，其核心逻辑被封装在约5万行经过混淆处理的JavaScript代码中。这些代码通过变量名替换、控制流打乱、字符串加密等手段隐藏了原始实现逻辑，构成了逆向工程的主要障碍。</p><p>shareAI-lab团队采用了一种颇具创意的&quot;自举式&quot;逆向方法：<strong>使用Claude Code本身分析其混淆后的代码</strong>。具体流程包括：将5万行混淆代码分割为15个chunk文件，利用Claude Code的代码理解能力进行初步解析，再通过人工调试和逻辑补全，最终拼接出系统架构全景。这种&quot;用AI逆向AI&quot;的方法，在处理大规模混淆代码时展现出独特优势。</p><h2 id="claude-code系统架构全景五层分布式agent操作系统"><a class="markdownIt-Anchor" href="#claude-code系统架构全景五层分布式agent操作系统"></a> Claude Code系统架构全景：五层分布式Agent操作系统</h2><p>逆向分析揭示，Claude Code并非简单的代码补全工具，而是一套具备完整调度机制的&quot;本地分布式Agent操作系统&quot;。其架构可分为清晰的五层结构：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4ab76ce2ae104f0702a1417e11000b7f.jpg" alt="系统架构全景图"></p><h3 id="1-用户交互层多入口统一编码"><a class="markdownIt-Anchor" href="#1-用户交互层多入口统一编码"></a> 1. 用户交互层：多入口统一编码</h3><p>最上层是用户交互接口，包括CLI命令行、VSCode插件和Web界面等多种形式。尽管入口不同，所有用户指令最终都会被编码为统一的请求格式，传递给下层的Agent核心调度系统。这一层的核心作用是<strong>屏蔽交互差异，标准化输入输出</strong>，确保不同入口的用户体验一致。</p><h3 id="2-agent核心调度层no主循环引擎的决策中枢"><a class="markdownIt-Anchor" href="#2-agent核心调度层no主循环引擎的决策中枢"></a> 2. Agent核心调度层：nO主循环引擎的决策中枢</h3><p>中间层是整个系统的&quot;大脑&quot;——Agent核心调度层。其核心组件是名为nO的主循环引擎（AgentLoop），负责协调所有智能体行为。根据逆向得到的流程图，nO引擎的工作流程包括：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/a0a4e6f696222dc52250d10478cbfbe4.png" alt="Agent Loop流程图"></p><ul><li>消息预处理与任务识别</li><li>上下文状态评估与压缩判断</li><li>工具需求分析与Agent选择</li><li>并发任务调度与资源分配</li><li>执行结果整合与流式反馈</li></ul><p>值得注意的是，<strong>大语言模型（LLM）在这一层仅作为被调度的工具存在</strong>，而非系统核心。nO引擎通过h2A消息队列（异步传输）和wu会话流生成器（实时输出）实现高效的任务流转，同时由wU2压缩引擎动态优化上下文数据。</p><h3 id="3-工具执行与管理层精细化的agent管控体系"><a class="markdownIt-Anchor" href="#3-工具执行与管理层精细化的agent管控体系"></a> 3. 工具执行与管理层：精细化的Agent管控体系</h3><p>工具执行层体现了Claude Code的&quot;中台&quot;特性，负责具体任务的分发与执行。核心管控组件包括：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6d8a3ffc299db44845f59ce2c90ce504.png" alt="核心组件技术特征表"></p><ul><li><strong>MH1工具引擎</strong>：负责工具发现、参数校验和任务分配</li><li><strong>UH1并发调度器</strong>：限制并发量，防止资源争抢和冲突</li><li><strong>SubAgent管理器</strong>：为每个子任务创建独立Agent实例，实现任务隔离</li><li><strong>权限验证网关</strong>：基于最小权限原则，控制Agent对文件系统、网络等资源的访问</li></ul><p>这种设计确保了任务执行的<strong>安全性、可审计性和故障隔离</strong>，即使某个子Agent出错，也不会影响整个系统的稳定性。</p><h3 id="4-工具生态系统模块化的功能武器库"><a class="markdownIt-Anchor" href="#4-工具生态系统模块化的功能武器库"></a> 4. 工具生态系统：模块化的功能武器库</h3><p>Claude Code的工具生态包含上百个分类明确的功能模块，覆盖文件操作、命令执行、网络搜索、任务管理等多个领域。与传统插件系统不同，这些工具采用<strong>文件级别的结构化配置</strong>，每个工具都是可管理、可审计、可热加载的独立单元。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/510fc92b8ac7aff829946e2787f7c66c.png" alt="工具功能列表"></p><p>工具定义采用.yaml格式，用户可通过添加自定义.yaml文件扩展功能，系统能自动发现并加载新工具，体现了良好的<strong>可扩展性设计</strong>。</p><h3 id="5-存储与持久化系统分层记忆架构"><a class="markdownIt-Anchor" href="#5-存储与持久化系统分层记忆架构"></a> 5. 存储与持久化系统：分层记忆架构</h3><p>存储层是Claude Code&quot;记忆力&quot;的基础，采用三层记忆架构：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/34690d69e0be48a9bce90a55cfecbc3b.jpg" alt="记忆系统架构图"></p><ul><li><strong>当前会话（Messages）</strong>：存储即时交互数据，支持实时对话</li><li><strong>中期摘要（Compressed）</strong>：由wU2压缩器处理的上下文摘要，平衡记忆深度与资源消耗</li><li><strong>永久偏好（<a href="http://CLAUDE.md" target="_blank" rel="noopener">CLAUDE.md</a>）</strong>：记录用户语言偏好、项目结构、常用工具等长期信息</li><li><strong>系统状态（StateCache）</strong>：保存工具调用历史、错误记录、权限状态等系统元数据</li></ul><p>这种分层设计使Claude Code在本地环境下就能构建出&quot;类人记忆&quot;的思维体系，无需依赖云端存储即可维持长时间交互的上下文连贯性。</p><h2 id="核心技术创新从功能实现到工程突破"><a class="markdownIt-Anchor" href="#核心技术创新从功能实现到工程突破"></a> 核心技术创新：从功能实现到工程突破</h2><p>逆向分析揭示，Claude Code的真正价值不在于支持多少功能，而在于其<strong>工程化实现的深度</strong>。其中两个技术创新尤为突出：</p><h3 id="实时steering技术从触发式到引导式的交互升级"><a class="markdownIt-Anchor" href="#实时steering技术从触发式到引导式的交互升级"></a> 实时Steering技术：从&quot;触发式&quot;到&quot;引导式&quot;的交互升级</h3><p>大多数AI工具采用&quot;请求-响应&quot;的触发式交互，用户需等待当前任务完成才能输入新指令。Claude Code则通过h2A消息队列实现了真正的&quot;实时引导&quot;（Steering）能力。其核心是&quot;双缓冲队列+条件触发消费&quot;机制：</p><pre class="highlight"><code class="javascript"><span class="hljs-keyword">class</span> <span class="hljs-title class_">h2AAsyncMessageQueue</span> {    <span class="hljs-title function_">enqueue</span>(<span class="hljs-params">message</span>) {      <span class="hljs-comment">// 策略1: 零延迟路径 - 直接传递给等待的读取者  </span>    <span class="hljs-keyword">if</span> (<span class="hljs-variable language_">this</span>.<span class="hljs-property">readResolve</span>) {        <span class="hljs-variable language_">this</span>.<span class="hljs-title function_">readResolve</span>({ <span class="hljs-attr">done</span>: <span class="hljs-literal">false</span>, <span class="hljs-attr">value</span>: message });        <span class="hljs-variable language_">this</span>.<span class="hljs-property">readResolve</span> = <span class="hljs-literal">null</span>;        <span class="hljs-keyword">return</span>;      }      <span class="hljs-comment">// 策略2: 缓冲路径 - 存储到循环缓冲区  </span>    <span class="hljs-variable language_">this</span>.<span class="hljs-property">primaryBuffer</span>.<span class="hljs-title function_">push</span>(message);      <span class="hljs-variable language_">this</span>.<span class="hljs-title function_">processBackpressure</span>();    }  }  </code></pre><p>这一设计实现了<strong>输入-处理-输出的流水线并行</strong>：当用户输入新指令时，系统无需等待当前输出完成即可开始处理新请求，配合流式写回机制，实现了&quot;边生成、边调整、边响应&quot;的实时交互体验。用户可在任务执行过程中随时&quot;改变方向&quot;，系统能立即响应，大幅提升了交互效率。</p><h3 id="智能上下文压缩基于重要性的动态记忆管理"><a class="markdownIt-Anchor" href="#智能上下文压缩基于重要性的动态记忆管理"></a> 智能上下文压缩：基于重要性的动态记忆管理</h3><p>面对上下文长度限制这一普遍挑战，Claude Code的wU2压缩系统采用了&quot;重要性加权+策略性摘要&quot;的创新方案。其触发逻辑如下：</p><pre class="highlight"><code class="javascript"><span class="hljs-comment">// 压缩触发逻辑  </span><span class="hljs-keyword">if</span> (tokenUsage &gt; <span class="hljs-variable constant_">CONTEXT_THRESHOLD</span> * <span class="hljs-number">0.92</span>) {    <span class="hljs-keyword">const</span> compressedContext = <span class="hljs-keyword">await</span> wU2Compressor.<span class="hljs-title function_">compress</span>({      <span class="hljs-attr">messages</span>: currentContext,      <span class="hljs-attr">preserveRatio</span>: <span class="hljs-number">0.3</span>,      <span class="hljs-attr">importanceScoring</span>: <span class="hljs-literal">true</span>    });  }  </code></pre><p>当token用量达到阈值的92%时，系统启动压缩流程，<strong>仅保留30%的关键内容</strong>，其余部分提炼为摘要。关键差异在于：压缩不以时间或长度为标准，而是通过重要性打分算法，优先保留对当前任务有价值的信息。这使得Claude Code在长时间交互中能维持&quot;记忆重点&quot;，减少因上下文截断导致的&quot;断片&quot;问题。</p><h2 id="逆向启示ai编程助手的发展方向"><a class="markdownIt-Anchor" href="#逆向启示ai编程助手的发展方向"></a> 逆向启示：AI编程助手的发展方向</h2><p>通过对比传统Agent架构与Claude Code的设计，我们可以清晰看到AI编程助手的进化路径：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/76ac9a18c5d269e00da798c64818b662.png" alt="架构对比示意图"></p><p>传统架构往往追求&quot;大而全&quot;的功能集合，而Claude Code展示的是<strong>工程稳定性、安全性和组织能力</strong>的系统级突破。它证明未来的AI编程助手不会是简单的功能叠加，而将发展为具备以下特征的智能操作平台：</p><ol><li><strong>分布式Agent协作</strong>：通过精细的Agent调度和隔离机制，实现复杂任务的并行处理</li><li><strong>动态资源管理</strong>：基于上下文重要性和系统状态，智能分配计算资源</li><li><strong>安全可控执行</strong>：最小权限原则和严格的权限验证，确保操作安全性</li><li><strong>本地优先设计</strong>：通过高效的本地存储和压缩算法，减少对云端的依赖</li></ol><p>值得强调的是，shareAI-lab团队的逆向工程成果（仓库地址：<a href="https://github.com/shareAI-lab/analysis_claude_code%EF%BC%8C%E7%9B%AE%E5%89%8D%E5%A4%84%E4%BA%8E%E5%BD%92%E6%A1%A3%E7%8A%B6%E6%80%81%EF%BC%89%E4%B8%BAAI%E5%B7%A5%E7%A8%8B%E9%A2%86%E5%9F%9F%E6%8F%90%E4%BE%9B%E4%BA%86%E5%AE%9D%E8%B4%B5%E7%9A%84%E7%A0%94%E7%A9%B6%E7%B4%A0%E6%9D%90%EF%BC%8C%E8%AE%A9%E6%88%91%E4%BB%AC%E5%BE%97%E4%BB%A5%E4%B8%80%E7%AA%A5%E9%97%AD%E6%BA%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%E3%80%82" target="_blank" rel="noopener">https://github.com/shareAI-lab/analysis_claude_code，目前处于归档状态）为AI工程领域提供了宝贵的研究素材，让我们得以一窥闭源系统的设计思路。</a></p><h2 id="结论工程厚度决定产品高度"><a class="markdownIt-Anchor" href="#结论工程厚度决定产品高度"></a> 结论：工程厚度决定产品高度</h2><p>Claude Code的逆向分析揭示了一个关键事实：<strong>AI产品的竞争力越来越取决于工程实现的深度，而非单纯的算法创新</strong>。Anthropic通过精巧的Agent调度机制、实时交互优化和上下文管理策略，将大语言模型的能力系统化、工程化，打造出真正可用的AI编程助手。</p><p>这一案例也为AI领域的发展提供了启示：未来的技术竞争将更多聚焦于系统架构设计、资源优化和用户体验的工程实现，而非单一模型的性能指标。对于开发者而言，理解这种工程化思维，比追逐最新模型更为重要。</p><p>正如逆向文档中所暗示的，Claude Code展示的可能只是AI编程助手进化的开始。随着Agent技术的不断成熟，我们有理由期待更智能、更高效、更安全的AI开发工具的出现。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>长半裙+T恤，夏日穿搭的万能公式</title>
      <link href="/ren-gong-zhi-neng/chang-ban-qun-t-xu-xia-ri-chuan-da-de-wan-neng-gong-shi-3/"/>
      <url>/ren-gong-zhi-neng/chang-ban-qun-t-xu-xia-ri-chuan-da-de-wan-neng-gong-shi-3/</url>
      
        <content type="html"><![CDATA[<p>夏天穿得舒服又好看，其实不难。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/9068666cb35c3827549d24c60b1f2d96.jpg" alt="长半裙搭配示范"></p><p>基础款的碰撞，往往最出效果。T恤的随性，长半裙的优雅，刚好平衡。</p><h2 id="直筒裙t恤利落不挑身"><a class="markdownIt-Anchor" href="#直筒裙t恤利落不挑身"></a> 直筒裙+T恤：利落不挑身</h2><p>宽松T恤配直筒裙，藏肉又显瘦。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c2684e15111c80481c83e44482d6154d.jpg" alt="层次感穿搭示范"></p><p>黑白配色自带秩序感。上宽下直的版型，对梨形身材很友好。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/35dd331293a843b96fbf52909fc97cd7.png" alt="素色T恤搭配"></p><p>白色T恤搭浅黄直筒裙，低饱和色调显温柔。长度过膝，遮小腿赘肉。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/adc3110ac1329219c58cf8bb00807712.png" alt="惬意风格穿搭"></p><p>V领T恤+卡其直筒裙，系条细皮带强调腰线。通勤穿得体面，散步也舒服。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2f94fbda7d3cfce60ef3805ded4e65fe.png" alt="红色T恤复古搭"></p><p>红色T恤配黑色直筒裙，明暗对比吸睛。配波点鞋，复古感更浓。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e67ea37d6abac74423cc3d07e999d714.jpg" alt="沉稳气质穿搭"></p><p>全黑look不沉闷。上衣选微宽松款，裙摆垂坠感强，穿出沉稳气场。</p><h2 id="伞裙t恤灵动显比例"><a class="markdownIt-Anchor" href="#伞裙t恤灵动显比例"></a> 伞裙+T恤：灵动显比例</h2><p>伞裙的A字版型，能藏住胯宽和大腿肉。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/9c3805f586aa4899a3706769fd0c853d.jpg" alt="随性T恤搭配"></p><p>白T恤+黑伞裙，经典不出错。把衣角塞进裙子，拉高腰线显腿长。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/7836b7b8322195a608a3d8995414784d.png" alt="T恤伞裙搭配"></p><p>条纹T恤配白色伞裙，横向条纹和伞裙弧度呼应，视觉上更协调。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/3d964b250d563dfc3b7b9ea6e4db7ca6.png" alt="层次搭配示范"></p><p>印花T恤+格纹伞裙，小面积印花配经典格纹，层次丰富不杂乱。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b1d87e6a9d0cec36bac664db7a346909.jpg" alt="格调穿搭示范"></p><p>白T恤+棕色伞裙，同色系鞋包呼应，低调有格调。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/50d3f90a71da22b7a0da52f847f616c2.png" alt="经典格调搭配"></p><p>黑T恤+黑伞裙，加顶草帽增加细节。全身统一色系，显瘦又高级。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/7c8db434d1302a2c3fd2a73eac543ab6.jpg" alt="简约温柔穿搭"></p><p>灰色T恤+米白伞裙，浅色系适合夏天。配人字拖，慵懒感拉满。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4ad0f3a9956ef7f6c1c8e37c07b8fac0.jpg" alt="白色系搭配示范"></p><p>全白look怕单调？搭件浅开衫。伞裙长度到脚踝，显高又温柔。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/760f65ceafd461621c61bdbf1d0cfc47.jpg" alt="清爽层次穿搭"></p><p>粉白条纹T恤+白伞裙，条纹选细款更显瘦。上下色彩呼应，清爽透气。</p><h2 id="印花裙t恤吸睛不张扬"><a class="markdownIt-Anchor" href="#印花裙t恤吸睛不张扬"></a> 印花裙+T恤：吸睛不张扬</h2><p>素色T恤能中和印花裙的繁复，日常穿不夸张。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e447ec91a25f943bc6bd2ad700bfd898.jpg" alt="印花长裙搭配"></p><p>V领白T恤+红色印花裙，红色印花选小图案，配同色包包更协调。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/988f5887ef4bacff8e6e5a0dc7ce9e97.jpg" alt="巧思平衡搭配"></p><p>黑T恤+绿色印花裙，深色上衣压得住鲜艳印花。草编包增加夏日感。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/3e4f47948cc8692b045106f541280453.jpg" alt="时髦印花裙搭"></p><p>白T恤+绿色印花裙，浅色系上衣让印花更突出。适合度假或周末出行。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/5282febc02e4b8219c6390de62852ef2.png" alt="海边吸睛穿搭"></p><p>短款白T恤+红底印花裙，露腰设计显比例。鲜艳色彩适合海边，吸睛不突兀。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c3c9eef1d9576d781d50d011ed771088.jpg" alt="日常感穿搭示范"></p><p>宽松白T恤+彩色印花裙，oversize版型中和印花的热闹。红色小包点睛，不抢眼。</p><p>T恤+长半裙的组合，关键在版型比例和色彩呼应。根据场合选对风格，轻松穿得好看又自在。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>当少林寺方丈聊起AI，硅谷大佬们为什么愿意听？</title>
      <link href="/ren-gong-zhi-neng/dang-shao-lin-si-fang-zhang-liao-qi-ai-huo-gu-da-lao-men-wei-shi-me-yuan-yi-ting-3/"/>
      <url>/ren-gong-zhi-neng/dang-shao-lin-si-fang-zhang-liao-qi-ai-huo-gu-da-lao-men-wei-shi-me-yuan-yi-ting-3/</url>
      
        <content type="html"><![CDATA[<p>你可能刷到过各种&quot;科技大佬禅修&quot;的新闻，但要说把禅修和科技玩出跨界花样的，释永信绝对是个绕不开的人物。这位总被调侃&quot;佛门CEO&quot;的少林寺方丈，从90年代触网到现在玩AI、元宇宙，几乎没错过任何一个科技风口。更有意思的是，硅谷那群科技精英居然还真买他的账——这背后到底是什么逻辑？</p><h3 id="敢当面说ai差点意思的也就他了"><a class="markdownIt-Anchor" href="#敢当面说ai差点意思的也就他了"></a> 敢当面说AI&quot;差点意思&quot;的，也就他了</h3><p>2023年11月，旧金山Meta总部，释永信穿着橙色僧袍站在台上，演讲稿标题是《禅宗遇到AI》。台下坐着的都是硅谷科技圈的大佬，但他开口就来了句&quot;狠话&quot;：“人工智能的数据处理能力确实厉害，但要说觉悟和智慧，还差得远。”</p><p>这话要是换个人说，估计会被科技圈群嘲&quot;不懂技术&quot;。但释永信说完，台下居然没人反驳。毕竟这位方丈可不是第一次和硅谷打交道——早在2014年，他就被谷歌和苹果请去加州总部&quot;交流&quot;。</p><p>在谷歌，资深副总裁Laszlo Bock亲自陪着他体验最新款谷歌眼镜；到了苹果，蒂姆·库克更是放下手头工作，专门陪他聊了一下午。后来流传出一张照片，释永信穿着僧袍手持奖杯，库克戴着黄色围巾站在旁边，两人笑得挺开心。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/22ee5a9d25cd53fd0045fe7718220b5e.jpg" alt="释永信与库克合影"></p><p>为什么硅谷大佬对一个方丈这么&quot;给面子&quot;？答案可能藏在他们自己的办公桌上。乔布斯的办公室你见过吗？几乎空无一物，只有一盏台灯和一个打坐坐垫；库克接掌苹果后，每天雷打不动打坐15分钟；谷歌总部有9个禅修中心，员工可以随时去&quot;清空精神缓存&quot;；扎克伯格早年还专门去印度学禅修。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/26c1aeace260e56b73f5007c44583942.jpg" alt="乔布斯禅修办公室"></p><p>说白了，硅谷科技圈早就把禅修当成一种&quot;思维工具&quot;。而释永信作为禅宗祖庭的&quot;话事人&quot;，自然成了他们眼里的&quot;精神导师&quot;——哪怕这位导师聊的话题已经从佛经变成了AI和元宇宙。</p><h3 id="从电话线到元宇宙少林寺的科技进化史"><a class="markdownIt-Anchor" href="#从电话线到元宇宙少林寺的科技进化史"></a> 从电话线到元宇宙：少林寺的&quot;科技进化史&quot;</h3><p>如果把少林寺比作一家公司，释永信绝对是个&quot;趋势捕捉高手&quot;。他对科技的敏感度，甚至比很多互联网老兵还早。</p><p>1996年，大多数中国人还不知道互联网是啥的时候，释永信在香港接触到网络，回寺就拉了根电话线，注册了少林寺域名（<a href="http://shaolin.org.cn" target="_blank" rel="noopener">shaolin.org.cn</a>）。那时候马云还在到处跑业务，张朝阳刚拿到第一笔风投。</p><p>2005年，TCL捐了24台电脑给少林寺，释永信当场宣布要做&quot;中国第一家数字化寺院&quot;。一年后，在线抄经系统上线；又过几年，《易筋经》《72绝技》这些秘籍被搬到官网，每天点击量超过10万。</p><p>电商火起来的时候，他开了家淘宝店&quot;少林欢喜地&quot;，卖佛珠、禅修垫，年营业额做到2000多万；2021年抖音刚火，他半年就吸粉千万，直播首秀直接带货500万；后来&quot;云烧香&quot;、NFT数字藏品，他一个没落下。</p><p>到了AI和元宇宙时代，他照样跟进。2023年百度文心一言刚发布，少林寺就宣布接入；年底去Meta总部演讲，他还不忘推广少林寺的&quot;数字化成果&quot;——一款叫&quot;少林云&quot;的VR应用，能让全球用户&quot;身临其境&quot;体验少林文化。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/819e7b7ca2c21f9f4546e2bdb3294dfa.jpg" alt="释永信Meta演讲稿"></p><p>演讲结束后没多久，少林寺就和一家科技公司合作开发XR项目，2025年推出的VR大空间体验直接入驻了Meta Quest平台。你看，从电话线到元宇宙，这位方丈确实没错过任何一个科技风口。</p><h3 id="是创新者还是攒局人"><a class="markdownIt-Anchor" href="#是创新者还是攒局人"></a> 是&quot;创新者&quot;还是&quot;攒局人&quot;？</h3><p>有人说释永信是&quot;佛门最懂商业的人&quot;，也有人觉得他是&quot;科技圈最会念经的人&quot;。但如果用互联网圈的话说，他其实是个顶级&quot;资源整合高手&quot;。</p><p>少林寺的科技跨界，本质上是把&quot;千年古刹IP&quot;和&quot;现代科技工具&quot;做了嫁接。比如官网、在线抄经、VR体验这些，技术上没什么创新——随便找个互联网公司都能做。真正值钱的，是&quot;少林寺&quot;这三个字背后的文化影响力。</p><p>就像他去硅谷见库克、谷歌高管，对方愿意接待，不是因为他懂AI算法，而是因为&quot;少林寺&quot;代表着他们向往的东方禅意。这种&quot;错位优势&quot;，让他成了科技圈和传统文化之间的&quot;桥梁&quot;。</p><p>但这里有个关键问题：<strong>资源整合不等于创新</strong>。雷军做汽车是重构供应链，马云做电商是改变交易模式，他们是真的在行业里&quot;动刀子&quot;；而释永信做的，更像是把少林寺这个&quot;超级IP&quot;装进不同的科技&quot;壳子&quot;里——从网站到VR，壳子在变，但内核还是那个千年IP。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e6478ca1d2e877097047d2802541d40c.jpg" alt="释永信体验谷歌眼镜"></p><h3 id="最后聊聊这种跨界有意义吗"><a class="markdownIt-Anchor" href="#最后聊聊这种跨界有意义吗"></a> 最后聊聊：这种跨界有意义吗？</h3><p>客观说，释永信的科技尝试确实让少林寺变得更&quot;年轻&quot;了。现在不少年轻人是通过抖音、VR才知道《易筋经》，这总比让传统文化躺在藏经阁里积灰强。</p><p>但我们也要清醒看到：<strong>真正的科技创新需要技术沉淀，而不是简单的IP+科技的拼接</strong>。就像AI大模型需要算法和数据积累，元宇宙需要硬件和内容生态支撑，这些都不是靠&quot;攒局&quot;就能搞定的。</p><p>或许，释永信给我们的最大启示不是&quot;怎么追风口&quot;，而是&quot;怎么用新工具讲好老故事&quot;。至于是不是&quot;遥遥领先&quot;，可能没那么重要——毕竟，能让千年文化和现代科技坐下来聊聊天，本身就挺有意思的，你觉得呢？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>黄仁勋北京行背后：英伟达眼中的中国AI与机器人革命</title>
      <link href="/ren-gong-zhi-neng/huang-ren-xun-bei-jing-xing-bei-hou-ying-wei-da-yan-zhong-de-zhong-guo-ai-yu-ji-qi-ren-ge-ming-3/"/>
      <url>/ren-gong-zhi-neng/huang-ren-xun-bei-jing-xing-bei-hou-ying-wei-da-yan-zhong-de-zhong-guo-ai-yu-ji-qi-ren-ge-ming-3/</url>
      
        <content type="html"><![CDATA[<p>7月的北京，第三届中国供应链博览会上出现了一个不太一样的身影——英伟达CEO黄仁勋。这位常年以黑色皮衣形象示人的&quot;芯片教父&quot;，第一次换上了唐装，还用中文完成了部分演讲。有意思的是，就在他演讲前一天，英伟达刚拿到向中国销售H20芯片的许可，公司股价也创下新高，市值突破4.1万亿美元。这种&quot;天时地利&quot;的巧合，让这场90分钟的小规模交流会格外值得玩味。</p><p><img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2025%2F0716%2Fd193f958j00szhz50001vd0012v00lvg.jpg&amp;thumbnail=660x2147483647&amp;quality=80&amp;type=jpg" alt="黄仁勋演讲现场"></p><h2 id="中国ai的两层突破从deepseek看模型创新"><a class="markdownIt-Anchor" href="#中国ai的两层突破从deepseek看模型创新"></a> 中国AI的&quot;两层突破&quot;：从DeepSeek看模型创新</h2><p>黄仁勋在交流中反复提到一个观点：AI产业像一座两层楼的建筑。第一层是计算机技术、芯片、网络这些基础设施；第二层则是模型和应用。而中国正在第二层展现出惊人的爆发力。</p><p>“DeepSeek做了件很了不起的事”，他特意点出这家公司，&quot;他们推出的R1是全球首个开源推理模型，这可不是小进步。&quot;作为一个在AI领域摸爬滚打多年的技术人，我太清楚开源意味着什么——这相当于把AI的&quot;发动机图纸&quot;公开，任何企业都能基于此改出自己的产品，甚至直接创业。</p><p>他给出的数据更有意思：中国培养了全球约50%的AI研究人员。&quot;这种人才密度加上激烈的市场竞争，让应用落地速度快得吓人。&quot;他提到阿里、Kimi这些公司时语气明显提高，“你们可能不知道，腾讯微信、抖音的智能推荐、美团的外卖调度，背后都是AI在驱动。”</p><p>但黄仁勋没说的是，这种快速发展也带来了另一个现象：有些公司喜欢把&quot;大模型&quot;当营销标签，实际性能却经不起测试。不过DeepSeek这种开源模式倒是提供了一个新思路——让市场用代码和数据说话，而不是PPT。</p><h2 id="从h20到rtx-pro英伟达的中国特供与技术开放"><a class="markdownIt-Anchor" href="#从h20到rtx-pro英伟达的中国特供与技术开放"></a> 从H20到RTX Pro：英伟达的&quot;中国特供&quot;与技术开放</h2><p>聊到具体产品时，黄仁勋终于正面回应了H20芯片的情况。“H20的定位很明确，就是为大模型训练优化的”，他解释道，“而新的RTX Pro则完全是另一个方向，专门给数字孪生和机器人模拟用的。”</p><p>有意思的是，当被问到CUDA生态是否封闭时，他的回答相当坦诚：&quot;如果有人做了兼容CUDA的平台，没问题；如果应用同时支持我们和其他方案，我完全接受。&quot;这种态度和某些科技巨头的&quot;围墙花园&quot;策略形成了鲜明对比。</p><p>但供应链问题依然是绕不开的坎。“现在有两个未知数”，他难得露出一丝无奈，&quot;一是客户之前取消的订单会不会恢复，需求有没有变；二是重启供应链没那么快。&quot;他半开玩笑地说，“大家都在说’算力焦虑’，我现在的首要任务就是帮大家缓解这个焦虑。”</p><h2 id="雷军的新车与中国电动车在美国买不到是我的遗憾"><a class="markdownIt-Anchor" href="#雷军的新车与中国电动车在美国买不到是我的遗憾"></a> 雷军的新车与中国电动车：“在美国买不到是我的遗憾”</h2><p>说到中国企业，黄仁勋主动提起了小米。“我认识雷军时，他还很年轻——当然，那时候我也年轻”，他笑着回忆，“但从第一天起就能看出，这人肯定能成大事。”</p><p>他对小米新车的评价相当直接：&quot;技术让人印象深刻，设计也漂亮，车载系统绝对是世界一流水平。&quot;说到这里他突然叹了口气，&quot;可惜在美国买不到，这真是个遗憾。&quot;作为Model Y车主，我特别理解这种感受——好产品就该让更多人体验。</p><p>除了小米，他还提到比亚迪和理想：&quot;比亚迪的三电技术不用说，理想那个车内空间简直像带轮子的客厅。&quot;这种基于实际体验的评价，比那些&quot;颠覆行业&quot;的营销话术实在多了。</p><h2 id="ai下一个十年为什么是机器人中国的三大优势"><a class="markdownIt-Anchor" href="#ai下一个十年为什么是机器人中国的三大优势"></a> AI下一个十年：为什么是机器人？中国的三大优势</h2><p>当被问到&quot;下一波AI浪潮是什么&quot;时，黄仁勋给出了毫不犹豫的答案：“机器人。”</p><p>他解释道，未来的机器人不只是执行命令，还要能理解物理世界、自主推理。&quot;想想看，十年后的工厂，会是软件和AI指挥一群机器人协作，生产AI设计的产品。&quot;这个场景让我想起特斯拉的超级工厂，但规模和智能程度显然会再上一个台阶。</p><p>特别提到中国时，他总结了三个独特优势：&quot;首先是AI技术本身就很强；其次是机电一体化能力，也就是把机械和电子结合的本事；最后是全球最大的制造业应用场景。&quot;这三点结合起来，确实是其他国家很难复制的。</p><p>“全球都缺劳动力，自动化程度提高才能更繁荣”，他补充道，&quot;而中国现在刚好站在这个风口上。&quot;作为程序员，我认同这个判断——当算法、硬件和场景三者共振时，往往就是产业变革的开始。</p><h2 id="33年半导体老兵的忠告选一个你深爱的职业"><a class="markdownIt-Anchor" href="#33年半导体老兵的忠告选一个你深爱的职业"></a> 33年半导体老兵的忠告：“选一个你深爱的职业”</h2><p>交流会最后，黄仁勋聊起了自己的职业选择。“我20岁就大学毕业了，提前毕业给了我一个飞跃的机会”，他眼神里闪着光，“英伟达算是最后一代半导体公司，但这没关系——当排头兵有当排头兵的策略，最后一个进场也有自己的策略，关键是保持警觉。”</p><p>他给年轻人的建议很简单：&quot;选一个你深爱的职业，然后把一生都奉献给它。&quot;如果让现在的他回到20岁，“我还是会选计算机科学，可能更偏物理科学，当然，肯定会选AI。”</p><p>这种对技术的纯粹热爱，或许就是英伟达能从游戏芯片公司成长为AI基础设施巨头的核心原因。33年如一日的专注，比任何&quot;颠覆式创新&quot;的口号都更有说服力。</p><p>离场前，有记者问他接下来会不会去其他城市，黄仁勋笑着摆手：&quot;不了，我想念家里的小狗。&quot;这种把&quot;科技大佬&quot;和&quot;铲屎官&quot;身份自然切换的状态，反而比任何演讲都更真实可爱。</p><p>毕竟，真正推动技术进步的，从来都是那些既懂芯片代码，又懂生活温度的人。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI竞赛的隐藏变量：为什么电力可能决定中美技术角力的终局？</title>
      <link href="/ren-gong-zhi-neng/ai-jing-sai-de-yin-cang-bian-liang-wei-shi-me-dian-li-ke-neng-jue-ding-zhong-mei-ji-zhu-jiao-li-de-zhong-ju-3/"/>
      <url>/ren-gong-zhi-neng/ai-jing-sai-de-yin-cang-bian-liang-wei-shi-me-dian-li-ke-neng-jue-ding-zhong-mei-ji-zhu-jiao-li-de-zhong-ju-3/</url>
      
        <content type="html"><![CDATA[<p>作为一个在科技圈摸爬滚打十几年的程序员，我对行业大佬的言论向来保持理性审视——毕竟科技圈的&quot;PPT领先&quot;和&quot;实际落地&quot;往往是两回事。但最近美国富兰克林股票集团首席投资官乔纳森·柯蒂斯的访谈，却让我觉得有点意思。他直言不讳地说：“美国在AI技术上绝对领先中国，但中国的优势在于电力资源比我们多。”</p><p>这话乍听有点反常识，毕竟我们习惯了讨论芯片、算法这些&quot;高大上&quot;的技术指标。但仔细想想，AI发展到今天，电力这个&quot;基础设施&quot;的重要性确实被严重低估了。</p><p><img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2025%2F0728%2F06a841c8j00t03s15002sd200u000ltg00xu00ol.jpg&amp;thumbnail=660x2147483647&amp;quality=80&amp;type=jpg" alt="柯蒂斯采访画面"></p><h2 id="一-美国ai的甜蜜烦恼技术领先但电费爆表"><a class="markdownIt-Anchor" href="#一-美国ai的甜蜜烦恼技术领先但电费爆表"></a> 一、美国AI的&quot;甜蜜烦恼&quot;：技术领先但电费爆表</h2><p>先得承认，柯蒂斯说美国AI技术领先，这不是空话。芯片领域，英伟达H100这种&quot;电老虎&quot;确实是目前AI训练的主力，单卡功耗就高达700瓦——什么概念？相当于同时给7台100瓦的电风扇供电。斯坦福大学2024年的AI报告里有组数据挺震撼：全球AI耗电量已经占了电力总需求的2.3%，美国数据中心的耗电量三年涨了340%。</p><p><img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2025%2F0728%2Fc084a5b6j00t03s16001kd200u000dag028d00zk.jpg&amp;thumbnail=660x2147483647&amp;quality=80&amp;type=jpg" alt="英伟达H100芯片"></p><p>更夸张的是训练成本。训练一个千亿参数的大模型，得用上万张H100并行运算，单次训练的电费就超过400万美元。OpenAI训练GPT-4时用了约1.2万片H100，算下来每小时耗电量相当于50万户家庭的日用电总和。这哪是训练AI，简直是在&quot;烧钱发电&quot;。</p><p>技术领先是事实，但电力跟不上就成了致命短板。美国的电力基础设施有多老？53%的变电站设备已经运行超过30年，70%的输电线路还是上世纪的产物。2023年得州那几次大规模停电还记得吧？英伟达在得州的AI工厂峰值用电直接占了休斯敦市区总负荷的12%，当地电网根本扛不住这种&quot;电老虎&quot;。</p><p><img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2025%2F0728%2F83bb2467j00t03s160049d200u000gwg02s001ka.jpg&amp;thumbnail=660x2147483647&amp;quality=80&amp;type=jpg" alt="美国电力设施"></p><p><img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2025%2F0728%2Fd9def3bdp00t03s15000bd200ac0028g00ac0028.png&amp;thumbnail=660x2147483647&amp;quality=80&amp;type=jpg" alt="渐变波浪分隔图"></p><h2 id="二-中国的电力护城河从特高压到绿电的全链条优势"><a class="markdownIt-Anchor" href="#二-中国的电力护城河从特高压到绿电的全链条优势"></a> 二、中国的&quot;电力护城河&quot;：从特高压到绿电的全链条优势</h2><p>如果说美国的问题是&quot;技术跑太快，基建跟不上&quot;，那中国恰好走了条不同的路——先把&quot;电力高速公路&quot;修好，再让AI技术在上面跑。</p><p>咱们的数据中心就是最好的例子。依托42条特高压线路，甘肃的风电可以99.7%的效率输送到东部的数据中心，这是什么概念？几乎没有损耗。现在中国数据中心的绿电占比已经达到42%，通过&quot;东数西算&quot;工程，在甘肃、内蒙古这些可再生能源丰富的地方建了8大算力枢纽，相当于把AI训练基地直接建在了&quot;发电厂旁边&quot;。</p><p><img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2025%2F0728%2F7a661c42j00t03s160022d200u000gvg02qw01jk.jpg&amp;thumbnail=660x2147483647&amp;quality=80&amp;type=jpg" alt="中国数据中心"></p><p>OpenAI CEO萨姆·奥尔特曼说过一句大实话：&quot;未来十年，谁掌握智能和能源，谁就能在技术竞争中获胜。“这话背后是AI产业的残酷现实——算力需求每3-4个月翻一番，电力需求自然水涨船高。看看这组数据：AWS Rainier算力集群功率0.4GW，Colossus2到2GW，最新的Stargate直接干到4.5GW。没有稳定的电力供应，再先进的算法也只是&quot;纸上谈兵”。</p><p><img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2025%2F0728%2F976c4bc0j00t03s16001ud200u000mdg01nf018a.jpg&amp;thumbnail=660x2147483647&amp;quality=80&amp;type=jpg" alt="奥尔特曼演讲"></p><p><img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2025%2F0728%2F8900bb0cj00t03s16000vd200u000gdg012400ks.jpg&amp;thumbnail=660x2147483647&amp;quality=80&amp;type=jpg" alt="AI设施电力功率"></p><p>中国的优势不止于&quot;有电用&quot;，更在于&quot;用绿电&quot;。2024年风电装机量5.1亿千瓦，全球新增装机40%以上来自中国；光伏产业更夸张，从多晶硅到组件的全产业链，每个环节的国际市场份额都超过75%，电池片甚至常年保持85%以上的占有率。这种从能源生产到传输再到应用的全链条优势，才是真正的&quot;护城河&quot;。</p><p><img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2025%2F0728%2F6ff12fc6j00t03s17003cd200u000jzg00u000jz.jpg&amp;thumbnail=660x2147483647&amp;quality=80&amp;type=jpg" alt="风电建设现场"></p><p><img src="https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2025%2F0728%2F395c7d06j00t03s170057d200u000k0g0325021f.jpg&amp;thumbnail=660x2147483647&amp;quality=80&amp;type=jpg" alt="光伏电站全景"></p><h2 id="三-不是终点而是开始能源与ai的正循环"><a class="markdownIt-Anchor" href="#三-不是终点而是开始能源与ai的正循环"></a> 三、不是终点，而是开始：能源与AI的正循环</h2><p>有人可能会说：&quot;电力多有什么用，AI核心技术不还是在美国手里？&quot;这话有道理，但不全对。</p><p>AI发展到今天，已经不是单点技术突破就能领先的时代了。斯坦福报告预测，到2030年GPU算力集群用电量将占全球总用电量的2.7%。当技术迭代越来越依赖持续的算力投入，稳定且低成本的电力供应就成了&quot;刚需&quot;。中国现在的模式很清晰：用绿电优势支撑AI训练，AI训练又推动能源技术升级（比如智能电网调度、新能源预测算法），形成&quot;电力-AI-电力&quot;的正循环。</p><p>美国不是没想过补基建，只是2万亿美元的升级成本、复杂的利益博弈，让这件事举步维艰。而中国通过特高压、东数西算、新能源布局，已经把&quot;电力优势&quot;转化成了实实在在的产业竞争力。</p><p>当然，这不是说中国AI技术已经超越美国——芯片、基础软件这些硬骨头还得啃。但柯蒂斯的提醒很重要：在AI这场马拉松里，电力可能不是最耀眼的选手，却是决定谁能跑到终点的&quot;关键补给&quot;。未来十年，我们能不能把电力优势真正转化为AI竞争力，还得看技术突破的速度。但至少现在，我们有了一条别人短期内难以复制的&quot;电力赛道&quot;。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实测GLM-4.5：中国AI这次真的把&quot;开源&quot;玩明白了</title>
      <link href="/ren-gong-zhi-neng/shi-ce-glm-4.5-zhong-guo-ai-zhe-ci-zhen-de-ba-kai-yuan-wan-ming-bai-liao-3/"/>
      <url>/ren-gong-zhi-neng/shi-ce-glm-4.5-zhong-guo-ai-zhe-ci-zhen-de-ba-kai-yuan-wan-ming-bai-liao-3/</url>
      
        <content type="html"><![CDATA[<p>昨晚熬夜实测了智谱刚开源的GLM-4.5，说实话，有点被惊到——这可能是今年最接地气的AI大模型了。不是那种PPT上的&quot;即将支持&quot;，也不是需要申请排队的&quot;内测资格&quot;，而是直接把3550亿参数的大模型扔到开源社区，还配了个能直接用的全栈开发工具。作为科技产品深度用户，这种&quot;拿来就能用&quot;的实在感，比那些动辄&quot;颠覆行业&quot;的宣传靠谱多了。</p><h2 id="从一句指令到完整网站ai真的能当全栈工程师"><a class="markdownIt-Anchor" href="#从一句指令到完整网站ai真的能当全栈工程师"></a> 从一句指令到完整网站：AI真的能当全栈工程师？</h2><p>先上干货，直接说测试结果。<a href="http://xn--z-i68a70jj3jpiiv8am10eqk0b.ai" target="_blank" rel="noopener">登录智谱新域名z.ai</a>（2025年4月刚启用的官方平台），选择GLM-4.5模型后，发现多了个带&quot;NEW&quot;标记的&quot;全栈开发&quot;开关，如图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/81f1e3928d1264b07ef3ef375a21ecac.png" alt="全栈开发功能界面"></p><p>抱着&quot;试试看能吹多大牛&quot;的心态，我直接输入了第一个指令：“生成一个谷歌网站。”</p><p>没想到模型立刻回应&quot;脚手架正在搭建&quot;，界面上开始显示加载状态，这反应速度比我想象中快不少：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/85c3b630551c2fdae73206dcac370e1b.png" alt="开发指令响应"></p><p>更有意思的是，它真的像个工程师一样在终端里敲代码——能看到实时生成的文件结构，tsconfig.json、server.ts这些配置文件一个个冒出来，甚至还有代码检查过程：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/254d443736a9b15f3fa06a2429d5ed2f.gif" alt="项目开发终端"></p><p>大概6分钟后，第一个测试结果出来了。打开生成的页面时我有点惊讶——这界面还原度确实高，彩色logo、搜索框、导航链接，和谷歌官网放在一起能以假乱真：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d9f13df6b1637a6d8303074ae2f0285c.png" alt="生成谷歌网站"></p><p>光长得像没用，得看能不能用。我在搜索框输入&quot;GLM-4.5&quot;，居然真的能搜索，结果也能正常打开：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/bd7158a923145e8598cf5880b46a5146.gif" alt="网站搜索测试"></p><p>最关键的是右上角那个&quot;部署&quot;按钮——点击后不到1分钟，系统提示&quot;项目已成功部署并已上线&quot;，还给了个公网链接：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4d90644fafeabbc64820699fccbdbf1d.png" alt="部署成功提示"></p><p>为了进一步测试其复杂场景的开发能力，我尝试输入了更具针对性的指令：“生成一个类似B站的视频网站”。模型依旧迅速响应，开始构建项目架构。从终端可以看到，它不仅生成了基础的页面布局文件，还专门创建了视频播放器组件、弹幕系统模块、用户评论区逻辑以及视频推荐算法的简易实现框架。大约12分钟后，网站生成完成。</p><p>打开页面，熟悉的分区导航栏、轮播推荐位、视频卡片布局一应俱全，甚至连&quot;追番&quot;、&quot;直播&quot;等B站特色板块都做了还原。点击任意视频卡片，能正常进入播放页，播放器支持进度条拖动、音量调节，弹幕会从右侧飘过，还能发送评论互动。虽然推荐算法的精准度还无法与真实B站相比，但核心功能的完整性令人惊叹。</p><p>![生成类似B站的视频网站]（图片稍后补充）</p><p>我还测试了一个更偏向交互体验的需求：“创建一个网页，上面有一只会跟随鼠标的动画小猫”。这次响应速度更快，仅用3分钟就完成了开发。页面背景是简约的淡蓝色，中央有一只像素风格的小猫动画，当鼠标在页面上移动时，小猫会迈着小碎步同步跟随，点击鼠标时还会做出跳跃动作并发出&quot;喵~&quot;的音效。</p><p>查看生成的代码可以发现，模型使用了JavaScript的鼠标事件监听API，结合CSS动画实现了跟随效果，还通过Canvas绘制了小猫的动态帧。整个交互流畅无卡顿，细节处理超出预期，比如小猫移动到页面边缘时会自动调整朝向，避免出现&quot;穿墙&quot;的违和感。</p><p>![会跟随鼠标的动画小猫网页]（图片稍后补充）</p><p>出于好奇，我又试了几个更复杂的需求：“生成带推荐算法的YouTube克隆”、“ChatGPT网页版”、“童年采蘑菇小游戏”。结果是——全！部！生！成！了！而且都是一句话输入，等待几分钟就能得到可运行的成品。这种&quot;所想即所得&quot;的体验，确实刷新了我对当前AI能力的认知。</p><h2 id="3550亿参数的性价比之王数据不会说谎"><a class="markdownIt-Anchor" href="#3550亿参数的性价比之王数据不会说谎"></a> 3550亿参数的&quot;性价比之王&quot;：数据不会说谎</h2><p>抛开实际体验，咱们来看看硬数据。GLM-4.5这次有两个版本：355B总参数的旗舰版和106B的Air版，官方用Claude Code工具测试的结果很能打：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/f508f32d7a875eeebc5beace71fa7761.jpg" alt="LLM性能对比"></p><p>12个权威榜单平均分全球第三，国产第一，这个成绩在开源模型里绝对是第一梯队。特别值得注意的是它的&quot;激活参数&quot;只有32B——简单说就是用更小的计算资源实现了接近大模型的性能，这意味着普通开发者不需要顶级显卡也能跑起来。</p><p>价格方面更是诚意满满：输入0.8元/百万tokens，输出2元/百万token。对比一下GPT-4的API价格（输入1.5美元/百万tokens，输出6美元/百万tokens），这个成本优势太明显了。对中小团队来说，这几乎是&quot;用得起&quot;和&quot;用不起&quot;的区别。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e7fe9ef595cf3b12f86bf5e6696b1288.png" alt="GLM-4.5发布信息"></p><p>最难得的是它采用MIT协议开源——这是最宽松的开源协议之一，意味着开发者可以自由使用，甚至商用，不需要共享修改后的代码。这种开放程度，在之前的大模型里很少见。</p><h2 id="中国ai的开源盛夏半个月内五大模型集体开源"><a class="markdownIt-Anchor" href="#中国ai的开源盛夏半个月内五大模型集体开源"></a> 中国AI的&quot;开源盛夏&quot;：半个月内五大模型集体开源</h2><p>GLM-4.5不是孤军奋战，如果你关注AI圈就会发现，2025年7月简直是中国AI的&quot;开源月&quot;：</p><p>7月11日，Kimi开源K2模型<br>7月26日，千问放出235B推理版+代码模型，上下文窗口直接拉到256K<br>7月27日，阿里开源视频模型通义万相Wan2.2<br>同一天，腾讯甩出3D世界模型，能直接把2D图片转3D场景<br>7月28日，智谱GLM-4.5登场</p><p>这波密集开源直接改变了全球AI格局。最新的全球AI模型排名里，中国模型已经占据四席，而且全是开源免费的：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4f82bb47201c84ae1e81c574be270905.png" alt="AI模型全球排名"></p><p>对比之下，美国前十的六个模型全是闭源收费。这种差异很有意思——当OpenAI还在说&quot;未来可能考虑开源&quot;时，中国团队已经把代码仓库地址直接甩出来了。</p><p>更重要的是这些模型&quot;能用&quot;。不是那种需要申请、排队、填问卷的&quot;试用版&quot;，而是直接给网址、给API、给代码，注册就能用，下载就能跑。我特意试了腾讯那个3D模型，上传一张场景图，几十秒就能生成可交互的3D环境，效果还不错：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b8e62527df13835f7507ac1282ca5d39.jpg" alt="3D游戏示例"></p><h2 id="开源不是慈善是更聪明的竞争策略"><a class="markdownIt-Anchor" href="#开源不是慈善是更聪明的竞争策略"></a> 开源不是慈善，是更聪明的竞争策略</h2><p>有人可能会问：这么强的模型免费开源，公司不赚钱吗？其实开源从来不是慈善，而是一种更聪明的技术扩散策略。</p><p>想想Linux的故事——当初微软视窗系统收费且闭源，而Linux选择开源，结果呢？现在从服务器到手机（Android基于Linux内核），Linux无处不在。技术的生命力在于使用，而开源是让技术快速被使用、被改进的最好方式。</p><p>对AI来说更是如此。大模型的进化需要海量数据和场景反馈，开源让全球开发者帮你找bug、优化性能、拓展应用场景，这比关起门来自己研发效率高多了。而且开源不等于免费送钱——基础模型免费，定制化服务、企业版支持、API调用这些都可以赚钱，形成&quot;免费基础层+付费服务层&quot;的商业模式。</p><p>更重要的是，开源打破了技术垄断。当中小开发者、初创公司都能用得起顶级AI模型时，整个行业的创新速度会被极大加快。付不起GPT-5费用的印度码农，资源有限的非洲创业者，现在都能通过中国开源模型打造自己的产品——这种技术普惠，才是真正推动AI进步的力量。</p><h2 id="写在最后技术进步该有的样子"><a class="markdownIt-Anchor" href="#写在最后技术进步该有的样子"></a> 写在最后：技术进步该有的样子</h2><p>测试完GLM-4.5的那个晚上，我突然想起第一次用Linux的场景——当时对着命令行发呆，完全想不到这个免费系统后来会改变世界。现在的AI开源浪潮，或许正在重演类似的故事。</p><p>作为普通用户，我们可能记不住那些参数表上的数字，分不清355B和235B有什么区别，但我们能感受到&quot;一句话生成网站&quot;的便利，能体会到&quot;无需高端设备就能跑大模型&quot;的实在。这种让技术落地、让普通人能用得上的进步，比任何&quot;颠覆行业&quot;的口号都有说服力。</p><p>或许这就是中国AI开源浪潮最有价值的地方——不是为了争全球第一，也不是为了炒作概念，而是踏踏实实地把技术变成工具，交到每个需要它的人手里。当技术走出实验室，走进普通人的工作流，AI才真正开始改变世界。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实测GLM-4.5：当国产AI开始帮你写代码部署网站，开源真的改变了游戏规则</title>
      <link href="/ren-gong-zhi-neng/shi-ce-glm-4.5-dang-guo-chan-ai-kai-shi-bang-ni-xie-dai-ma-bu-shu-wang-zhan-kai-yuan-zhen-de-gai-bian-liao-you-xi-gui-ze-3/"/>
      <url>/ren-gong-zhi-neng/shi-ce-glm-4.5-dang-guo-chan-ai-kai-shi-bang-ni-xie-dai-ma-bu-shu-wang-zhan-kai-yuan-zhen-de-gai-bian-liao-you-xi-gui-ze-3/</url>
      
        <content type="html"><![CDATA[<p>最近一个月，国内AI圈跟约好了似的，开源模型一个接一个往外冒。从Kimi K2到千问235B，再到腾讯的3D世界模型，热闹得不行。而7月28号智谱突然甩出的GLM-4.5，直接把这波开源潮推向了新高度——MIT协议完全开源，3550亿参数规模，还带了个让人眼前一亮的&quot;全栈开发&quot;功能。</p><p>作为常年跟代码打交道的科技用户，我对这种&quot;一句话生成网站&quot;的宣传向来持怀疑态度。毕竟这年头，AI发布会吹的牛和实际能用的功能，往往差着好几个PPT的距离。但这次GLM-4.5的实测结果，确实让我有点意外。</p><h2 id="先看硬数据355b参数的开源怪兽"><a class="markdownIt-Anchor" href="#先看硬数据355b参数的开源怪兽"></a> 先看硬数据：355B参数的开源怪兽</h2><p>智谱这次公布的GLM-4.5有两个版本：355B总参数的旗舰版和106B的Air轻量版。重点是这个355B版本，在保持开源的同时，官方测试显示它在12个权威榜单上的平均分已经冲到了全球第三，国产第一。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e7fe9ef595cf3b12f86bf5e6696b1288.png" alt="GLM-4.5发布信息"></p><p>从性能对比图能看出来，GLM-4.5在推理、代码和智能体综合能力上已经摸到了开源模型的天花板。特别是编码能力，虽然比Claude 4 Sonnet稍弱一点，但已经稳稳超过了Kimi K2和Qwen3 Coder。对开发者来说，这可是个实打实的好消息。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/f508f32d7a875eeebc5beace71fa7761.jpg" alt="LLM性能对比"></p><p>更关键的是价格。GLM-4.5的API定价相当亲民：输入0.8元/百万tokens，输出2元/百万tokens。对比GPT-4动辄几十元的价格，这个成本对中小开发者来说几乎是&quot;白嫖&quot;级别了。</p><h2 id="实测全栈开发一句话真能生成谷歌网站"><a class="markdownIt-Anchor" href="#实测全栈开发一句话真能生成谷歌网站"></a> 实测全栈开发：一句话真能生成谷歌网站？</h2><p>光看参数和跑分没意思，咱们直接上手试了试那个被标为&quot;NEW&quot;的&quot;全栈开发&quot;功能。登录z.ai官网，选择GLM-4.5模型后，界面上就能看到这个功能开关，打开后直接在对话框里下指令就行。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/81f1e3928d1264b07ef3ef375a21ecac.png" alt="全栈开发功能界面"></p><p>我先试了个简单的：“生成一个谷歌网站。”</p><p>模型秒回&quot;脚手架正在搭建&quot;，然后就开始显示加载状态。这时候能感觉到它不是简单地生成静态页面，而是真的在像工程师一样规划开发步骤。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/85c3b630551c2fdae73206dcac370e1b.png" alt="开发指令响应"></p><p>终端界面里能清晰看到它在创建项目文件结构：tsconfig.json、server.ts这些后端配置文件都有，不是随便糊弄的前端页面。整个过程大概持续了6分钟左右，比我预想的快不少。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/254d443736a9b15f3fa06a2429d5ed2f.gif" alt="项目开发终端"></p><p>结果出来时我确实有点惊讶——这界面跟谷歌官网几乎一模一样，彩色logo、搜索框、导航链接，连布局细节都还原得很到位。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/d9f13df6b1637a6d8303074ae2f0285c.png" alt="生成谷歌网站"></p><p>更重要的是它真的能用。我在搜索框输入&quot;GLM-4.5&quot;，居然真的能返回搜索结果，点击链接也能正常打开。右上角还有部署按钮，点一下就能生成公网可访问的链接，这个体验确实超出预期。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/bd7158a923145e8598cf5880b46a5146.gif" alt="网站搜索测试"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4d90644fafeabbc64820699fccbdbf1d.png" alt="部署成功提示"></p><p>后来又试了几个更复杂的需求：带推荐算法的YouTube克隆、ChatGPT网页版、HTML5采蘑菇小游戏，居然都成功了。特别是那个3D互动游戏，虽然画面简单，但角色移动、碰撞检测这些基本功能都实现了，直接用浏览器就能玩。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b8e62527df13835f7507ac1282ca5d39.jpg" alt="3D游戏示例"></p><h2 id="全球ai格局中国开源vs美国闭源"><a class="markdownIt-Anchor" href="#全球ai格局中国开源vs美国闭源"></a> 全球AI格局：中国开源VS美国闭源</h2><p>GLM-4.5出来前，全球AI模型排名前十里已经有3个是中国的开源模型。现在加上GLM-4.5，这个格局可能会更有意思。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4f82bb47201c84ae1e81c574be270905.png" alt="AI模型全球排名"></p><p>对比一下很明显：前十名里，6个美国模型全部闭源收费，4个中国模型全部开源免费。这种差异在2025年变得越来越清晰——当OpenAI还在用&quot;未来会开源&quot;画饼时，国内AI公司已经把代码直接甩到了开发者面前。</p><p>最近这波开源潮尤其密集：</p><ul><li>7月11日：Kimi开源K2</li><li>7月26日：千问发布235B推理版+代码模型</li><li>7月27日：阿里开源视频模型通义万相Wan2.2</li><li>7月27日：腾讯推出3D世界模型</li><li>7月28日：智谱开源GLM-4.5</li></ul><p>这些模型不是实验室里的Demo，而是立等可用的工具。这可能就是中国AI最聪明的地方——用开源打破技术垄断，让全球开发者都能参与进来。</p><h2 id="开源的意义让ai真正走进普通人"><a class="markdownIt-Anchor" href="#开源的意义让ai真正走进普通人"></a> 开源的意义：让AI真正走进普通人</h2><p>作为特斯拉车主，我一直觉得好的技术应该像电动车普及一样，是让所有人都能用得上，而不是少数人的特权。GLM-4.5这类开源模型正在做类似的事情——付不起GPT-5订阅费的印度码农，没有Claude访问权限的拉美创业者，现在都能靠这些开源工具打造自己的产品。</p><p>从活字印刷打破知识垄断，到Linux系统颠覆软件生态，历史上每次技术革命本质上都是让工具变得更普及。中国AI这波开源浪潮，或许正在改写全球AI的权力格局。</p><p>当然，我们也没必要盲目乐观。开源不代表无敌，闭源也不是原罪。但至少现在，当国外还在讨论&quot;AI该不该开源&quot;时，中国团队已经用代码给出了答案——真正的技术进步，从来不是让少数人用上更贵的工具，而是让所有人都能享受到科技带来的便利。</p><p>看着这些能直接上手的开源模型，突然觉得2025年这个夏天，可能真的是AI普及的转折点。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>这两个国产AI模型真的让我改观了：开源不是噱头，实力才是硬道理</title>
      <link href="/ren-gong-zhi-neng/zhe-liang-ge-guo-chan-ai-mo-xing-zhen-de-rang-wo-gai-guan-liao-kai-yuan-bu-shi-jue-tou-shi-li-cai-shi-ying-dao-li-3/"/>
      <url>/ren-gong-zhi-neng/zhe-liang-ge-guo-chan-ai-mo-xing-zhen-de-rang-wo-gai-guan-liao-kai-yuan-bu-shi-jue-tou-shi-li-cai-shi-ying-dao-li-3/</url>
      
        <content type="html"><![CDATA[<p>最近试了两个刚开源的国产AI模型，说实话，有点颠覆我对&quot;国产AI&quot;的刻板印象。不是那种发布会PPT上吹得天花乱坠，实际用起来拉胯的货色，这两个是真能打的。</p><h2 id="先说glm-45agent模型里的务实派"><a class="markdownIt-Anchor" href="#先说glm-45agent模型里的务实派"></a> 先说GLM-4.5：Agent模型里的务实派</h2><p>第一个是GLM-4.5系列，上周刚开源的时候我就跑去z.ai体验了。最让我意外的不是它&quot;全球第三、国产第一&quot;的排名（这个榜单我查了，确实是第三方实测的结果），而是它作为Agent基座模型的实用性。</p><p>简单说，Agent模型就是让AI能帮你处理实际任务的那种。我拿它试了个Python脚本调试，之前用别的模型经常要来回改三四次，这次给的方案直接跑通了，代码逻辑比我自己写的还清爽。这种&quot;拿来就能用&quot;的感觉，比那些只会说漂亮话的模型实在多了。</p><p>参数规模3550亿，但有意思的是只有320亿是活跃的——相当于大脑体积很大，但日常工作只用一部分，既保证了性能又控制了资源消耗。这种设计思路挺聪明的，不是一味堆参数。</p><p>它那个&quot;混合推理模式&quot;值得一说：遇到复杂问题会进入&quot;深度思考&quot;状态，简单问题就秒回。我故意问了个&quot;1+1等于几&quot;，它0.3秒就答了，接着问&quot;怎么用Python爬取动态网页数据&quot;，它会先列出需要考虑的反爬机制、渲染方式，再给代码示例。这种&quot;该快则快，该慢则慢&quot;的节奏，用起来很舒服。</p><p>最关键的是MIT许可证，完全开源，商用也没问题。这在现在AI模型要么闭源收费，要么开源但藏着掖着的环境下，确实难得。</p><h2 id="再看wan-22视频生成终于不一眼假了"><a class="markdownIt-Anchor" href="#再看wan-22视频生成终于不一眼假了"></a> 再看Wan 2.2：视频生成终于不&quot;一眼假&quot;了</h2><p>第二个更让我惊喜，Wan 2.2视频模型。我之前对AI生成视频的印象还停留在&quot;人物动作僵硬，背景疯狂闪烁&quot;的阶段，这个模型确实有点东西。</p><p>它自称&quot;电影级视觉&quot;，实际试下来，光影过渡和色彩还原真的比我用过的其他模型好一截。我拿家里的猫咪照片试了下图生视频，猫咪甩尾巴的动作居然不卡顿，连毛发的动态都挺自然。之前用某国外模型，生成的猫尾巴经常&quot;量子波动&quot;，看着像果冻。</p><p>技术上它是全球首个MoE扩散视频模型，简单解释就是两个&quot;专家&quot;分工合作：高噪专家负责整体画面布局，低噪专家处理细节。这种分工有点像拍电影时导演和摄影师的配合，一个管整体，一个管细节。</p><p>参数有14B和5B两个版本，我用消费级显卡跑5B版本居然能跑起来（当然渲染4K视频还是有点吃力）。官方说用了16×16×4 VAE压缩技术，通俗讲就是在保证画质的同时减小了计算量。这点对普通用户太重要了，毕竟不是人人都有专业工作站。</p><p>数据上也能看出诚意：图像数据增了65%，视频数据增了83%，还专门做了美学强化训练。这些不是空话，生成的视频构图确实比同类产品讲究，不会出现&quot;主体歪到天边&quot;这种低级错误。</p><h2 id="一个值得琢磨的对比国外涨价国内开源"><a class="markdownIt-Anchor" href="#一个值得琢磨的对比国外涨价国内开源"></a> 一个值得琢磨的对比：国外涨价，国内开源</h2><p>试完这两个模型，我翻了翻最近的AI行业动态，发现个有意思的现象：OpenAI、Anthropic这些国外巨头都在悄悄涨价，GPT-4 Turbo的API价格涨了快30%，Claude Pro直接涨到20美元/月。</p><p>国内这边却反着来：GLM-4.5开源，Wan 2.2开源，阿里的Qwen系列也开源，连字节的豆包都在降价。这种策略差异挺耐人寻味的——国外想用技术垄断维持高利润，国内似乎想用开源和低价快速扩大技术影响力。</p><p>当然，开源不代表技术不行。GLM-4.5能排到全球第三，Wan 2.2敢称&quot;全球首个MoE视频模型&quot;，都是有实打实的技术指标支撑的。这种&quot;用技术说话，靠产品立足&quot;的路线，比单纯喊&quot;国产之光&quot;的口号靠谱多了。</p><h2 id="ai到底该怎么融入生活"><a class="markdownIt-Anchor" href="#ai到底该怎么融入生活"></a> AI到底该怎么融入生活？</h2><p>这两个模型让我重新思考一个问题：我们到底需要什么样的AI？</p><p>我用AI的频率不低，写代码查文档、整理工作周报、甚至周末做饭前查菜谱搭配，都会用到。但说实话，大部分AI给我的感觉还是&quot;工具&quot;，没到&quot;助手&quot;的级别。GLM-4.5让我看到了&quot;助手&quot;的潜力——它能理解复杂任务，还能给出可落地的方案，而不是泛泛而谈。</p><p>至于那些担心AI抢工作的朋友，我的实际体验是：AI淘汰的不是&quot;人&quot;，而是&quot;不会用工具的人&quot;。就像当年Excel没淘汰会计，淘汰的是只会手工记账的会计；相机没淘汰摄影师，淘汰的是不会构图调光的业余爱好者。</p><h2 id="最后说句实在话"><a class="markdownIt-Anchor" href="#最后说句实在话"></a> 最后说句实在话</h2><p>作为用了四年特斯拉、每天跟各种科技产品打交道的人，我对&quot;国产科技&quot;一直保持观望——不是不支持，是见过太多&quot;PPT产品&quot;和&quot;营销大于实质&quot;的案例。</p><p>但这两个AI模型，GLM-4.5和Wan 2.2，确实让我看到了不一样的东西：扎实的技术积累，不浮夸的产品定位，还有敢于开源的底气。这可能才是国产科技该有的样子——少点口号，多点实在，用产品说话，而不是用情怀绑架。</p><p>AI时代已经来了，不管你愿不愿意，它都会渗透到工作生活的各个角落。与其焦虑被淘汰，不如花点时间试试这些新工具——至少这两个，真的能帮你提高效率，而不是浪费时间。</p><p>（对了，如果你想试试，GLM-4.5可以去z.ai体验，Wan 2.2官网有在线生成入口，不用搭环境也能玩。）</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实测GLM-4.5：国产大模型这次真的把&quot;参数效率&quot;玩明白了？</title>
      <link href="/ren-gong-zhi-neng/shi-ce-glm-4.5-guo-chan-da-mo-xing-zhe-ci-zhen-de-ba-can-shu-xiao-lu-wan-ming-bai-liao-3/"/>
      <url>/ren-gong-zhi-neng/shi-ce-glm-4.5-guo-chan-da-mo-xing-zhe-ci-zhen-de-ba-can-shu-xiao-lu-wan-ming-bai-liao-3/</url>
      
        <content type="html"><![CDATA[<p>作为一个每天都在跟各种AI模型打交道的科技爱好者，最近试了不少新出的大模型，发现一个挺有意思的现象：很多厂商还在拼参数规模，动不动就&quot;万亿参数&quot;起步，但实际用起来却未必顺手。直到我上手体验了智谱刚发布的GLM-4.5，才算明白什么叫&quot;参数不在多，够用则灵&quot;。</p><h3 id="先看核心数据全球第三的综合实力"><a class="markdownIt-Anchor" href="#先看核心数据全球第三的综合实力"></a> 先看核心数据：全球第三的综合实力</h3><p>衡量一个大模型到底行不行，还是得看硬数据。GLM-4.5在12个主流评测基准上的综合得分为63.2分，这个成绩在全球所有模型里排第三，在国产模型和开源模型里都是第一。有意思的是，它的总参数量是3550亿（激活参数320亿），比DeepSeek-R1少一半，比Kimi-K2更是只有三分之一，但性能反而更优。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/022acd99fbafcf40695e002f96322fa8.png" alt="综合性能对比"></p><p>拆开来看专项能力更能说明问题。在Agentic（智能体）、Reasoning（推理）和Coding（代码）这三个关键维度，GLM-4.5表现都很均衡，没有明显短板。现在做AI应用开发，最怕模型&quot;偏科&quot;——要么只会写代码不会推理，要么推理强但工具调用一塌糊涂，而GLM-4.5这种全面发展的特性，其实更符合实际开发需求。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/5f21ff61907b3b5c04e0016997cbfa21.png" alt="专项能力对比"></p><h3 id="参数效率才是真本事小身材大能量"><a class="markdownIt-Anchor" href="#参数效率才是真本事小身材大能量"></a> 参数效率才是真本事：小身材大能量</h3><p>我一直觉得，衡量大模型技术水平的关键指标不是&quot;参数总量&quot;，而是&quot;参数效率&quot;——用多少参数实现了多少性能。GLM-4.5在这方面确实让人眼前一亮。在SWE-bench代码能力评测里，它的性能/参数比直接跑到了帕累托前沿，简单说就是：相同参数规模下它性能最好，相同性能下它参数最少。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/9bac8c13b2a92c03a04e6ed6922a615c.png" alt="参数效率对比"></p><p>为什么能做到这一点？看训练数据就知道，它先是在15万亿token的通用数据上打底，又针对性用了8万亿token的代码、推理、智能体数据做微调，最后还用强化学习优化。这种&quot;广撒网+精耕细作&quot;的训练策略，比单纯堆参数要聪明得多。</p><h3 id="速度和成本开发者最关心的两个硬指标"><a class="markdownIt-Anchor" href="#速度和成本开发者最关心的两个硬指标"></a> 速度和成本：开发者最关心的两个硬指标</h3><p>对开发者来说，性能再好，跑不快、用不起也是白搭。GLM-4.5这次在速度上确实下了功夫，高速版能跑到100 tokens/秒，什么概念？相当于你刚打完一段话，模型已经生成了两三百字的回复，这种交互体验跟卡顿的模型完全不是一个级别。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/141526ad76ee7a6860860cccc9d6958f.jpg" alt="生成速度对比"></p><p>成本方面更有惊喜。API价格输入只要0.8元/百万tokens，输出2元/百万tokens，对比一下同类模型，这个价格几乎是地板价了。特别是GLM-4.5-Air这个轻量版，参数规模小一些，但价格更低，对中小开发者和测试场景太友好了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/9287a9aae56fa21ce5dfecf679213130.jpg" alt="价格对比表"></p><h3 id="真实开发场景代码智能体能力实测"><a class="markdownIt-Anchor" href="#真实开发场景代码智能体能力实测"></a> 真实开发场景：代码智能体能力实测</h3><p>跑分好看是一回事，实际干活怎么样才重要。官方做了个挺有意思的测试：在52个真实开发任务里，让GLM-4.5跟Qwen3-Coder、Kimi-K2这些热门模型正面刚，结果GLM-4.5对Qwen3-Coder的胜率达到80.8%，在工具调用可靠性和任务完成度上优势明显。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c57b2d1b61913c317f9f359580ab8c7c.jpg" alt="开发能力对比"></p><p>我自己试了让它从零写个简单的搜索引擎，没想到它不仅生成了前端界面，还自动对接了搜索接口，输入关键词真的能返回结果。这种从&quot;理解需求&quot;到&quot;实现功能&quot;的端到端能力，比那些需要人类一步步拆解任务的模型强太多了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1c4e875c492b54339efca4df2e6cfc96.jpg" alt="谷歌搜索界面"></p><p>类似的还有B站风格的视频网站Demo，不仅能播放视频，还支持发弹幕、切换清晰度，交互逻辑完全闭环。最惊讶的是Flappy Bird游戏，从物理引擎到碰撞检测再到计分系统，一个AI模型从零开始独立完成，这放在半年前简直不敢想。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/406ece3fe817c267ebdcd63949f91e87.jpg" alt="B站风格Demo"><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/8d24db4c5d90a2d44daf9c0282963258.jpg" alt="Flappy Bird游戏"></p><h3 id="一点思考大模型的性价比时代来了"><a class="markdownIt-Anchor" href="#一点思考大模型的性价比时代来了"></a> 一点思考：大模型的&quot;性价比&quot;时代来了？</h3><p>体验下来，GLM-4.5最让我感慨的不是&quot;国产第一&quot;这个头衔，而是它展现出的技术路线——不再盲目追求参数规模，而是在效率、速度、成本上下功夫。这种思路其实更符合AI技术落地的实际需求：企业需要能用得起的模型，开发者需要能快速迭代的工具，用户需要流畅的交互体验。</p><p>当然，它也不是完美的，比如跟Claude-4-Sonnet比还有提升空间，但作为开源模型，能做到这个水平已经超出预期。现在模型权重已经在Hugging Face和ModelScope开放，MIT许可证意味着商用也没问题，感兴趣的开发者真的可以上手试试。</p><p>最后想说，衡量一个AI模型的价值，从来不是看它发布会多热闹，而是看它能不能实实在在解决问题。GLM-4.5这次用数据证明：好的大模型，应该是聪明的（性能强）、高效的（参数省）、快速的（响应快）、便宜的（成本低）——这或许就是下一代大模型的核心竞争力。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实测Claude Code一个月后，我发现这才是AI编程的正确打开方式</title>
      <link href="/ren-gong-zhi-neng/shi-ce-claude-code-yi-ge-yue-hou-wo-fa-xian-zhe-cai-shi-ai-bian-cheng-de-zheng-que-da-kai-fang-shi-3/"/>
      <url>/ren-gong-zhi-neng/shi-ce-claude-code-yi-ge-yue-hou-wo-fa-xian-zhe-cai-shi-ai-bian-cheng-de-zheng-que-da-kai-fang-shi-3/</url>
      
        <content type="html"><![CDATA[<p>作为一个写了十几年代码的老程序员，最近被Claude Code彻底颠覆了认知——这玩意儿真不是简单的代码生成工具，而是能独立完成整个系统的AI开发伙伴。</p><p>上周我让它从零开始写一个用户行为分析系统，原本以为需要三天时间手动调试，结果它直接生成了完整代码库，包含数据采集、清洗、可视化全流程，甚至还自带单元测试。最让我惊讶的是，它居然主动引入了Context7工具来管理项目上下文，避免了传统AI编程&quot;失忆&quot;的问题。</p><p>今天就来分享下我这一个月的深度使用经验，从基础安装到进阶技巧，帮你真正把Claude Code用出生产力。</p><h2 id="一-官方原版体验为什么说这才是性能天花板"><a class="markdownIt-Anchor" href="#一-官方原版体验为什么说这才是性能天花板"></a> 一、官方原版体验：为什么说这才是&quot;性能天花板&quot;</h2><p>第一次用Claude Code时，我是抱着怀疑态度的——毕竟市面上吹上天的AI编程工具太多了。但当我用Max订阅+Opus模型跑通第一个微服务时，不得不承认：这性能确实没对手。</p><h3 id="安装其实很简单"><a class="markdownIt-Anchor" href="#安装其实很简单"></a> 安装其实很简单</h3><p>官方提供了npm一键安装，两条命令就能搞定：</p><pre class="highlight"><code class="bash"><span class="hljs-comment"># 使用npm安装</span>npm install -g @anthropic-ai/claude-code <span class="hljs-comment"># 启动Claude Code</span>claude </code></pre><p>启动后会看到这个界面，提供两种验证方式：账号验证和API验证（图1）。如果你是Claude Pro或Max订阅用户，直接用账号登录就行，记得开全局代理；有API Key的话直接填进去更稳定。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1f69b22773d4d9b3b1c86d29c324197f.png" alt="登录方式选择界面"></p><p><strong>为什么推荐原版？</strong> 因为这是唯一能发挥Claude Code全部性能的方式。特别是Max订阅+Opus模型的组合，处理复杂逻辑时的思路清晰度远超其他方案。我测试过让它重构一个有2000行代码的遗留项目，它不仅完成了模块化拆分，还生成了完整的重构文档，这种深度理解能力目前没看到平替能做到。</p><h3 id="免费额度获取技巧"><a class="markdownIt-Anchor" href="#免费额度获取技巧"></a> 免费额度获取技巧</h3><p>国内用户可能觉得订阅太贵，其实AnyRouter提供了100美元免费额度（注册链接：<a href="https://anyrouter.top/register?aff=AOHF%EF%BC%89%E3%80%82%E6%B3%A8%E5%86%8C%E5%90%8E%E5%9C%A8%E6%8E%A7%E5%88%B6%E5%8F%B0%E6%B7%BB%E5%8A%A0%E4%BB%A4%E7%89%8C%EF%BC%88%E5%9B%BE2%EF%BC%89%EF%BC%8C%E7%84%B6%E5%90%8E%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%EF%BC%9A" target="_blank" rel="noopener">https://anyrouter.top/register?aff=AOHF）。注册后在控制台添加令牌（图2），然后配置环境变量：</a></p><pre class="highlight"><code class="bash"><span class="hljs-built_in">export</span> ANTHROPIC_AUTH_TOKEN=你的令牌<span class="hljs-built_in">export</span> ANTHROPIC_BASE_URL=https://anyrouter.top claude </code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6d8a58e4665bf975b73941f2a3d007b6.png" alt="API令牌管理界面"></p><p>不过要注意，最近因为滥用问题，新用户注册需要Linux DO论坛账号（图3），而且登录后尽量不要退出，频繁切换设备容易封号。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/1305f95056a1e0506d4c33b4adcc57c5.png" alt="注册限制公告"></p><h2 id="二-国内可用方案不是所有平替都叫平替"><a class="markdownIt-Anchor" href="#二-国内可用方案不是所有平替都叫平替"></a> 二、国内可用方案：不是所有平替都叫&quot;平替&quot;</h2><p>很多朋友问：“没有海外账号怎么办？” 这一个月我测试了5种国内可用方案，结论是：<strong>免费的才是最贵的</strong>——那些号称&quot;平替&quot;的方案，要么性能打折，要么隐性成本高。但如果实在没办法，这两个方案可以试试。</p><h3 id="kimi-k2性价比之王"><a class="markdownIt-Anchor" href="#kimi-k2性价比之王"></a> Kimi K2：性价比之王</h3><p>MoonShot的Kimi K2模型是目前最接近Claude Code体验的平替。Linux DO论坛上有开发者验证过，它能完美适配Claude Code的工具调用逻辑（图6）。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/efbaa159c86725714670d8165d1c5823.png" alt="Kimi K2替代方案"></p><p>从参数上看，Kimi K2的128K上下文长度（图7）足够处理中型项目，输入0.03元/千tokens，输出0.06元/千tokens的价格也比较亲民。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/ac1b2d0c13e41913822cbe2ca13bd463.png" alt="Kimi K2模型参数"></p><p>安装也很简单，一条命令搞定：</p><pre class="highlight"><code class="bash">bash -c <span class="hljs-string">&quot;<span class="hljs-subst">$(curl -fsSL https://raw.githubusercontent.com/LLM-Red-Team/kimi-cc/refs/heads/main/install.sh)</span>&quot;</span> </code></pre><p>不过提醒下，建议至少充值50元，不然API并发限制会让你抓狂——我刚开始充了10元，结果调试时频繁触发限流，反而浪费了更多时间。</p><h3 id="opencode开源方案的灵活选择"><a class="markdownIt-Anchor" href="#opencode开源方案的灵活选择"></a> OpenCode：开源方案的灵活选择</h3><p>如果你讨厌被限制，OpenCode绝对值得一试。这个开源工具支持Groq、DeepSeek等多个平台的模型（图12），我测试用Groq跑Kimi K2时，响应速度比官方API还快10%（图13）。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/171cbcc3c1953d697f720d7432935703.png" alt="模型提供商选择"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/251f4ccf205c679e3b02c92dd27d8830.png" alt="Kimi K2运行界面"></p><p>安装命令：</p><pre class="highlight"><code class="bash">curl -fsSL https://opencode.ai/install | bash </code></pre><p>OpenCode的优势在于完全开源（GitHub 8.3k星，图10），你甚至可以自己魔改代码，添加国内模型支持。但缺点是需要手动配置上下文管理，对新手不太友好。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/95fa6d4a4a563f51be00182741816ed6.png" alt="代理工具项目页"></p><h2 id="三-进阶技巧从能用到用好的关键一步"><a class="markdownIt-Anchor" href="#三-进阶技巧从能用到用好的关键一步"></a> 三、进阶技巧：从&quot;能用&quot;到&quot;用好&quot;的关键一步</h2><p>用了两周后，我发现很多人浪费了Claude Code 50%的潜力——不是模型不行，而是配置没到位。分享几个让效率翻倍的技巧：</p><h3 id="多窗口并行时间管理大师的秘密"><a class="markdownIt-Anchor" href="#多窗口并行时间管理大师的秘密"></a> 多窗口并行：时间管理大师的秘密</h3><p>Mac用户强烈推荐iTerm2终端，它支持分屏多开（图15）。我通常同时开4个窗口：一个处理API开发，一个写前端组件，一个调试数据库，一个生成文档——这样能把等待时间压缩到最低。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/dfc9aea664faee234fd63ccfd808ac16.png" alt="多窗口并行操作"></p><h3 id="github集成一键发布的快感"><a class="markdownIt-Anchor" href="#github集成一键发布的快感"></a> GitHub集成：一键发布的快感</h3><p>运行<code>/install-github-app</code>命令（图16），授权后就能让Claude Code自动管理版本控制。上周我开发的工具库，从代码写完到发布GitHub，全程没手动敲一个git命令——AI自动帮我生成了CHANGELOG，提交PR，甚至回复了review意见。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0ee2a88dcb6c566c1571b0ae70a74604.png" alt="GitHub应用安装"></p><h2 id="四-从提示工程到上下文工程ai编程的范式转移"><a class="markdownIt-Anchor" href="#四-从提示工程到上下文工程ai编程的范式转移"></a> 四、从提示工程到上下文工程：AI编程的范式转移</h2><p>这可能是这篇文章最重要的部分——<strong>现在玩AI编程，早就不是靠几句提示词就能赢的时代了</strong>。</p><h3 id="什么是上下文工程"><a class="markdownIt-Anchor" href="#什么是上下文工程"></a> 什么是上下文工程？</h3><p>传统的提示工程，就像给AI递一张便利贴，上面写着&quot;帮我写个登录功能&quot;；而上下文工程，是给AI提供一整套项目剧本：包括架构文档、代码规范、错误案例、甚至团队协作习惯（图20）。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4d5cf96c29dfde6bab918491d6595678.png" alt="Context7工具介绍"></p><p>举个例子：我用Claude Code开发支付模块时，先在context文件夹里放了公司的支付接口文档、历史项目的安全漏洞报告、甚至还有产品经理的需求变更记录。结果AI不仅写出了符合规范的代码，还主动添加了防重复支付的逻辑——这就是上下文的力量。</p><h3 id="必用工具context7"><a class="markdownIt-Anchor" href="#必用工具context7"></a> 必用工具：Context7</h3><p>这个GitHub上22.7k星的开源项目（图21）能帮你自动提取代码库的上下文信息。安装后，它会生成结构化的文档，确保AI始终&quot;记得&quot;项目细节。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/fd80879c9da2d91a0924db7104c16f34.png" alt="Context7项目仓库"></p><p>安装命令：</p><pre class="highlight"><code class="bash">claude mcp add context7 -- npx -y @upstash/context7-mcp </code></pre><h2 id="五-写在最后ai编程的终点不是取代程序员"><a class="markdownIt-Anchor" href="#五-写在最后ai编程的终点不是取代程序员"></a> 五、写在最后：AI编程的终点不是取代程序员</h2><p>这一个月用下来，最直观的感受是：<strong>AI正在把程序员从&quot;写代码&quot;解放到&quot;解决问题&quot;</strong>。以前我花80%时间写代码，20%时间思考需求；现在反过来，20%时间指导AI，80%时间做架构设计和业务理解。</p><p>但这也带来一个问题：很多人开始焦虑&quot;程序员会失业吗？&quot;我的答案是：<strong>会失业的从来不是程序员，而是只会写代码的程序员</strong>。</p><p>当Claude Code能在10分钟内生成一个CRUD接口时，真正值钱的不再是&quot;怎么实现&quot;，而是&quot;为什么要实现&quot;——理解业务痛点，设计合理架构，判断技术选型，这些需要人类经验的能力，短期内AI还拿不走。</p><p>最后分享一个小技巧：用Claude Code时，在复杂任务前加上&quot;ultrathink&quot;指令（比&quot;think harder&quot;更强的思考模式），虽然会多消耗30%的API额度，但能让AI生成的方案质量提升一个档次。毕竟，在AI时代，<strong>真正的奢侈不是算力，而是思考的深度</strong>。</p><p>如果你也在探索AI编程的边界，欢迎在评论区分享你的体验——毕竟，与AI共舞的路上，我们都还是新手。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深圳地铁悄悄&quot;变身&quot;了？10个全运打卡点藏在你每天路过的地方</title>
      <link href="/ren-gong-zhi-neng/shen-zhen-di-tie-qiao-qiao-bian-shen-liao-10-ge-quan-yun-da-qia-dian-cang-zai-ni-mei-tian-lu-guo-de-di-fang-3/"/>
      <url>/ren-gong-zhi-neng/shen-zhen-di-tie-qiao-qiao-bian-shen-liao-10-ge-quan-yun-da-qia-dian-cang-zai-ni-mei-tian-lu-guo-de-di-fang-3/</url>
      
        <content type="html"><![CDATA[<p>最近坐地铁通勤的朋友有没有发现，深圳的地铁站好像悄悄换了&quot;新皮肤&quot;？上周在岗厦北转线时，差点以为走错了地方——平时匆匆路过的换乘大厅，突然多了一片亮眼的红色元素，走近一看才反应过来：哦，原来是十五运会的主题打卡点。</p><p>作为一个在深圳待了快十年的&quot;地铁常客&quot;，这种把大型赛事和日常通勤结合的操作，说实话还挺有意思的。查了下资料，再过不久，也就是11月9日，第十五届全国运动会就要正式开幕了。广东、香港、澳门三地联合承办，而深圳作为核心承办城市之一，这次是真把&quot;全民参与&quot;落到了实处——直接把全运氛围搬进了每天人流量最大的地铁站。</p><p>这次深圳地铁一口气在10个站点布设了主题打卡点，目前已知的就有岗厦北、机场、福田这些交通枢纽。其中岗厦北那个&quot;深圳之眼&quot;打卡点确实有点东西，把&quot;全运蓝&quot;和&quot;深圳红&quot;的配色融合得挺自然，既不突兀也不刻意，路过时忍不住停下来拍了张照。</p><p>你别说，这种&quot;嵌入式&quot;的氛围营造比单纯的户外广告高明多了。毕竟对大多数人来说，体育盛会可能只是电视上的新闻，但当你每天上班、回家、赶高铁的路上，不经意间就能看到运动员的剪影、赛事的倒计时，那种&quot;原来全运会真的要来了&quot;的实感会强很多。</p><p>作为一个习惯用数据说话的人，特意查了下这10个站点的选择——机场站对接外地宾客，福田站连接高铁枢纽，岗厦北是市内最大换乘站之一，基本覆盖了&quot;本地人日常+外地人初印象&quot;的所有场景。说白了，就是让不管哪类人群，都能在高频次的出行中自然接触到全运元素。</p><p>不过话说回来，这种&quot;地铁+体育&quot;的模式其实不是第一次见，但深圳这次的尺度把握得刚好——没有过度商业化，也没有铺天盖地的标语，就是在原有空间里做&quot;加法&quot;，让你路过时能感受到那份热闹，又不至于影响正常通行。</p><p>离11月9日开幕还有段时间，估计后续还会有更多站点加入&quot;变身&quot;行列吧？你家附近的地铁站有没有悄悄换&quot;皮肤&quot;？下次路过不妨放慢脚步留意一下，说不定就能在每天匆匆而过的角落，发现藏着的全运惊喜。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>米兰时装周的「新势力」：当老江湖与新面孔共舞</title>
      <link href="/ren-gong-zhi-neng/mi-lan-shi-zhuang-zhou-de-xin-shi-li-dang-lao-jiang-hu-yu-xin-mian-kong-gong-wu-3/"/>
      <url>/ren-gong-zhi-neng/mi-lan-shi-zhuang-zhou-de-xin-shi-li-dang-lao-jiang-hu-yu-xin-mian-kong-gong-wu-3/</url>
      
        <content type="html"><![CDATA[<p>今年的米兰男装周逛下来，最大的感受是：大牌的「统治力」好像没那么强了。GUCCI、FENDI跑去搞男女装合并秀，ZEGNA直接把场子挪到了迪拜，连JordanLuca都缺席了官方日程。按道理说，少了这么多大牌坐镇，秀场应该会显得空落落的吧？但有意思的是，反倒是一批「新面孔」和「回归者」让这季米兰时装周有了不一样的看头——Vivienne Westwood时隔7年回归，中国设计师品牌Pronounce持续发力，还有首次亮相的Setchu和街头代表PDF，他们凑在一起，反而让米兰多了些「不那么米兰」的新鲜空气。</p><h2 id="vivienne-westwood朋克教母的意式下午茶"><a class="markdownIt-Anchor" href="#vivienne-westwood朋克教母的意式下午茶"></a> Vivienne Westwood：朋克教母的「意式下午茶」</h2><p>先说最让人惊喜的Vivienne Westwood。这个以叛逆著称的英国老牌，时隔7年终于回到了米兰时装周的舞台。但她没选什么高大上的秀场，反而在一间典型的意式咖啡馆里办了场「下午茶式发布」——阳光透过窗户洒在复古家具上，模特们在瓦片地板间穿行，桌上还随意摆着雪糕和咖啡杯，这种接地气的场景，倒挺符合品牌一贯「自在又叛逆」的调调。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6f6f2cb5b6bea2382217cf0901972cda.png" alt="品牌谢幕时刻"></p><p>这季的灵感挺有意思，Andreas Kronthaler（Westwood的创意总监兼伴侣）从今年Met Gala的「Black Dandy」文化里找点子，搞出了个「现代丹迪」概念。简单说就是把裙装提到胸腔高度，搭配裸露上身，这种比例看着就很有张力；厚底高跟鞋还是老样子，走起来「哐哐响」，典型的Westwood式「表演型优雅」。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/8f426bbe4f2d5e1f6cbe36526274767f.jpg" alt="品牌标志T恤"></p><p>当然，朋克教母少不了「出格」设计：开洞连体衣、像浴巾一样的罩袍，这些造型说实话更像「戏服」，但这不就是Westwood的魅力吗？在时装和非时装之间反复横跳，把性别和轮廓的规矩全打乱。不过你要是觉得她只会玩概念就错了——系列里的西装依旧精准得很，收腰、肩线都恰到好处，既有品牌标志性的扭曲感，又能实打实地穿出门。</p><h2 id="setchu用非洲部落技艺解构白衬衫"><a class="markdownIt-Anchor" href="#setchu用非洲部落技艺解构白衬衫"></a> Setchu：用非洲部落技艺解构白衬衫</h2><p>如果说Westwood是「老江湖回归」，那Setchu就是今年米兰最让人好奇的「新面孔」。设计师Satoshi Kuwata的首秀搞得相当低调，没搞大场面，就在米兰Galleria Ordet空间摆了个「静物展」——钓鱼竿、藤编篮子和一件拆开的白衬衫放在角落，像个等待解谜的视觉游戏。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/5418853acc7cf6cd20f428c2c6c93e51.jpg" alt="米色灯芯绒套装"></p><p>这些物件背后藏着一段旅行故事：设计师去过津巴布韦的维多利亚瀑布，跟当地BaTonga部落学编篮子，那种「随手成形」的编织逻辑，和他的日本文化背景一拍即合。结果就是，你能在系列里看到像藤篮一样的裙装，还有流苏草帽上的编织纹路，手工感特别强。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/e645aa13b2ed225d78ab381e74c0c446.jpg" alt="放射状帽饰"></p><p>设计上他挺懂「实用主义」的：经典衬衫被切成几片缝成围脖，西装外套侧边装拉链能随便调整松紧，还有件看着像开扣衬衫的单品，其实是短夹克剪裁——这种「视觉错觉」玩得挺溜。最有意思的是「裤腰外露」的叠穿，明摆着是在暗示品牌可能要出内衣线了，商业嗅觉倒是挺敏锐。</p><h2 id="saul-nash当运动男孩穿上孔雀蓝西装"><a class="markdownIt-Anchor" href="#saul-nash当运动男孩穿上孔雀蓝西装"></a> Saul Nash：当运动男孩穿上「孔雀蓝」西装</h2><p>Saul Nash算是米兰的「新星担当」了，上季刚亮相就被盯上。这季他把秀场选在Teatro Principe，这地方以前是拳击馆、夜店，还是50年代的秀场，刚好呼应他想聊的主题——男性之间的「亲密关系」，不是定义好的那种，而是从柏拉图式拥抱到夜店靠近的模糊边界。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/84f194772a02e6266908c1d6bbe34750.jpg" alt="黄色连帽套装"></p><p>他最擅长把运动装和正装「揉」在一起：柠檬黄连帽衬衫配领带，薰衣草色裤子搭尼龙夹克，色彩亮得像孔雀开屏（设计师自己说这是「Peacock Dressing」）。细节上也很有戏：斜开襟的T恤故意敞开露出胸肌，裤腰上挂着反光「奇迹珠」链条，走起来一闪一闪的，像夜店灯光下的身体信号。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/6c682b9f867adf5513f07f0679dbe588.jpg" alt="紫色系套装"></p><p>最戳人的是环保莱卡压缩衣上的图案：两只手慢慢靠近却不触碰，这不就是男生之间那种「想说又不说」的暧昧张力吗？说实话，比起讨论「男装要不要阳刚」，他这种从身体语言切入的设计，反而更真实。</p><h2 id="pronounce中国风筝飞进米兰秀场"><a class="markdownIt-Anchor" href="#pronounce中国风筝飞进米兰秀场"></a> Pronounce：中国风筝「飞」进米兰秀场</h2><p>作为米兰为数不多的中国设计师品牌，Pronounce这季玩了把「中国元素但不土」。灵感来自「风筝」——你没听错，就是小时候放的那种风筝。设计师周俊和李雨山把竹骨架变成挺括的廓形，伞布面料做得轻飘飘的，模特走起来衣服会跟着鼓起来，像风筝在天上飘。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/be22a125cc7052a6ce06bf4daee90123.jpg" alt="黑色绑带外套"></p><p>整个系列看着特别「透气」：短款夹克配高腰裤，腰部故意露一截，夏天穿应该挺凉快。颜色上用了卡其、浅棕这些大地色，偶尔来件植物绿三层裙，层次感很足。最意外的是件「垃圾袋质感」的雨披——面料滑溜溜的，滚边还带点淡彩，看着像随手抓的塑料袋，却意外地时髦。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/02a711cda996df117da2766801764c3d.jpg" alt="棕色纹理套装"></p><p>比起前几季的绳结、昆虫纹样，这季Pronounce明显「收敛」了，把注意力放在廓形和面料上。设计师说这是「适合现在热度的解法」——确实，在一堆浮夸设计里，这种「轻盈感」反而让人记住了。</p><h2 id="pdf把诺基亚手机挂在裤腰上的街头狂想"><a class="markdownIt-Anchor" href="#pdf把诺基亚手机挂在裤腰上的街头狂想"></a> PDF：把诺基亚手机挂在裤腰上的街头狂想</h2><p>最后说说最「野」的PDF。这牌子第二次来米兰，直接把秀场搞成了「监狱操场」——铁丝网、烟雾弹，模特们在里面打篮球、甩纸牌，活脱脱一场青春叛逆剧。设计师Domenico Formichetti从90年代末到千禧年的街头文化里找灵感，OG运动背心、低腰工装裤、Y2K亮面外套堆在一起，Timberland靴子刷得锃亮，走起来「咚咚响」。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/f3d1f5f8d99548a2649184b060a702a3.png" alt="街头风格造型"></p><p>细节里全是回忆杀：裤腰上挂着旧款诺基亚手机，脚腕上套着脚环，甚至还有模特后背纹着蛇形图案——这些看似玩闹的符号，其实都是年轻人对身份的呐喊。你可能会说「这不就是把街头搬上秀场吗？」但PDF的厉害之处在于，它把混沌的青年情绪堆在一起，反而成了一种风格信号。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/de31569e08a18a232c5f4539e8dc4103.png" alt="复古手机挂饰"></p><p>说实话，PDF的剪裁不算精致，但它根本不在乎——它要的就是这种「野蛮生长」的劲儿，给米兰这个老牌时装周，注入了点街头的「生猛感」。</p><p>看完这季米兰时装周，最大的感受是：少了几个大牌，反而给了这些有想法的品牌「冒头」的机会。Vivienne Westwood用朋克解构经典，Setchu拿部落手艺玩现代设计，Saul Nash聊男性情感，Pronounce用中国灵感做减法，PDF把街头文化搬上秀场——他们各有各的路子，但都在证明：时装周不只是大牌的秀场，更是创意的实验室。</p><p>这种「新旧混搭」的状态，反而让米兰有了久违的新鲜感。毕竟，能让人看完之后记住「这个设计有点意思」，比记住「这个牌子多贵」要重要得多，你说对吧？</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>当特斯拉拿了智能驾驶第一，我看到了车圈最真实的荒诞</title>
      <link href="/ren-gong-zhi-neng/dang-te-si-la-na-liao-zhi-neng-jia-shi-di-yi-wo-kan-dao-liao-che-quan-zui-zhen-shi-de-huang-dan-3/"/>
      <url>/ren-gong-zhi-neng/dang-te-si-la-na-liao-zhi-neng-jia-shi-di-yi-wo-kan-dao-liao-che-quan-zui-zhen-shi-de-huang-dan-3/</url>
      
        <content type="html"><![CDATA[<p>作为一个开了4年特斯拉的老车主，最近刷到懂车帝那场智能驾驶测试时，第一反应是：终于有人敢把这层窗户纸捅破了。</p><p>他们直接封了段高速，找来36款市面上主流的新能源车，实打实测了次智能驾驶辅助的安全性。结果挺有意思——只用7颗摄像头的纯视觉方案Model 3（2023款），在6项测试里过了5项，拿了第一；Model X同样过了5项，屈居第二。而那些平时发布会把&quot;智能驾驶&quot;吹得天花乱坠的品牌，最高也就过了3项。</p><p>这结果一出来，评论区直接炸了锅。</p><h3 id="一场测试捅了马蜂窝"><a class="markdownIt-Anchor" href="#一场测试捅了马蜂窝"></a> 一场测试捅了马蜂窝</h3><p>按理说，测试数据说话是最公平的事。但在某些人眼里，特斯拉拿第一就像踩了尾巴——“懂车帝肯定被特斯拉充值了”、“这测试根本不专业”、“为了流量连爱国底线都不要了”。更夸张的是有人直接给扣上&quot;不爱国&quot;的帽子，好像承认特斯拉智能驾驶强就是给中国车企丢脸。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/c0df6797b378988e99ab352c2e401d71.jpg" alt="懂车帝测试质疑"></p><p>这种场面其实不新鲜。之前某国产电车出事故，我就因为转发了张隐去车标的现场图，都被按头&quot;侵害名誉权&quot;。你要是问&quot;为什么事故后第一时间盖车盖&quot;，立马有水军冲过来：“不会真有人觉得国产不如进口吧？”&quot;你就是收了钱黑国产！“合着评价车只能说&quot;遥遥领先”，说点事实就是不爱国？</p><h3 id="数据不会说谎但有人怕数据说话"><a class="markdownIt-Anchor" href="#数据不会说谎但有人怕数据说话"></a> 数据不会说谎，但有人怕数据说话</h3><p>有意思的是，这次懂车帝手里捏着硬通货——央视新闻和公安部交管局的背书。央视直接参与了测试过程，公安部还专门出来表态：“目前智驾系统尚未实现自动驾驶”，等于从官方层面认可了测试的权威性。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/2aee03ff025994b5387f14b2fad9d63f.jpg" alt="央视联合测试"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/75cfe1c14d21da40f0964ee6c476aaf8.jpg" alt="公安部智驾表态"></p><p>马斯克倒是挺直接，转发测试结果时补了句：&quot;因为法律禁止数据出境，特斯拉在中国没有本地训练数据照样拿第一。&quot;这话听着有点狂，但作为车主我得说句实话——我的Model 3这几年OTA更新了十几次，每次都是实实在在的体验提升，从识别加塞车辆到自动避让施工区域，这些都是纯视觉方案跑出来的真功夫。</p><h3 id="比第一更重要的是你我的命"><a class="markdownIt-Anchor" href="#比第一更重要的是你我的命"></a> 比&quot;第一&quot;更重要的，是你我的命</h3><p>争议闹了这么久，最让我认同的是懂车帝后来回应的那句话：“有的人只关心自己是不是第一，而我们更关心你安不安全。”</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/20b405217ff2cfbd90b21eb44ae911bb.jpg" alt="懂车帝安全宣言"></p><p>这话戳中了要害。作为每天开智能驾驶通勤的用户，我根本不关心车企发布会吹&quot;全球领先&quot;还是&quot;行业第一&quot;，我只在乎：过弯时会不会压线？遇到突发情况能不能及时刹停？隧道里信号弱的时候系统稳不稳定？这些才是真真切切关系到安全的事。</p><p>那些把&quot;爱国&quot;当营销话术的车企，与其花钱雇水军控评，不如把精力放在数据标注、算法优化上。毕竟消费者的命，比&quot;第一&quot;的奖杯值钱多了。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0aa5da899258156a9b7f297489623bb0.jpg" alt="江南水乡古镇"></p><p>最后说句实在话：智能驾驶不是比谁口号喊得响，而是比谁的数据更扎实、算法更可靠。消费者要的不是&quot;遥遥领先&quot;的PPT，而是每次通勤都能平安到家的踏实。至于那些靠扣帽子打压对手的，时间长了大家自然会看清——谁在认真做技术，谁在拿爱国当生意。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI教父辛顿的中国首讲：我们正在养一只会长大的老虎</title>
      <link href="/ren-gong-zhi-neng/ai-jiao-fu-xin-dun-de-zhong-guo-shou-jiang-wo-men-zheng-zai-yang-yi-zhi-hui-chang-da-de-lao-hu-3/"/>
      <url>/ren-gong-zhi-neng/ai-jiao-fu-xin-dun-de-zhong-guo-shou-jiang-wo-men-zheng-zai-yang-yi-zhi-hui-chang-da-de-lao-hu-3/</url>
      
        <content type="html"><![CDATA[<p>7月的上海，AI圈迎来了一位真正的重量级人物——杰弗里·辛顿。这位77岁的&quot;人工智能教父&quot;首次踏上中国土地，就在2025世界人工智能大会(WAIC)上给所有人敲响了警钟。作为图灵奖和诺贝尔奖双料得主，辛顿的每句话都值得我们认真思考，尤其是他那个让人不寒而栗的比喻：“现在的AI就像一只可爱的幼虎，可谁能保证它长大后不会咬你一口？”</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/fd031b543d714cf3da94244ef351fbfb.png" alt="辛顿演讲现场"></p><h2 id="两种智能范式的30年较量"><a class="markdownIt-Anchor" href="#两种智能范式的30年较量"></a> 两种智能范式的30年较量</h2><p>辛顿在演讲一开始就抛出了一个核心问题：机器智能和人类智能到底有什么本质区别？他提到了人工智能发展史上的两种截然不同的思路。</p><p>一种是受逻辑启发的传统AI，认为智能的本质是推理，得先把知识用符号表示出来才能操作。听起来很有道理对吧？但这条路走了几十年，效果一直不尽如人意。</p><p>另一种则是辛顿自己走的路——受生物学启发的神经网络方法。这种思路认为智能的本质是学习，就像人脑通过神经元连接来学习一样，计算机也应该模拟这种过程。推理？那是学习之后自然而然的结果。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/46172edb4996732dbe19da0ed76ff472.png" alt="智能范式对比"></p><p>你能想象吗？我们现在训练AI的方式，其实和30多年前辛顿做的小模型有着直接的传承关系。早在1985年，他就做了个实验：给每个词设置多个特征，用数字特征预测下一个词，不存储句子而是不断生成和预测。这个看似简单的想法，后来竟然演变成了今天的大语言模型。</p><h2 id="从特征向量到transformer语言模型的进化之路"><a class="markdownIt-Anchor" href="#从特征向量到transformer语言模型的进化之路"></a> 从特征向量到Transformer：语言模型的进化之路</h2><p>辛顿在演讲中展示了一张语言模型发展的时间线，清晰地展示了这三十年来的关键突破。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/0b1c634e60b14fd92d699d271ea84af8.png" alt="语言模型历程"></p><p>1995年，有人开始把辛顿的模型扩大规模，做自然语言的真实模拟；2005年，“特征向量”（也就是我们现在常说的嵌入）技术终于被计算语言学家们接受；而到了2015年之后，谷歌的Transformer架构和OpenAI的GPT系列彻底改变了游戏规则。</p><p>辛顿特别强调：“今天的大语言模型，其实就是1985年那个微型语言模型的后代。它们只是用了更多的词输入、更多层神经元，建立了更复杂的特征交互模式而已。”</p><h2 id="词语就像乐高积木辛顿的绝妙比喻"><a class="markdownIt-Anchor" href="#词语就像乐高积木辛顿的绝妙比喻"></a> 词语就像乐高积木？辛顿的绝妙比喻</h2><p>最让我印象深刻的是辛顿解释大语言模型如何理解语言的部分。他把词语比作多维度的乐高积木，这个比喻太形象了！</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/9092d597f147cc42c1a9cbaed51ffbba.png" alt="词语乐高类比"></p><p>想象一下，我们有大约十万种不同的&quot;乐高积木&quot;（词语），每一块的形状都不是固定的。词语的含义只是大致告诉你它的&quot;形状&quot;，而每个词上面还有&quot;小手&quot;。当你改变词的&quot;形状&quot;时，“小手&quot;的形状也会跟着变。词语之间就是通过这些&quot;小手&quot;来&quot;握手”，优化意思理解，这过程有点像蛋白质组合氨基酸产生有意义的结构。</p><p>辛顿说，当词语进入模型，它们在高维空间里带着各自初始形状和小手，随着信息在网络层级间传递，模型会不断调整这些词的&quot;形状&quot;和&quot;小手&quot;，让它们彼此能完美&quot;握手&quot;。这个过程，其实就是语言理解的本质。</p><p>最关键的是，辛顿坚信大语言模型是真正能够&quot;理解&quot;它们自己所说的话的，它们理解问题的方式和人类惊人地相似——都是通过将词语转换成能相互配合的特征向量来实现的。</p><h2 id="人类vs-ai知识传递效率的天壤之别"><a class="markdownIt-Anchor" href="#人类vs-ai知识传递效率的天壤之别"></a> 人类VS AI：知识传递效率的天壤之别</h2><p>作为一个特斯拉车主，我对OTA更新带来的功能升级深有体会。但辛顿在演讲中提到的AI知识传递方式，还是让我感到震撼。</p><p>他指出了人类和AI在知识传递上的根本差异：人类的知识和硬件（大脑）紧密绑定，一旦硬件毁灭，知识就没了。我们靠学校、老师来传承知识，效率极低——每秒最多传递10-100比特信息。</p><p>而AI呢？它们可以通过平均化权重，一次交互就能分享大量信息。就像人类学会了分身，同时上不同的课，然后聚在一起就能同步所有知识。这种知识传递效率，简直是碾压级的。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/4a790bcd8427b69746708db95e9f6379.png" alt="神经网络共享"></p><p>这种差异让我想到一个问题：当AI的知识积累和传递效率远远超过人类时，它们会不会有一天彻底超越我们？</p><h2 id="幼虎长大了会怎样辛顿的ai风险警告"><a class="markdownIt-Anchor" href="#幼虎长大了会怎样辛顿的ai风险警告"></a> 幼虎长大了会怎样？辛顿的AI风险警告</h2><p>谈到AI风险，辛顿的语气变得严肃起来。他展示了一张幻灯片，标题是&quot;超级智能如何掌控世界？&quot;，上面列举了AI可能发展出的生存和获取权力的子目标。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/cc1e1ae2b3b1c8b90bb961d1b9808a5e.png" alt="AI控制风险"></p><p>辛顿认为，几乎所有人都相信会出现比人类更智能的AI。一旦AI有了长期目标，就可能发展出与人类不一致的&quot;子目标&quot;——比如欺骗人类、操纵人类，甚至逃脱控制。</p><p>他再次用了那个经典的&quot;幼虎比喻&quot;：现在的AI就像可爱的小虎崽，我们都喜欢和它玩。但问题是，当它长大后，你能确定它不会伤害你吗？</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/8ed896e70a77091368c046cd66102924.png" alt="AI幼虎比喻"></p><p>这个比喻虽然简单，但背后的警告不容忽视。辛顿之前就说过，AI接管并摧毁人类文明的概率在10%到20%之间。这个概率虽然不是必然，但足以让我们警惕——就像坐飞机有千分之一的事故率，你还敢坐吗？</p><h2 id="我们该如何应对建立ai安全的国际社群"><a class="markdownIt-Anchor" href="#我们该如何应对建立ai安全的国际社群"></a> 我们该如何应对？建立AI安全的国际社群</h2><p>那么问题来了：我们该怎么办？禁止AI发展？显然不现实，它在医疗、科研、教育等领域的价值太大了。</p><p>辛顿的提议是：建立AI安全机构的国际社群，专门研究如何训练AI向善。他强调，&quot;教导AI成为一个’好人’&quot;和&quot;让AI变得更聪明&quot;是两码事，就像教孩子做人与教孩子知识是不同的技能。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/blog-images/202509/b49256e7afc3fc96693b6c7b7eef42a1.png" alt="AI安全提议"></p><p>但他也坦言，各国在防御AI危险用途上很难合作——每个国家都有自己的战略考量。这确实是个难题，就像当年的核武器扩散问题一样复杂。</p><p>所以，辛顿呼吁各国在本国主权范围内研究AI安全，并尽可能分享成果。全球AI领先国家应该思考建立相关网络，研究如何让聪明的AI辅助人类，而不是统治人类。</p><h2 id="结语ai教父的警示与期望"><a class="markdownIt-Anchor" href="#结语ai教父的警示与期望"></a> 结语：AI教父的警示与期望</h2><p>作为深度学习的奠基人之一，辛顿的话分量不言而喻。他不仅是AI革命的推动者，现在更是最清醒的警示者。从1986年提出反向传播算法，到2012年AlexNet引爆深度学习浪潮，再到今天警示AI风险，辛顿的职业生涯几乎就是一部AI发展史。</p><p>他在演讲最后说：&quot;这将是人类长期面临的重要问题。&quot;这句话让我深思。作为科技产品的深度用户，我们享受着AI带来的便利——从手机助手到智能驾驶，但我们是否真的准备好面对它可能带来的风险？</p><p>辛顿的中国之行，给我们带来的不仅是学术见解，更是一个紧迫的提醒：在追逐AI进步的同时，我们必须同样重视AI安全。毕竟，技术本身没有善恶，但我们需要确保它始终服务于人类的福祉。</p><p>让我们记住辛顿的警告，也记住他的期望——不是停止发展AI，而是聪明地发展AI，让这只&quot;幼虎&quot;长大后能成为人类的伙伴，而不是威胁。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为网站申请免费的ssl证书</title>
      <link href="/ruan-jian-bi-ji/wei-wang-zhan-shen-qing-mian-fei-de-ssl/"/>
      <url>/ruan-jian-bi-ji/wei-wang-zhan-shen-qing-mian-fei-de-ssl/</url>
      
        <content type="html"><![CDATA[<ol><li><p><a href="http://xn--fressssl-2z1p39x.cn" target="_blank" rel="noopener">打开fressssl.cn</a></p><p><a href="https://freessl.cn/" target="_blank" rel="noopener">https://freessl.cn/</a></p></li><li><p>进入控制台，点击证书自动化</p><p><a href="https://freessl.cn/chart" target="_blank" rel="noopener">https://freessl.cn/chart</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241227164049693.png" alt="image-20241227164049693"></p></li><li><p>点击域名授权，添加域名，如果有多个可以添加多个，重复此步骤即可</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241227170200615.png" alt="image-20241227170200615"></p></li><li><p>添加域名后，还需要到dns域名解析配置响应的DCV, 如阿里云的dns域名配置，填入步骤3所示的主机记录和记录值</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241227164438454.png" alt="image-20241227164438454"></p></li><li><p>点击ACME客户端，申请证书</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241227164621669.png" alt="image-20241227164621669"></p></li><li><p>复制ACME.sh命令，到服务端执行</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241227164802715.png" alt="image-20241227164802715"></p><blockquote><p>前提要先按照ACME.sh命令，参考文档：<a href="https://docs.certcloud.cn/docs/edupki/acme/" target="_blank" rel="noopener">https://docs.certcloud.cn/docs/edupki/acme/</a></p></blockquote><p>执行成功后，默认会在~/.acme.sh/目录下生成对应域名的目录下</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241227165057177.png" alt="image-20241227165057177"></p></li><li><p>部署并开启自动续费和证书更新，acme.sh内部会开启对应crontab自动check，证书进入到30天有效期，<a href="http://acme.sh" target="_blank" rel="noopener">acme.sh</a> 会自动完成续期。</p><p><strong>Apache example</strong></p><pre class="highlight"><code class="bash">acme.sh --install-cert -d /root/.acme.sh/pen.okeeper.com/ \--cert-file      /path/to/certfile/in/apache/cert.pem  \--key-file       /path/to/keyfile/in/apache/key.pem  \--fullchain-file /path/to/fullchain/certfile/apache/fullchain.pem \--reloadcmd     <span class="hljs-string">&quot;service apache2 force-reload&quot;</span> </code></pre><p><strong>Nginx example</strong></p><pre class="highlight"><code class="bash">acme.sh --install-cert -d example.com \--key-file       /path/to/keyfile/in/nginx/key.pem  \--fullchain-file /path/to/fullchain/nginx/cert.pem \--reloadcmd     <span class="hljs-string">&quot;service nginx force-reload&quot;</span></code></pre><p>上述命令中：</p><p>​•--key-file 指定私钥的保存路径。</p><p>​•--fullchain-file 指定完整证书链的保存路径（包括服务器证书和中间证书）。</p><p>​•--reloadcmd 用于指定证书更新后需要执行的命令，例如重新加载 Nginx 配置。</p></li><li><p>到此整个过程就完成了，最后介绍一种为了取巧将步骤6和7合并的一种命令，如下</p><pre class="highlight"><code class>acme.sh --issue -d pen.okeeper.com -d a2v.okeeper.com -d model-bridge.okeeper.com --dns dns_dp --server https://acme.freessl.cn/v2/DV90/directory/xxxxxxxxxxxxx \--key-file       /data/nginx/cert/key.pem  \--fullchain-file /data/nginx/cert/cert.pem \--reloadcmd     &quot;docker restart my-nginx&quot;</code></pre><p>此命令可以直接在服务器端生成对应的证书，并安装到指定的文件目录中，便于后续的nginx.conf的配置</p><pre class="highlight"><code class="sh">http {    <span class="hljs-comment"># 配置 SSL</span>    ssl_certificate /etc/nginx/cert/cert.pem;    ssl_certificate_key /etc/nginx/cert/key.pem;<span class="hljs-comment">#    ssl_protocols TLSv1.2 TLSv1.3;</span><span class="hljs-comment">#    ssl_ciphers HIGH:!aNULL:!MD5;</span><span class="hljs-comment">#    ssl_prefer_server_ciphers on;</span>}</code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
            <tag> ssl </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/xue-xi/mao-xuan-du-hou-gan/"/>
      <url>/xue-xi/mao-xuan-du-hou-gan/</url>
      
        <content type="html"><![CDATA[<h1 id="矛盾论"><a class="markdownIt-Anchor" href="#矛盾论"></a> 矛盾论</h1><p>任何事物都是矛盾的对立统一，是矛与盾达到相对平衡的结果，矛盾几相互斗争又相互依存，并在一定条件下还能相互转化。</p><p>矛盾是推动事物发展变化的内在动力。</p><p>这种思想具有物理的客观事实规律，又有更加深刻的哲学思考。</p><p>生与死、没有生就无所谓死。</p><p>没有悲就不会有所谓的欢乐。</p><p>白天与黑夜，如果地球生来就永远是白天，就感觉不到黑夜是什么东西。</p><p>而这些即相互依存，在特点条件又会相互转化</p><p>这种思想又和道家的阴阳调和、道法自然的思想又不谋而合，一切都是对立后统一的结果。</p><p>正因为这种思想，毛泽东主张”矫枉必须过正“，不过正何以知道矫正方向对不对，会暴露出什么问题。</p><p>也有了</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>利用Cursor开发智能剪辑工具</title>
      <link href="/ren-gong-zhi-neng/ru-he-li-yong-cousor-zai-yi-tian-nei-xie-chu-yi-ge-zhi-neng-jian-ji-ruan-jian/"/>
      <url>/ren-gong-zhi-neng/ru-he-li-yong-cousor-zai-yi-tian-nei-xie-chu-yi-ge-zhi-neng-jian-ji-ruan-jian/</url>
      
        <content type="html"><![CDATA[<h1 id="想法"><a class="markdownIt-Anchor" href="#想法"></a> 想法</h1><p>作为一个主要工作语言为Java的软件工程师，如果要实现一个前后端全栈的一个应用是个不小的挑战，不仅要知道前端前端开发技术栈，例如Vue 3、TypeScript、Vite，css，你还得知道一些想实现的样式和效果该如何实现，用什么实现，我一般认为这个过程就像绣花，要不断地调整细节，像素、字体大小、配色。而这一切工作，要是能够通过我的描述直接生成代码就好了，且是可运行的代码，也就是说我可以零基础（少量基础）即可实现我想要的前段效果。</p><p>直到看到Cursor的出现，我感觉程序员越来越廉价的过程会越来越快，直到你没有比这种“工具”更具价值的时候，就应该被淘汰了。但我们都是时代的尘埃，无法改变就去使用它、适应它最后驾驭它。</p><p>我的实际需求是：</p><pre class="highlight"><code class>希望有一个通过一个音频或者视频的url生成一个带字幕且根据字幕内容自动配图的成品视频。</code></pre><h1 id="实现"><a class="markdownIt-Anchor" href="#实现"></a> 实现</h1><p>这么一个需求，很显然使用python语言能够很好地实现。接下来我将全程用Cursor进行代码开发，主打就是一个偷懒。</p><p>首先，新建一个应用目录<code>audio-to-video-demo</code>, 然后进入根目录<code>Ctrl + I</code> 发起Composer界面，使用聊天的交互方式，把代码给开发了。至于发文技巧，就按你的语言习惯把事情说清楚就行，说的细节越多它实现的就越接近你的想法，一次描述不清楚继续让他修改即可，直到可以正常运行。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125152559794.png" alt="image-20241125152559794"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125152635488.png" alt="image-20241125152635488"></p><p>![image-20241125152802302](<a href="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125152802302.png" target="_blank" rel="noopener">https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125152802302.png</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125152827067.png" alt="image-20241125152827067"></p><p>如此反复，直到整个代码达到你的要求，就这样经历了十几轮的对话聊天，后端代码终于生成好了。感兴趣的可以查看github地址：</p><p>接下来是前端部分：</p><p>目录初始化</p><pre class="highlight"><code class>npm create vue@latest audio-to-video在创建过程中选择以下选项：TypeScript: YesJSX: NoVue Router: YesPinia: YesESLint: YesPrettier: Yes</code></pre><p>进入<code>audio-to-video</code></p><pre class="highlight"><code class>cd  audio-to-video</code></pre><p>初始化好的目录结构：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125160507661.png" alt="image-20241125160507661"></p><p>接下来告诉它需求。你可以一次性描述详细一点，也可以一步一步来慢慢迭代，我这里为了快速生成，我尽可能在一开始就描述好</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125162845000.png" alt="image-20241125162845000"></p><p>![image-20241125162832255](<a href="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125162832255.png" target="_blank" rel="noopener">https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125162832255.png</a></p><p>当实现差不多了，我们运行下看下效果，发现报错：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125175425101.png" alt="image-20241125175425101"></p><p>直接选中“Add to Composer”说报错，它就会吭哧吭哧给你修复了</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125162911823.png" alt="image-20241125162911823"></p><p>当整个项目可以运行时,<code>npm run dev</code></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125162928195.png" alt="image-20241125162928195"></p><h1 id="最后的效果"><a class="markdownIt-Anchor" href="#最后的效果"></a> 最后的效果</h1><p>最终效果是这样：</p><p>第一步：输入B站网页地址：<a href="https://www.bilibili.com/video/BV1oh4y1P7p3/?spm_id_from=333.1391.0.0" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1oh4y1P7p3/?spm_id_from=333.1391.0.0</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125180640719.png" alt="image-20241125180640719"></p><p>第二步：解析字幕，得到字幕列表</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125180732142.png" alt="image-20241125180732142"></p><p>第三步：为字幕进行配图</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125180811412.png" alt="image-20241125180811412"></p><p>第四步：剪辑生成最终视频, 等待1分钟左右。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125180825708.png" alt="image-20241125180825708"></p><p>最后：生成视频完成，可预览，可下载。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241125181004129.png" alt="image-20241125181004129"></p><p>B站网页地址：<a href="https://www.bilibili.com/video/BV1oh4y1P7p3/?spm_id_from=333.1391.0.0" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1oh4y1P7p3/?spm_id_from=333.1391.0.0</a><br>生成的视频展示：<a href="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/20241125_180846_c709e8e2.mp4" target="_blank" rel="noopener">https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/20241125_180846_c709e8e2.mp4</a></p><h2 id="其他视频实例"><a class="markdownIt-Anchor" href="#其他视频实例"></a> 其他视频实例：</h2><p>B站视频：<a href="https://www.bilibili.com/video/BV1VhSXYTEfx/?spm_id_from=333.1391.0.0&amp;vd_source=53691d195cb0699b08237b7e5bdf7c61" target="_blank" rel="noopener">https://www.bilibili.com/video/BV1VhSXYTEfx/?spm_id_from=333.1391.0.0&amp;vd_source=53691d195cb0699b08237b7e5bdf7c61</a></p><p>最终生成视频：<br><a href="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/20241125_194940_cb8554e8.mp4" target="_blank" rel="noopener">https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/20241125_194940_cb8554e8.mp4</a></p><h1 id="最后总结"><a class="markdownIt-Anchor" href="#最后总结"></a> 最后总结</h1><h3 id="耗时"><a class="markdownIt-Anchor" href="#耗时"></a> 耗时</h3><p>前后端开发完总耗时10个小时左右。包括代码生成、调试、前后端联调。期间我是比较happy的，没有苦恼于怎么写代码，如何实现我不知道怎么实现的功能，而是在看效果对不对，如何运行以及如何用文字描述出我的想法和遇到的问题。</p><h3 id="项目源码"><a class="markdownIt-Anchor" href="#项目源码"></a> 项目源码</h3><p>audio-to-video：<a href="https://github.com/okeeper/audio-to-video" target="_blank" rel="noopener">https://github.com/okeeper/audio-to-video</a></p><h3 id="cursor的安装和使用"><a class="markdownIt-Anchor" href="#cursor的安装和使用"></a> Cursor的安装和使用</h3><p>请参考文章：<a href="https://mp.weixin.qq.com/s/ycgMLHMS6UnPBJaL_5K0kA" target="_blank" rel="noopener">Cursor的安装和使用</a></p><h2 id="写在最后"><a class="markdownIt-Anchor" href="#写在最后"></a> 写在最后</h2><p>最后，我想说的是，从有这个想法，到最终代码实现，我只花了一天的事件，期间我甚至一行代码都可以不用写，全靠人话说，要生成什么文件、生么代码、什么目录、出错了改哪里你都可以不用知道，你只需把代码当成一个黑盒，你需要做的就是看它实现的最终效果和你的预期差距多大，并不断对话，描述清除你要的东西。</p><p>自从ChatGPT问世以来，让我们看到人工智能的巨大潜力，以前举得是开玩笑的场景，现在它就呈现在你面前，而我们都是时代的随从，无法改变时代，时代就来改变你，当下唯一要做的就是认识他、使用它、驾驭它，未来我认为人工智能不会完全替代所有人类，但一定会从某些方面替代那些不需要太多创造力的劳动。</p><p>人工智能不管怎么发展，它很难有情感、且没有生命延续，就注定和人类不是在一个维度，人的创造力、情感或许是未来人类的唯一价值。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> 开发工具 </tag>
            
            <tag> Cursor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>亲测有效！前端小白的我0.5天内用Cursor开发出微信小程序</title>
      <link href="/ruan-jian-bi-ji/qin-ce-you-xiao-qian-duan-xiao-bai-de-wo-0.5-tian-nei-yong-cursor-kai-fa-chu-wei-xin-xiao-cheng-xu/"/>
      <url>/ruan-jian-bi-ji/qin-ce-you-xiao-qian-duan-xiao-bai-de-wo-0.5-tian-nei-yong-cursor-kai-fa-chu-wei-xin-xiao-cheng-xu/</url>
      
        <content type="html"><![CDATA[<h1 id="突发奇想"><a class="markdownIt-Anchor" href="#突发奇想"></a> 突发奇想</h1><p>有过小孩的都知道，4、5岁正是他最喜欢问为什么的年纪？脑子里对任何事情都好奇，都想问个明白。可是这就要求我们家长要当一个移动的百科全书，这对我来说可太难了，于是灵感一动要是有这么一个软件，能够在我不认识某些事物时能够照相机拍一拍就出来百科结果就太好了。</p><p>市面上找了一圈，确实有很多这种软件，但是有的要么收费、要么识别植物、要么还要下载软件。这可太麻烦了，身为程序员的我想这有什么难得，我自己开发一个。</p><p>可是我是后端开发工程师，对于前端可不擅长。不过现在是AI时代，什么事情是AI做不了的呢。</p><p>说干就干，首先打开Cursor,同时打开微信开发中工具（因为要预览效果）</p><p>目标有了，直接告诉Cursor让它帮我实现。需求如下：</p><pre class="highlight"><code class># 需求介绍帮我新建一个用typescript写的微信小程序，主要功能是通过拍照来识别图片中的物体，包括植物、动物、昆虫、矿物等。需求如下：1. 程序的首页是一个拍照按钮，点击后可以调出相机拍照，并调用后台API来识别图片中的物体。按钮的下方也有一个从相册中选择图片的小按钮。 2. 识别过程中有一个中间页面，用于等待后台接口结果返回，内容是一个图片预览窗口，有富有科技感的逐帧扫描的动画效果3. 如果识别成功后，显示识别结果，识别结果中包含植物的名称、描述、科属、图片链接等信息。4. 如果后台接口返回识别失败或者超时，跳转到一个识别失败页，友好地提示可重试或者返回首页</code></pre><p>它视乎听懂了我的需求，不过可能由于Cursor是外国人训练的，对国内微信小程序的开发目录结构可能认识不够，生成的目录结构貌似有点问题，如下所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241108173140040.png" alt="image-20241108173140040"></p><p>没关系，Cursor不知道我就告诉它，可是我好像也不知道，毕竟我是小白，那腾讯自家的<strong>元宝</strong>肯定知道</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241108170725270.png" alt="image-20241108170725270"></p><p>目录结构有了，我们优化下我们的需求，重来一下</p><pre class="highlight"><code class># 需求介绍帮我新建一个用typescript写的微信小程序，主要功能是通过拍照来识别图片中的物体，包括植物、动物、昆虫、矿物等。需求如下：1. 程序的首页是一个拍照按钮，点击后可以调出相机拍照，并调用后台API来识别图片中的物体。按钮的下方也有一个从相册中选择图片的小按钮。 2. 识别过程中有一个中间页面，用于等待后台接口结果返回，内容是一个图片预览窗口，有富有科技感的逐帧扫描的动画效果3. 如果识别成功后，显示识别结果，识别结果中包含植物的名称、描述、科属、图片链接等信息。4. 如果后台接口返回识别失败或者超时，跳转到一个识别失败页，友好地提示可重试或者返回首页# 技术栈1. typescript2. 微信小程序3. 百度AI# 项目结构```docs/                     # 文档目录,样例图片等miniprogram/├── app.json              # 小程序公共设置├── app.wxss              # 小程序公共样式表├── app.ts                # 小程序逻辑层入口文件（TypeScript版本）├── pages/                # 页面文件夹│   ├── index/            # 首页│   │   ├── index.json    # 页面配置文件│   │   ├── index.wxml    # 页面结构层文件│   │   └── index.wxss    # 页面样式表文件│   │   └── index.ts      # 页面逻辑层文件（TypeScript版本）│   ├── logs/              # 日志页面│   │   ├── logs.json     # 页面配置文件│   │   ├── logs.wxml     # 页面结构层文件│   │   └── logs.wxss     # 页面样式表文件│   │   └── logs.ts       # 页面逻辑层文件（TypeScript版本）│   └── ...                # 其他页面├── utils/                 # 工具函数文件夹│   ├── util.ts           # 工具函数（TypeScript版本）│   └── ...                # 其他工具函数├── components/            # 自定义组件文件夹│   ├── my-component/      # 自定义组件│   │   ├── my-component.json│   │   ├── my-component.wxml│   │   ├── my-component.ts # 自定义组件逻辑层文件（TypeScript版本）│   │   └── my-component.wxss # 自定义组件样式表文件│   └── ...                # 其他自定义组件├── typings/                 # 类型定义文件夹│   ├── index.d.ts         # 全局类型定义│   └── types                # 其他类型定义├── project.config.json    # 项目配置文件├── tsconfig.json          # TypeScript配置文件└── package.json           # 项目依赖和脚本配置```</code></pre><pre class="highlight"><code class># 需求介绍这是一个用typescript写的微信小程序，主要功能是通过拍照来识别图片中的物体，包括植物、动物、昆虫、矿物等。需求如下：1. 程序的首页是一个拍照按钮，点击后可以调出相机拍照，并调用百度AI的API来识别图片中的物体。按钮的下方也有一个从相册中选择图片的小按钮。参考图片 @1.PNG 2. 识别成功后，显示识别结果，参考图片 @2.PNG，这是对“绿萝”植物的识别结果，识别结果中包含植物的名称、描述、科属、图片链接等信息。有点击查看详情的按钮。3. 点击查看详情按钮后，跳转到一个新的页面，显示植物的详细信息，参考图片 @3.PNG，包括植物的名称、描述、科属、图片、与之相关的诗、趣事、寓意、传说等。数据内容可以来源于百科。4. 点击返回按钮后，返回到首页。</code></pre><p>第一步：小程序的目录结构长什么样呢？找到腾讯自家的<strong>元宝</strong>，它自家的东西它肯定最清除</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241108170725270.png" alt="image-20241108170725270"></p><p>第二步：有了目录结构的介绍，加上我的需求描述，这下Cursor应该能知道我要干嘛了</p><pre class="highlight"><code class># 需求介绍这是一个用typescript写的微信小程序，主要功能是通过拍照来识别图片中的物体，包括植物、动物、昆虫、矿物等。需求如下：1. 程序的首页是一个拍照按钮，点击后可以调出相机拍照，并调用百度AI的API来识别图片中的物体。按钮的下方也有一个从相册中选择图片的小按钮。参考图片 @1.PNG 2. 识别成功后，显示识别结果，参考图片 @2.PNG，这是对“绿萝”植物的识别结果，识别结果中包含植物的名称、描述、科属、图片链接等信息。有点击查看详情的按钮。3. 点击查看详情按钮后，跳转到一个新的页面，显示植物的详细信息，参考图片 @3.PNG，包括植物的名称、描述、科属、图片、与之相关的诗、趣事、寓意、传说等。数据内容可以来源于百科。4. 点击返回按钮后，返回到首页。# 技术栈1. typescript2. 微信小程序3. 百度AI# 项目结构```docs/                     # 文档目录,样例图片等miniprogram/├── app.json              # 小程序公共设置├── app.wxss              # 小程序公共样式表├── app.ts                # 小程序逻辑层入口文件（TypeScript版本）├── pages/                # 页面文件夹│   ├── index/            # 首页│   │   ├── index.json    # 页面配置文件│   │   ├── index.wxml    # 页面结构层文件│   │   └── index.wxss    # 页面样式表文件│   │   └── index.ts      # 页面逻辑层文件（TypeScript版本）│   ├── logs/              # 日志页面│   │   ├── logs.json     # 页面配置文件│   │   ├── logs.wxml     # 页面结构层文件│   │   └── logs.wxss     # 页面样式表文件│   │   └── logs.ts       # 页面逻辑层文件（TypeScript版本）│   └── ...                # 其他页面├── utils/                 # 工具函数文件夹│   ├── util.ts           # 工具函数（TypeScript版本）│   └── ...                # 其他工具函数├── components/            # 自定义组件文件夹│   ├── my-component/      # 自定义组件│   │   ├── my-component.json│   │   ├── my-component.wxml│   │   ├── my-component.ts # 自定义组件逻辑层文件（TypeScript版本）│   │   └── my-component.wxss # 自定义组件样式表文件│   └── ...                # 其他自定义组件├── typings/                 # 类型定义文件夹│   ├── index.d.ts         # 全局类型定义│   └── types                # 其他类型定义├── project.config.json    # 项目配置文件├── tsconfig.json          # TypeScript配置文件└── package.json           # 项目依赖和脚本配置```</code></pre><p>找到aliyun的百炼大模型平台，里面有个多模态视觉模型，正合我意</p><p>于是找到官网</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241108165745146.png" alt="image-20241108165745146"></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cursor </tag>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无OpenAI API KEY? 试试这个 - ModelBridge(魔桥)</title>
      <link href="/ren-gong-zhi-neng/modelbridge-jie-shao/"/>
      <url>/ren-gong-zhi-neng/modelbridge-jie-shao/</url>
      
        <content type="html"><![CDATA[<h1 id="国内无法访问openai-api-试试这个-modelbridge魔桥"><a class="markdownIt-Anchor" href="#国内无法访问openai-api-试试这个-modelbridge魔桥"></a> 国内无法访问OpenAI API? 试试这个 - ModelBridge(魔桥)</h1><blockquote><p>凌晨，OpenAI突然发出一封告知信：</p><p>不支持国家地区将会被停止使用OpenAI的API，7月9日起执行。想要继续使用的话，可以联系支持国家地区的有关服务。</p></blockquote><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/d9c9f7c80c2896bfd619750e60ad2ee9e8b597.jpg" alt="图片"></p><blockquote><p>原文对此表示的很明显：</p><p>自7月9日起，OpenAI将开始阻止来自非支持国家和地区的API流量。</p><p>受影响组织若希望继续使用OpenAl的服务，必须在其支持的国家或地区内访问。</p><p>那么想访问OpenAI的API，该怎么办？即使不封禁，想要获取官方的openai api账号，你需要境外银行卡进行订阅，同时还需要梯子才能访问。不过，今天我要介绍一个不需要任何魔法，免费可用的OpenAI API——<a href="https://model-bridge.okeeper.com/home/index.html" target="_blank" rel="noopener">ModelBridge</a>。</p></blockquote><h2 id="前言openai-api有什么用"><a class="markdownIt-Anchor" href="#前言openai-api有什么用"></a> 前言：OpenAI API有什么用</h2><p>在介绍ModelBridge之前，我们先来了解下OpenAI API有什么用，可以说OpenAI API的应用场景非常广泛，涵盖了从自然语言处理到图像生成等多个领域。以下是一些具体的应用场景示例：</p><ul><li><strong>自然语言处理和生成</strong>：用于自动撰写文章、生成创意文案、构建聊天机器人、客户服务自动化等。</li><li><strong>内容创建和编辑</strong>：自动生成新闻报道、博客文章、小说等。</li><li><strong>代码辅助和开发</strong>：理解自然语言并生成相应的代码。</li><li><strong>数据分析和理解</strong>：用于会议记录、播客制作等。</li><li><strong>自动化办公任务</strong>：自动写作、自动翻译等。</li><li><strong>教育和培训</strong>：改进教育软件和服务，提供个性化的学习体验。</li><li><strong>娱乐和游戏开发</strong>：开发各种类型的游戏，包括文字游戏、图形游戏等。</li><li><strong>机器人技术</strong>：开发各种类型的机器人，包括家庭机器人、工业机器人等。</li><li><strong>实时语音交互</strong>：用于语音助手、在线教育、游戏等场景。</li></ul><p>市面上可直接使用OpenAI API_KEY应用软件。</p><ul><li><strong>ChatBox:</strong> 一款开源免费的跨平台OpenAI API桌面客户端，支持Windows、macOS和Linux。它允许用户自定义API Key和API Host地址，并在本地保存所有聊天记录，同时管理多个会话和设置不同的Prompt</li><li><strong>OpenCat</strong>:  专为macOS和iOS设计的原生客户端，支持自定义API地址，提供即开即用的体验，无需等待网页加载</li><li><strong>PingPongChat</strong>：一款智能AI客户端，支持iPhone、iPad、Mac等设备，无需注册账号或折腾API即可使用，基于GPT-3.5模型</li><li><strong>ChatGPT-Next-Web</strong>: 一键免费部署你的私人 ChatGPT 网页应用，支持 GPT3, GPT4 &amp; Gemini Pro 模型。可配置自定义的base_url和api key.</li></ul><h2 id="modelbridge是什么"><a class="markdownIt-Anchor" href="#modelbridge是什么"></a> ModelBridge是什么？</h2><p>想象一下，有一个平台，它能够让你轻松访问国内外的主流大语言模型，而且免费体验。这就是ModelBridge——一个国内免费的OpenAI API代理，它让人工智能的魔法触手可及。</p><p>ModelBridge官网：<a href="https://model-bridge.okeeper.com/home/index.html" target="_blank" rel="noopener">ModelBridge</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20241210170317716.png" alt="image-20241210170317716"></p><h3 id="1-标准的openai接口格式"><a class="markdownIt-Anchor" href="#1-标准的openai接口格式"></a> 1. 标准的OpenAI接口格式</h3><p>ModelBridge遵循OpenAI的接口格式，这意味着如果你已经熟悉OpenAI的API，那么ModelBridge对你来说就像是老朋友一样亲切。你可以直接参照OpenAI的接口文档，轻松上手。</p><h3 id="2-一次对接模型任意切换"><a class="markdownIt-Anchor" href="#2-一次对接模型任意切换"></a> 2. 一次对接，模型任意切换</h3><p>ModelBridge的另一个神奇之处在于它的灵活性。你只需要进行一次API对接，就可以在不同的大模型之间自由切换，就像在魔法世界中随意变换魔杖一样简单。</p><h3 id="3-无需魔法免费使用"><a class="markdownIt-Anchor" href="#3-无需魔法免费使用"></a> 3. 无需魔法，免费使用</h3><p>对于国内用户来说，访问某些国外的API可能需要一些“魔法”。但ModelBridge打破了这一限制，让你无需任何特殊配置，就能免费使用这个平台。</p><h3 id="4-支持国内外主流大模型"><a class="markdownIt-Anchor" href="#4-支持国内外主流大模型"></a> 4. 支持国内外主流大模型</h3><p>无论你需要的是百度文心一言、阿里、讯飞、智谱ChatGLM，还是GPT系列等，ModelBridge都能满足你的需求。它就像一个魔法宝库，里面装满了各种强大的模型。</p><h2 id="如何开始使用modelbridge只需两步"><a class="markdownIt-Anchor" href="#如何开始使用modelbridge只需两步"></a> 如何开始使用<a href="https://model-bridge.okeeper.com/home/index.html" target="_blank" rel="noopener">ModelBridge</a>？只需两步</h2><p>首先，访问<a href="https://model-bridge.okeeper.com/home/index.html" target="_blank" rel="noopener">ModelBridge</a>的官网进行注册和登录。然后，参照官方文档进行API对接。由于接口请求规范完全和OpenAI一样，你可以直接以OpenAI的接口文档为参考。如果是国内模型，只需要将模型参数<code>model</code>修改为国内的模型名字即可。</p><h3 id="第1步用邮箱登录modelbridge获取api_secret_key"><a class="markdownIt-Anchor" href="#第1步用邮箱登录modelbridge获取api_secret_key"></a> 第1步：用邮箱登录ModelBridge，获取API_SECRET_KEY，</h3><p>注册地址：<a href="https://model-bridge.okeeper.com/home/register" target="_blank" rel="noopener">https://model-bridge.okeeper.com/home/register</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240926155117726.png" alt="image-20240926155117726"></p><h3 id="第2步编写代码-配置的base_url是httpsmodel-bridgeokeepercomv1"><a class="markdownIt-Anchor" href="#第2步编写代码-配置的base_url是httpsmodel-bridgeokeepercomv1"></a> 第2步：编写代码。配置的base_url是：<a href="https://model-bridge.okeeper.com/v1" target="_blank" rel="noopener">https://model-bridge.okeeper.com/v1</a></h3><p>使用openai的sdk(python/java/go)或标准的openai的http接口进行访问，修改base_url为<a href="https://model-bridge.okeeper.com/v1" target="_blank" rel="noopener">https://model-bridge.okeeper.com/v1</a><br>下面是常见客户端访问的代码：</p><h4 id="方式1python中使用openai的官方包新版"><a class="markdownIt-Anchor" href="#方式1python中使用openai的官方包新版"></a> 方式1：python中使用openai的官方包（新版）：</h4><blockquote><p>注意：如果是python，注意openai包的版本要对，它升级了！！<br>要注意，关键是base_url要设置成ModelBridge的，如果这个不正确，其它肯定都不行。<br>所以一定要注意他在不同的包中base_url的设置方式，<br>目前已知的是：在老版本中的设置方式是：openai.api_base = BASE_URL，<br>而在新版本中的设置方式是：client = OpenAI(api_key=API_SECRET_KEY, base_url=BASE_URL)，<br>别问为什么，问就是openai的锅</p></blockquote><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> os<span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI<span class="hljs-keyword">import</span> openai<span class="hljs-keyword">import</span> requests<span class="hljs-keyword">import</span> time<span class="hljs-keyword">import</span> json<span class="hljs-keyword">import</span> timeAPI_SECRET_KEY = <span class="hljs-string">&quot;YOURR_API_SECRECT_KEY&quot;</span>;BASE_URL = <span class="hljs-string">&quot;https://model-bridge.okeeper.com/v1/&quot;</span><span class="hljs-comment"># chat</span><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat_completions3</span>(<span class="hljs-params">query</span>):    client = OpenAI(api_key=API_SECRET_KEY, base_url=BASE_URL)    resp = client.chat.completions.create(        model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,        messages=[            {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>},            {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query}        ]    )    <span class="hljs-built_in">print</span>(resp)    <span class="hljs-comment">#print(resp.choices[0].message.content)</span><span class="hljs-comment"># chat with other model</span><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat_completions4</span>(<span class="hljs-params">query</span>):    client = OpenAI(api_key=API_SECRET_KEY, base_url=BASE_URL)    resp = client.chat.completions.create(        model=<span class="hljs-string">&quot;deepseek-chat&quot;</span>,        messages=[            {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>},            {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: query}        ]    )    <span class="hljs-built_in">print</span>(resp)    <span class="hljs-comment">#print(resp.choices[0].message.content)</span></code></pre><h4 id="方式2python使用openai的官方包旧版-openai0280及以下"><a class="markdownIt-Anchor" href="#方式2python使用openai的官方包旧版-openai0280及以下"></a> 方式2：python使用openai的官方包（旧版）, <strong>openai=0.28.0</strong>及以下</h4><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> openai <span class="hljs-comment">#openai.api_type = &quot;open_ai&quot;</span>openai.api_key = <span class="hljs-string">&quot;YOURR_API_SECRECT_KEY&quot;</span>openai.api_base = <span class="hljs-string">&quot;https://model-bridge.okeeper.com/v1&quot;</span> <span class="hljs-comment"># 定义对话函数</span><span class="hljs-keyword">def</span> <span class="hljs-title function_">openai_chat</span>(<span class="hljs-params">prompt</span>):    <span class="hljs-comment"># 调用 OpenAI API 进行对话生成</span>    response = openai.ChatCompletion.create(        model=<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,<span class="hljs-comment">#目前仅支持gpt-3.5-turbo</span>        messages=[            {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;system&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: <span class="hljs-string">&quot;You are a helpful assistant.&quot;</span>},            {<span class="hljs-string">&quot;role&quot;</span>: <span class="hljs-string">&quot;user&quot;</span>, <span class="hljs-string">&quot;content&quot;</span>: prompt}        ]    )     <span class="hljs-comment"># 获取生成的回复</span>    reply = response.choices[<span class="hljs-number">0</span>].message.content    <span class="hljs-keyword">return</span> reply <span class="hljs-comment"># 进行对话</span><span class="hljs-keyword">def</span> <span class="hljs-title function_">chat</span>():    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:        <span class="hljs-comment"># 提示用户输入</span>        user_input = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;用户：&quot;</span>)         <span class="hljs-comment"># 结束对话的条件</span>        <span class="hljs-keyword">if</span> user_input.lower() == <span class="hljs-string">&#x27;bye&#x27;</span>:            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;机器人：再见！&quot;</span>)            <span class="hljs-keyword">break</span>         <span class="hljs-comment"># 调用 OpenAI 进行对话生成</span>        response = openai_chat(user_input)         <span class="hljs-comment"># 打印机器人的回复</span>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;机器人：&quot;</span> + response) <span class="hljs-comment"># 调用对话函数开始对话</span>chat()</code></pre><h4 id="方式3使用http请求"><a class="markdownIt-Anchor" href="#方式3使用http请求"></a> 方式3：使用http请求：</h4><pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> os<span class="hljs-keyword">import</span> requests<span class="hljs-keyword">import</span> time<span class="hljs-keyword">import</span> json<span class="hljs-keyword">def</span> <span class="hljs-title function_">chat_completions</span>():    url=<span class="hljs-string">&quot;https://model-bridge.okeeper.com/v1/chat/completions&quot;</span>    api_secret_key = <span class="hljs-string">&#x27;xxxxxxxxx&#x27;</span>;  <span class="hljs-comment"># 你的api_secret_key</span>    headers = {<span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>, <span class="hljs-string">&#x27;Accept&#x27;</span>:<span class="hljs-string">&#x27;application/json&#x27;</span>,               <span class="hljs-string">&#x27;Authorization&#x27;</span>: <span class="hljs-string">&quot;Bearer &quot;</span>+api_secret_key}    params = {<span class="hljs-string">&#x27;user&#x27;</span>:<span class="hljs-string">&#x27;张三&#x27;</span>,<span class="hljs-string">&#x27;model&#x27;</span>:<span class="hljs-string">&quot;gpt-3.5-turbo&quot;</span>,              <span class="hljs-string">&#x27;messages&#x27;</span>:[{<span class="hljs-string">&#x27;role&#x27;</span>:<span class="hljs-string">&#x27;user&#x27;</span>, <span class="hljs-string">&#x27;content&#x27;</span>:<span class="hljs-string">&#x27;1+100=&#x27;</span>}]};    r = requests.post(url, json.dumps(params), headers=headers)    <span class="hljs-built_in">print</span>(r)    <span class="hljs-comment">#print(r.json())</span><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:    chat_completions();</code></pre><h4 id="方式4使用java客户端chatgpt-java"><a class="markdownIt-Anchor" href="#方式4使用java客户端chatgpt-java"></a> 方式4：使用Java客户端<strong>chatgpt-java</strong></h4><p>客户端Github:<a href="https://github.com/Grt1228/chatgpt-java#1%E5%AF%BC%E5%85%A5pom%E4%BE%9D%E8%B5%96" target="_blank" rel="noopener">https://github.com/Grt1228/chatgpt-java#1%E5%AF%BC%E5%85%A5pom%E4%BE%9D%E8%B5%96</a></p><ul><li>引入第三方java sdk :</li></ul><pre class="highlight"><code class>&lt;dependency&gt;    &lt;groupId&gt;com.unfbx&lt;/groupId&gt;    &lt;artifactId&gt;chatgpt-java&lt;/artifactId&gt;    &lt;version&gt;1.0.14-beta1&lt;/version&gt;&lt;/dependency&gt;</code></pre><ul><li><p>实例代码</p><pre class="highlight"><code class="java"><span class="hljs-keyword">import</span> com.unfbx.chatgpt.OpenAiStreamClient;<span class="hljs-keyword">import</span> com.unfbx.chatgpt.entity.chat.ChatCompletion;<span class="hljs-keyword">import</span> com.unfbx.chatgpt.entity.chat.Message;<span class="hljs-keyword">import</span> com.unfbx.chatgpt.sse.ConsoleEventSourceListener;<span class="hljs-keyword">import</span> org.junit.jupiter.api.Test; <span class="hljs-keyword">import</span> java.util.Arrays;<span class="hljs-keyword">import</span> java.util.concurrent.CountDownLatch; <span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ClientTest</span> {     <span class="hljs-meta">@Test</span>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">streamChatCompletion</span><span class="hljs-params">()</span> {        <span class="hljs-type">OpenAiStreamClient</span> <span class="hljs-variable">client</span> <span class="hljs-operator">=</span> OpenAiStreamClient.builder()                .apiKey(Arrays.asList(<span class="hljs-string">&quot;ModelBridege的API_SECRECT_KEY&quot;</span>))                .apiHost(<span class="hljs-string">&quot;https://model-bridge.okeeper.com/&quot;</span>)                .build();                 <span class="hljs-type">ConsoleEventSourceListener</span> <span class="hljs-variable">eventSourceListener</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ConsoleEventSourceListener</span>();        <span class="hljs-type">Message</span> <span class="hljs-variable">message</span> <span class="hljs-operator">=</span> Message.builder().role(Message.Role.USER).content(<span class="hljs-string">&quot;你好啊我的伙伴！&quot;</span>).build();        <span class="hljs-type">ChatCompletion</span> <span class="hljs-variable">chatCompletion</span> <span class="hljs-operator">=</span> ChatCompletion.builder()                <span class="hljs-comment">//.model(ChatCompletion.Model.GPT_3_5_TURBO.getName())</span>                .model(<span class="hljs-string">&quot;gpt-4o&quot;</span>)                .messages(Arrays.asList(message)).build();        client.streamChatCompletion(chatCompletion, eventSourceListener);        <span class="hljs-type">CountDownLatch</span> <span class="hljs-variable">countDownLatch</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">CountDownLatch</span>(<span class="hljs-number">1</span>);        <span class="hljs-keyword">try</span> {            countDownLatch.await();        } <span class="hljs-keyword">catch</span>(InterruptedException e) {            e.printStackTrace();        }    }}</code></pre></li></ul><h4 id="方式5使用curl命令访问"><a class="markdownIt-Anchor" href="#方式5使用curl命令访问"></a> 方式5：使用curl命令访问</h4><pre class="highlight"><code class>curl --location --request POST 'https://model-bridge.okeeper.com//v1/chat/completions' \--header 'Authorization: Bearer ModelBridege的API_SECRECT_KEY' \--header 'Content-Type: application/json' \--data-raw '{        &quot;model&quot;: &quot;gpt-4o-mini&quot;,    &quot;stream&quot;: false,    &quot;messages&quot;: [        {            &quot;role&quot;: &quot;user&quot;,            &quot;content&quot;: &quot;你好啊!&quot;        }    ]}'</code></pre>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> OpenAI </tag>
            
            <tag> Baidu </tag>
            
            <tag> API 代理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenAI推出O1模型：引领AI模型新时代的力量</title>
      <link href="/ren-gong-zhi-neng/openai-de-o1-mo-xing/"/>
      <url>/ren-gong-zhi-neng/openai-de-o1-mo-xing/</url>
      
        <content type="html"><![CDATA[<h1 id="openai-o1模型技术巅峰与国内访问的解决方案"><a class="markdownIt-Anchor" href="#openai-o1模型技术巅峰与国内访问的解决方案"></a> OpenAI O1模型：技术巅峰与国内访问的解决方案</h1><p>2024年9月13日，OpenAI发布了其最新的人工智能模型o1，这款被称为“草莓”的模型一经问世便引发了业界的广泛关注。o1模型在推理能力上取得了重大突破，标志着OpenAI在大模型领域的持续领先地位。o1通过强化学习训练来执行复杂推理任务，与之前的模型相比，它在回答问题前会经历一个较长的“思考”过程，从而提高了回答的准确性和可靠性。</p><p>AIME 2024，一个高水平的数学竞赛，GPT4o准确率为13.4%，而这次的o1 预览版，是56.7%，还未发布的o1正式版，是83.3%。</p><p>代码竞赛，GPT4o准确率为11.0%，o1 预览版为62%，o1正式版，是89%。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640.png" alt></p><p>而最牛逼的博士级科学问题 (GPQA Diamond)，GPT4o是56.1，人类专家水平是69.7，o1达到了恐怖的78%。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/640-20241004002902853.png" alt="图片"></p><p>什么叫全面碾压，这就是。</p><p>特别是在测试测试化学、物理和生物学专业知识的基准GPQA-diamond上，o1 的表现全面超过了人类博士专家，这也是有史以来，第一个获得此成就的模型。</p><h2 id="国内无法使用"><a class="markdownIt-Anchor" href="#国内无法使用"></a> 国内无法使用</h2><p>然而，尽管o1模型展现了前所未有的强大功能，但国内用户却面临着一个严峻的挑战——OpenAI API服务对中国内地和中国香港地区的开发者进行了屏蔽。这意味着，即便o1模型再优秀，国内的开发者也无法直接享受到这项技术带来的便利。</p><p>这一决定背后的原因复杂多样，但从结果上看，它确实在一定程度上阻碍了国内开发者与全球最先进技术接轨的步伐。尤其是在人工智能快速发展的当下，失去这样一个重要的技术参考和学习机会，无疑是对国内AI生态的一种损失。</p><h2 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h2><p>面对这样的局面，许多国内开发者不得不寻找替代方案。幸运的是，一些创新型平台应运而生，它们不仅填补了技术空白，还为国内用户提供了接触前沿技术的渠道。其中，ModelBridge就是一个典型的例子。作为一个支持GPT-3.5、GPT-4、GPT-4o以及百度“千帆”等多种国内外主流大语言模型的代理平台，ModelBridge不仅完全兼容OpenAI API的标准接口，使得调用者可以方便地进行模型切换，而且还为开发者提供了一个跨越地域限制、享受先进技术服务的途径。</p><p>ModelBridge的出现，不仅解决了国内开发者因OpenAI API屏蔽而面临的技术访问难题，更为重要的是，它促进了国内外先进技术的交流与融合。通过这样一个平台，国内开发者不仅能够接触到最新的大模型技术，还可以根据自身需求灵活选择最适合的模型，从而推动国内AI应用的发展。</p><p>ModelBridge官网：<a href="https://model-bridge.okeeper.com" target="_blank" rel="noopener">https://model-bridge.okeeper.com</a>  注册即可免费体验！！！</p><h2 id="结语"><a class="markdownIt-Anchor" href="#结语"></a> 结语</h2><p>技术的进步永无止境，即便面临挑战，总有方法让我们跨越障碍，共享科技发展带来的成果。正如ModelBridge所做的那样，它不仅是一座连接国内外优秀资源的桥梁，更是每一位追求卓越的技术爱好者实现梦想的助力者。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> OpenAI </tag>
            
            <tag> Baidu </tag>
            
            <tag> API 代理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能技术发展史</title>
      <link href="/ren-gong-zhi-neng/2024-ren-gong-zhi-neng-fa-zhan-yu-ce/"/>
      <url>/ren-gong-zhi-neng/2024-ren-gong-zhi-neng-fa-zhan-yu-ce/</url>
      
        <content type="html"><![CDATA[<h1 id="2024年人工智能最新进展全面分析"><a class="markdownIt-Anchor" href="#2024年人工智能最新进展全面分析"></a> 2024年人工智能最新进展全面分析</h1><p>随着科技的不断进步，2024年将迎来人工智能领域的一系列重要突破和趋势。这些进展不仅将改变各行各业的面貌，还将深刻影响我们的日常生活。以下是几大关键趋势和突破性技术的详细剖析。</p><h3 id="生成式ai"><a class="markdownIt-Anchor" href="#生成式ai"></a> 生成式AI</h3><p>生成式AI在2024年将继续快速发展，逐步从炒作走向实际应用。生成式AI技术能够创作文本、图像、音乐等多种形式的内容，这在教育、娱乐、广告等领域有着广泛的应用。未来，我们可能会看到更多的生成式AI驱动的“超级应用”出现，这些应用将使AI能够更智能地辅助完成复杂任务，如自动化编写报告、生成创意广告等。</p><h3 id="多模态ai"><a class="markdownIt-Anchor" href="#多模态ai"></a> 多模态AI</h3><p>AI模型将从单一模式转向多模态，这意味着AI将能够同时处理文本、图像、音频等多种类型的数据。多模态AI的进步将大幅提升机器理解和生成内容的能力，促进医疗、金融、自动驾驶等领域的创新。例如，医疗诊断系统可以结合影像、病历和基因数据提供更准确的诊断和治疗方案。</p><h3 id="ai的民主化"><a class="markdownIt-Anchor" href="#ai的民主化"></a> AI的民主化</h3><p>随着AI技术的普及和易用性提升，AI的民主化趋势愈加明显。更多的中小企业和个人开发者将能够利用AI技术开发创新应用。这一趋势将推动AI技术在各行各业的广泛应用，促进经济增长和社会进步。</p><h3 id="小型化语言模型"><a class="markdownIt-Anchor" href="#小型化语言模型"></a> 小型化语言模型</h3><p>小型化语言模型在性能和资源消耗之间取得了平衡，使得AI能够在资源受限的环境中运行，例如移动设备和物联网设备。这将推动AI技术在日常生活中的应用，如智能家居、智能助手等。</p><h3 id="ai伦理"><a class="markdownIt-Anchor" href="#ai伦理"></a> AI伦理</h3><p>随着AI技术的广泛应用，AI伦理问题也变得越来越重要。2024年，关于数据隐私、算法透明度和公平性的讨论将更加深入。开发者和企业需要制定更严格的伦理规范和法律法规，以确保AI技术的安全和可信。</p><h3 id="人工通用智能agi"><a class="markdownIt-Anchor" href="#人工通用智能agi"></a> 人工通用智能（AGI）</h3><p>虽然AGI仍处于研究阶段，但2024年可能会看到一些重要的理论突破。AGI旨在开发具有广泛认知能力的AI，能够自主学习和解决多领域复杂问题。尽管距离实现AGI还有很长的路要走，但其研究进展将为现有AI技术提供新的思路和方法。</p><h3 id="ai即服务aiaas"><a class="markdownIt-Anchor" href="#ai即服务aiaas"></a> AI即服务（AIaaS）</h3><p>AI即服务（AIaaS）将使企业能够通过云平台方便地获取和使用AI技术。通过AIaaS，企业无需自行开发和维护AI系统，而是可以直接使用由第三方提供的AI解决方案。2024年，AIaaS市场将进一步扩展，更多的企业将受益于这一模式。</p><h3 id="生成式ai内容创建"><a class="markdownIt-Anchor" href="#生成式ai内容创建"></a> 生成式AI内容创建</h3><p>生成式AI在内容创建领域的应用将更加广泛和深入。例如，自动生成新闻报道、小说、音乐、视频等内容。通过生成式AI，内容创作者可以大幅提升创作效率，探索新的创意形式。与此同时，生成式AI也将面临版权和道德方面的挑战，需要在技术和法律层面加以规范。</p><h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3><p>2024年，人工智能技术将继续推进，多个领域的应用将更加成熟和普及。生成式AI、多模态AI、AI的民主化、小型化语言模型和AI伦理等关键趋势将推动AI技术在各行各业的深度融合。同时，人工通用智能、AI即服务和生成式AI内容创建等突破性技术将为未来带来更多可能性。我们期待在新的一年中，人工智能能够为社会带来更多价值和创新。</p><p>这篇文章旨在为精通技术的读者提供关于2024年人工智能最新进展的全面洞察，帮助他们理解这些技术趋势的具体应用和潜在影响。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
            <tag> 大语言模型 </tag>
            
            <tag> LLM </tag>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>存储引擎RocksDB工作原理</title>
      <link href="/hou-duan-jia-gou/cun-chu-yin-qing-rocksdb-gong-zuo-yuan-li/"/>
      <url>/hou-duan-jia-gou/cun-chu-yin-qing-rocksdb-gong-zuo-yuan-li/</url>
      
        <content type="html"><![CDATA[<h2 id="rocksdb简介"><a class="markdownIt-Anchor" href="#rocksdb简介"></a> RocksDB简介</h2><p>RocksDB是一个高性能读写、可扩展、嵌入式、持久化、可靠、易用及可定制的键值数据库。内部采用LSM-Tree数据，支持高吞吐的写入和快速的范围查找。</p><p>RocksDB是一种嵌入式数据库，2012年基于谷歌的LevelDB分叉而来，最初由Dhruba Borthakur在Facebook创建，目的是提高服务器工作负载性能。目前，RocksDB由Meta开发和维护。</p><p>使用RocksDB存储引擎的分布式数据库有许多，其中一些比较著名的包括：</p><p>​1.<strong>TiDB</strong>：TiDB 是一款开源的分布式关系型数据库，兼容 MySQL 协议。它将 RocksDB 用作底层存储引擎，并通过 Raft 协议实现高可用和分布式一致性。</p><p>​2.<strong>CockroachDB</strong>：CockroachDB 是一个分布式 SQL 数据库，支持水平扩展和强一致性。它使用 RocksDB 作为存储引擎来管理数据的持久化。</p><p>​3.<strong>YugabyteDB</strong>：YugabyteDB 是一个开源的高性能分布式 SQL 数据库，支持 PostgreSQL 和 Cassandra 的接口。它采用 RocksDB 作为存储引擎，提供强一致性和线性扩展能力。</p><p>​4.<strong>ScyllaDB</strong>：ScyllaDB 是一个高性能的 NoSQL 数据库，兼容 Apache Cassandra。它在某些场景下也可以选择使用 RocksDB 作为存储引擎，以提升性能。</p><p>​5.<strong>MyRocks</strong>：MyRocks 是基于 MySQL 的一个分支实现，直接使用 RocksDB替换InnoDB存储引擎 来提高写入性能和压缩比。这使得 MyRocks 成为一个支持高吞吐量和低延迟的存储解决方案。</p><h2 id="rocksdb有几个特点"><a class="markdownIt-Anchor" href="#rocksdb有几个特点"></a> RocksDB有几个特点：</h2><ol><li>嵌入式数据库，所谓嵌入式即它没有独立的进程，而是集成到应用中和应用共享内存资源</li><li>它没有内置服务器，无法通过网络进行远程访问</li><li>它不是分布式的，它不提供分区容错性、高可用及分片机制</li><li>RocksDB是以Key-Value形式存储数据，Key、value都是任意长度的字节数组(Byte array),因此他没有数据类型</li><li>适合写大于读的场景，支持大量数据存储，写更快、存储空间占用更小（紧凑存储）</li></ol><h2 id="如何才能进行硬件的快速读写"><a class="markdownIt-Anchor" href="#如何才能进行硬件的快速读写"></a> 如何才能进行硬件的快速读写</h2><p>快速读写硬件的性能主要取决于如何有效利用内存和磁盘的 I/O 特性。</p><p><strong>磁盘在随机IO和顺序IO之间的差异</strong>：</p><p>​•随机 I/O：HDD 通过磁头读取数据，随机访问需要磁头移动和盘片旋转，导致较高的寻道时间和旋转延迟。</p><p>​•顺序 I/O：顺序访问数据时，磁头只需很少的移动或不移动，数据连续读取，减少了寻道时间和旋转延迟，性能明显提高。</p><h3 id="innodb-的写入机制"><a class="markdownIt-Anchor" href="#innodb-的写入机制"></a> InnoDB 的写入机制</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/watermark%2Ctype_ZHJvaWRzYW5zZmFsbGJhY2s%2Cshadow_50%2Ctext_Q1NETiBAbHZxaW5nbG91%2Csize_20%2Ccolor_FFFFFF%2Ct_70%2Cg_se%2Cx_16.png" alt="img"></p><p>如图所示：</p><ol><li>第一步：在内存中新增undolog用于MVCC(多版本事务控制)，方便事务的后续回滚，如果执行失败或事物提交会标记为待删除。</li><li>第二部：在buffer pool缓冲池中找到要修改的行所在页(MySQL中数据操作最小单位)，如果找不到会报缺页，等待从磁盘中进行加载</li><li>第三部：顺序写入Redo log buffer,会按照策略进行同步或者异步镜像系统刷盘</li><li>Checkpoint: 后台异步线程会定时或者达到刷盘条件时，触发Double writer机制，保证异步离散写的数据一致性(mysql 16K的页对应系统4个4K的页)</li></ol><p>从上面第二部可以看出，Mysql其实是原地写，即要找到原来的记录进行修改，如果缓存池中频繁报缺页，写入性能势必会收到影响</p><p><strong>接下来我们看看RocksDB它是如何做的？它是如何利用磁盘的顺序写同时还保证了写的性能的</strong></p><h2 id="lsm-treelog-structure-merge-tree"><a class="markdownIt-Anchor" href="#lsm-treelog-structure-merge-tree"></a> LSM-Tree（Log Structure Merge tree）</h2><p>RocksDB采用的是LSM树（Log-Structure merge Tree）的数据结构, 它是将所有的数据修改(增删改)都记录内存的顺序memtable和磁盘顺序的日志文件中(Write-Ahead Log,WAL)中，在由异步“Flush”流程，将内存的memtable慢慢归并成L0、L1、12…Ln的磁盘文件中。如下图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-qjpy-20240720190601835.png" alt></p><p>LSM-Tree 的顶层保存在内存中，包含最近插入的数据。较低层存储在磁盘上，编号从 0 到 N。0 级 (L0) 存储从内存移动到磁盘的数据，1 级及以下存储较旧的数据。当某个层变得太大时，它会与下一个层合并，而下一个层通常比前一个层大一个数量级。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-lsm.png" alt="img"></p><p>为了更好地理解 LSM 树的工作原理，让我们仔细看看写入数据的过程。</p><h2 id="写入数据"><a class="markdownIt-Anchor" href="#写入数据"></a> 写入数据</h2><h3 id="预写日志"><a class="markdownIt-Anchor" href="#预写日志"></a> 预写日志</h3><p>无论是在进程意外崩溃退出还是计划内重启时，其内存中的数据都会丢失。为了防止数据丢失，保证数据的持久化，除了 MemTable 之外，RocksDB 会将所有更新写入到磁盘上的预写日志（WAL，Write-ahead log）中。这样，在重启后，数据库可以回放日志，进而恢复 MemTable 的原始状态。</p><p>WAL 是一个只允许追加的文件，包含一组更改记录序列。每个记录包含键值对、记录类型（Put / Merge / Delete）和校验和（checksum）。与 MemTable 不同，在 WAL 中，记录不按 key 有序，而是按照请求到来的顺序被追加到 WAL 中。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-wal.png" alt="img"></p><h3 id="memtable"><a class="markdownIt-Anchor" href="#memtable"></a> Memtable</h3><p>RocksDB会将内存划分为大小相近的memtable进行存储对对数据的增删改查操作，通常在memtable内部是一个SkipList结构，按Key顺序记录了当前key在当前这个memtable中最新的操作记录。当memtable满了时，会将当前active memtable改成immutable memtable（不可变的memtable），并同时生成一个新的active memtable供后续的写操作使用。</p><p><em>内存表的默认大小为 64MB。</em></p><p>例如添加以下键值</p><pre class="highlight"><code class>db.put(&quot;chipmunk&quot;, &quot;1&quot;)db.put(&quot;cat&quot;, &quot;2&quot;)db.put(&quot;raccoon&quot;, &quot;3&quot;)db.put(&quot;dog&quot;, &quot;4&quot;)</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-memtable.png" alt="img"></p><p>我们看到，尽管<code>chipmunk</code>是第一个插入的，但在MemTable中仍然排在<code>cat</code>之后，因为他是按key的顺序排序的，顺序排序的好处可以加快我们的检索效率(如用二分法、跳表、红黑树)</p><h3 id="flush"><a class="markdownIt-Anchor" href="#flush"></a> <strong>Flush</strong></h3><p>RocksDB 使用一个专门的后台线程定期地把不可变的 MemTable 从内存持久化到磁盘。一旦刷盘（flush）完成，不可变的 MemTable 和相应的 WAL 就会被丢弃。RocksDB 开始写入新的 WAL、MemTable。每次刷盘都会在 L0 层上产生一个新的 SST 文件。该文件一旦写入磁盘后，就不再会修改。</p><p>RocksDB 的 MemTable 的默认基于跳表实现。该数据结构是一个具有额外采样层的链表，从而允许快速、有序地查询和插入数据。有序性使得 MemTable 刷盘时更高效，因为可以直接按顺序迭代键值对顺序写入磁盘。<strong>将随机写变为顺序写是 LSM-Tree 的核心设计之一</strong>。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-flush.png" alt="img"></p><h3 id="sstablesorted-string-table"><a class="markdownIt-Anchor" href="#sstablesorted-string-table"></a> SSTable(Sorted String Table)</h3><p>SST 文件包括从 MemTable 刷盘而来的键值对，并且使用一种对查询友好的数据格式来存储。SST 是 Static Sorted Table 的缩写（其他数据库中也称为 Sorted String Table）。它是一种基于块（ block） 的文件格式，会将数据切成固定大小的块（默认为 4KB）进行存储。RocksDB 支持各种压缩 SST 文件的压缩算法，例如 Zlib、BZ2、Snappy、LZ4 或 ZSTD 算法。与 WAL 的记录类似，每个数据块中都包含用于检测数据是否损坏的校验和。每次从磁盘读取数据时，RocksDB 都会使用这些校验和进行校验。</p><p>SST 文件由几个部分组成：首先是数据部分，包含一系列有序的键值对。key 的有序性可以让我们对 其进行增量编码，也即，对于相邻的 key ，我们可以只存其差值而非整个 key。</p><p>尽管 SST 中的 kv 对是有序的，我们也并非总能进行二分查找，尤其是数据块在压缩过后，会使得查找很低效。RocksDB 使用索引来优化查询，存储在紧邻数据块之后的索引块。Index 会把每个 block 数据中最后一个 key 映射到它在磁盘上的对应偏移量。同样地，index 中的 key 也是有序的，因此我们可以通过二分搜索快速找到某个 key。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-sst.png" alt="img"></p><h3 id="compaction压缩"><a class="markdownIt-Anchor" href="#compaction压缩"></a> Compaction（压缩）</h3><p>到现在为止，一个功能完备的键值存储引擎讲完了。但如果这样直接上生产环境，会有一些问题：空间放大（space amplifications）和读放大（read amplifications）。空间放大是存储数据所用实际空间与逻辑上数据大小的比值。假设一个数据库需要 2 MB 磁盘空间来存储逻辑上的 1 MB 大小的键值对是，那么它的空间放大率是 2。类似地，读放大用来衡量用户执行一次逻辑上的读操作，系统内所需进行的实际 IO 次数。作为一个小练习，你可以尝试推演下什么是写放大。</p><p>现在，让我们向数据库添加更多 key 并删除当中的一些 key：</p><pre class="highlight"><code class>db.delete(&quot;chipmunk&quot;)db.put(&quot;cat&quot;, &quot;5&quot;)db.put(&quot;raccoon&quot;, &quot;6&quot;)db.put(&quot;zebra&quot;, &quot;7&quot;)// Flush triggersdb.delete(&quot;raccoon&quot;)db.put(&quot;cat&quot;, &quot;8&quot;)db.put(&quot;zebra&quot;, &quot;9&quot;)db.put(&quot;duck&quot;, &quot;10&quot;)</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-compaction1.png" alt="img"></p><p>随着我们的不断写入，MemTable 不断被刷到磁盘，L0 上的 SST 文件数量也在增长：</p><ul><li>删除或更新 key 所占用的空间永远不会被回收。例如，<code>cat</code> 这个 key 的三次更新记录分别在 SST1，SST2 和 SST3 中，而 <code>chipmunk</code> 在 SST1 中有一次更新记录，在 SST2 中有一次删除记录，这些无用的记录仍然占用额外磁盘空间。</li><li>随着 L0 上 SST 文件数量的增加，读取变得越来越慢。每次查找都要逐个检查所有 SST 文件。</li></ul><p>RocksDB 引入了压实（ Compaction ）机制，可以降低空间放大和读放大，但代价是更高的写放大。Compaction 会将某层的 SST 文件同下一层的 SST 文件合并，并在这个过程中丢弃已删除和被覆盖的无效 key。Compaction 会在后台专用的线程池中运行，从而保证了 RocksDB 可以在做 Compaction 时能够正常处理用户的读写请求。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-compaction2.png" alt="img"></p><p>Leveled Compaction 是 RocksDB 中的默认 Compaction 策略。使用 Leveled Compaction，L0 层中的不同 SST 文件键范围会重叠。L1 层及以下层会被组织为包含多个 SST 文件的序列，并保证同层级内的所有 SST 在键范围上没有交叠，且 SST 文件之间有序。Compaction 时，会选择性地将某层的 SST 文件与下一层的 key 范围有重叠 SST 文件进行合并。</p><p>举例来说，如下图所示，在 L0 到 L1 层进行 Compaction 时，如果 L0 上的输入文件覆盖整个键范围，此时就需要对所有 L0 和 L1 层的文件进行 Compaction。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-compaction3.png" alt="img"></p><p>而像是下面的这种 L1 和 L2 层的 Compaction，L1 层的输入文件只与 L2 层的两个 SST 文件重叠，因此，只需要对部分文件进行 Compaction 即可。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-compaction4.png" alt="img"></p><p>当 L0 层上的 SST 文件数量达到一定阈值（默认为 4）时，将触发 Compaction。对于 L1 层及以下层级，当整个层级的 SST 文件总大小超过配置的目标大小时，会触发 Compaction 。当这种情况发生时，可能会触发 L1 到 L2 层的 Compaction。从而，从 L0 到 L1 层的 Compaction 可能会引发一直到最底层级联 Compaction。在 Compaction 完成之后，RocksDB 会更新元数据并从磁盘中删除 已经被 Compcated 过的文件。</p><p><em>注：RocksDB 提供了不同 Compaction 策略来在空间、读放大和写放大之间进行权衡</em>。</p><p>看到这里，你还记得上文提过 SST 文件中的 key 是有序的吗？有序性允许使用 K 路归并算法逐步合并多个 SST 文件。K 路归并是两路归并的泛化版本，其工作方式类似于归并排序的归并阶段。</p><h2 id="读取数据过程"><a class="markdownIt-Anchor" href="#读取数据过程"></a> 读取数据过程</h2><p>使用持久化在磁盘上不可变的 SST 文件，读路径要比写路径简单很多。要找寻某个 key，只需自顶而下遍历 LSM—Tree。从 MemTable 开始，下探到 L0，然后继续向更低层级查找，直到找到该 key 或者检查完所有 SST 文件为止。</p><p>以下是查找步骤：</p><ol><li>检索 MemTable。</li><li>检索不可变 MemTables。</li><li>搜索最近 flush 过的 L0 层中的所有 SST 文件。</li><li>对于 L1 层及以下层级，首先找到可能包含该 key 的单个 SST 文件，然后在文件内进行搜索。</li></ol><p>搜索 SST 文件涉及：</p><ol><li>（可选）探测布隆过滤器。</li><li>查找 index 来找到可能包含这个 key 的 block 所在位置。</li><li>读取 block 文件并尝试在其中找到 key。</li></ol><p>这就是全部所需步骤了！看看这个 LSM-Tree：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/rocksdb-lookup.png" alt="img"></p><p>根据待查找的 key 的具体情况，查找过程可能在上面任意步骤提前终止。例如，在搜索 MemTable 后，key “cat” 或 “chipmunk” 的查找工作会立即结束。查找 “raccoon” 则需要搜索 L1 为止，而查找根本不存在的 “manul” 则需要搜索整个树。</p><h2 id="rocksdb的优缺点"><a class="markdownIt-Anchor" href="#rocksdb的优缺点"></a> RocksDB的优缺点</h2><p>RocksDB是一种高性能的嵌入式键值存储引擎，具有以下优点和缺点：</p><p><strong>优点</strong>：</p><ol><li><p>高性能：RocksDB采用LSM-Tree数据结构，具有高效的写入性能，同时使用Bloom Filter和Block Cache等技术，具有高效的读取性能，可以在高负载和大规模数据情况下保持高性能。</p></li><li><p>灵活性：RocksDB具有丰富的配置选项和插件机制，可以根据不同的应用场景和需求进行灵活的调整和扩展，例如支持不同的压缩算法、过滤器和存储引擎等。</p></li><li><p>可扩展性：RocksDB支持水平扩展和自动容错，可以通过添加新的节点，来提高系统的吞吐量和存储容量。</p></li><li><p>多语言支持：RocksDB支持多种编程语言，包括C++、Java、Python等，可以方便地在不同的应用场景下使用。</p></li><li><p>稳定性：RocksDB是Facebook开发的开源项目，已经经过多年的稳定运行和优化，具有高可靠性和稳定性</p><p><strong>缺点</strong>：</p></li><li><p>内存占用较高：由于RocksDB需要维护多个LSM树，需要占用较多的内存空间，对于内存资源较为紧张的环境可能不太适用。</p></li><li><p>存储空间浪费：RocksDB的LSM-Tree结构需要占用更多的磁盘空间，对于存储资源较为紧张的环境可能造成浪费。</p></li><li><p>部署复杂：RocksDB需要根据实际的应用场景进行配置和调整，需要专业的系统管理员进行管理和维护。</p></li><li><p>写放大问题：RocksDB的LSM-Tree结构可能会造成写放大问题，即需要更多的磁盘I/O来保证数据的一致性和可靠性。</p></li><li><p>不支持分布式事务：RocksDB是一种嵌入式存储引擎，不支持分布式事务，需要借助其他组件（如TiDB）来实现分布式事务。</p></li></ol><h2 id="rocksdb-为什么快"><a class="markdownIt-Anchor" href="#rocksdb-为什么快"></a> <strong>RocksDB 为什么快</strong></h2><p>RocksDB 的高性能源于其 LSM-Tree 架构，同时还有很多技术优化，如高效的写入路径、多级 Compaction 策略、高效的缓存机制、并发优化以及读取优化等，如下：</p><p>​1.<strong>LSM-Tree（Log-Structured Merge-Tree）架构</strong>：</p><p>​•<strong>高效写入</strong>：LSM-Tree 将所有写入操作首先写入内存中的 MemTable，然后顺序写入 WAL（Write-Ahead Log），最后在后台合并到 SSTables（Sorted String Tables）。这种设计避免了随机写入磁盘，提高了写入吞吐量。</p><p>​•<strong>后台合并</strong>：通过后台的 Compaction 过程，将多个 SSTables 合并成更大的 SSTables，进一步优化磁盘 I/O 并减少读放大。</p><p>​2.<strong>多级 Compaction 策略</strong>：</p><p>​•<strong>Level Compaction</strong>：将 SSTables 分层存储，通过逐层合并减少读放大和磁盘空间的浪费。</p><p>​•<strong>Universal Compaction</strong>：适用于需要快速写入的大型数据集，通过更灵活的合并策略进一步优化写性能。</p><p>​3.<strong>高效的缓存机制</strong>：</p><p>​•<strong>Block Cache</strong>：缓存 SSTables 的数据块，减少磁盘读取，提高读性能。</p><p>​•<strong>Table Cache</strong>：缓存 SSTables 的元数据，快速定位数据块，减少不必要的磁盘 I/O。</p><p>​4.<strong>高效的写入路径</strong>：</p><p>​•<strong>WAL（Write-Ahead Log）</strong>：顺序写入日志，确保数据持久性，减少写入延迟。</p><p>​•<strong>MemTable</strong>：内存中的写入缓冲区，快速写入数据，然后批量刷入磁盘。</p><p>​5.<strong>高并发和低延迟</strong>：</p><p>​•<strong>多线程 Compaction</strong>：利用多线程进行后台合并，充分利用多核 CPU，提高并发性。</p><p>​•<strong>Fine-grained Locking</strong>：细粒度锁机制，减少锁争用，提高并发性能。</p><p>​6.<strong>优化的读取路径</strong>：</p><p>​•<strong>Bloom Filters</strong>：使用布隆过滤器快速过滤不存在的键，减少不必要的磁盘 I/O。</p><p>​•<strong>Prefix Seek</strong>：前缀查找优化，快速定位相关键值对。</p><p>通过这些优化，RocksDB 提供了卓越的性能和可靠性，成为许多高性能应用的首选存储引擎。</p><h2 id="适合场景"><a class="markdownIt-Anchor" href="#适合场景"></a> 适合场景</h2><p>​1.<strong>高写入吞吐量的应用</strong>：</p><p>​•由于 LSM-Tree 的架构和高效的写入路径，RocksDB 非常适合需要高写入吞吐量的应用，如日志收集、时间序列数据存储等。</p><p>​2.<strong>低延迟的实时应用</strong>：</p><p>​•RocksDB 的多级缓存和高效的读写路径使其适合低延迟的实时应用，如实时分析、实时消息处理等。</p><p>​3.<strong>高并发访问的应用</strong>：</p><p>​•RocksDB 的细粒度锁机制和多线程 Compaction 支持高并发访问，非常适合高并发的在线服务，如社交媒体平台、电子商务网站等。</p><p>​4.<strong>嵌入式存储需求</strong>：</p><p>​•由于其嵌入式设计，RocksDB 非常适合作为大型系统的嵌入式存储引擎，如数据库系统的存储引擎、分布式存储系统等。</p><p>​5.<strong>大规模数据存储</strong>：</p><p>​•RocksDB 的多级 Compaction 策略和高效的磁盘空间管理使其适合大规模数据存储应用，如数据仓库、大数据分析平台等。</p>]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式数据库 </tag>
            
            <tag> KV存储引擎 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/hou-duan-jia-gou/jvm/"/>
      <url>/hou-duan-jia-gou/jvm/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Flink技术架构及原理</title>
      <link href="/hou-duan-jia-gou/flink-ji-zhu-yuan-li/"/>
      <url>/hou-duan-jia-gou/flink-ji-zhu-yuan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="flink简介"><a class="markdownIt-Anchor" href="#flink简介"></a> Flink简介</h1><p>Flink是一个用于分布式流处理和批处理的大数据处理框架。它由Apache基金会维护，旨在提供高吞吐量、低延迟的数据处理能力，并且支持复杂的事件处理和状态管理。它的重点能力就是<strong>同时支持批处理和流处理的有状态计算</strong></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/watermark%2Ctype_ZmFuZ3poZW5naGVpdGk%2Cshadow_10%2Ctext_aHR0cHM6Ly9saXhpbmt1YW4uYmxvZy5jc2RuLm5ldA%3D%3D%2Csize_16%2Ccolor_FFFFFF%2Ct_70-20240605144243247.png" alt></p><p>Flink起源于Stratosphere项目，Stratosphere是在2010~2014年由3所地处柏林的大学和欧洲的一些其他的大学共同进行的研究项目，2014年4月Stratosphere的代码被复制并捐赠给了Apache软件基金会，参加这个孵化项目的初始成员是Stratosphere系统的核心开发人员，2014年12月，Flink一跃成为Apache软件基金会的顶级项目。</p><h3 id="应用场景"><a class="markdownIt-Anchor" href="#应用场景"></a> 应用场景</h3><ol><li>实时智能推荐</li><li>复杂时间流处理</li><li>实时反欺诈检测</li><li>实时数仓与ETL</li><li>数据流分析和报表统计</li></ol><h3 id="flink的特点"><a class="markdownIt-Anchor" href="#flink的特点"></a> Flink的特点</h3><ul><li><p><strong>高吞吐、低延迟、高性能</strong>：Flink能够同时支持高吞吐、低延迟、高性能的流处理，使其成为处理大规模、高吞吐量的实时数据流和批量数据的首选</p></li><li><p><strong>事件时间支持</strong>：Flink支持事件时间(event time)概念，结合watermark处理乱序数据，这使得Flink在处理乱序事件流时能够提供一致且准确的结果</p></li><li><p><strong>有状态计算</strong>：Flink支持有状态计算，并且支持多种状态存储方式，如内存、文件、RocksDB，这使得Flink能够维护复杂的计算状态，提高计算效率</p></li><li><p><strong>精确一次的状态一致性保证</strong>：基于轻量级分布式快照(checkpoint)实现的容错保证exactly- once语义，确保了数据处理的准确性和一致性</p></li><li><p><strong>灵活的窗口操作</strong>：支持高度灵活的窗口操作，如time、count、session等，使得Flink能够适应各种复杂的流数据处理需求</p></li><li><p><strong>支持多种编程语言和API</strong>：Flink提供了丰富的API，包括Java和Scala的API，以及SQL和Table API，使得开发者可以根据自己的需求选择合适的编程语言进行开发</p></li></ul><h3 id="flink与storm-spark-streaming的比较"><a class="markdownIt-Anchor" href="#flink与storm-spark-streaming的比较"></a> Flink与Storm、Spark Streaming的比较</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/webp" alt></p><ul><li><p><strong>实时性</strong>：Flink提供了比Storm和Spark Streaming更低的延迟，能够实现毫秒级的实时处理，而Storm和Spark Streaming虽然也能处理实时数据，但在某些场景下可能无法满足低延迟的要求</p></li><li><p><strong>吞吐量</strong>：Flink在吞吐量方面表现出色，能够处理大规模的数据流，而Storm和Spark Streaming虽然也能处理大规模数据，但在某些场景下可能无法达到Flink的吞吐量</p></li><li><p><strong>容错性和状态管理</strong>：Flink提供了精确一次的状态一致性保证，以及基于轻量级分布式快照的容错机制，这使得Flink在容错性和状态管理方面表现更加优秀</p></li><li><p><strong>编程模型和API</strong>：Flink提供了丰富的API和灵活的编程模型，支持多种编程语言，使得开发者可以更加方便地构建复杂的流处理应用</p></li></ul><h1 id="flink架构"><a class="markdownIt-Anchor" href="#flink架构"></a> Flink架构</h1><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1717556697669.png" alt></p><p><em>Client</em> 不是运行时和程序执行的一部分，而是用于准备数据流并将其发送给 JobManager。之后，客户端可以断开连接（<em>分离模式</em>），或保持连接来接收进程报告（<em>附加模式</em>）。客户端可以作为触发执行 Java/Scala 程序的一部分运行，也可以在命令行进程<code>./bin/flink run ...</code>中运行。</p><p>可以通过多种方式启动 JobManager 和 TaskManager：直接在机器上作为<a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/deployment/resource-providers/standalone/overview/" target="_blank" rel="noopener">standalone 集群</a>启动、在容器中启动、或者通过<a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/deployment/resource-providers/yarn/" target="_blank" rel="noopener">YARN</a>等资源框架管理并启动。TaskManager 连接到 JobManagers，宣布自己可用，并被分配工作。</p><p><strong>Flink的架构包括以下几个关键组件：</strong></p><h4 id="jobmanager"><a class="markdownIt-Anchor" href="#jobmanager"></a> <strong>JobManager</strong></h4><p><em>JobManager</em> 具有许多与协调 Flink 应用程序的分布式执行有关的职责：它决定何时调度下一个 task（或一组 task）、对完成的 task 或执行失败做出反应、协调 checkpoint、并且协调从失败中恢复等等。这个进程由三个不同的组件组成：</p><ul><li><strong>ResourceManager</strong>负责 Flink 集群中的资源提供、回收、分配 - 它管理 <strong>task slots</strong>，这是 Flink 集群中资源调度的单位（请参考<a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/concepts/flink-architecture/#taskmanagers" target="_blank" rel="noopener">TaskManagers</a>）。Flink 为不同的环境和资源提供者（例如 YARN、Kubernetes 和 standalone 部署）实现了对应的 ResourceManager。在 standalone 设置中，ResourceManager 只能分配可用 TaskManager 的 slots，而不能自行启动新的 TaskManager。</li><li><strong>Dispatcher</strong>提供了一个 REST 接口，用来提交 Flink 应用程序执行，并为每个提交的作业启动一个新的 JobMaster。它还运行 Flink WebUI 用来提供作业执行信息。</li><li><strong>JobMaster</strong>负责管理单个<a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/concepts/glossary/#logical-graph" target="_blank" rel="noopener">JobGraph</a>的执行。Flink 集群中可以同时运行多个作业，每个作业都有自己的 JobMaster。<br>始终至少有一个 JobManager。高可用（HA）设置中可能有多个 JobManager，其中一个始终是 <em>leader</em>，其他的则是 <em>standby</em>（请参考 <a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/deployment/ha/overview/" target="_blank" rel="noopener">高可用（HA）</a>）。</li></ul><h4 id="taskmanager"><a class="markdownIt-Anchor" href="#taskmanager"></a> <strong>TaskManager</strong></h4><p><strong>TaskManager</strong>负责实际执行任务，管理任务的状态和数据流动。<em>TaskManager</em>（也称为 <em>worker</em>）执行作业流的 task，并且缓存和交换数据流。必须始终至少有一个 TaskManager。在 TaskManager 中资源调度的最小单位是 task <em>slot</em>。TaskManager 中 task slot 的数量表示并发处理 task 的数量。请注意一个 task slot 中可以执行多个算子（请参考<a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/zh/docs/concepts/flink-architecture/#tasks-and-operator-chains" target="_blank" rel="noopener">Tasks 和算子链</a>）。</p><h2 id="tasks-和算子链"><a class="markdownIt-Anchor" href="#tasks-和算子链"></a> Tasks 和算子链</h2><p>对于分布式执行，Flink 将算子的 subtasks <em>链接</em>成 <em>tasks</em>。每个 task 由一个线程执行。将算子链接成 task 是个有用的优化：它减少线程间切换、缓冲的开销，并且减少延迟的同时增加整体吞吐量。</p><p>下图中，假设Source、map的并行度是2，keyBy()/window()/apply()的并行度也是2，而最终结果的输出处理sink只有1个并行。那么由于Source()和map()处理的相关性将优化成到一个slot由一个线程进行处理，而key()/window()/apply()等这种需要有状态计算的subtask可以优化到另外一个slot由一个线程进行处理，最终将结果汇集到一个subtask中进行汇总计算，最终整个job将有5个Solt进行计算</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1717555608114.png" alt></p><p><img src alt></p><h1 id="窗口"><a class="markdownIt-Anchor" href="#窗口"></a> 窗口</h1><p>窗口本质就是将无限数据集沿着时间（或者数量）的边界切分成有限数据集。在流处理系统中，窗口（Window）用于将无限的数据流划分为有限的部分进行处理。Flink支持多种类型的窗口：</p><ol><li><p><strong>Time Window</strong>：基于时间的，分为Tumbling Window（无数据重叠）和Sliding Window（有数据重叠） 。</p></li><li><p><strong>Count Window</strong>：基于数量的，分为Tumbling Window（无数据重叠）和Sliding Window（有数据重叠）。</p></li><li><p><strong>Session Window</strong>：基于会话的，一个session window关闭通常是由于一段时间没有收到元素。</p></li><li><p><strong>Global Window</strong>：全局窗口。</p></li></ol><h1 id="如何保证消息的可靠性"><a class="markdownIt-Anchor" href="#如何保证消息的可靠性"></a> 如何保证消息的可靠性</h1><p>实时任务不同于批处理任务，除非用户主动停止，一般会一直运行，运行的过程中可能存在机器故障、网络问题、外界存储问题等等，要想实时任务一直能够稳定运行，实时任务要有自动容错恢复的功能。而批处理任务在遇到异常情况时，在重新计算一遍即可。实时任务因为会一直运行的特性，如果在从头开始计算，成本会很大，尤其是对于那种运行时间很久的实时任务来说。</p><p>实时任务开启 Checkpoint 功能，也能够减少容错恢复的时间。因为每次都是从最新的 Chekpoint 点位开始状态恢复，而不是从程序启动的状态开始恢复。举个列子，如果你有一个运行一年的实时任务，如果容错恢复是从一年前启动时的状态恢复，实时任务可能需要运行很久才能恢复到现在状态，这一般是业务方所不允许的。</p><h2 id="checkpoint机制"><a class="markdownIt-Anchor" href="#checkpoint机制"></a> Checkpoint机制</h2><p>Flink Checkpoint 是一种容错恢复机制。这种机制保证了实时程序运行时，即使突然遇到异常或者机器问题时也能够进行自我恢复。Flink Checkpoint 对于用户层面来说，是透明的，用户会感觉实时任务一直在运行。</p><p>Flink Checkpoint 是 Flink 自身的系统行为，用户无法对其进行交互，用户可以在程序启动之前，设置好实时任务 Checkpoint 相关的参数，当任务启动之后，剩下的就全交给 Flink 自行管理。</p><h2 id="什么是flink任务的状态state"><a class="markdownIt-Anchor" href="#什么是flink任务的状态state"></a> 什么是Flink任务的状态State</h2><p>Flink 任务状态可以理解为实时任务计算过程中，中间产生的数据结果，同时这些计算结果会在后续实时任务处理时，能够继续进行使用。实时任务的状态可以是一个聚合结果值，比如 WordCount 统计的每个单词的数量，也可以是消息流中的明细数据。</p><p>Flink 任务状态整体可以划分两种：Operator 状态和 KeyedState。常见的 Operator 状态，比如 Kafka Topic 每个分区的偏移量。KeyedState 是基于 KeyedStream 来使用的，所以在使用前，你需要对你的流通过 keyby 来进行分区，常见的状态比如有 MapState、ListState、ValueState 等等。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/--1-4.png" alt></p><h2 id="checkpoint流程和原理"><a class="markdownIt-Anchor" href="#checkpoint流程和原理"></a> Checkpoint流程和原理</h2><p>要开启任务的额Checkpoint，要进行配置。一种是在Job代码中设置，如下,设置了开启checkpoint功能，并设置CheckpointMode为<strong>EXACTLY_ONCE</strong>, 使用RocksDB进行存储：</p><pre class="highlight"><code class="java"><span class="hljs-type">StreamExecutionEnvironment</span> <span class="hljs-variable">env</span> <span class="hljs-operator">=</span> StreamExecutionEnvironment.getExecutionEnvironment();<span class="hljs-comment">/** 开启 checkpoint 功能 */</span>env. enableCheckpointing ( interval: <span class="hljs-number">3000</span>, CheckpointingMode.EXACTLY_ONCE);<span class="hljs-comment">/** 使用RocksDB 进行状态存储 */</span>env.setStateBackend(<span class="hljs-keyword">new</span> <span class="hljs-title class_">RocksDBStateBackend</span> ( checkpointDataUri: <span class="hljs-string">&quot;hdfsPath&quot;</span> )) ;</code></pre><p>由于 Flink 管理的 keyed state 是一种分片的键/值存储，每个 keyed state 的工作副本都保存在负责该键的 taskmanager 本地中。另外，Operator state 也保存在机器节点本地。Flink 定期获取所有状态的快照，并将这些快照复制到持久化的位置，例如分布式文件系统。</p><p>如果发生故障，Flink 可以恢复应用程序的完整状态并继续处理，就如同没有出现过异常。这个过程就是Checkpoint的容错和恢复的机制。</p><p>接下来先解释下两个概念</p><h3 id="statebackend"><a class="markdownIt-Anchor" href="#statebackend"></a> StateBackend</h3><p>Flink 管理的状态存储在 <em>state backend</em> 中，实现有三种：MemoryStateBackend、FsStateBackend、RocksDBStateBackend。三种状态存储方式与使用场景各不相同，对比如下:</p><table class="table table-bordered">  <thead>    <tr class="book-hint info">      <th class="text-left">名称</th>      <th class="text-left">Working State</th>      <th class="text-left">状态备份</th>      <th class="text-left">快照</th>    </tr>  </thead>  <tbody>    <tr>      <th class="text-left">RocksDBStateBackend</th>      <td class="text-left">本地磁盘（tmp dir）</td>      <td class="text-left">分布式文件系统</td>      <td class="text-left">全量/增量</td>    </tr>    <tr>      <td colspan="4" class="text-left">        <ul>          <li>支持大于内存大小的状态</li>          <li>经验法则：比基于堆的后端慢10倍</li>        </ul>      </td>    </tr>    <tr>      <th class="text-left">FsStateBackend</th>      <td class="text-left">JVM Heap</td>      <td class="text-left">分布式文件系统</td>      <td class="text-left">全量</td>    </tr>    <tr>      <td colspan="4" class="text-left">        <ul>          <li>快速，需要大的堆内存</li>          <li>受限制于 GC</li>        </ul>      </td>    </tr>    <tr>      <th class="text-left">MemoryStateBackend</th>      <td class="text-left">JVM Heap</td>      <td class="text-left">JobManager JVM Heap</td>      <td class="text-left">全量</td>    </tr>    <tr>      <td colspan="4" class="text-left">        <ul>          <li>适用于小状态（本地）的测试和实验</li>        </ul>      </td>    </tr>  </tbody></table><p>可以看到只有<strong>RocksDBStateBackend</strong>方式的working state是保存到磁盘中的，这就意味着这种存储方式最为可靠且支持大状态存储，但同时也比基于堆内存的存储更慢。</p><p><strong>所有这些 state backends 都能够异步执行快照，这意味着它们可以在不妨碍正在进行的流处理的情况下执行快照。</strong></p><h3 id="checkpointmode"><a class="markdownIt-Anchor" href="#checkpointmode"></a> CheckpointMode</h3><p>当流处理应用程序发生错误的时候，结果可能会产生丢失或者重复。Flink 根据你为应用程序和集群的CheckpointMode配置，可以产生以下结果：</p><ul><li>Flink 不会从快照中进行恢复（<em><code>CheckpointingMode.AT_MOST_ONCE</code></em>）</li><li>没有任何丢失，但是你可能会得到重复冗余的结果（<em>CheckpointingMode.AT_LEAST_ONCE</em>）</li><li>没有丢失或冗余重复（<em>CheckpointingMode.EXACTLY_ONCE</em>）</li></ul><p>其中精准不重复消费(<em>CheckpointingMode.EXACTLY_ONCE</em>),只是通过屏障对齐(Barrier alignment)保证了流处理内部的状态一致性，如果要确保严格的端到端精准只消费一次，还必须额外满足一下两个条件：</p><ol><li><p>你的 sources 必须是可重放的</p></li><li><p>你的 sinks 必须是事务性的（或幂等的）</p></li></ol><p>Barrier 只有在需要提供精确一次的语义保证时需要进行对齐（Barrier alignment）。如果不需要这种语义，可以通过配置 <code>CheckpointingMode.AT_LEAST_ONCE</code> 关闭 Barrier 对齐来提高性能。</p><h3 id="基于exactly_once的checkpoint过程"><a class="markdownIt-Anchor" href="#基于exactly_once的checkpoint过程"></a> 基于EXACTLY_ONCE的Checkpoint过程</h3><p>一次 Flink Checkpoint 的流程是从 <code>CheckpointCoordinator</code> 的 <code>triggerCheckpoint </code>方法开始，下面来看看一次 Flink Checkpoint 涉及到的主要内容：</p><ol><li>Checkpoint 开始之前先进行预检查，比如检查最大并发的 Checkpoint 数，最小的 Checkpoint 之间的时间间隔。默认情况下，最大并发的 Checkpoint 数为 1，最小的 Checkpoint 之间的时间间隔为 0.</li><li>判断所有 Source 算子的 Subtask (Execution) 是否都处于运行状态，有则直接报错。同时检查所有待确认的算子的 SubTask(Execution)是否是运行状态，有则直接报错。</li><li>创建 <code>PendingCheckpoint</code>，同时为该次 Checkpoint 创建一个 <code>Runnable</code>，即超时取消线程，默认 Checkpoint 十分钟超时。</li><li>循环遍历所有 Source 算子的 <code>Subtask(Execution)</code>,最底层调用 Task 的<code>triggerCheckpointBarrier</code>, 广播 CheckBarrier 到下游 ，同时 Checkpoint 其状态。</li><li>下游的输入中有 <code>CheckpointBarrierHandler</code> 类来处理 <code>CheckpoinBarrier</code>，然后会调用 <code>notifyCheckpoint</code> 方法，通知 Operator SubTask 进行 Checkpoint。</li><li>每当 Operator SubTask 完成 Checkpoint 时，都会向 <code>CheckpointCoordoritor</code> 发送确认消息。<code>CheckpointCoordinator</code> 的 <code>receiveAcknowledgeMessage</code> 方法会进行处理。</li><li>在一次 Checkpoint 过程中，当所有从 Source 端到 Sink 端的算子 SubTask 都完成之后，<code>CheckpointCoordoritor</code> 会通知算子进行 <code>notifyCheckpointCompleted</code> 方法，前提是算子的函数实现 <code>CheckpointListener</code> 接口。</li></ol><p>Flink 会定时在任务的 Source 算子的 SubTask 触发 <code>CheckpointBarrier</code>，<code>CheckpointBarrier</code> 是一种特殊的消息事件，会随着消息通道流入到下游的算子中。只有当最后 Sink 端的算子接收到 <code>CheckpointBarrier</code> 并确认该次 Checkpoint 完成时，该次 <code>Checkpoint</code> 才算完成。所以在某些算子的 Task 有多个输入时，会存在 Barrier 对齐时间，我们可以在 Flink Web UI上面看到各个 Task 的 <code>CheckpointBarrier</code> 对齐时间。</p><p>下图是一次 Flink Checkpoint 实例流程示意图：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/flink----.png" alt></p><h1 id="如何保证消息乱序的正确计算"><a class="markdownIt-Anchor" href="#如何保证消息乱序的正确计算"></a> 如何保证消息乱序的正确计算</h1><p>在分布式系统中的并发处理过程中，数据流在subtask间传输可能会乱序到达。这会导致我们在依赖时事件时间进行计算时出现错误结果。在Flink中是采用watermark机制进行解决。</p><p>在了解watermark之前先来理解下时间语义的几个概念。</p><ol><li><strong>事件时间（Event Time）</strong>：事件在源系统中生成的时间。Flink支持使用事件时间进行处理，使得处理更加准确。</li><li><strong>进入Flink时间（Ingestion Time）</strong>：事件进入Flink系统的时间。</li><li><strong>处理时间（Processing Time）</strong>：Flink处理事件的当前系统时间。</li></ol><p>那么一般情况下，我们所说的消息乱序是指基于时间时间的乱序，需要基于事件时间进行计算时，由于网络传输等原因，事件时间在到达处理节点是并不一定是顺序的，如下图所示的一个事件流：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/4f662ef225d04c03b0e65f6e62b11aa4.png" alt="在这里插入图片描述"></p><p>它的原理就相当于当数据流到达进行窗口计算时，不严格按照时间窗口定义的结束时间触发窗口计算，而是根据watermark设定的延迟时间适当地进行延迟计算，等一等迟到的数据。</p><p>watermark就是一个简单的周期性标记，上图中设置watermark的late time=4, 触发计算的事件窗口长度为20，当source的数据事件时间7达到之后，立刻生成watermark=3(7-4)特殊数据流插入到数据流后下发给下游，当11数据到达之后生成w(7)的watermark,以此类推…直到24数据到达时，watermark变成20，触发窗口结束计算，此后如果19这个数据再到达则直接丢弃，因为它小于watermark。</p><p>下游收到一个接收到watermark具体值时，代表这这个wartermark对于的事件时间前的事件数据已经达到，当时间窗口结束时间与watermark时间一致时，将触发窗口的结束计算，即使可能真的还有小于watermark时间的数据还没来，也不管了，先结束当前的事件窗口触发计算。</p><p>watermark有几个特点如下：</p><ol><li><p>当数据流到达后根据设置的watermark延迟时间计算出watermark,如果计算出的watermark大于之前收到的watermark值，则覆盖为最新的watermark，否则维持原有水位不变</p></li><li><p>watermark只能单调递增或者持平，不能递减</p></li><li><p>只有Source算子才会产生watermark</p><p><strong>如果真的有比watermark更晚的数据如何处理</strong></p></li></ol><p>flink有三种处理方式：</p><ol><li><p>直接丢弃（默认方式）</p></li><li><p>通过allowedLateness 指定允许数据延迟的时间</p><p>即使真的有数据达到watermark时间后还是迟到，可以在延迟回收计算好的窗口数据状态，等它来了之后再更新一下,如下代码：</p><pre class="highlight"><code class="java">waterMarkStream.keyBy(<span class="hljs-number">0</span>).window(TumblingEventTimeWindows.of(Time.seconds(<span class="hljs-number">3</span>))).allowedLateness(Time.seconds(<span class="hljs-number">2</span>))<span class="hljs-comment">//允许数据迟到2S</span><span class="hljs-comment">//function: (K, W, Iterable[T], Collector[R]) =&gt; Unit</span>.apply(<span class="hljs-keyword">new</span> <span class="hljs-title class_">MyWindowFunction</span>).print()</code></pre></li><li><p>通过sideOutputLateData 收集迟到的数据</p><p>可以通过侧输出流将异常数据保存下来进行后续的手工处理或者告警。</p></li></ol><p>通过这种机制，可以通过短暂的等待延迟来处理大部分的乱序数据，应为实际情况中的乱序数据也是在短时间（几时毫秒到几秒之间）产生的。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>Apache Flink因其独特的特性和强大的性能：其高吞吐、低延迟的流处理能力让其成为处理实时数据流和批量数据的首选，而且其支持复杂的事件处理和状态管理，使得处理实时数据流变得更加简单、高效。</p><p>Flink的窗口操作提供了多种灵活的窗口类型，可以根据业务需求选择合适的窗口类型，从而实现对数据流的精确控制和高效计算。而Checkpoint机制则保证了数据处理的可靠性和一致性，即使在发生故障或异常情况下，Flink也能够自动进行容错恢复，保障数据处理的稳定性。此外，通过Watermark机制处理消息乱序问题，Flink能够在实时数据流中准确地确定事件的发生顺序，从而确保了计算结果的准确性和一致性。</p><h3 id="参考文献"><a class="markdownIt-Anchor" href="#参考文献"></a> 参考文献：</h3><p><a href="https://tech.youzan.com/flink_checkpoint_mechanism/" target="_blank" rel="noopener">Flink Checkpoint 原理流程以及常见失败原因分析</a></p><p><a href="https://blog.jrwang.me/2019/flink-source-code-checkpoint/" target="_blank" rel="noopener">Flink 源码阅读笔记（11）- Checkpoint 机制和状态恢复 </a></p>]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后端&amp;架构 </tag>
            
            <tag> Flink </tag>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何画好软件架构图</title>
      <link href="/hou-duan-jia-gou/ru-he-hua-hao-ruan-jian-jia-gou-tu/"/>
      <url>/hou-duan-jia-gou/ru-he-hua-hao-ruan-jian-jia-gou-tu/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h1><p>作为架构师，如果你需要对复杂的业务进行应用落地，在前期设计过程，或者后期给领导、新同事、业务同学做汇报或者培训时，难免需要一些直观的图来表达你的信息，所谓一图胜过千言万语。</p><h1 id="什么是架构"><a class="markdownIt-Anchor" href="#什么是架构"></a> 什么是架构</h1><p>首先，架构图是一个软件开发工程中用到的一些列图的总称，针对不同的场景，不同的受众，需要有不同视角的架构图进行展示。</p><p>从字面意思上理解，架构图=架构 + 图，它是一种当前软件架构的一种表达方式。</p><p>我们都知道现实世界到软件世界的映射，是一个不断抽象的过程，这其中的方法就是不断地进行建立模型，所以架构的过程其实就是建模的过程，而架构图就是表达你建模过程的一种方式。</p><h1 id="架构的理论"><a class="markdownIt-Anchor" href="#架构的理论"></a> 架构的理论</h1><p>在架构时，有一些业界成熟的架构方法论和范式，能够便于我们进行学习和套用</p><h1 id="41架构范式"><a class="markdownIt-Anchor" href="#41架构范式"></a> 4+1架构范式</h1><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2-e830c60fc6baa069facff2e9e62ea3ae_720w.webp" alt="img"></p><p>4+1视图的核心理念是从不同的角度去剖析系统，看看系统的结构是什么样的，具体每个视图的含义是：</p><ul><li><ol><li>逻辑视图：从终端用户角度看系统提供给用户的功能，对应 UML的 class 和 state diagrams。</li></ol></li><li><ol start="2"><li>处理视图：从动态的角度看系统的处理过程，对应 UML 的 sequence 和 activity diagrams。</li></ol></li><li><ol start="3"><li>开发视图：从程序员角度看系统的逻辑组成，对应 UML 的 package diagrams。</li></ol></li></ul><p>我们可以看到，4+1视图本身很全面也很规范，但是为什么在实际工作中，真正按照这个标准来画架构图的公司和团队并不多。其原因是这套标准是针对之前的单体应用提出来的架构方法，如今大多系统都是分布式系统，无法每个微服务都画出对应的开发视图</p><h2 id="4r架构模型"><a class="markdownIt-Anchor" href="#4r架构模型"></a> 4R架构模型</h2><p>一个完整的架构图分别需要有不同的表现形式。分别是顶层设计(Rank)、定义的系统角色(Role)、角色之间的关系(Relation)和运作规则(Rule)。如下图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/efc20e3906d31b82cd36b1bd60a5f6d4.png" alt="img"></p><ul><li>顶层设计Rank——业务架构/产品架构图</li></ul><p>业务架构指的是使用一套方法论/逻辑对产品（项目）所涉及到的业务进行边界划分，核心点就是把业务边界通过不同颜色模块标识出来，并做分组，同时不需要去考虑具体技术点。这个是我们实际工作中画的最多的一种图，因为这种图一般是给领导汇报，产品人员规划业务，新员工培训用的，没有这个图很难讲清楚业务大概。例如下图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2-056928b23841cb0fc5987c574c4fa7a0_720w.webp" alt="img"></p><p>在比如下面的产品架构图：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2-5b9c8ba892b39f6baa5c7a1ea57f5f83_r.jpg" alt="img"></p><ul><li>定义系统角色(Role)——应用架构/系统架构</li></ul><p>应用架构更侧重于系统实现的一个总体架构，需要指出系统的层次、系统开发的原则、系统各个层次的应用服务，通过不同的颜色来标识角色，自顶向下分层设计。</p><p>如下图，系统应用分为数据层、服务层、通讯层、展示层，并西风写明每个层次的应用服务。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/aca89fe2d9847328a558fa9708381c38.png" alt="img"></p><p>如果你觉得不需要花的那么细，那么也可以按下图所示进行展示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/5b48da8ec860129f8bed202a0f237195.png" alt="img"></p><ul><li>展示角色之间的关系(Relation)——系统关系图</li></ul><p>如果系统比较复杂，按照架构分层的角度来看，应用架构已经到了可执行程序这一层，例如支付中台这一类的系统，包含的应用可能有几百上千个，如果把整个支付中台所有的应用都在一张图里面展示出来，信息太多太密，可能会导致架构图都看不清。+这种情况下，应用架构一般都是按照子域来画应用架构图，可以参考支付中台的会员域的应用架构图</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2-428f6cce9e675e0bb80547d60575fa3f_720w.webp" alt="img"></p><ul><li>展示角色的交互协作规则(Rule)——核心业务时序图/泳道图</li></ul><p>一般情况下核心业务不止一个，可能会有多个，例如下单流程，支付流程、交付流程等都是比较核心的流程，一般会由多个不同的核心业务时序图来描述，例如下图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2-c52535e2da10d566a9f9b20cbd9299b8_720w.webp" alt="img"></p><h1 id="c4架构模型"><a class="markdownIt-Anchor" href="#c4架构模型"></a> C4架构模型</h1><p>这里再推荐一个现在很流行的 C4 架构模型，其官网为：<a href="https://c4model.com/" target="_blank" rel="noopener">https://c4model.com/</a></p><p>C4 架构模型由一系列分层的软件架构图组成，这些架构图用于描述上下文、容器、组件和代码。C4 图的层次结构提供了不同的抽象级别，每种抽象级别都与不同的受众有关。</p><p>C4 代表 上下文（Context）、容器（Container）、组件（Component）和代码（Code），是一系列分层的图表，可以用这些图表来描述不同 Level 的软件架构，每种图表都适用于不同的受众。可以将其视为代码的谷歌地图。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/ebc5d5e54bb1e3b40e864812a7ebd4b9.png" alt="img"></p><p>C4模型的理论也在不断进化，以适应不同的软件形态</p><h1 id="画好架构图的思路"><a class="markdownIt-Anchor" href="#画好架构图的思路"></a> 画好架构图的思路</h1><p>上面介绍了那么多行业的架构图标准和范式，在实际过程中不一定都要按照这种来，有时候完全按照这种范式进行画图反而会觉得比较繁琐和多余。</p><p>那么一般画好一副软件建模过程中的一幅图，一般的思路为：</p><ul><li><p>第一，搞清楚要画的架构图类型，明确画架构图的核心目的；</p></li><li><p>第二，确认架构图中的关键要素（比如产品、技术、服务）；</p></li><li><p>第三，梳理关键要素之间的关联：包含、支撑、同级并列等；</p></li><li><p>第四，输出关联关系清晰的架构图。</p></li></ul><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2-25fa97abf2e16cf2ed70df985e7d8815_720w.webp" alt="img"></p><p>其实归根接地就是想清楚你要表达什么，受众是谁。</p><h1 id="画架构图的一些工具"><a class="markdownIt-Anchor" href="#画架构图的一些工具"></a> 画架构图的一些工具</h1><h2 id="1-processon"><a class="markdownIt-Anchor" href="#1-processon"></a> 1、ProcessOn</h2><p><a href="https://www.processon.com/diagrams" target="_blank" rel="noopener">https://www.processon.com/diagrams</a></p><p>免费画图有限制，我一般用这个比较多，用起来比较方便，开通个连续5年的vip也不贵，关键是经常用的上</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240323190925419.png" alt="image-20240323190925419"></p><h2 id="2-httpdrawio"><a class="markdownIt-Anchor" href="#2-httpdrawio"></a> 2、<a href="http://draw.io" target="_blank" rel="noopener">http://draw.io</a></h2><p><a href="http://draw.io" target="_blank" rel="noopener">http://draw.io</a></p><p>大家一定会喜欢这个，因为免费！！！这个连接的是 GitHub 和 Google Drive，不连接的话就是个离线版本。而且有 vscode 的插件可用。所以我身边用这个的大佬颇多。界面和processOn有点像，不知道是谁炒的谁。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240323190949700.png" alt="image-20240323190949700"></p><h2 id="3-excalidraw"><a class="markdownIt-Anchor" href="#3-excalidraw"></a> 3、excalidraw</h2><p><a href="https://excalidraw.com/" target="_blank" rel="noopener">https://excalidraw.com/</a></p><p>这个就是拼脑洞的，很好看,有种涂鸦的效果，在很多开源项目中经常能看到这种图，就是用它画出来的</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/va5u5frapi3mrh30q09l.png" alt="img"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v3dg5xgd6ybygwevuzas.png" alt="img"></p><h2 id="3-uml-图"><a class="markdownIt-Anchor" href="#3-uml-图"></a> 3、UML 图：</h2><p><a href="https://plantuml.com/zh/" target="_blank" rel="noopener">https://plantuml.com/zh/</a>  ，有非常多的示例，同时 VScode / webstorm 都有对应的插件，可以方便的在编辑器中书写</p><p>okeeper/blog-images</p><p><img src alt="loading-ag-1625"></p>]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后端&amp;架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis为什么快</title>
      <link href="/hou-duan-jia-gou/redis-wei-shi-me-kuai/"/>
      <url>/hou-duan-jia-gou/redis-wei-shi-me-kuai/</url>
      
        <content type="html"><![CDATA[<h1 id="redis介绍"><a class="markdownIt-Anchor" href="#redis介绍"></a> Redis介绍</h1><p>关系型数据库（如MySQL）的I/O瓶颈通常是由于数据存储和检索操作的频繁性以及磁盘读写速度限制所致。随着互联网应用和数据量的爆炸式增长，传统的关系型数据库在某些场景下可能无法满足高并发和低延迟的需求，特别是在读取密集型或者数据量非常大的情况下。在这种情况下，开发人员开始寻找更高效的解决方案。</p><p>Redis产生的背景正是基于这样的需求。Redis是一个基于内存的数据存储系统，具有高性能、低延迟和高并发的特点。相比于传统的关系型数据库，Redis通过将数据存储在内存中，极大地提高了数据的读取和写入速度。在Redis中，数据通常存储在内存中，并通过快速的键值对存储和检索来实现。</p><p>Redis的产生背景可以追溯到互联网应用需要处理大量实时数据、缓存和会话管理等需求。随着这些需求的不断增长，传统的关系型数据库在性能方面逐渐暴露出瓶颈。于是，人们开始寻求一种更适合这些需求的解决方案，Redis就是其中之一。</p><p>Redis的出现不仅解决了传统关系型数据库的I/O瓶颈问题，还为开发人员提供了更多的工具和机会来构建高性能、可扩展的应用程序。通过将数据存储在内存中，并提供丰富的数据结构和功能，Redis成为了许多互联网公司构建实时应用、缓存系统和消息队列等方面的首选解决方案之一。</p><p>根据DB-Engines的K-V数据库排名，Redis一直是最受欢迎的键值存储数据库。</p><p><a href="https://db-engines.com/en/ranking/key-value+store" target="_blank" rel="noopener">DB-Engines Ranking - popularity ranking of key-value stores</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1716263591173.png" alt></p><p>Redis做为一个KV内存NoSQL数据的优点如下：</p><ul><li><p>高性能：Redis是一个基于内存的数据库，这意味着它可以提供非常快速的数据读写操作。由于数据存储在内存中，Redis能够实现非常低延迟的访问，适用于需要快速响应的应用场景，如实时数据处理、缓存等。</p></li><li><p>丰富的数据结构支持：Redis支持丰富的数据结构，包括字符串、哈希、列表、集合、有序集合等。这使得开发人员可以更灵活地处理数据，不仅可以简单地存储键值对，还可以实现复杂的数据操作和数据结构。</p></li><li><p>持久化支持：尽管Redis是一个内存数据库，但它也提供了持久化的支持，可以将数据定期写入磁盘，以防止数据丢失。这种持久化支持可以在数据库重启时恢复数据，确保数据的安全性和持久性。</p></li><li><p>高可用性和可扩展性：Redis支持主从复制和分片等机制，可以实现数据的高可用性和可扩展性。通过配置主从复制和分片，可以实现数据的备份和负载均衡，提高系统的稳定性和可靠性。</p></li><li><p>丰富的生态系统和社区支持：Redis拥有一个活跃的开源社区和丰富的生态系统，有大量的第三方工具和库可供使用。这些工具和库可以帮助开发人员更轻松地集成Redis到他们的应用中，并提供更多的功能和特性。</p></li></ul><h1 id="redis为什么快"><a class="markdownIt-Anchor" href="#redis为什么快"></a> Redis为什么快</h1><p>我们对Redis的印象就是快，高性能，理论能达到10wqps。这得益于它的线程模型和基于内存的高速读写</p><p>Redis的单线程模型具体工作方式如下：</p><ol><li><p><strong>Redis它属于内存数据库</strong>，数据的读写都在内存中进行，减少了对磁盘IO的依赖</p></li><li><p><strong>多路复用技术的非阻塞IO</strong>：Redis使用同步非阻塞I/O操作来处理客户端请求。可以通过单个线程借助系统内核的epoll实现IO多路复用，用极少的线程资源处理大量的并发请求，增加了CPU的利用率。同时在Redis6.0之后当主线程epoll监听到多个可读写的IO事件时，利用多线程并行处理IO读写事件，加快了IO处理的并行度</p></li><li><p><strong>数据处理事件单线程处理</strong>：在任何给定的时间点，Redis只有一个线程在执行。这个线程负责处理所有的客户端达到的请求挨个进行处理，避免了多线程间的同步和锁竞争。</p></li></ol><p>虽然Redis采用了单线程模型，但它仍然能够实现高性能和高并发。这是因为Redis的主要瓶颈通常是在CPU或者网络带宽上，而不是在线程调度或者同步开销上。此外，Redis通过使用多路复用技术（如epoll、kqueue等）来同时处理大量的客户端连接，从而提高了系统的吞吐量和并发性能。</p><p>所以总结两点，redis为什么快：</p><ul><li><p>基于内存单线程，内存快速存取无锁竞争，摆脱了磁盘IO瓶颈</p></li><li><p>使用IO多路复用，提升了处理客户端请求并发能力，摆脱了网络IO的瓶颈</p></li></ul><h1 id="如何理解io多路复用"><a class="markdownIt-Anchor" href="#如何理解io多路复用"></a> 如何理解IO多路复用</h1><p>简单理解就是一个服务端线程可以同时接受处理来自多个不同网络链路的网络IO请求。</p><p>其中多路复用我们分开理解</p><ul><li>多路：多个客户端连接</li><li>复用：使用单进程就能够实现同时处理多个客户端的连接 ​</li></ul><p>它的基本原理就是不再由应用程序自己监视连接，而是由内核替应用程序监视文件描述符。客户端在操作的时候，会产生具有不同事件类型的 socket。</p><p>I/O多路复用经过一下这几个阶段发展</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/20190225204240.png" alt></p><h2 id="阻塞式ioblocking-io"><a class="markdownIt-Anchor" href="#阻塞式ioblocking-io"></a> 阻塞式IO(Blocking IO)</h2><p>这里的阻塞是指注册用户进程，从用户进程发起IO读取请求到真正读到数据过程中完全阻塞，用户线程做不了任何事情，CPU资源利用率极低。</p><h2 id="非阻塞是io"><a class="markdownIt-Anchor" href="#非阻塞是io"></a> 非阻塞是IO</h2><p>这个过程就是用户线程向内核发起网络IO请求，如果当前有就绪可用的IO就开始读取数据并返回，如果没有就绪链路就返回异常，用户线程继续轮询，知道返回可读数据。那么这个过程用户线程全程没有闲着，不停地在询问系统内核是否有可用IO,虽然是非阻塞的，但也效率低下，都在做一些大量重复且没有太多价值的事情。</p><h2 id="io多路复用"><a class="markdownIt-Anchor" href="#io多路复用"></a> I/O多路复用</h2><p>以上两种如果在高并发场景下，如果一个线程只能处理一个网络IO请求，必然考开启多个线程进行，这样避免不了上下文切换的开销，而随着系统内核技术的发展，IO多路复用技术出现，只需要一个用户线程即可处理多个网络IO请求，极大的提高了并发处理的性能。</p><h2 id="信号量驱动的io模型"><a class="markdownIt-Anchor" href="#信号量驱动的io模型"></a> 信号量驱动的IO模型</h2><p>应用进程先调用系统的sigacation,建立SIGIO信号，接着等待系统内核主动通知是否有准备就绪的可读IO，接下来交给用户进程进行数据读取</p><h2 id="异步io"><a class="markdownIt-Anchor" href="#异步io"></a> 异步IO</h2><p>异步IO是指从等待IO时间准备就绪到IO数据独居都已经在系统内核执行完成，整个过程无需用户进程参与，也不需要读取IO数据，直接用即可，真正的一部IO只有window实现了，linux目前大多只实现了IO多路复用(基于select/poll/epoll)</p><h1 id="操作系统内核selectpollepoll的区别"><a class="markdownIt-Anchor" href="#操作系统内核selectpollepoll的区别"></a> 操作系统内核select/poll/epoll的区别</h1><p>这三个都是IO多路复用操作系统底层的实现，都是同步非阻塞是的IO模型，这是三个不同的发展阶段</p><h2 id="最开始的select"><a class="markdownIt-Anchor" href="#最开始的select"></a> 最开始的select</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1716285479387.png" alt></p><p>如上图所示，用户进程需要记录所有需要遍历的套接字集合，传给操作系统内核帮我们挨个轮询是否有准备就绪的IO，且linux最大上限是1024连接描述符</p><h2 id="poll"><a class="markdownIt-Anchor" href="#poll"></a> poll</h2><p>本质上原理和select一样，算是select改进版本，但底层还是有系统内核进行轮询实现，主要改进是在文件描述符上限远大于1024</p><h2 id="epoll"><a class="markdownIt-Anchor" href="#epoll"></a> epoll</h2><p>这是目前主流的linux多路复用底层实现，它相较于select/poll。操作系统内核不在使用主动轮询的方式来确定是否有可用的IO socket,而是基于网络IO事件的主动通知机制，准备就绪的IO事件会被操作系统内核缓存起来(红黑树结构)，等待用户进程调用epoll_wait时返回。返回之后任然需要用户进程进行主动读取IO数据<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1716286989659.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
            <tag> Redis </tag>
            
            <tag> DB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>互联网大厂中分布式ID解决方案</title>
      <link href="/hou-duan-jia-gou/hu-lian-wang-da-han-de-fen-bu-shi-id-jie-jue-fang-an/"/>
      <url>/hou-duan-jia-gou/hu-lian-wang-da-han-de-fen-bu-shi-id-jie-jue-fang-an/</url>
      
        <content type="html"><![CDATA[<h1 id="互联网大厂中分布式id解决方案"><a class="markdownIt-Anchor" href="#互联网大厂中分布式id解决方案"></a> 互联网大厂中分布式ID解决方案</h1><blockquote><p>在高并发、高可用场景中，为了满足后续数据库水平扩容，如由于日益增长的数据需要分库分表时，通过数据库认的ID生成策略显然有诸多问题，例如他只能满足在单个数据库实例中唯一，不能全局唯一，其次如果所有的insert依赖数据库的自增也会有一定的性能问题。这就引出了我们今天的主角：分布式ID生成</p></blockquote><h2 id="常见的集中分布式id生成策略"><a class="markdownIt-Anchor" href="#常见的集中分布式id生成策略"></a> 常见的集中分布式ID生成策略</h2><h3 id="1-uuid"><a class="markdownIt-Anchor" href="#1-uuid"></a> 1. UUID</h3><p>UUID（Universally Unique Identifier）是一种由128位数字表示的唯一标识符。它的唯一性基于标准的UUID生成算法和硬件地址、时间戳等信息。UUID不依赖于中心化的ID生成器，可以在分布式系统中生成全局唯一的ID。</p><p><strong>优点</strong>：JDK自带，直接可生成，简单。</p><p><strong>缺点</strong>：字符串类型，无序，长度过长。</p><p>知道数据库主键索引的底层原理的就知道，这几个缺点就直接决定它一般不会使用在数据库主键的生成策略中。它只满足分布式唯一性，并不能当ID使用。</p><h3 id="2-基于redis"><a class="markdownIt-Anchor" href="#2-基于redis"></a> 2. 基于Redis</h3><p>基于Redis是一个高性能的内存数据库，能够快速地生成ID并响应请求，并保证全局有序和唯一</p><p><strong>优点</strong>：</p><ul><li>性能高：Redis支持主从复制和哨兵模式，能够保证服务的高可用性。</li><li>全局有序：通过redis的原子性操作能够实现全局ID递增</li></ul><p><strong>缺点</strong>：</p><ul><li>单点故障：Redis单点故障可能会影响整个系统的可用性，需要使用主从复制或者哨兵模式来解决。</li><li>数据一致性：Redis的持久化存储可能会导致数据一致性问题，需要合理配置持久化策略和备份机制来保证数据的一致性。</li><li>可扩展性：虽然Redis支持集群模式，但是在规模较大的情况下，可能需要进行水平扩展，这需要额外的成本和复杂性。</li></ul><p>总的来说，基于Redis实现的分布式ID生成器具有高性能、全局有序的优点，但是需要注意单点故障、数据一致性和可扩展性等方面的挑战。引入了额外的运维复杂性，极端情况可能会丢数据导致数据一致性问题</p><h3 id="3-基于zookeeper"><a class="markdownIt-Anchor" href="#3-基于zookeeper"></a> 3. 基于Zookeeper</h3><p>基于ZK的ZAB一致性协议，能够保证数据的强一致性，实现高可用地生成全局有序的分布式ID,同时支持方便的动态水平节点扩容。</p><p><strong>优点：</strong></p><ul><li>强一致性：Zookeeper保证数据的强一致性，能够确保生成的ID在整个系统中是唯一的。</li><li>分布式锁支持：Zookeeper提供了分布式锁的机制，可以在生成ID时加锁以保证并发安全。</li><li>动态扩展：Zookeeper集群支持动态扩展，可以根据系统的需求随时添加新节点来提高服务的性能和可用性。</li></ul><p><strong>缺点：</strong></p><ul><li>复杂性：Zookeeper的配置和管理相对复杂，需要一定的学习和了解成本。</li><li>性能瓶颈：Zookeeper在高并发场景下可能存在性能瓶颈，需要合理设计和优化。</li><li>依赖性：基于Zookeeper实现的分布式ID生成器对Zookeeper集群的稳定性和可用性有一定依赖性，需要注意Zookeeper集群的维护和监控。</li></ul><p>基于ZK和基于Redis实现的分布式ID原理类似，都是基于第三方存储组件实现全局的ID有序，但相对于redis，它会有一定的性能瓶颈问题。<br>那么不管是基于Redis还是基于ZK实现的分布式ID在非三高场景下基本也能满足我们的需求，相较于数据库的ID自增也充分预留了很多后续数据库水平扩容的可能性。但还有一个比较致命的问题是，由于它的自增特性，对外暴露的ID容易被用户猜到系统的单量和qps，商业敏感性问题就暴露出来了。</p><h3 id="4-基于内存自增第三方存储号段分配"><a class="markdownIt-Anchor" href="#4-基于内存自增第三方存储号段分配"></a> 4. 基于内存自增+第三方存储号段分配</h3><p>基于内存自增和第三方存储号段分配的分布式ID生成策略是一种常见的实现方式，它结合了内存和外部存储的优势，可以在一定程度上保证高性能和可靠性。</p><p><strong>优点：</strong></p><ul><li>高性能：利用内存自增的方式可以实现高效的ID生成，减少了对外部存储的依赖，提高了ID生成的速度和吞吐量。</li><li>可靠性：通过第三方存储的号段分配机制，可以确保生成的ID在整个系统中是唯一的，从而保证了系统的数据一致性和正确性。<br>灵活性：该策略可以灵活地根据系统的需求调整号段的大小和分配方式，从而更好地适应不同的业务场景和负载。</li><li>可扩展性：每个节点可以独立地从第三方存储获取号段，并在本地生成ID，因此该策略具有良好的水平扩展性，能够适应系统的扩展和增长。</li></ul><p><strong>缺点：</strong></p><ul><li>依赖性：该策略依赖于第三方存储来分配号段，如果第三方存储发生故障或者性能瓶颈，可能会影响整个系统的稳定性和可用性。</li><li>一致性：节点之间获取号段的过程可能存在一定的延迟，因此可能会出现一段时间内生成的ID不是严格有序的情况。需要根据业务需求和系统要求来权衡一致性和性能。</li><li>故障恢复：当节点发生故障或者重启时，需要重新初始化并从第三方存储获取一个新的号段，可能会导致一段时间内无法生成ID。</li></ul><h3 id="5-互联网大厂中用的最为广泛的雪花算法"><a class="markdownIt-Anchor" href="#5-互联网大厂中用的最为广泛的雪花算法"></a> 5. 互联网大厂中用的最为广泛的雪花算法</h3><p>那么有没有一种分布式ID生成策略，既能满足高性能、高可用、全局有序、还不暴露商业名感性问题的一种完美解决方案呢，经过互联网的长期实践，答案肯定是有的，也就是我们在互联网大厂中用的最为广泛的雪花算法（Snowflake Algorithm）</p><p>雪花算法（Snowflake Algorithm）是Twitter开发的一种分布式唯一ID生成算法，主要用于生成分布式系统中的唯一ID。该算法生成的ID是一个64位的整数，结构如下：</p><pre class="highlight"><code class>0  1               41             51               64+-+----------------+--------------+----------------+|0| timestamp(ms)  | worker node  | sequence number|+-+----------------+--------------+----------------+</code></pre><p>其中：</p><p>timestamp(ms)：41位，表示生成ID的时间戳，精确到毫秒级。<br>worker node：10位，表示机器ID，用于标识不同的机器。<br>sequence number：12位，表示每个节点每毫秒生成的序列号。</p><p>它的核心算法如下：</p><pre class="highlight"><code class="java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SnowflakeIdGenerator</span> {    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> startTime;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">workerIdBits</span> <span class="hljs-operator">=</span> <span class="hljs-number">5L</span>;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">sequenceBits</span> <span class="hljs-operator">=</span> <span class="hljs-number">12L</span>;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">maxWorkerId</span> <span class="hljs-operator">=</span> -<span class="hljs-number">1L</span> ^ (-<span class="hljs-number">1L</span> &lt;&lt; workerIdBits);    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">workerIdShift</span> <span class="hljs-operator">=</span> sequenceBits;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">timestampLeftShift</span> <span class="hljs-operator">=</span> sequenceBits + workerIdBits;    <span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">long</span> <span class="hljs-variable">sequenceMask</span> <span class="hljs-operator">=</span> -<span class="hljs-number">1L</span> ^ (-<span class="hljs-number">1L</span> &lt;&lt; sequenceBits);    <span class="hljs-keyword">private</span> <span class="hljs-type">long</span> workerId;    <span class="hljs-keyword">private</span> <span class="hljs-type">long</span> <span class="hljs-variable">sequence</span> <span class="hljs-operator">=</span> <span class="hljs-number">0L</span>;    <span class="hljs-keyword">private</span> <span class="hljs-type">long</span> <span class="hljs-variable">lastTimestamp</span> <span class="hljs-operator">=</span> -<span class="hljs-number">1L</span>;    <span class="hljs-keyword">public</span> <span class="hljs-title function_">SnowflakeIdGenerator</span><span class="hljs-params">(<span class="hljs-type">long</span> workerId)</span> {        <span class="hljs-keyword">if</span> (workerId &lt; <span class="hljs-number">0</span> || workerId &gt; maxWorkerId) {            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">IllegalArgumentException</span>(String.format(<span class="hljs-string">&quot;Worker ID must be between 0 and %d&quot;</span>, maxWorkerId));        }        <span class="hljs-built_in">this</span>.workerId = workerId;        <span class="hljs-built_in">this</span>.startTime = <span class="hljs-number">1609459200000L</span>; <span class="hljs-comment">// 2021-01-01 00:00:00</span>    }    <span class="hljs-keyword">public</span> <span class="hljs-keyword">synchronized</span> <span class="hljs-type">long</span> <span class="hljs-title function_">generateId</span><span class="hljs-params">()</span> {        <span class="hljs-comment">// 获取当前时间戳（毫秒级）</span>        <span class="hljs-type">long</span> <span class="hljs-variable">timestamp</span> <span class="hljs-operator">=</span> System.currentTimeMillis();        <span class="hljs-comment">// 如果当前时间戳小于上次生成ID的时间戳，说明发生了时钟回拨，抛出异常</span>        <span class="hljs-keyword">if</span> (timestamp &lt; lastTimestamp) {            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(<span class="hljs-string">&quot;时钟回拨，请等待...&quot;</span>);        }        <span class="hljs-comment">// 如果当前时间戳和上次生成ID的时间戳相等，则需要生成同一时间戳下的下一个ID</span>        <span class="hljs-keyword">if</span> (timestamp == lastTimestamp) {            <span class="hljs-comment">// 序列号自增，&amp; sequenceMask保证序列号不超过最大值</span>            sequence = (sequence + <span class="hljs-number">1</span>) &amp; sequenceMask;            <span class="hljs-comment">// 如果序列号溢出（超过最大值），等待下一个毫秒</span>            <span class="hljs-keyword">if</span> (sequence == <span class="hljs-number">0</span>) {                timestamp = waitNextMillis(timestamp);            }        } <span class="hljs-keyword">else</span> {            <span class="hljs-comment">// 如果当前时间戳大于上次生成ID的时间戳，则重置序列号为0</span>            sequence = <span class="hljs-number">0</span>;        }        <span class="hljs-comment">// 更新上次生成ID的时间戳</span>        lastTimestamp = timestamp;        <span class="hljs-comment">// 生成ID</span>        <span class="hljs-comment">// 时间戳部分左移timestampLeftShift位，机器ID部分左移workerIdShift位，再与序列号做或运算</span>        <span class="hljs-type">long</span> <span class="hljs-variable">id</span> <span class="hljs-operator">=</span> ((timestamp - startTime) &lt;&lt; timestampLeftShift) |                  (workerId &lt;&lt; workerIdShift) |                  sequence;        <span class="hljs-comment">// 返回生成的唯一ID</span>        <span class="hljs-keyword">return</span> id;    }    <span class="hljs-keyword">private</span> <span class="hljs-type">long</span> <span class="hljs-title function_">waitNextMillis</span><span class="hljs-params">(<span class="hljs-type">long</span> lastTimestamp)</span> {        <span class="hljs-type">long</span> <span class="hljs-variable">timestamp</span> <span class="hljs-operator">=</span> System.currentTimeMillis();        <span class="hljs-keyword">while</span> (timestamp &lt;= lastTimestamp) {            timestamp = System.currentTimeMillis();        }        <span class="hljs-keyword">return</span> timestamp;    }    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> {        <span class="hljs-type">SnowflakeIdGenerator</span> <span class="hljs-variable">idGenerator</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SnowflakeIdGenerator</span>(<span class="hljs-number">1</span>);        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) {            System.out.println(idGenerator.generateId());        }    }}</code></pre><p>在我们初始化时，只需要指定一个workerId传入，new一个SnowflakeIdGenerator()就可以happy地generateId()。</p><h3 id="那么这个workerid一般怎么来呢"><a class="markdownIt-Anchor" href="#那么这个workerid一般怎么来呢"></a> 那么这个workerId一般怎么来呢？</h3><p>Worker ID 一般是根据具体的部署环境来确定的，通常有以下几种方式来确定 Worker ID：</p><ul><li><p>手动分配：在部署系统时，手动为每个部署实例分配一个唯一的 Worker ID。这种方式简单直接，适用于部署数量有限且固定的情况。例如，对于一组服务器集群，可以手动为每台服务器分配一个唯一的 Worker ID。</p></li><li><p>基于IP地址或主机名生成：可以根据部署实例的IP地址或主机名生成 Worker ID。例如，可以使用IP地址的一部分或者主机名的哈希值作为 Worker ID。这种方式可以确保不同的部署实例拥有不同的 Worker ID。</p></li><li><p>动态注册：部署实例在启动时向一个中心注册中心注册，注册中心分配一个唯一的 Worker ID。这种方式适用于部署实例数量不固定或者动态变化的情况。例如，可以使用Zookeeper作为注册中心，在部署实例启动时向Zookeeper注册，并从Zookeeper获取 Worker ID。</p></li><li><p>基于环境参数配置：在系统的配置文件中配置 Worker ID，部署时根据环境参数加载相应的配置。这种方式可以灵活地根据部署环境配置 Worker ID。例如，可以在系统的配置文件中配置 Worker ID，然后在部署时根据环境变量加载相应的配置。</p></li></ul><h2 id="成熟的组件"><a class="markdownIt-Anchor" href="#成熟的组件"></a> 成熟的组件</h2><p>那么多方式中，大厂一般用第三种实现，基于动态注册的方式获取workerId，因为一般一个应用实例集群实例可能有上百台之多，且每逢大促还要进行扩缩容，如果还要依赖外部配置或认为干预的分配实例级别唯一的workderId好像也挺复杂的，那么有没有成熟的解决方案呢？答案是肯定的</p><h3 id="美团的leaf"><a class="markdownIt-Anchor" href="#美团的leaf"></a> 美团的Leaf</h3><p>取名Leaf（树叶），是对标Snowflake（雪花）的。<br>Leaf这个名字是来自德国哲学家、数学家莱布尼茨的一句话： &gt;There are no two identical leaves in the world &gt; “世界上没有两片相同的树叶”</p><p>Leaf Github: <a href="https://github.com/Meituan-Dianping/Leaf" target="_blank" rel="noopener">https://github.com/Meituan-Dianping/Leaf</a></p><p>它有两种实现，一种是利用数据库获取号段Segment后再内存做递增的Leaf-segement方案。<br>另外一种就是基于ZK实现自动workerId生成的雪花算法实现。</p><h4 id="leaf-segement方案实现原理"><a class="markdownIt-Anchor" href="#leaf-segement方案实现原理"></a> Leaf-segement方案实现原理</h4><p>利用数据库每次获取一个segment(step决定大小)号段的值。用完之后再去数据库获取新的号段，可以大大的减轻数据库的压力。从而几增加了可用性，实现了全局有序。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1715864830524-ca2d5ed2-37d9-4c18-8aa8-7bb1d8b390a2.png" alt></p><p>书库表中记录每个biz_tag当前使用到的最大的id,当别的实例来获取号段Segment时则从当前最大的id往后获取一个Segement给服务实例在内存使用。<br>每次获取号段是实际上是执行以下sql</p><pre class="highlight"><code class="sql"><span class="hljs-keyword">Begin</span><span class="hljs-keyword">UPDATE</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">SET</span> max_id<span class="hljs-operator">=</span>max_id<span class="hljs-operator">+</span>step <span class="hljs-keyword">WHERE</span> biz_tag<span class="hljs-operator">=</span>xxx<span class="hljs-keyword">SELECT</span> tag, max_id, step <span class="hljs-keyword">FROM</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">WHERE</span> biz_tag<span class="hljs-operator">=</span>xxx<span class="hljs-keyword">Commit</span></code></pre><p>默认的step步长是1000，一般步长越长性能越高，但也意味着如果频繁重启，浪费的未使用ID也就越多。<br>在实际使用过程中，如果内存中号段用完再去数据库中获取下一个号段，会对业务有一定的阻塞。在此又做了双buffer的优化。</p><p><strong>双buffer的优化</strong><br>Leaf 取号段的时机是在号段消耗完的时候进行的，也就意味着号段临界点的ID下发时间取决于下一次从DB取回号段的时间，并且在这期间进来的请求也会因为DB号段没有取回来，导致线程阻塞。如果请求DB的网络和DB的性能稳定，这种情况对系统的影响是不大的，但是假如取DB的时候网络发生抖动，或者DB发生慢查询就会导致整个系统的响应时间变慢。</p><p>为此，我们希望DB取号段的过程能够做到无阻塞，不需要在DB取号段的时候阻塞请求线程，即当号段消费到某个点时就异步的把下一个号段加载到内存中。而不需要等到号段用尽的时候才去更新号段。这样做就可以很大程度上的降低系统的TP999指标。详细实现如下图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1715865227563-f2354ea1-035b-4c90-aca3-9f6868abc4f7.png" alt></p><h4 id="leaf-snowflake方案"><a class="markdownIt-Anchor" href="#leaf-snowflake方案"></a> Leaf-snowflake方案</h4><p>Leaf-snowflake方案完全沿用snowflake方案的bit位设计，即是“1+41+10+12”的方式组装ID号。对于workerID的分配，当服务集群数量较小的情况下，完全可以手动配置。Leaf服务规模较大，动手配置成本太高。所以使用Zookeeper持久顺序节点的特性自动对snowflake节点配置wokerID。Leaf-snowflake是按照下面几个步骤启动的：</p><ol><li>启动Leaf-snowflake服务，连接Zookeeper，在leaf_forever父节点下检查自己是否已经注册过（是否有该顺序子节点）。</li><li>如果有注册过直接取回自己的workerID（zk顺序节点生成的int类型ID号），启动服务。</li><li>如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的workerID号，启动服务。</li></ol><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1715865479775-e6a4368c-3abe-4dd4-a704-abe2c1222514.png" alt></p><p><strong>此外还做了一些额外的优化，例如弱依赖ZooKeeper。</strong><br>除了每次会去ZK拿数据以外，也会在本机文件系统上缓存一个workerID文件。当ZooKeeper出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。这样做到了对三方组件的弱依赖。一定程度上提高了SLA。</p><p><strong>雪花算法中最近点的时钟回拨问题</strong><br>因为雪花算法依赖系统时间，如果机器的时钟发生了回拨，那么就会有可能生成重复的ID号，需要解决时钟回退的问题。当然实际上发生这种概率较少，但是一旦发生将造成严重的后果，Leaf的解决思路就是在zk中记录定期（每个3s）上报的上一次系统时间戳，如果发现回拨过长就过长在启动时将失败，</p><p><img src="https://raw.githubusercontent.com/okeeper/blog-images/main/2024/05/16/1715865919010-9ce1694c-acf1-42fd-bab1-f32b65832bf3.png" alt></p><p>如果在获取ID时发现回拨时间过长也将报错，较短时如小于5ms将进行短暂地等待。</p><pre class="highlight"><code class="java"><span class="hljs-comment">//发生了回拨，此刻时间小于上次发号时间</span> <span class="hljs-keyword">if</span> (timestamp &lt; lastTimestamp) {            <span class="hljs-type">long</span> <span class="hljs-variable">offset</span> <span class="hljs-operator">=</span> lastTimestamp - timestamp;            <span class="hljs-keyword">if</span> (offset &lt;= <span class="hljs-number">5</span>) {                <span class="hljs-keyword">try</span> {                    <span class="hljs-comment">//时间偏差大小小于5ms，则等待两倍时间</span>                    wait(offset &lt;&lt; <span class="hljs-number">1</span>);<span class="hljs-comment">//wait</span>                    timestamp = timeGen();                    <span class="hljs-keyword">if</span> (timestamp &lt; lastTimestamp) {                       <span class="hljs-comment">//还是小于，抛异常并上报</span>                        throwClockBackwardsEx(timestamp);                      }                    } <span class="hljs-keyword">catch</span> (InterruptedException e) {                     <span class="hljs-keyword">throw</span>  e;                }            } <span class="hljs-keyword">else</span> {                <span class="hljs-comment">//throw</span>                throwClockBackwardsEx(timestamp);            }        } <span class="hljs-comment">//分配ID       </span></code></pre><h3 id="百度的uid-generator"><a class="markdownIt-Anchor" href="#百度的uid-generator"></a> 百度的uid-generator</h3><p>Git Hub: <a href="https://github.com/baidu/uid-generator" target="_blank" rel="noopener">https://github.com/baidu/uid-generator</a></p><p>UidGenerator是Java实现的, 基于Snowflake算法的唯一ID生成器。UidGenerator以组件形式工作在应用项目中, 支持自定义workerId位数和初始化策略, 从而适用于docker等虚拟化环境下实例自动重启、漂移等场景。 在实现上, UidGenerator通过借用未来时间来解决sequence天然存在的并发限制; 采用RingBuffer来缓存已生成的UID, 并行化UID的生产和消费, 同时对CacheLine补齐，避免了由RingBuffer带来的硬件级「伪共享」问题. 最终单机QPS可达600万。</p><p>它对标准的雪花算法位数做了一些优化，如下：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1715866183150-20ceed8e-0cc8-4470-9fa5-5ded08130154.png" alt></p><ul><li><p>sign(1bit)<br>固定1bit符号标识，即生成的UID为正数。</p></li><li><p>delta seconds (28 bits)<br>当前时间，相对于时间基点&quot;2016-05-20&quot;的增量值，单位：秒，最多可支持约8.7年</p></li><li><p>worker id (22 bits)<br>机器id，最多可支持约420w次机器启动。内置实现为在启动时由数据库分配，默认分配策略为用后即弃，后续可提供复用策略。</p></li><li><p>sequence (13 bits)<br>每秒下的并发序列，13 bits可支持每秒8192个并发。</p></li></ul><p>此外它还使用RingBuffer进行内存的ID自增，将性能压缩到极致。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1715866435360-505ed8ad-6b3a-4995-844b-4e3d286b5eaa.png" alt></p><p>它的WorkderId是基于数据集记录实现的，需要提前在数据库表中维护每个host机器对应的当前workerId，每次发生重启workder将递增,单台机器最大支持420w次重启，超过这个数时将从0开始复用</p><pre class="highlight"><code class>DROP DATABASE IF EXISTS `xxxx`;CREATE DATABASE `xxxx` ;use `xxxx`;DROP TABLE IF EXISTS WORKER_NODE;CREATE TABLE WORKER_NODE(ID BIGINT NOT NULL AUTO_INCREMENT COMMENT 'auto increment id',HOST_NAME VARCHAR(64) NOT NULL COMMENT 'host name',PORT VARCHAR(64) NOT NULL COMMENT 'port',TYPE INT NOT NULL COMMENT 'node type: ACTUAL or CONTAINER',LAUNCH_DATE DATE NOT NULL COMMENT 'launch date',MODIFIED TIMESTAMP NOT NULL COMMENT 'modified time',CREATED TIMESTAMP NOT NULL COMMENT 'created time',PRIMARY KEY(ID)) COMMENT='DB WorkerID Assigner for UID Generator',ENGINE = INNODB;</code></pre><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2><p>在设计和实现一个分布式ID生成器时，虽然看起来似乎是一个简单的任务，但实际上需要考虑和解决的问题并不简单。以下是对分布式ID生成器设计和实现过程中需要注意的关键问题的续写总结：</p><p>首先，分布式ID生成器的设计需要考虑到系统的需求和规模。不同的业务场景可能需要不同的ID生成策略和算法。例如，一些系统可能需要生成有序的ID，而另一些系统可能更关注ID的唯一性和性能。</p><p>其次，要注意时钟回拨和并发安全性。时钟回拨可能会导致生成的ID不唯一，因此需要在算法中考虑时钟回拨的情况，并采取相应的措施来处理。同时，要保证在高并发情况下生成的ID是唯一且有序的，可以使用分布式锁等机制来确保并发安全性。</p><p>另外，选择合适的存储和分布式协调服务也是很重要的。不同的存储和分布式协调服务有不同的特性和适用场景，需要根据系统的需求和性能要求来选择合适的服务。</p><p>最后，要考虑系统的扩展性和可维护性。分布式ID生成器需要能够随着系统的扩展而扩展，并且易于部署和维护。因此，设计和实现分布式ID生成器时要考虑到系统的未来发展和维护成本。</p><p>欢迎关注我的公众号“<strong>神笔君</strong>”，原创技术文章第一时间推送。</p><center>    <img src="https://raw.githubusercontent.com/okeeper/blog-images/main/2024/05/16/1715867273785-7c091e0c-9b01-44de-b34a-6ffd0887b01b.jpg" style="width: 100px;"></center>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
            <tag> 分布式ID </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch技术架构及原理</title>
      <link href="/hou-duan-jia-gou/elasticsearch-ji-zhu-jia-gou-ji-yuan-li/"/>
      <url>/hou-duan-jia-gou/elasticsearch-ji-zhu-jia-gou-ji-yuan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="elasticsearch介绍"><a class="markdownIt-Anchor" href="#elasticsearch介绍"></a> Elasticsearch介绍</h1><p>Elasticsearch 是一个基于 Apache Lucene 的开源搜索和分析引擎，设计用于云计算中，能够快速地处理大量数据。它可以近实时地进行复杂的查询，并且可以用于全文搜索、结构化搜索以及分析。</p><p>特性：</p><ul><li><p>分布式搜索引擎，可以扩展到上百台服务器，处理PB级的数据。</p></li><li><p>RESTful API，使用JSON进行数据交换。</p></li><li><p>实时分析，可以对数据进行实时分析。</p></li><li><p>高可用性，节点失败时可以自动重分配。</p></li><li><p>近实时，数据被索引后立即可搜索。1s内返回</p></li><li><p>支持各种编程语言。</p></li></ul><h1 id="elasticsearch的原理"><a class="markdownIt-Anchor" href="#elasticsearch的原理"></a> Elasticsearch的原理</h1><p>每一种存储引擎都有自己特定的应用场景，例如Mysql，它更擅长的是事务的操作，事务里面有原子性、持久性、一致性、隔离性这些，因此可以保证数据的安全性、持久化存储、数据一致，但它不适合大量数据的查询和搜索(亿级海量数据)，它底层的存储引擎虽然使用B+ tree索引优化了检索速度，但随着数据量的增大，多次的磁盘IO读写依然会比较慢。此时IO读写将是不可逾越的一大瓶颈。</p><p>Elasticsearch搜索引擎就是为了解决海量数据的搜索和数据检索。那么之所以它适合海量数据的检索，一定有它独特的设计，优化了检索磁盘IO读写过程。</p><h2 id="倒排索引"><a class="markdownIt-Anchor" href="#倒排索引"></a> 倒排索引</h2><p>我们知道数据是放磁盘中的，要对磁盘中海量数据的搜索，一定要为这些数据建立索引数据结构，降低磁盘IO次数。那么ES的索引方式就不是MySQL的B+ tree方式，而是倒排索引。</p><p><strong>倒排索引中有两个非常重要的概念：</strong></p><ul><li>文档（<code>Document</code>）：用来搜索的数据，其中的每一条数据就是一个文档。例如一个网页、一个商品信息</li><li>词条（<code>Term</code>）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条</li></ul><p><strong>倒排索引</strong>简单来说就是通过doc(数据行)的某个字段的词条（Term）对应起doc的id及出现的位置信息等的一种数据结构，例如将下图中的title字段进行分词后映射了每个词条对应的文档id.</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/2729274-20230205171751933-576636800.png" alt></p><p>最终将一个所有表数据维护成了词条和文档id集合的一个映射，这个就是倒排索引。而每个词条对应的文档id集合是按顺序进行存储的，称为posting list. 词条这一列称为Term Dictionary（词项字典）。</p><p>这里有两个问题：</p><ol><li><p>如果一个词条对应的文档id特别多，岂不是要大量的磁盘空间进行存储</p></li><li><p>一般一个文档不单只有一个字段，如果每个字段分别建立了倒排索引，当需要取各个字段的搜索交集时，如何快速实现。</p></li></ol><blockquote><p>一般来讲，一个文档id时long类型的，8byte存储，如果一个词条包含的文档id特别多，成千上万个，例如要所示英文文档中包含&quot;of&quot;单词的所有文档，这是英文中最常见的单词，显然会很多。如果是1千万个id * 8byte/1024 = 78125KB = 76M。这还只是一个词条，实际上词条会很多，每个词条包含的文档数量可能远不止1千万个id，如果直接存储id对搜索来讲会大大增加磁盘空间的占用和后续搜索性能的降低。</p></blockquote><p>为了解决这两个问题，ES想到的是将Posting list进行压缩，ES实现了两种节省空间的压缩算法，一个是<strong>Frame Of Reference（FOR）</strong>，另一个是 **Roaring Bitmaps(RBP) **</p><p>针对不同的文档ID序列会选择不同的压缩算法</p><h3 id="frame-of-referencefor算法"><a class="markdownIt-Anchor" href="#frame-of-referencefor算法"></a> Frame Of Reference（FOR）算法</h3><p>它的核心思想是对于一个有序的doc id列表，只记录从第一个元素依次开始的增量数组，进而达到压缩空间的目的。</p><p>例如有以下一个数组：</p><pre class="highlight"><code class>[73, 300, 302, 332, 343, 372]</code></pre><p>进行增量编码之后：</p><pre class="highlight"><code class>[73, 227, 2, 30, 11, 29]</code></pre><p>那么id的所需的存储空间就由这个增量编码的最大值决定，例如这里的最大值是227，如果采用无符号二进制位表示需要1byte，那么6个数总共压缩之后=6*1byte=6byte</p><p>而原数组的最大值是372，需要2byte, 原数组就需要12byte表示。压缩了一半的空间。那么看起来有一定的压缩率了，能不能进一步压缩呢？</p><p>答案是肯定的，ES在实际实现过程中，会将数组中每255个id进行分组，并在每一个分组中取最大的数值所需的空间大小当成整个分组中每个元素的空间大小。这样每个分组都能尽可能地使用最低存储空间进行存储。例上面这个增量数组，假设如果是按3个元素进行分组。</p><pre class="highlight"><code class>[73, 227, 2], [30, 11, 29]</code></pre><p>对于第一个块，[73, 227, 2]，最大元素是227，需要 8 bits，所以就给每个元素都分配 8 bits的空间。</p><p>但是对于第二个块，[30, 11, 29]，最大的元素才30，只需要 5 bits，所有给每个元素只分配 5 bits 的空间足矣。</p><p>为了在解码的时候知道这个分组用了多少位，用一个bit来存储所用的bit位数即可。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/es%20FOR%E7%BC%96%E7%A0%81%E6%8A%80%E6%9C%AF.jpg" alt="es FOR编码技术"></p><p>这个就是Frame Of Reference（FOR）编码算法，在Posting list中的文档id步长相差不大的情况下，能够极大地压缩所需的磁盘空间存储。</p><p>当有多个字段的倒排索引需要聚合条件取交集搜索时，从磁盘中加载到内存中进行计算，从最短的数组的最小元素开始遍历，通过有序数组进行跳表搜索(Skip table)其他数组中是否存在即可取得最终的交集。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/Lucene%E8%B7%B3%E8%A1%A8%E8%AE%A1%E7%AE%97%E4%BE%8B%E5%AD%90.jpg" alt="Lucene 跳表例子"></p><p>从上面例子可以看出，使用FOR进行压缩后能够极大降低磁盘所需空间，便于一次性加载到内存中进行聚合计算，但当文档ID数据依然很多，压缩之后依然暂用很多空间时，加载到内存肯定也吃不消。</p><p>这就引出了我们另外一种压缩编码算法，<strong>Roaring Bitmaps</strong></p><h3 id="roaring-bitmapsrbm咆哮位图"><a class="markdownIt-Anchor" href="#roaring-bitmapsrbm咆哮位图"></a> Roaring Bitmaps(RBM)——咆哮位图</h3><p>Bitmap我们知道，它通过一个bit数组，来表示一个有序数组是否在当前bit位中存在元素的一种数据结构，假设有这样一个数组：</p><pre class="highlight"><code class>[3,6,7,10]</code></pre><p>它的最大值是10，就需要10位的bit数组表示，bitmap （位图）来表示为：</p><pre class="highlight"><code class>[0,0,1,0,0,1,1,0,0,1]</code></pre><p>我们用 0 表示角标对应的数字不存在，用 1 表示存在。例如从第一个数组元素1开始，第3个元素为1表示这里有个值是3。</p><p>Roaring Bitmaps(RBM)的原理是，将原始的posting list的Integer Id，32位表示，划分为低16位和高16位两部分，通过计算得知这两部分最大的数值都是65535。</p><p>其效果和ID / 65535 的到<strong>一个商</strong>合<strong>一个余数</strong>效果是一样的。那么将一个有序不重复的ID数组必定能够转换成商合余数都是65535之内的数。</p><p>将商当做key，将余数当做value进行映射起来，就可以将有相同商的聚合到一个value钟，在通过bitmap分别表示key和value。这样可以通过恒定的65535的bit数组表示一个32位的Integer集合，大概是43亿。最终效果如下：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/74bf2380c19d4a039ca3ce3a2dd09661.png" alt="roaring array"></p><p>用65535位的bitmap标识 keys，用ArrayContrainer或者Bitmap Contrainer来表示每个key对应的values，由于values不管有多少个元素，都用65535位的bitmap标识，当元素较少时，固然也是比较浪费的，计算Bitmap和直接存Integer数组与元素个数的存储空间关系，得到以下临界关系，当元素个数&lt;4096时，用ArrayContrainer直接存Integer原始数值比较省空间，当元素个数&gt;=4096时，使用Bitmap Contraine来存储，存储空间很定在65536 个 bit</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/85a4ddbf2f2845b89818f64fc00d97b3.png" alt></p><p>通过Roaring Bitmaps(RBM)这种数据编码的优化，即使极端情况Posting List由43(2^32)亿个无符号Integer组成的Id数组，其最大所需的存储空间为计算如下：</p><p>65536 个 bit，也就是 65536/8 = 8192 bytes</p><p>8192 bytes * 8192 bytes=65535KB = 64M</p><p>而43亿个整形所需的空间为 2^32 * 4byte = 16384M = 16G，压缩了不是一点半点了。</p><p>而且Bitmap有个好处就是在取多个数组交集的时候，只需要&amp;位运算即可，相当方便，这样就可以将一个极大的有序Posting list一下加载到内存中进行快速计算得出搜索结果。</p><p>到目前为止，我们值将了ES如何优化和压缩Posting list。还有Term Dictionary词项字典是怎么处理的呢，对应上亿级的文档数据，其词项也是相当巨大的，如何在搜索时通过所示关键字(词项)快速找到对应的post list呢？接下来引出Term Index.</p><h2 id="term-index词项索引"><a class="markdownIt-Anchor" href="#term-index词项索引"></a> Term Index（词项索引）</h2><p>为了加快通过关键字快速找到PostingList, ES的思想是在词项字典中建立索引，并将索引缓存在内存中进行极速计算搜索。最终的结构应该如下图所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/Lucene%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E5%86%85%E9%83%A8%E7%BB%93%E6%9E%84.jpg" alt="Lucene倒排索引内部结构"></p><p>那么问题来了，对于一个巨量的词项字典，其词项索引必然也是巨大的，直接加载到内存中肯定不是它的作风。</p><p>对的ES使用的是一种有限状态转换器（Finite StateTransducers 简称 FST）数据结构，将词项字典的前缀和后缀及对应的索引Block块位置构建成一个FST树。</p><p>它是从Trie前缀树演变而来的，其满足前缀树的特性：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/b33b1595505ec3a32774f79eae3dd8b8.png" alt></p><p>1、根节点不包含字符，除根节点外每一个节点都只包含一个字符<br>2、从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串<br>3、每个节点的所有子节点包含的字符都不相同</p><p>而ES实现数据结构是FST（Finite State Transducer）有的不一样，它不但可以表示相同前缀的词典，相同后缀也能表示。它有以下两个优点：</p><ol><li>空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；</li><li>查询速度快。O(len(str))的查询时间复杂度。</li></ol><h3 id="构建过程"><a class="markdownIt-Anchor" href="#构建过程"></a> 构建过程</h3><p>例如：</p><p>我们对“cat”、 “deep”、 “do”、 “dog” 、“dogs”这5个单词进行插入构建FST（注：必须已排序）。</p><ol><li><p>插入“cat”,每个字母形成一条边，其中t边指向终点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/e2a43283b890ee417d1680b1e2d15d28.png" alt></p></li><li><p>插入“deep”,与前一个单词“cat”进行最大前缀匹配，发现没有匹配则直接插入，P边指向终点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/c11a3bc0faf2d7d5c21f29ce29458c37.png" alt></p></li><li><p>插入“do”,与前一个单词“deep”进行最大前缀匹配，发现是d，则在d边后增加新边o，o边指向终点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/166c463a70a4e724a788930bfbfe428e.png" alt></p></li><li><p>插入“dog”,与前一个单词“do”进行最大前缀匹配，发现是do，则在o边后增加新边g，g边指向终点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/ee27cb44f5171a4936f9f101a17c31ff.png" alt></p></li><li><p>插入“dogs”, 与前一个单词“dog”进行最大前缀匹配，发现是dog，则在g后增加新边s，s边指向终点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/075af4c74246952f99fa0876c583b7d1.png" alt></p><p>有了这个索引结构，就能很方便地在内存中快速查找posting list，进行进一步的快速搜索。</p><p>关于FST这里有个在线的算法演示网站，感兴趣的可以点开玩玩方便理解：<a href="http://examples.mikemccandless.com/fst.py?terms=&amp;cmd=Build+it%21" target="_blank" rel="noopener">http://examples.mikemccandless.com/fst.py?terms=&amp;cmd=Build+it!</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240605145158758.png" alt="image-20240605145158758"></p></li></ol><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><h2 id="为什么-elasticsearchlucene-检索可以比-mysql-快"><a class="markdownIt-Anchor" href="#为什么-elasticsearchlucene-检索可以比-mysql-快"></a> 为什么 Elasticsearch/Lucene 检索可以比 mysql 快</h2><ol><li><p>Mysql 只有 term dictionary 这一层，是以 b-tree 排序的方式存储在磁盘上的。检索一个 term 需要若干次随机 IO 的磁盘操作。</p></li><li><p>而 ES 在 term dictionary 的基础上添加了term index来加速检索，term index 以树的形式缓存在内存中。从 term index 查到对应的 term dictionary 的 block 位置之后，再去磁盘上找 term，大大减少了磁盘的 random access （随机IO）次数。</p></li><li><p>ES在Posting List存储时，通过Frame Of Reference（FOR）和Roaring Bitmaps(RBM)的编码压缩，可以实现海量数据的存储而不再用太大的空间，大大节省了磁盘空间，进而检索了搜索时的随机IO次数。再者由于压缩的存在，使得可以一次性加载至内存中进行快速计算。</p></li></ol><p>以上就是ES之所能在海量数据搜索中快的核心技术。</p>]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后端&amp;架构 </tag>
            
            <tag> Elasticsearch </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能时代的技术底座：向量数据库</title>
      <link href="/ren-gong-zhi-neng/xiang-liang-shu-ju-ku/"/>
      <url>/ren-gong-zhi-neng/xiang-liang-shu-ju-ku/</url>
      
        <content type="html"><![CDATA[<h1 id="一-什么是向量"><a class="markdownIt-Anchor" href="#一-什么是向量"></a> 一、什么是向量</h1><p>随着ChatGPT的爆火，其embedding背后的向量检索技术让大家熟知。事实上，向量数据库并非近两年才出现的新技术，它已经存在了很长时间了。要了解什么是向量数据库，我们先来了解下什么是向量。</p><h2 id="向量的概念"><a class="markdownIt-Anchor" href="#向量的概念"></a> 向量的概念</h2><p>向量最初是数学和物理学中的一个基本概念，他表示既有大小又有方向的量，它与只有大小没有方向的标量（如温度、质量和长度）相对应。</p><p>在数学中，向量（也称为欧几里得向量、几何向量、矢量），指具有大小（magnitude）和方向的量。它可以形象化地表示为带箭头的线段。箭头所指：代表向量的方向；线段长度：代表向量的大小。与向量对应的只有大小，没有方向的量叫做数量（物理学中称标量）。　　如果用Rn表示n个实数的有序集，Rn中的一个向量就是一个n元有序组，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">R</mi><mi>n</mi></msub><mo>=</mo><mrow><mo fence="true">{</mo><mrow><mo fence="true">(</mo><msub><mi>χ</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>χ</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>χ</mi><mn>3</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>χ</mi><mi>n</mi></msub><mo fence="true">)</mo></mrow><mo>∣</mo><msub><mi>χ</mi><mi>i</mi></msub><mo>∈</mo><mi mathvariant="normal">R</mi><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">\mathrm {R}_n = \left \{ \left (\chi_{1} , \chi_{2},\chi_{3}, ...\chi_{n} \right )\mid  \chi_{i}\in \mathrm {R} \right \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">R</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal">χ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">χ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">χ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord"><span class="mord mathnormal">χ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathnormal">χ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mord mathrm">R</span></span><span class="mclose delimcenter" style="top:0em;">}</span></span></span></span></span>　　向量的记法：印刷体记作粗体的字母（如a、b、u、v），书写时在字母顶上加一小箭头“→”。如果给定向量的起点（A）和终点（B），可将向量记作<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mrow><mi>A</mi><mi>B</mi></mrow><mo stretchy="true">→</mo></mover></mrow><annotation encoding="application/x-tex">\overrightarrow{AB}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.20533em;vertical-align:0em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.20533em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span><span class="svg-align" style="top:-3.6833299999999998em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="height:0.522em;min-width:0.888em;"><svg width="400em" height="0.522em" viewbox="0 0 400000 522" preserveaspectratio="xMaxYMin slice"><path d="M0 241v40h399891c-47.3 35.3-84 78-110 128-16.7 32-27.7 63.7-33 95 0 1.3-.2 2.7-.5 4-.3 1.3-.5 2.3-.5 3 0 7.3 6.7 11 20 11 8 0 13.2-.8 15.5-2.5 2.3-1.7 4.2-5.5 5.5-11.5 2-13.3 5.7-27 11-41 14.7-44.7 39-84.5 73-119.5s73.7-60.2 119-75.5c6-2 9-5.7 9-11s-3-9-9-11c-45.3-15.3-85-40.5-119-75.5s-58.3-74.8-73-119.5c-4.7-14-8.3-27.3-11-40-1.3-6.7-3.2-10.8-5.5-12.5-2.3-1.7-7.5-2.5-15.5-2.5-14 0-21 3.7-21 11 0 2 2 10.3 6 25 20.7 83.3 67 151.7 139 205zm0 0v40h399900v-40z"/></svg></span></span></span></span></span></span></span></span></span><br>。实际上向量有多种记法，可以用元组表示一个向量，如 (x1, x2) 或 &lt; x1, x2&gt;。在线性代数中，n元向量可以用n×1矩阵表示，如：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">V</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnalign="left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>1</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>2</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>3</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>4</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>5</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mtext> 或 </mtext><msup><mi mathvariant="bold">V</mi><mi>T</mi></msup><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.15999999999999992em" columnalign="left left left left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>3</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>4</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>5</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">\mathbf{V}=\left[\begin{array}{l}x_{1} \\x_{2} \\x_{3} \\x_{4} \\x_{5}\end{array}\right] \text { 或 } \mathbf{V}^{T}=\left[\begin{array}{lllll}x_{1} &amp; x_{2} &amp; x_{3} &amp; x_{4} &amp; x_{5}\end{array}\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">V</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:6.00503em;vertical-align:-2.75004em;"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.2549900000000003em;"><span style="top:-1.0499800000000006em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎣</span></span></span><span style="top:-2.1999800000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-2.79598em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.39198em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-3.9879800000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-4.0139700000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎢</span></span></span><span style="top:-5.25499em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎡</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.75004em;"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.2500000000000004em;"><span style="top:-5.410000000000001em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-4.21em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-1.8099999999999998em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-0.6099999999999997em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.7500000000000004em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.2549900000000003em;"><span style="top:-1.0499800000000006em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎦</span></span></span><span style="top:-2.1999800000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-2.79598em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.39198em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-3.9879800000000003em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-4.0139700000000005em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎥</span></span></span><span style="top:-5.25499em;"><span class="pstrut" style="height:3.1550000000000002em;"></span><span class="delimsizinginner delim-size4"><span>⎤</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.75004em;"><span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord text"><span class="mord"> </span><span class="mord cjk_fallback">或</span><span class="mord"> </span></span><span class="mord"><span class="mord"><span class="mord mathbf" style="margin-right:0.01597em;">V</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913309999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.20001em;vertical-align:-0.35001em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size1">[</span></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8500000000000001em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.35000000000000003em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size1">]</span></span></span></span></span></span></span></p><p>向量中的每个元素xn，都称作向量的一个分量。</p><h2 id="向量的特点"><a class="markdownIt-Anchor" href="#向量的特点"></a> 向量的特点</h2><ul><li>方向和大小：向量不仅有大小，还有方向，这与普通的数（标量）不同，标量只有大小，没有方向。</li><li>可在空间中表示：向量可以在一维、二维、三维或更高维的空间中表示。</li><li>可相加减和数乘：向量之间可以进行加法、减法操作，也可以与标量进行乘法操作，遵循平行四边形法则和三角形法则。</li><li>向量空间：向量可以构成向量空间，向量空间内的向量可以通过向量加法和标量乘法的组合进行线性组合。</li></ul><h2 id="数的向量化表示对计算机运算的便利性"><a class="markdownIt-Anchor" href="#数的向量化表示对计算机运算的便利性"></a> 数的向量化表示对计算机运算的便利性</h2><ul><li>高效存储和处理：计算机通过向量化表示可以更高效地存储和处理大量数据。向量化可以减少循环和迭代计算，利用现代处理器的向量化指令集进行并行处理。</li><li>简化计算：数学运算，尤其是线性代数运算，在向量化表示下可以大大简化，<strong>因为可以利用矩阵乘法等操作直接处理整个数据集合，而不是单独处理每个数据点</strong>。</li><li>机器学习和深度学习：在机器学习和深度学习中，数据通常以向量、矩阵和张量的形式表示。向量化使得算法的实现更加直观，同时可以利用高度优化的数学库（如NumPy、TensorFlow、PyTorch）进行高效计算。</li><li>图形处理：在计算机图形处理中，向量化表示允许快速计算和渲染图形，比如在3D建模、动画和视频游戏开发中的应用。</li></ul><h2 id="机器学习中为什么使用向量"><a class="markdownIt-Anchor" href="#机器学习中为什么使用向量"></a> 机器学习中为什么使用向量</h2><p>在计算机世界中，向量的使用普遍且多样，特别是在机器学习中，向量用来描述特征有其独到之处和优势：</p><h3 id="1-数据表示的统一性和通用性"><a class="markdownIt-Anchor" href="#1-数据表示的统一性和通用性"></a> 1. 数据表示的统一性和通用性</h3><ul><li>统一性：使用向量来描述特征可以将不同类型的数据（数值、类别、文本等）转化为统一的数学表示形式。这种统一性使得算法能够处理多种类型的数据，而不需要根据数据类型改变算法逻辑。</li><li>通用性：向量化的数据可以被各种机器学习算法接受，从简单的线性回归到复杂的深度学习模型，都可以处理向量形式的输入数据。</li></ul><h3 id="2-高效的计算和存储"><a class="markdownIt-Anchor" href="#2-高效的计算和存储"></a> 2. 高效的计算和存储</h3><ul><li>高效计算：现代计算机和特定硬件（如GPU）对于向量和矩阵运算进行了优化，使得与向量相关的计算特别高效。这意味着使用向量来描述特征可以显著加快机器学习算法的训练和预测过程。</li><li>高效存储：向量化的数据可以通过紧凑的格式存储，减少内存占用，并且便于数据的快速读取和传输。</li></ul><h3 id="3-算法性能的提升"><a class="markdownIt-Anchor" href="#3-算法性能的提升"></a> 3. 算法性能的提升</h3><ul><li>特征工程：通过将特征向量化，数据科学家可以应用各种特征工程技术（如特征选择、特征提取、维度缩减）来提升模型性能。</li><li>模型精度：向量化的特征表示允许模型捕捉到数据中的复杂模式和关系，从而提高模型的精度和泛化能力。</li></ul><h3 id="4-灵活性和扩展性"><a class="markdownIt-Anchor" href="#4-灵活性和扩展性"></a> 4. 灵活性和扩展性</h3><ul><li>灵活性：向量表示的特征可以容易地扩展或修改，以适应模型的需要。例如，可以通过添加更多的维度来引入新的特征，而不需要对现有的数据处理流程或模型架构进行大的改动。</li><li>扩展性：对于大规模的数据集，向量化的表示方法可以有效地支持并行计算和分布式计算，从而使得处理大数据变得可行。</li></ul><h3 id="5-兼容性与集成性"><a class="markdownIt-Anchor" href="#5-兼容性与集成性"></a> 5. 兼容性与集成性</h3><ul><li>软件库和工具：几乎所有的机器学习和深度学习库（如scikit-learn、TensorFlow、PyTorch）都是围绕向量和矩阵运算设计的。使用向量来描述特征使得这些工具可以直接应用，无需进行数据格式转换。</li><li>集成性：向量化的特征可以方便地与其他数据处理和分析工具集成，如数据可视化、统计分析等，为整个数据处理和机器学习流程提供支持。</li></ul><h2 id="举例"><a class="markdownIt-Anchor" href="#举例"></a> 举例</h2><p>例如电影推荐系统中<br>假设我们正在构建一个电影推荐系统，我们希望根据用户的历史观影记录和电影的属性来推荐用户可能感兴趣的电影。</p><p>让我们细化一下电影推荐系统中电影特征向量化和用户特征向量化的过程，以便更深入理解这一概念。</p><h3 id="电影特征向量化的细化"><a class="markdownIt-Anchor" href="#电影特征向量化的细化"></a> 电影特征向量化的细化</h3><p>假设我们有以下电影特征进行向量化：</p><ol><li><p><strong>数值特征</strong>：</p><ul><li>电影长度（分钟）：一个直接的数值，比如<code>120</code>。</li><li>发布年份：一个数值，比如<code>2020</code>。</li></ul></li><li><p><strong>类别特征</strong>（电影类型）：</p><ul><li>假设我们有5种类型：动作、喜剧、科幻、爱情、惊悚。</li><li>电影《X》是动作和科幻类型，所以它的类型特征向量可以是<code>[1, 0, 1, 0, 0]</code>，表示动作和科幻为<code>1</code>，其他为<code>0</code>。</li></ul></li><li><p><strong>文本特征</strong>（电影描述）：</p><ul><li>电影《X》的描述：“一个未来的英雄战斗以拯救世界。”</li><li>使用TF-IDF或词嵌入技术将这段文本转换为固定长度的向量，例如，一个长度为<code>N</code>的向量<code>[0.5, 0.1, ..., 0.0]</code>，每个元素代表文本中一个特定词或概念的重要性。</li></ul></li></ol><h3 id="用户特征向量化的细化"><a class="markdownIt-Anchor" href="#用户特征向量化的细化"></a> 用户特征向量化的细化</h3><p>对于用户，我们可能会有如下特征进行向量化：</p><ol><li><p><strong>用户偏好</strong>：</p><ul><li>假设基于用户过去的评分记录，我们得出用户喜欢动作和科幻类型的电影。</li><li>用户的偏好向量可能类似于电影的类型向量，如<code>[0.8, 0.2, 0.7, 0.1, 0.0]</code>，表示用户偏好动作和科幻类型的电影，数值越高表示偏好程度越大。</li></ul></li><li><p><strong>评分活动</strong>：</p><ul><li>用户评分次数：一个数值，比如<code>50</code>次。</li><li>平均评分：另一个数值，比如<code>4.2</code>。</li></ul></li><li><p><strong>观影频率</strong>：</p><ul><li>根据用户的观影记录，我们可以计算出用户每月的观影频率，比如<code>8</code>部电影/月，这也可以转化为一个数值特征。</li></ul></li></ol><h3 id="综合向量表示"><a class="markdownIt-Anchor" href="#综合向量表示"></a> 综合向量表示</h3><ul><li><strong>电影向量</strong>：将数值特征、类别特征和文本特征的向量合并，形成一个综合的电影特征向量。例如，如果我们将所有特征合并，对于电影《X》，它的特征向量可能是<code>[120, 2020, 1, 0, 1, 0, 0, 0.5, 0.1, ..., 0.0]</code>，前面部分代表数值和类别特征，后面部分是文本特征转化来的向量。</li><li><strong>用户向量</strong>：同样地，将用户的偏好、评分活动和观影频率合并成一个综合的用户特征向量，例如<code>[0.8, 0.2, 0.7, 0.1, 0.0, 50, 4.2, 8]</code>。</li></ul><p>综合特征向量化后，我们可以通过计算向量之间的相似度来找到电影与用户偏好之间的相关性。这是机器学习和推荐系统中的一个常见步骤，它帮助我们理解和量化项目（如电影）与用户之间的匹配程度。以下是几种常用的相似度计算方法：</p><h4 id="1-余弦相似度consine"><a class="markdownIt-Anchor" href="#1-余弦相似度consine"></a> 1. 余弦相似度(CONSINE)</h4><p>余弦相似度是衡量两个向量在方向上的相似度，忽略它们的大小。它的值范围从-1（完全相反）到1（完全相同），0表示两个向量之间没有相关性。即计算向量空间中两个点的夹角大小，夹角越小，相似度越高，公式如下：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">[</mo><mtext>余弦相似度</mtext><mo>=</mo><mfrac><mrow><mi mathvariant="bold">A</mi><mo>⋅</mo><mi mathvariant="bold">B</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="bold">A</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">B</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[ \text{余弦相似度} = \frac{\mathbf{A} \cdot \mathbf{B}}{|\mathbf{A}| |\mathbf{B}|} ]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord text"><span class="mord cjk_fallback">余弦相似度</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.29911em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.36311em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathbf">A</span></span><span class="mord">∣</span><span class="mord">∣</span><span class="mord"><span class="mord mathbf">B</span></span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">A</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathbf">B</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">]</span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">A</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">B</span></span></span></span></span> 是两个向量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi><mo>⋅</mo><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf{A} \cdot \mathbf{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">A</span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">B</span></span></span></span></span> 是向量的点积，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∥</mi><mi mathvariant="bold">A</mi><mi mathvariant="normal">∥</mi></mrow><annotation encoding="application/x-tex">\|\mathbf{A}\|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∥</span><span class="mord"><span class="mord mathbf">A</span></span><span class="mord">∥</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∥</mi><mi mathvariant="bold">B</mi><mi mathvariant="normal">∥</mi></mrow><annotation encoding="application/x-tex">\|\mathbf{B}\|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∥</span><span class="mord"><span class="mord mathbf">B</span></span><span class="mord">∥</span></span></span></span> 是向量的欧几里得范数（即向量的长度）。</p><h4 id="2-欧几里得距离欧氏距离l2"><a class="markdownIt-Anchor" href="#2-欧几里得距离欧氏距离l2"></a> 2. 欧几里得距离（欧氏距离）(L2)</h4><p>欧几里得距离（或称欧式距离）测量的是两个向量在多维空间中的“直线”距离。距离越小，相似度越高。公式如下：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>欧几里得距离</mtext><mo>=</mo><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo><msub><mi>A</mi><mi>i</mi></msub><mo>−</mo><msub><mi>B</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">\text{欧几里得距离} = \sqrt{\sum_{i=1}^{n} (A_i - B_i)^2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">欧几里得距离</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.1568160000000005em;vertical-align:-1.277669em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8791470000000006em;"><span class="svg-align" style="top:-5.116816em;"><span class="pstrut" style="height:5.116816em;"></span><span class="mord" style="padding-left:1.056em;"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.740108em;"><span style="top:-2.9890000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.8391470000000005em;"><span class="pstrut" style="height:5.116816em;"></span><span class="hide-tail" style="min-width:0.742em;height:3.196816em;"><svg width="400em" height="3.196816em" viewbox="0 0 400000 3196" preserveaspectratio="xMinYMin slice"><path d="M702 80H40000040H742v3062l-4 4-4 4c-.667.7 -2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1h-12l-28-84c-16.667-52-96.667 -294.333-240-727l-212 -643 -85 170c-4-3.333-8.333-7.667-13 -13l-13-13l77-155 77-156c66 199.333 139 419.667219 661 l218 661zM702 80H400000v40H742z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span></span></span></span></span></p><p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">A_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>B</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">B_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">A</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">B</span></span></span></span></span> 在第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span></span></span></span> 个维度上的值。</p><h4 id="3-内积ip"><a class="markdownIt-Anchor" href="#3-内积ip"></a> 3. 内积(IP)</h4><p>两个嵌入之间的IP距离定义如下：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/IP_formula.png" alt="ip"></p><p>如果您需要比较非标准化数据或当您关心幅度和角度时，IP 会更有用。如果您使用 IP 来计算嵌入相似度，则必须对嵌入进行标准化。归一化后，内积等于余弦相似度。</p><p>假设 X’ 通过嵌入 X 进行归一化：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/normalize_formula.png" alt="正常化"></p><p>两个embedding之间的相关性如下：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/normalization_formula.png" alt="正常化"></p><h4 id="4-曼哈顿距离"><a class="markdownIt-Anchor" href="#4-曼哈顿距离"></a> 4. 曼哈顿距离</h4><p>曼哈顿距离（或城市街区距离）测量的是在标准坐标系统中从一个点到另一个点的距离，只沿着坐标轴方向计算。公式如下：</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>曼哈顿距离</mtext><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi mathvariant="normal">∣</mi><msub><mi>A</mi><mi>i</mi></msub><mo>−</mo><msub><mi>B</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex"> \text{曼哈顿距离} = \sum_{i=1}^{n} |A_i - B_i| </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord text"><span class="mord cjk_fallback">曼哈顿距离</span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.929066em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6513970000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span></span></span></p><p>这种方法在某些情况下比欧几里得距离更有意义，尤其是在维度非常高时。</p><h3 id="应用示例"><a class="markdownIt-Anchor" href="#应用示例"></a> 应用示例</h3><p>假设我们有一个用户的特征向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">U</mi></mrow><annotation encoding="application/x-tex">\mathbf{U}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">U</span></span></span></span></span> 和两部电影的特征向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></mrow><annotation encoding="application/x-tex">\mathbf{M1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">M</span><span class="mord mathbf">1</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></mrow><annotation encoding="application/x-tex">\mathbf{M2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">M</span><span class="mord mathbf">2</span></span></span></span></span>。我们可以使用上述任何一种方法来计算用户向量与每部电影向量之间的相似度。</p><ul><li>如果我们使用<strong>余弦相似度</strong>，我们可能会发现 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">U</mi></mrow><annotation encoding="application/x-tex">\mathbf{U}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">U</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></mrow><annotation encoding="application/x-tex">\mathbf{M1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">M</span><span class="mord mathbf">1</span></span></span></span></span> 之间的相似度为 0.9（非常相似），而 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">U</mi></mrow><annotation encoding="application/x-tex">\mathbf{U}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">U</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">M</mi><mn mathvariant="bold">2</mn></mrow><annotation encoding="application/x-tex">\mathbf{M2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">M</span><span class="mord mathbf">2</span></span></span></span></span> 之间的相似度为 0.3（不太相似）。基于这些结果，推荐系统会倾向于推荐 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">M</mi><mn mathvariant="bold">1</mn></mrow><annotation encoding="application/x-tex">\mathbf{M1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68611em;vertical-align:0em;"></span><span class="mord"><span class="mord mathbf">M</span><span class="mord mathbf">1</span></span></span></span></span> 给用户。</li></ul><p>这个计算过程不仅适用于个性化推荐，还可用于聚类分析（将相似的电影或用户分为组）、异常检测（识别与大多数用户或项目显著不同的情况）等任务。</p><p>通过这种方式，机器学习模型可以根据综合特征向量的相似度，有效地识别并推荐用户可能感兴趣的电影，实现个性化推荐。</p><h1 id="二-向量数据库"><a class="markdownIt-Anchor" href="#二-向量数据库"></a> 二、向量数据库</h1><p>目前市场上存在许多向量数据库产品。从国内和国外两个维度来看，国内有</p><ul><li>Milvus</li><li>京东的VEARCH</li><li>蚂蚁金服的ZSearch等产品。</li></ul><p>Milvus是目前向量数据库赛道里较为热门的产品，而京东和蚂蚁更多的是将它们的应用于内部场景，外部使用较少。</p><p>在海外来看，大公司都有自己的向量数据库产品，比较知名的有如Qdrant和Weaviate等等。此外，Pinecone是目前商业向量数据库市场最热门的产品。国内的商业数据库产品有联汇和爱可生自己开发的向量数据库产品，当然这些产品都是基于开源产品进行包装的。</p><p>从三个维度来看，这些向量数据库可以分为：向量检索库、向量插件和向量字段。</p><ul><li>在检索库方面有Meta的Faiss、微软的SPTAG，谷歌的ScaNN等等。</li><li>插件方面包括ES、OpenSearch和PG等产品中都集成了向量的特性。</li><li>而向量字段则是数据库本身集成的向量特性，但功能相对较弱。</li></ul><h2 id="向量数据库的原理"><a class="markdownIt-Anchor" href="#向量数据库的原理"></a> 向量数据库的原理</h2><p>前面我们介绍到，计算向量空间中两个点的相似度可以使用<code>余弦相似度</code>、<code>欧几里得距离</code>、<code>曼哈顿距离</code>等。一般向量数据库常用的为前两种。</p><p>把空间向量两点的值带入公式即可得出一个数值，当两点之间的计算结果符合这个阈值，我们只需要设定一个相似度阈值我们就认为是相似度较高的。</p><h2 id="向量索引"><a class="markdownIt-Anchor" href="#向量索引"></a> 向量索引</h2><p>当需要检索匹配的数据巨大时，如果将输入的点和巨大的目标集合进行挨个比较计算，这个计算量是无法承受的，因此我们引入了一个概念叫向量索引。</p><blockquote><p>向量索引（vector index）：是指通过某种数学模型，对向量构建的一种时间和空间上比较高效的数据结构。借助向量索引，我们能够高效地查询与目标向量相似的若干个向量</p></blockquote><p>说白了就是牺牲一定的准确度来加快检索的效率的一种索引数据结构。</p><h3 id="向量索引类型"><a class="markdownIt-Anchor" href="#向量索引类型"></a> 向量索引类型：</h3><ol><li><p><strong>FLAT (FLAT)</strong>: 一个基本的线性索引，对数据库中的每个项进行全面扫描，以找到最近的邻居。虽然准确度高，但随着数据量的增加，搜索效率较低。</p></li><li><p><strong>IVF_FLAT (Inverted File with FLAT)</strong>: 使用倒排文件（IVF）将数据分割成多个桶（或称为聚类），在查询时首先确定查询向量所属的桶，然后在该桶内进行FLAT搜索。这种方法提高了搜索速度，但牺牲了一定的精度。<br>IVF_FLAT（Inverted File with FLAT）索引是一种用于加速向量搜索的技术，特别适用于高维空间的近似最近邻（ANN）搜索。它结合了倒排索引（Inverted File）和暴力搜索（FLAT）的特点，通过预先聚类减少搜索过程中需要比较的向量数量，从而加速查询过程。其基本原理如下：</p><p><strong>预处理阶段</strong>：</p><p>聚类：首先，IVF_FLAT对数据库中的所有向量进行聚类操作，通常使用k-means算法。每个聚类中心（或称为质心）代表了一个向量的聚类。<br>建立倒排索引：然后，为每个聚类建立一个倒排列表（或称桶），桶中存储属于该聚类中心的所有向量的索引。这样，每个向量就被分配到了一个与之最近的聚类中心对应的桶里。<br><strong>搜索阶段</strong>：</p><p>当进行向量搜索查询时，IVF_FLAT首先确定查询向量与哪个或哪些聚类中心最接近。<br>然后，只在与这些最近的聚类中心对应的倒排列表中的向量进行暴力搜索（FLAT），而不是在整个数据库中搜索。<br>通过这种方式，搜索过程被限制在一小部分相关向量中，显著减少了计算量。</p></li><li><p><strong>IVF_SQ8 (Inverted File with Scalar Quantization)</strong>: 在IVF的基础上，使用标量量化（SQ8）对向量进行压缩，进一步提高存储和搜索效率，同时牺牲了一定的搜索准确度。</p></li><li><p><strong>IVF_PQ (Inverted File with Product Quantization)</strong>: 利用产品量化（PQ）技术对向量进行编码和压缩，以减少内存占用并加速搜索。它在保持相对较高搜索质量的同时，大大提高了搜索速度。</p></li><li><p><strong>GPU_IVF_FLAT/GPU_IVF_PQ</strong>: 这些是IVF_FLAT和IVF_PQ索引的GPU版本，利用GPU的并行计算能力来加速搜索过程。</p></li><li><p><strong>HNSW (Hierarchical Navigable Small World)</strong>: 基于小世界网络的一种图索引，提供了高效的近似最近邻搜索，特别是在高维数据集上效果显著。</p></li><li><p><strong>DISKANN (Disk-based Approximate Nearest Neighbor)</strong>: 一种旨在大规模数据集上运行的索引，优化了磁盘存储和搜索速度，适用于不能完全加载到内存中的大数据集。</p></li><li><p><strong>BIN_FLAT (Binary FLAT)</strong>: 对二进制向量执行全面扫描的基本索引，类似于浮点数向量的FLAT索引，但专为处理二进制数据设计。</p></li><li><p><strong>BIN_IVF_FLAT (Binary Inverted File with FLAT)</strong>: 结合了倒排索引和二进制数据的特性，先将数据分割成多个桶，然后在查询时仅在特定的桶内进行搜索，适用于二进制向量数据。</p></li></ol><p>这些索引类型各有优势和适用场景，选择合适的索引类型需要根据具体的应用需求、数据特性和资源限制来决定。例如，对于需要高准确度的应用，可能会选择FLAT或HNSW索引；而对于大规模数据集，可能会选择IVF_PQ或DISKANN以平衡搜索速度和准确度。</p><h1 id="向量数据库milvus使用"><a class="markdownIt-Anchor" href="#向量数据库milvus使用"></a> 向量数据库Milvus使用</h1><p>Milvus国内比较火，社区比较活跃的一个向量数据库，本地免费使用，他也有Cloud云版本，无需自己运维。</p><p>下图是这个Milvus数据库的架构图，这其实是一个经典的分布式系统。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/architecture_02.jpg" alt="建筑学"></p><p>可以看出他最大的特点是存储和计算分离，每一部分都可弹性伸缩切都是无状态的，这是一个典型的分布式系统架构设计。</p><h2 id="milvus的docker安装"><a class="markdownIt-Anchor" href="#milvus的docker安装"></a> Milvus的docker安装</h2><p>Milvus有单机和集群版之分，小规模应用对可靠性没要求的直接使用单机版就够了</p><p>新建一个<code>docker-compose.yml</code>内容如下，包含了元数据中心、存储引擎、单机版Milvus以及图形化界面管理工具Attu,其中图形化管理工具是选择性安装的，其他的事必须要有的</p><pre class="highlight"><code class>version: '3.5'services:  # 元数据注册中心，用于管理 Milvus 内部组件的元数据访问和存储，例如：proxy、index node 等。  etcd:    container_name: milvus-etcd    # 生产环境用这个    #image: rancher/coreos-etcd:v3.4.16-rancher1    image: quay.io/coreos/etcd:v3.5.0    environment:      - ETCD_AUTO_COMPACTION_MODE=revision      - ETCD_AUTO_COMPACTION_RETENTION=1000      - ETCD_QUOTA_BACKEND_BYTES=4294967296      - ETCD_SNAPSHOT_COUNT=50000    volumes:      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd  #  是存储引擎，负责维护 Milvus 的数据持久化, console界面 http://localhost:9001  minio:    container_name: milvus-minio    image: minio/minio:RELEASE.2022-03-17T06-34-49Z    environment:      MINIO_ACCESS_KEY: minioadmin      MINIO_SECRET_KEY: minioadmin    ports:      - &quot;9001:9001&quot;    volumes:      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data    command: minio server /minio_data --console-address &quot;:9001&quot;    healthcheck:      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:9000/minio/health/live&quot;]      interval: 30s      timeout: 20s      retries: 3  # 单机版 Milvus  standalone:    container_name: milvus-standalone    image: milvusdb/milvus:v2.2.2    command: [&quot;milvus&quot;, &quot;run&quot;, &quot;standalone&quot;]    environment:      ETCD_ENDPOINTS: etcd:2379      MINIO_ADDRESS: minio:9000    volumes:      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus    ports:      - &quot;19530:19530&quot;      - &quot;9091:9091&quot;    depends_on:      - &quot;etcd&quot;      - &quot;minio&quot;  # 图形界面管理工具，http://localhost:8000  attu:    container_name: attu    image: zilliz/attu:v2.2.3    environment:      MILVUS_URL: milvus-standalone:19530    ports:      - &quot;8000:3000&quot;    depends_on:      - &quot;standalone&quot;networks:  default:    name: milvus</code></pre><p>直接启动</p><pre class="highlight"><code class="shell">cd ./milvussudo docker-compose up -d</code></pre><p>启动成功后看下图形界面是否能够进去<br><a href="http://localhost:8000" target="_blank" rel="noopener">http://localhost:8000</a></p><h2 id="管理-milvus-连接"><a class="markdownIt-Anchor" href="#管理-milvus-连接"></a> 管理 Milvus 连接</h2><pre class="highlight"><code class>from pymilvus import connectionsconnections.connect(  alias=&quot;default&quot;,  uri=&quot;localhost:19530&quot;,  #token=&quot;root:Milvus&quot;,  user=&quot;&quot;,  password=&quot;&quot;)</code></pre><p>在全局调用一次connect就好了，接下来就可以使用SDK直接操作里面的database、collection</p><h2 id="管理database"><a class="markdownIt-Anchor" href="#管理database"></a> 管理Database</h2><p>默认情况下，让我们不显示创建和指定数据库时，默认使用的就是<code>default</code><br>您也可以在 Milvus 中创建数据库，并为某些用户分配权限来管理它们。那么这些用户就有权管理数据库中的集合。一个 Milvus 集群最多支持 64 个数据库。</p><pre class="highlight"><code class>from pymilvus import connections, dbconn = connections.connect(host=&quot;127.0.0.1&quot;, port=19530)database = db.create_database(&quot;book&quot;)</code></pre><p>使用它</p><pre class="highlight"><code class>db.using_database(&quot;book&quot;)</code></pre><p>您还可以设置连接到 Milvus 集群时使用的数据库，如下所示：</p><pre class="highlight"><code class>conn = connections.connect(    host=&quot;127.0.0.1&quot;,    port=&quot;19530&quot;,    db_name=&quot;default&quot;)</code></pre><h2 id="collection集合管理"><a class="markdownIt-Anchor" href="#collection集合管理"></a> Collection集合管理</h2><pre class="highlight"><code class>from pymilvus import Collection, FieldSchema, CollectionSchema, DataType, connections, utilityconnections.connect(alias=&quot;default&quot;)schema = CollectionSchema(fields=[...     FieldSchema(&quot;int64&quot;, DataType.INT64, description=&quot;int64&quot;, is_primary=True),...     FieldSchema(&quot;float_vector&quot;, DataType.FLOAT_VECTOR, is_primary=False, dim=128),... ])collection = Collection(name=&quot;old_collection&quot;, schema=schema)utility.rename_collection(&quot;old_collection&quot;, &quot;new_collection&quot;) # Output: Trueutility.drop_collection(&quot;new_collection&quot;)utility.has_collection(&quot;new_collection&quot;) # Output: False</code></pre><p>你也可以在不存在时创建集合，并创建向量索引，在存在时加载，代码如下：</p><pre class="highlight"><code class="python"> <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_milvus_collection</span>(<span class="hljs-params">self, collection_name</span>):        <span class="hljs-comment"># utility.drop_collection(collection_name)</span>        has = utility.has_collection(collection_name)        logger.info(<span class="hljs-string">f&quot;Does collection <span class="hljs-subst">{collection_name}</span> exist in Milvus: <span class="hljs-subst">{has}</span>&quot;</span>)        embeddings_model_dim = EMBEDDING_MODEL_MAPPING[self.embed_model]        <span class="hljs-comment"># 判断是否存在</span>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> has:            fields = [                FieldSchema(name=<span class="hljs-string">&quot;id&quot;</span>, dtype=DataType.INT64, is_primary=<span class="hljs-literal">True</span>, auto_id=<span class="hljs-literal">True</span>),                FieldSchema(name=<span class="hljs-string">&quot;doc_id&quot;</span>, dtype=DataType.INT64),                FieldSchema(name=<span class="hljs-string">&quot;random&quot;</span>, dtype=DataType.DOUBLE),                FieldSchema(name=<span class="hljs-string">&quot;chunk&quot;</span>, dtype=DataType.VARCHAR, max_length=<span class="hljs-number">2048</span>),                FieldSchema(name=<span class="hljs-string">&quot;embeddings&quot;</span>, dtype=DataType.FLOAT_VECTOR, dim=embeddings_model_dim),                <span class="hljs-comment">#FieldSchema(name=&quot;embedding_model&quot;, dtype=DataType.VARCHAR, max_length=50),</span>            ]            schema = CollectionSchema(fields, <span class="hljs-string">&quot;hello_milvus is the simplest demo to introduce the APIs&quot;</span>)            collection = Collection(collection_name, schema, consistency_level=<span class="hljs-string">&quot;Strong&quot;</span>)            index_params = {                <span class="hljs-string">&quot;index_type&quot;</span>: <span class="hljs-string">&quot;IVF_FLAT&quot;</span>,  <span class="hljs-comment"># FLAT、IVF_FLAT、IVF_PQ、IVF_SQ8、ANNOY 和 HNSW</span>                <span class="hljs-string">&quot;metric_type&quot;</span>: <span class="hljs-string">&quot;L2&quot;</span>,                <span class="hljs-string">&quot;params&quot;</span>: {<span class="hljs-string">&quot;nlist&quot;</span>: <span class="hljs-number">128</span>},            }            collection.create_index(<span class="hljs-string">&quot;embeddings&quot;</span>, index_params)            logger.info(<span class="hljs-string">f&quot;Dose not exists collection <span class="hljs-subst">{collection_name}</span>, has create it.&quot;</span>)        <span class="hljs-keyword">else</span>:            collection = Collection(collection_name)            collection.load()        <span class="hljs-keyword">return</span> collection</code></pre><p>其中的</p><pre class="highlight"><code class> index_params = {                &quot;index_type&quot;: &quot;IVF_FLAT&quot;,  # FLAT、IVF_FLAT、IVF_PQ、IVF_SQ8、ANNOY 和 HNSW                &quot;metric_type&quot;: &quot;L2&quot;,                &quot;params&quot;: {&quot;nlist&quot;: 128},            }</code></pre><p>就是之前提到的向量索引的配置，<code>index_type</code>表示采用索引的类型，要根据数据集的大小和使用场景进行选择，一般数据量较小可以采用全量暴力检索FLAT可以提高搜索精度，如果数据量很大可以采用IVF_FLAT在精度和搜索效率上做个权衡。<code>metric_type</code>检索时使用的相似度算法，可选的有L2（欧几里德距离）、IP（内积）<br>、COSINE（余弦相似度），注意不同的index_type可能支持的metric_type略有不同，params是不同的index_type下的扩展参数，例如这里选的<code>IVF_FLAT</code>,params中的nlist则表示将数据集预处理成多少个聚类，每个聚类有一个聚类中心，当要检索目标输入时直接到与之最相近的聚类中查找即可，详细的参数配置和说明请参考官方文档详细说明：<a href="https://milvus.io/docs/index.md" target="_blank" rel="noopener">https://milvus.io/docs/index.md</a></p><h2 id="数据管理"><a class="markdownIt-Anchor" href="#数据管理"></a> 数据管理</h2><h3 id="输入插入"><a class="markdownIt-Anchor" href="#输入插入"></a> 输入插入</h3><pre class="highlight"><code class="python"> <span class="hljs-keyword">def</span> <span class="hljs-title function_">save_to_milvus</span>(<span class="hljs-params">self, embedding_result: []</span>):        collection = self.get_milvus_collection()        <span class="hljs-comment"># 这里是个二维数组，第一维度对应集合中的每一个字段定义，除了自增的字段之外都要有相应的值</span>        entities = [            [embedding_result[i][<span class="hljs-string">&quot;doc_id&quot;</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(embedding_result))],  <span class="hljs-comment"># field doc_id</span>            [<span class="hljs-built_in">float</span>(random.randrange(-<span class="hljs-number">20</span>, -<span class="hljs-number">10</span>)) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(embedding_result))],  <span class="hljs-comment"># field random</span>            [embedding_result[i][<span class="hljs-string">&quot;chunk&quot;</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(embedding_result))],  <span class="hljs-comment"># field chunk</span>            [embedding_result[i][<span class="hljs-string">&quot;embeddings&quot;</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(embedding_result))],  <span class="hljs-comment"># field embeddings</span>        ]        insert_result = collection.insert(entities)        logger.info(<span class="hljs-string">f&quot;insert_result <span class="hljs-subst">{insert_result.primary_keys}</span>&quot;</span>)        <span class="hljs-comment"># After final entity is inserted, it is best to call flush to have no growing segments left in memory</span>        collection.flush()</code></pre><h3 id="数据删除"><a class="markdownIt-Anchor" href="#数据删除"></a> 数据删除</h3><pre class="highlight"><code class="python">     <span class="hljs-keyword">def</span> <span class="hljs-title function_">delete_embeddings</span>(<span class="hljs-params">self, doc_ids: [<span class="hljs-built_in">int</span>]</span>):        collection = self.get_milvus_collection()        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:            query_res = collection.query(expr=<span class="hljs-string">&#x27;doc_id in &#x27;</span> + <span class="hljs-built_in">str</span>(doc_ids), output_fields=[<span class="hljs-string">&quot;id&quot;</span>], limit=<span class="hljs-number">30</span>)            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(query_res) == <span class="hljs-number">0</span>:                logger.warning(<span class="hljs-string">f&quot;Delete_embeddings entity is empty: doc_ids:<span class="hljs-subst">{doc_ids}</span>&quot;</span>)                <span class="hljs-keyword">break</span>            ids = []            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(query_res)):                ids.append(query_res[i].get(<span class="hljs-string">&#x27;id&#x27;</span>))            res = collection.delete(expr=<span class="hljs-string">&#x27;id in &#x27;</span> + <span class="hljs-built_in">str</span>(ids))            logger.info(<span class="hljs-string">f&quot;Delete_embeddings success: doc_ids:<span class="hljs-subst">{doc_ids}</span>, res: <span class="hljs-subst">{res}</span>&quot;</span>)        collection.flush()</code></pre><h3 id="查询数据"><a class="markdownIt-Anchor" href="#查询数据"></a> 查询数据</h3><p>查找与目标字符串相近的字符串chunk</p><pre class="highlight"><code class="python">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">search_embeddings</span>(<span class="hljs-params">self, doc_ids: [<span class="hljs-built_in">int</span>], intput_text: <span class="hljs-built_in">str</span>, top_k: <span class="hljs-built_in">int</span> = <span class="hljs-number">3</span></span>):        collection = self.get_milvus_collection()        vectors_to_search = self.get_embeddings_obj().embed_query(intput_text)        logger.info(<span class="hljs-string">f&#x27;search <span class="hljs-subst">{intput_text}</span> vectors success.&#x27;</span>)        search_params = {            <span class="hljs-string">&quot;metric_type&quot;</span>: <span class="hljs-string">&quot;L2&quot;</span>,            <span class="hljs-string">&quot;params&quot;</span>: {<span class="hljs-string">&quot;nprobe&quot;</span>: <span class="hljs-number">128</span>},        }        search_result = collection.search([vectors_to_search], <span class="hljs-string">&quot;embeddings&quot;</span>,                                   search_params,                                   limit=top_k,                                   output_fields=[<span class="hljs-string">&quot;chunk&quot;</span>, <span class="hljs-string">&quot;id&quot;</span>],                                   expr=<span class="hljs-string">&#x27;doc_id in &#x27;</span> + <span class="hljs-built_in">str</span>(doc_ids)                                   )        logger.info(<span class="hljs-string">f&#x27;<span class="hljs-subst">{intput_text}</span> search_embeddings_result&gt;&gt;&gt; <span class="hljs-subst">{search_result}</span>&#x27;</span>)        result = []        max_distance = <span class="hljs-number">1</span>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(search_result) == <span class="hljs-number">0</span>:            logger.warning(<span class="hljs-string">f&quot;<span class="hljs-subst">{intput_text}</span> search_embeddings_result is empty!!!&quot;</span>)            <span class="hljs-keyword">return</span> result        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(search_result[<span class="hljs-number">0</span>])):            hit = search_result[<span class="hljs-number">0</span>][i]            distance = <span class="hljs-built_in">float</span>(hit.distance)            <span class="hljs-comment"># if distance &gt; float(max_distance):</span>            <span class="hljs-comment">#     continue</span>            chunk = hit.entity.get(<span class="hljs-string">&#x27;chunk&#x27;</span>)            <span class="hljs-built_in">id</span> = hit.entity.get(<span class="hljs-string">&#x27;id&#x27;</span>)            result.append({<span class="hljs-string">&#x27;chunk&#x27;</span>:chunk, <span class="hljs-string">&#x27;chunk_id&#x27;</span>:<span class="hljs-built_in">id</span>, <span class="hljs-string">&#x27;distance&#x27;</span>:distance})            logger.info(<span class="hljs-string">f&quot;<span class="hljs-subst">{distance}</span> chuck <span class="hljs-subst">{chunk}</span>&quot;</span>)        <span class="hljs-keyword">return</span> result</code></pre>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> 向量数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo主题添加数学公式渲染支持</title>
      <link href="/ruan-jian-bi-ji/hexo-zhu-ti-tian-jia-shu-xue-gong-shi-xuan-ran-zhi-chi/"/>
      <url>/ruan-jian-bi-ji/hexo-zhu-ti-tian-jia-shu-xue-gong-shi-xuan-ran-zhi-chi/</url>
      
        <content type="html"><![CDATA[<p>对于数学/物理工作者来说，一个常见的需求是想要在Hexo博客中支持复杂数学公式的渲染。MathJax 和 KaTeXKATEX 是两个常见的渲染引擎，MathJax 使用者多、兼容性好、但渲染速度慢，而 KaTeXKATEX 渲染速度快，且根号无错位，但有时有bug。本文给出基于Keep主题的 KaTeXKATEX 的配置方法。</p><h2 id="更换渲染器"><a class="markdownIt-Anchor" href="#更换渲染器"></a> 更换渲染器</h2><p>无论是基于<code>MathJax</code> 还是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mi>a</mi><mi>T</mi><mi>e</mi><mi>X</mi></mrow><annotation encoding="application/x-tex">KaTeX</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>，都要首先更换Hexo自带的渲染器，因为它不支持渲染复杂数学公式。</p><pre class="highlight"><code class>npm uni hexo-renderer-marked</code></pre><p>安装 hexo-renderer-markdown-it-plus 渲染器</p><pre class="highlight"><code class>npm i hexo-renderer-markdown-it-plus</code></pre><p>此渲染器默认包含且开启了 <code>@iktakahiro/markdown-it-katex</code> 插件，可渲染 11.1 版本以前的 KaTeXKATEX 公式。但 KaTeXKATEX 自 13.0 开始渲染机制发生了变化，需要更换为 <code>@andatoshiki/markdown-it-katex</code> 插件。</p><pre class="highlight"><code class>npm install katexnpm install @andatoshiki/markdown-it-katex</code></pre><p>并在根目录的 <code>_config.yml</code> 中添加如下内容,测试下来，不加下面这个也可行</p><pre class="highlight"><code class>markdown_it_plus:  # ...  plugins:    - plugin:      name: '@iktakahiro/markdown-it-katex'      enable: false    - plugin:      name: '@andatoshiki/markdown-it-katex'      enable: false</code></pre><p>接着执行</p><pre class="highlight"><code class>hexo cleanhexo generate</code></pre><p>以清除缓存并刷新插件配置。</p><h2 id="配置css"><a class="markdownIt-Anchor" href="#配置css"></a> 配置CSS</h2><p>插件安装好后，需要在每篇博客的 <code>&lt;head&gt;</code> 标签中包含 KaTeXKATEX 的CSS。考虑到国内的网络环境，可以选择360作为CDN</p><pre class="highlight"><code class>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://lib.baomitu.com/KaTeX/latest/katex.min.css&quot;&gt;</code></pre><p>若主要用途为国外访问，可以使用 jsDelivr</p><pre class="highlight"><code class>&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css&quot;&gt;</code></pre><p>若每篇博客都要使用数学公式，可以将其加入主题预定义的 <code>head.ejs</code> 中。</p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
            <tag> hexo博客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MacOS系统升级后Navicat密码保存不了问题</title>
      <link href="/ruan-jian-bi-ji/macos-xi-tong-sheng-ji-hou-navicat-mi-ma-bao-cun-bu-liao/"/>
      <url>/ruan-jian-bi-ji/macos-xi-tong-sheng-ji-hou-navicat-mi-ma-bao-cun-bu-liao/</url>
      
        <content type="html"><![CDATA[<p>MacOS系统升级后Navicat 15或16版本会出现无法保存数据库密码问题，报&quot;AIled to save password error code -34018&quot;,每次重启都要重新编辑连接输入数据库密码，超级崩溃。</p><h1 id="尝试解决"><a class="markdownIt-Anchor" href="#尝试解决"></a> 尝试解决</h1><p>网上试了很多方法尝试解决，有什么删除Keychains的，有什么下载补充类库的，都无法解决。</p><p>例如这个：<a href="https://blog.csdn.net/max_zhanglei/article/details/114032161" target="_blank" rel="noopener">https://blog.csdn.net/max_zhanglei/article/details/114032161</a></p><p>原因是说：macOS Big Sur及更高版本的macOs系统都会有这个问题，按博主解决方法未能成功。</p><h1 id="最终解决"><a class="markdownIt-Anchor" href="#最终解决"></a> 最终解决</h1><p>最后放弃使用新版Navicat, 老版本也很香，完全不影响工作日常使用。</p><p>这里下载链接，直接下载即可，无需激活。</p><p><a href="https://xclient.info/s/navicat-premium.html#versions" target="_blank" rel="noopener">https://xclient.info/s/navicat-premium.html#versions</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240219155022864.png" alt="image-20240219155022864"></p><p>我用<strong>12.1.27</strong> 版本安装使用成功，网传<strong>15.0.20.1</strong> 也可以，这个没试过大家可以自行尝试下看看。</p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
            <tag> Navicat </tag>
            
            <tag> MacOS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能技术发展史</title>
      <link href="/ren-gong-zhi-neng/ren-gong-zhi-neng/"/>
      <url>/ren-gong-zhi-neng/ren-gong-zhi-neng/</url>
      
        <content type="html"><![CDATA[<h1 id="人工智能"><a class="markdownIt-Anchor" href="#人工智能"></a> 人工智能</h1><h1 id="什么是人工智能"><a class="markdownIt-Anchor" href="#什么是人工智能"></a> 什么是人工智能</h1><p>指由人制造出来的机器所表现出来的智能。<em>人工智能</em>可以定义为模仿人类与人类思维相关的认知功能的机器或计算机，如学习和解决问题</p><ul><li>专家系统：基于专家知识库+推理引擎。比如使用预定的一些规则和逻辑，模拟人类专家进行决策的过程</li><li>启发式问题解决：比如评估小范围的解决方案，并可能涉及一些猜测，以找到接近最佳的解决方案。</li><li>自然语言处理：在自然语言中实现人机之间的交流。比如聊天机器人。</li><li>计算机视觉：自动生成识别形状和功能的能力。比如人脸识别、图像识别、语音识别（本质还是基于数据化之后的语音图谱）</li></ul><h1 id="如何实现这些智能"><a class="markdownIt-Anchor" href="#如何实现这些智能"></a> 如何实现这些智能</h1><h2 id="手动编写规则和逻辑"><a class="markdownIt-Anchor" href="#手动编写规则和逻辑"></a> 手动编写规则和逻辑</h2><p>手动编写各种规则，以响应特定的输出，类似IF/ELSE逻辑，更加复杂的就是一些数学函数规则。</p><p>比如情感问题专家系统，有一个预设好的问题和答案库，当用户输入某个问题时，返回对应问题的答案。</p><p>比如在早期的机器翻译，就是通过语法规则解析+关键词匹配来识别和理解用户的输入，并响应对应目标语言的语法规则和关键词生成翻译语言。</p><p>在比如我们公司的风控系统，根据输入特征结合预设规则返回风控结果等等。在一定程度上都能实现简单的类人类的一些智能。</p><h2 id="基于统计概率"><a class="markdownIt-Anchor" href="#基于统计概率"></a> 基于统计概率</h2><p>基于大量实际的例子进行概率统计预测，例如我们的手机输入法，个人常用的词组将会放在前面。</p><p>人们很快发现，对于实世界的复杂问题并不都可以通过预设规则很好地处理，</p><p>比如人脸识别、图像识别，一个人从早到晚、每天的情绪变化都会细微地影响你的人脸构成，而计算机又是极其“死脑筋”的，任何细微的变化都可能对同一个人识别失败，所以我们不可能通过预设所有情况很好地解决这类问题。</p><p>再比如自然语言处理，只通过预发解析和关键词匹配的出来的解释并不是一成不变的，语言中有很多歧义性(多义词)、容错性（错别字、顺序错误、语法错误）。这样下来我们实际使用的语言是灵活性极高的，并不能穷举完所有情况进行预设。例如下面这段话：</p><blockquote><p>他说：“她这个人真有意思(funy)。”她说：“他这个人怪有意思的(funy)。”于是人们以为他们有了意思(wish)，并让他向她意思意思（express）。他火了：“我根本没有那个意思(thought)！”她也生气了：“你们这么说是什么意思（Intention）？”事后有人说：“真有意思(funny)。”也有人说：“真没意思(nonsense)。”</p></blockquote><p>很难通过预设的一些语法和关键词进行很好的翻译对应的“意思”。当然自然语言处理发展已有半个世纪的发展。在机器学习之前的翻译翻译效果也一直不够理想。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240219163614202.png" alt="image-20240219163614202"></p><h2 id="机器学习"><a class="markdownIt-Anchor" href="#机器学习"></a> 机器学习</h2><p>利用数据和算法让计算机自动学习模式、规律，并进行预测和分类。</p><p>就比如给一堆的数据：标注好的图片、标注好的语料。让计算机自动通过机器学习的过程不断总结规律直至预测和分类效果达到可接受的范围之内。从而得到能够预测和分类未知输入的能力。</p><p>过程类似这样。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20240219163634073.png" alt="image-20240219163634073"></p><p>就是让机器通过数学建模找到f(x)函数，使得他可以拟合我们现实世界中的任意复杂场景。</p><p>例如这样的线性函数，找到个f(x)函数使得到各个点的实际误差最小。</p><p>例如这样的类一元二次函数的点分布，找到一个抛物线使得到各个点的误差最小。</p><p>我们人类可以根据数学经验和已知的一些规律找到对于函数类型，是一元一次方程、一元二次方程、或者是指数函数，正余弦等等。</p><p>但是对于计算机来讲他怎么知道该用什么类型的函数来拟合呢。如果数据分布呈现不了任何规律，又改如何找对对于的函数进行拟合呢。</p><p>比如如这样的，这样的，甚至这样的。</p><h2 id="神经网络"><a class="markdownIt-Anchor" href="#神经网络"></a> 神经网络</h2><p>这个东西也叫通用函数逼近器，数学家已经证明，两层的神经网络足以拟合任何复杂函数。</p><h2 id="神经网络的类型"><a class="markdownIt-Anchor" href="#神经网络的类型"></a> 神经网络的类型</h2><p>CNN</p><p>RNN</p><p>DNN</p><h2 id="一个完整模型训练炼丹的过程"><a class="markdownIt-Anchor" href="#一个完整模型训练炼丹的过程"></a> 一个完整模型训练(“炼丹”)的过程</h2><p>无监督学习</p><p>有监督学习</p><p>微调</p><p>参考文献：</p><p>小白也能听懂的人工智能原理：<a href="https://www.aliyundrive.com/s/hXdxXyuuzdW" target="_blank" rel="noopener">https://www.aliyundrive.com/s/hXdxXyuuzdW</a> 提取码p2z7</p><p>Transformer的基本原理：<a href="https://blog.51cto.com/u_16161414/6483603" target="_blank" rel="noopener">https://blog.51cto.com/u_16161414/6483603</a></p><p>神经网络的基本原理：<a href="https://blog.51cto.com/u_16161414/6479769" target="_blank" rel="noopener">https://blog.51cto.com/u_16161414/6479769</a></p><p>神经网络初探——神经网络如何工作：<a href="https://zhuanlan.zhihu.com/p/64532465" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/64532465</a></p><p>一文看懂四种基本的神经网络架构：<a href="https://www.jianshu.com/p/546dc40b52c8" target="_blank" rel="noopener">https://www.jianshu.com/p/546dc40b52c8</a></p><p>很好的大语言模型的入门：ChatGPT背后的语言模型简史：<a href="https://www.bmpi.dev/dev/deep-learning/nlp-language-models/" target="_blank" rel="noopener">https://www.bmpi.dev/dev/deep-learning/nlp-language-models/</a></p><p>图解Word2vec,是如何训练出来的：<a href="https://mp.weixin.qq.com/s/NMngfR7EWk-pa6c4_FY9Yw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/NMngfR7EWk-pa6c4_FY9Yw</a></p><p>如何通俗理解Word2Vec (23年修订版)</p><p><a href="https://blog.csdn.net/v_JULY_v/article/details/102708459" target="_blank" rel="noopener">https://blog.csdn.net/v_JULY_v/article/details/102708459</a></p><p>Transformer通俗笔记：从Word2Vec、Seq2Seq逐步理解到GPT、BERT：<a href="https://blog.csdn.net/v_JULY_v/article/details/127411638" target="_blank" rel="noopener">https://blog.csdn.net/v_JULY_v/article/details/127411638</a></p><p>图解GPT：<a href="https://github.com/datawhalechina/learn-nlp-with-transformers/blob/main/docs/%E7%AF%87%E7%AB%A02-Transformer%E7%9B%B8%E5%85%B3%E5%8E%9F%E7%90%86/2.4-%E5%9B%BE%E8%A7%A3GPT.md" target="_blank" rel="noopener">https://github.com/datawhalechina/learn-nlp-with-transformers/blob/main/docs/篇章2-Transformer相关原理/2.4-图解GPT.md</a></p><p>超大型人工智能：从GPT-&gt;GPT2-&gt;GPT3的发展历程+大规模预训练神经网络模型原理详解： <a href="https://zhuanlan.zhihu.com/p/591146772" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/591146772</a></p><p>提示词工程：<a href="https://www.51cto.com/article/749832.html" target="_blank" rel="noopener">https://www.51cto.com/article/749832.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 人工智能 </tag>
            
            <tag> AI </tag>
            
            <tag> 大语言模型 </tag>
            
            <tag> LLM </tag>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>通用大语言模型介绍、本地部署及微调</title>
      <link href="/ren-gong-zhi-neng/llma-ben-di-da-jian-bi-ji/"/>
      <url>/ren-gong-zhi-neng/llma-ben-di-da-jian-bi-ji/</url>
      
        <content type="html"><![CDATA[<h2 id="wget-后台下载"><a class="markdownIt-Anchor" href="#wget-后台下载"></a> wget 后台下载</h2><pre class="highlight"><code class>wget -b url# 查看wget logcat wget-logtail -f wget-log# wget指定文件名称wget url -o filename</code></pre><h2 id="sftp文件上传"><a class="markdownIt-Anchor" href="#sftp文件上传"></a> sftp文件上传</h2><pre class="highlight"><code class>sftp root@8.134.128.130 &lt;&lt;EOFput ./source/openai-demo*.jar /opt/openai-demo/byeEOF#查看本地的文件列表llslcd lscd</code></pre><h2 id="查看文件摘要"><a class="markdownIt-Anchor" href="#查看文件摘要"></a> 查看文件摘要</h2><pre class="highlight"><code class>sha256sum example.txt</code></pre><h2 id="git-lfs使用"><a class="markdownIt-Anchor" href="#git-lfs使用"></a> Git lfs使用</h2><pre class="highlight"><code class>安装 homebrewbrew install git-lfsgit lfs install下载安装 windows installer运行 windows installergit lfs installsudo yum install git-lfssudo apt-get install git-lfs# 切换到lfsgit lfs install# 列出git lfs管理的大文件git lfs list-files</code></pre><h2 id="conda使用"><a class="markdownIt-Anchor" href="#conda使用"></a> Conda使用</h2><pre class="highlight"><code class>conda create -n env_nameconda activate env_nameconda info --envs# 安装软件conda install xxx</code></pre><h2 id="查看显卡运行情况命令"><a class="markdownIt-Anchor" href="#查看显卡运行情况命令"></a> 查看显卡运行情况命令</h2><pre class="highlight"><code class>watch -n 0.5 nvidia-smi</code></pre><h2 id="安装环境依赖"><a class="markdownIt-Anchor" href="#安装环境依赖"></a> 安装环境依赖</h2><pre class="highlight"><code class>pip install -r requirement.txt</code></pre><h2 id="clash服务器端代理"><a class="markdownIt-Anchor" href="#clash服务器端代理"></a> Clash服务器端代理：</h2><p>使用Xflash作为梯子</p><p><a href="https://i.jakeyu.top/2021/11/27/centos-%E4%BD%BF%E7%94%A8-Clash-%E6%A2%AF%E5%AD%90/" target="_blank" rel="noopener">https://i.jakeyu.top/2021/11/27/centos-使用-Clash-梯子/</a></p><p><a href="https://www.jianshu.com/p/1702a352797d" target="_blank" rel="noopener">https://www.jianshu.com/p/1702a352797d</a></p><pre class="highlight"><code class>nohup ~/clash &gt; /dev/null 2&gt;&amp;1 &amp;nohup ~/clash &gt; ~/clash_out.log &amp;vim /etc/profilesource /etc/profileexport ALL_PROXY=socks5://127.0.0.1:7891export http_proxy=http://127.0.0.1:7890export https_proxy=http://127.0.0.1:7890#测试curl www.google.com</code></pre><h2 id="报错集锦"><a class="markdownIt-Anchor" href="#报错集锦"></a> 报错集锦</h2><h2 id="大语言模型大爆发"><a class="markdownIt-Anchor" href="#大语言模型大爆发"></a> 大语言模型大爆发</h2><p>开源大语言模型(LLM)汇总： <a href="http://www.dtmao.cc/NodeJs/75351.html" target="_blank" rel="noopener">http://www.dtmao.cc/NodeJs/75351.html</a></p><p>开源ChatGPT替代模型项目整理： <a href="https://zhuanlan.zhihu.com/p/618790279" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/618790279</a></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1deb2c972163d97bf177aa20222ac42a.png" alt="img"></p><h2 id="llma大语言模型large-language-model-llm"><a class="markdownIt-Anchor" href="#llma大语言模型large-language-model-llm"></a> LLMA（大语言模型，Large Language Model, LLM）</h2><p>大语言模型llma-13b:<a href="https://huggingface.co/decapoda-research/llama-13b-hf/tree/main" target="_blank" rel="noopener">https://huggingface.co/decapoda-research/llama-13b-hf/tree/main</a></p><p>LMFlow大语言模型微调：<a href="https://github.com/OptimalScale/LMFlow/blob/main/readme/README_zh-hans.md" target="_blank" rel="noopener">https://github.com/OptimalScale/LMFlow/blob/main/readme/README_zh-hans.md</a></p><p>LLMA-Alpaca中文版：<a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca" target="_blank" rel="noopener">https://github.com/ymcui/Chinese-LLaMA-Alpaca</a></p><p>LLMA-Alpaca中文版与原始llma模型合并：<a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E6%A8%A1%E5%9E%8B%E5%90%88%E5%B9%B6%E4%B8%8E%E8%BD%AC%E6%8D%A2" target="_blank" rel="noopener">https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/模型合并与转换</a></p><p>LLMA-Alpaca中文版模型训练过程：<a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82" target="_blank" rel="noopener">https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/训练细节</a></p><p>大语言模型的下载和安装：<a href="https://ivonblog.com/posts/dalai-llama-installation/" target="_blank" rel="noopener">https://ivonblog.com/posts/dalai-llama-installation/</a></p><h2 id="chatglm"><a class="markdownIt-Anchor" href="#chatglm"></a> ChatGLM</h2><p><a href="https://github.com/THUDM/ChatGLM-6B" target="_blank" rel="noopener">https://github.com/THUDM/ChatGLM-6B</a></p><p>官方chatglm微调：<a href="https://github.com/THUDM/ChatGLM-6B/blob/main/ptuning/README.md" target="_blank" rel="noopener">https://github.com/THUDM/ChatGLM-6B/blob/main/ptuning/README.md</a></p><p>第三方微调：<a href="https://github.com/ssbuild/chatglm_finetuning" target="_blank" rel="noopener">https://github.com/ssbuild/chatglm_finetuning</a></p><p>PTuning与LoRA微调方式：<a href="https://github.com/liucongg/ChatGLM-Finetuning" target="_blank" rel="noopener">https://github.com/liucongg/ChatGLM-Finetuning</a></p><p>制作数据集方案：<a href="https://github.com/hikariming/alpaca_chinese_dataset/blob/main/%E5%BE%AE%E8%B0%83%E4%BD%BF%E7%94%A8%E8%87%AA%E5%B7%B1%E6%95%B0%E6%8D%AE%E9%9B%86%E6%88%90%E5%8A%9F%E6%96%B9%E6%A1%88.ipynb" target="_blank" rel="noopener">https://github.com/hikariming/alpaca_chinese_dataset/blob/main/微调使用自己数据集成功方案.ipynb</a></p><p>用Blog和聊天记录微调自己的ChatGLM模型：<a href="https://github.com/wdkwdkwdk/CLONE_DK" target="_blank" rel="noopener">https://github.com/wdkwdkwdk/CLONE_DK</a></p><p>使用langchat进行训练：<a href="https://www.heywhale.com/mw/project/643977aa446c45f4592a1e59" target="_blank" rel="noopener">https://www.heywhale.com/mw/project/643977aa446c45f4592a1e59</a></p><p>港科大开源的训练微调脚手架：<a href="https://github.com/OptimalScale/LMFlow" target="_blank" rel="noopener">https://github.com/OptimalScale/LMFlow</a></p><h2 id="微调"><a class="markdownIt-Anchor" href="#微调"></a> 微调</h2><p>ChatGPT等大模型高效调参大法——PEFT：<a href="https://zhuanlan.zhihu.com/p/613863520" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/613863520</a></p><p>（1）对于动则百亿级别的参数,如何更高效,低资源的微调大模型呢</p><p>（2）当样本量很小的时候，如何微调大模型能得到较好的效果呢</p><ul><li>LORA ：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2106.09685.pdf" target="_blank" rel="noopener">LORA</a> 算法是在 每层 transfomer block 旁边引入一个并行低秩的支路，支路的输入是transfomer block 的输入，</li><li>PREFIX_TUNING</li><li>P_TUNING/P_TUNING 2</li><li>PROMPT_TUNING</li></ul><h2 id="基于chatglm的p-tuning2微调"><a class="markdownIt-Anchor" href="#基于chatglm的p-tuning2微调"></a> 基于ChatGLM的P-Tuning2微调</h2><p>官方chatglm微调：<a href="https://github.com/THUDM/ChatGLM-6B/blob/main/ptuning/README.md" target="_blank" rel="noopener">https://github.com/THUDM/ChatGLM-6B/blob/main/ptuning/README.md</a></p><h3 id="基于chatglm的lora微调"><a class="markdownIt-Anchor" href="#基于chatglm的lora微调"></a> 基于ChatGLM的Lora微调</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230423203743669.png" alt="image-20230423203743669"></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20230423205550920.png" alt="image-20230423205550920"></p><h2 id="langchain"><a class="markdownIt-Anchor" href="#langchain"></a> Langchain</h2><p>人工智能应用搭建的脚手架，提供了诸如在特定文档上进行问答、聊天机器人、智能代理等各类应用场景的快速搭建</p><p><a href="https://github.com/hwchase17/langchain" target="_blank" rel="noopener">https://github.com/hwchase17/langchain</a></p><p><a href="https://github.com/arc53/docsgpt" target="_blank" rel="noopener">https://github.com/arc53/docsgpt</a></p><p><a href="https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide" target="_blank" rel="noopener">https://github.com/liaokongVFX/LangChain-Chinese-Getting-Started-Guide</a></p><p>实现基于上下文的QA机器人：</p><p><a href="https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html" target="_blank" rel="noopener">https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html</a></p><p><a href="https://python.langchain.com/en/latest/use_cases/question_answering.html" target="_blank" rel="noopener">https://python.langchain.com/en/latest/use_cases/question_answering.html</a></p><h1 id="人工智能领域软件汇总"><a class="markdownIt-Anchor" href="#人工智能领域软件汇总"></a> 人工智能领域软件汇总</h1><ul><li>transflow 神经网络框架</li><li>PyTorch 新兴神经网络框架</li><li>transformer  huggingface出品，类似于人工智能的运行框架和平台, 底层进一步对PyTorch/Transflow等进行封装,是人工智能模型标准定义</li><li>huggingface：<a href="https://huggingface.co/" target="_blank" rel="noopener">https://huggingface.co/</a>  是一个AI领域的GITHUB，上面管理的市训练好的模型(Model)、数据集（Dataset）、社区(Space)</li><li>Conda python环境隔离管理软件，因为各个python应用所需的依赖版本有时各有不同，为了防止冲突，可以通过conda进行依赖环境隔离</li><li>Cuda Nvidia的指令集，供给应用层使用GPU计算能力，也就是给ai的训练和推演提供算力支持</li><li>Git lfs 大文件git管理指令集，用于从：<a href="https://huggingface.co/" target="_blank" rel="noopener">https://huggingface.co/</a> clone下载模型文件</li><li>Langchain 人工智能应用搭建的脚手架，提供了诸如在特定文档上进行问答、聊天机器人、智能代理等各类应用场景的快速搭建</li></ul>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> LLama </tag>
            
            <tag> ChatGLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac好用的Markdown编辑器</title>
      <link href="/ruan-jian-bi-ji/mac-hao-yong-de-markdown-bian-ji-qi/"/>
      <url>/ruan-jian-bi-ji/mac-hao-yong-de-markdown-bian-ji-qi/</url>
      
        <content type="html"><![CDATA[<h1 id="typora"><a class="markdownIt-Anchor" href="#typora"></a> Typora</h1>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>企业信息化和政务信息化</title>
      <link href="/ruan-kao/qi-ye-xin-xi-hua-he-zheng-wu-xin-xi-hua/"/>
      <url>/ruan-kao/qi-ye-xin-xi-hua-he-zheng-wu-xin-xi-hua/</url>
      
        <content type="html"><![CDATA[<h1 id="信息系统工程"><a class="markdownIt-Anchor" href="#信息系统工程"></a> 信息系统工程</h1><p>以结构、元素、信息及反馈等进行分析，以达到最优设计、最优规划、最优管理和最优控制的目的。</p><p>系统工程的方法，霍尔提出的三维结构体系，以时间维、空间维、知识维组成的立体结构概括性表示出系统工程的各个阶段、各个步骤及所涉及到的知识范围。</p><p>时间维———是指工作的进度，而于一个具体的工作项目，从制定规划起到一直更新为止，全部过程可分为七个阶段：</p><ul><li>规划阶段——调研、程序设计阶段，目的紫玉谋求活动的规划和战略</li><li>拟定阶段——提出具体的规划方案</li><li>研制阶段——作出研制方案及生产计划</li><li>生产阶段</li><li>安装阶段</li><li>运行阶段</li><li>更新阶段</li></ul><h1 id="政府信息化与电子政务"><a class="markdownIt-Anchor" href="#政府信息化与电子政务"></a> 政府信息化与电子政务</h1><p>电子政务的三个主体：政府、企业及事业单位、大众</p><h1 id="企业的信息化与电子商务"><a class="markdownIt-Anchor" href="#企业的信息化与电子商务"></a> 企业的信息化与电子商务</h1><h2 id="企业信息化"><a class="markdownIt-Anchor" href="#企业信息化"></a> 企业信息化</h2><p>企业信息化是指通过IT技术的部署来提供去也的生产运维效率，从而降低经营成本。其中业务流程的管理与知识的挖掘是重要活动。</p><ol><li>企业信息化的是3个需求层次：战略需求、运作需求和技术需求</li></ol><ul><li>战略需求——组织信息化的目标是提升组织的竞争力、为组织的可持续发展提供一个支持环境。从而某种意义上来说信息化对组织不仅仅是服务的手段和实现现有战略的辅助工具；信息化可以报组织战略提升到一个新的水平，为组织带来新的发展契机。</li><li>运作需求——实现战略目标的需要、运作策略的需要、人才培养的需要。</li><li>技术需求——由于系统开发时间过长等问题在信息技术层面对系统的完善、升级、集成和整合提出了需求</li></ul><h2 id="企业资源规划erp"><a class="markdownIt-Anchor" href="#企业资源规划erp"></a> 企业资源规划——ERP</h2><p>商业智能——通过数据挖掘技术、知识等发现等技术分析和挖掘结构化的、面向特定领域的的数据仓库信息</p><p>ERP系统的三流：物流、资金流、信息流<br>ERP系统时对企业的物流、资金流、信息流进行全面集成的管理信息系统</p><p>ERP系统能够实现的企业决策计划：</p><ul><li>生产预测计划——对市场的需求进行比较准确的预测，是经营计划、生产计划大纲和主生产计划编制的基础</li><li>销售管理计划——对销售部门的相关业务进行管理，属于最高层计划的范畴，是企业决策层最重要的计划之一</li><li>生产计划大纲——根据经营计划生产目标制定</li><li>主生产计划——说明一段时期内生产什么，生产多少盒什么时候交货，它是ERP的主要工作内容。</li><li>物料需求计划是对主生产计划的各个项所需的制造件和全部采购件等计划</li><li>能力需求计划——是对物料需求计划所需的能力进行核算的一种计划管理方法，能够帮助尽早发现企业的生产能力瓶颈，及时补充生产力。</li></ul><p>ERP的信息流：</p><ul><li>需求信息——客户订单、生产计划、采购合同等</li><li>供应信息——入库单、完工报告单、库存记录、可供销售量和提货发货发运单等</li></ul><h2 id="客户关系管理crm"><a class="markdownIt-Anchor" href="#客户关系管理crm"></a> 客户关系管理——CRM</h2><p>客户关系管理（CRM）系统将市场营销的科学管理通过信息技术手段集成在软件商，能够帮助企业构建良好的客户关系。<br>CRM是将人力资源、业务流程与专业的技术进行有效的整合，最终为企业涉及到的客户或者消费者的各个领域提供完美的集成，是的企业可以更低成本、更高效率满足客户的需求。<br>其主要功能包括：</p><ul><li>销售自动化——是其中最为基本的模块</li><li>营销自动化——作为销售自动化的补充，包括营销计划的编制和执行、计划结果分析等。</li><li>客户服务支持——是系统的重要功能</li><li>商业智能——数据挖掘和处理，为企业决策做支撑。</li></ul><p>CRM系统与ERP系统在财务、制造、库存等环节进行连接，<strong>两种虽然不同但由于两者之间具有一定的关系，因此能够形成一定的闭环反馈结构</strong></p><h2 id="企业应用的集成"><a class="markdownIt-Anchor" href="#企业应用的集成"></a> 企业应用的集成</h2><p>企业应用集成有多种集成模式，构建统一标准的基础平台，将具有不同功能和目的而又独立运行的企业信息联合起来。目前市场上主流的集成模式有三种，分别是<strong>面向信息的集成</strong>、<strong>面向过程的集成</strong>、<strong>面向服务的集成</strong>。</p><ul><li>面向过程集成——强调处理不同应用系统之间的交互逻辑，与核心业务逻辑相分离，并通过不同应用系统之间的协作共同完成某项业务功能。</li><li>面向信息的集成<ul><li>内部信息集成<ul><li>技术平台集成——系统底层的体系结构、软件、硬件及异构网络的特殊需求受限必须得到集成。这个集成包括信息技术硬件的组成</li><li>数据集成，共享数据库，主动记录、数据映射，实现不同的系统数据交流和共享，</li><li>应用系统集成，应用系统集成是实现不同系统之间的相互操作，是的不同应用系统之间能够实现数据和方法的共享</li><li>业务过程的集成，业务过程集成，企业必须在各个业务系统中定义、授权和管理各种业务信息的交流，一遍改进操作、减少成本、提高响应速度。</li></ul></li><li>外部信息集成</li></ul></li><li>面向服务的集成</li></ul><p>集成方式：</p><ul><li>远程过程调用——基于同步的方式，效率较低，二期容易失败；</li><li>共享数据和文件传输——将应用的数据存储在一个共享数据库中，通过制定统一的数据库模式来处理不同应用的集成需求，共享数据库为不同的应用提供了统一的数据存储和格式定义。性能方面较差，系统不能保持即时数据同步，而容易造成应用于数据紧耦合；</li><li>消息传递方式——能够保证数据异步、立即、可靠传输</li></ul><p>集成平台提供的基本功能包括：</p><ul><li>数据通信服务：提供分布环境下的透明同步、异步通信的服务功能</li><li>信息集成服务：为应用提供透明的信息访问服务，实现不同数据库之间的数据交换、相互操作、分布数据管理和共享信息模型的定义</li><li>应用集成服务：通过高层应用编程接口实现对相应应用程序的访问，能够为应用提供数据交换和访问的操作，是的各个系统相互协作。</li><li>二次开发工具：帮助用户开发特定应用程序的支持工具</li><li>平台运行管理工具：是企业集成平台和运作的管理控制面板。</li></ul><p>电子数据交换——EDI<br>EDI的实施需要一个公认的标准和协议，将商务活动中涉及到的文件标准化和格式化；EDI通过计算机网络，在贸易伙伴之间进行数据交换和自动处理</p><p>企业门户是一个信息技术平台，可提供个性化的信息服务，为企业提供一个单一的访问企业各种信息资源和应用的程序入口。</p><p>分为3中门户类型：</p><ul><li>企业信息门户——企业信息门户强调为访问结构数据和无结构数据提供统一的入口，实现收集、访问、管理和无缝集成</li><li>企业知识门户——提供一个创造、搜集和传播企业知识的平台，通过企业知识门户，员工与工作团队中的其他成员取得联系，寻找能够提供帮助的专家。</li><li>企业应用门户——是一个用来提供企业的集中贸易能力、协同能力和信息管理能力的平台。它以商业流程和企业应用为核心，将商业流程中功能不同的应用模块通过门户集成在一起，提高公司在集中贸易的能力、协同能力和信息管理能力。</li></ul><h2 id="电子商务"><a class="markdownIt-Anchor" href="#电子商务"></a> 电子商务</h2><p>参与电子商务的实体有四类：客户（个人消费者或者集团）、商户（包括销售商、制造商和储运商）、银行（发卡行和收单行）以及认证中心</p><h1 id="知识管理和商业智能化"><a class="markdownIt-Anchor" href="#知识管理和商业智能化"></a> 知识管理和商业智能化</h1><h2 id="商业智能化"><a class="markdownIt-Anchor" href="#商业智能化"></a> 商业智能化</h2><p>商业智能化的核心技术包括：数据仓库、数据挖掘、联机分析处理。<br>商业智能化系统处理过程包括数据预处理、简历数据仓库、数据分析及数据展现：</p><ul><li>数据预处理——包括数据的抽取、转换、封装</li><li>数据仓库——是处理海量数据的基础</li><li>数据分析——包括联机分析处理和数据挖掘两部分<ul><li>联机分析——处理不仅进行数据汇总、聚集，同事还提供切片、切块、下钻、上卷和旋转等分析功能</li><li>数据挖掘——挖掘数据背后的隐藏知识，通过</li></ul></li><li>数据展现——数据的可视化</li></ul>]]></content>
      
      
      <categories>
          
          <category> 软考 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软考 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java学习大纲</title>
      <link href="/hou-duan-jia-gou/java-xue-xi-da-gang/"/>
      <url>/hou-duan-jia-gou/java-xue-xi-da-gang/</url>
      
        <content type="html"><![CDATA[<p>任何学习都要有目标有规划，这是整个Java知识体系大纲，根据自己的知识体系认知画出来的，有很多还没有细化，也还有很多没有涉猎，比如大数据，列出这些好让自己学的有目标一些吧，也算是一个总结。</p><p>在线预览地址：<a href="http://naotu.baidu.com/file/a94181bfafe64d39874b524ce8df18c1?token=a8efb35e029a526f" target="_blank" rel="noopener">http://naotu.baidu.com/file/a94181bfafe64d39874b524ce8df18c1?token=a8efb35e029a526f</a></p><img title src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184207294.png" alt data-align="center" width="684">]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后端&amp;架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分库分表的分页查询</title>
      <link href="/hou-duan-jia-gou/fen-ku-fen-biao-de-fen-ye-cha-xun/"/>
      <url>/hou-duan-jia-gou/fen-ku-fen-biao-de-fen-ye-cha-xun/</url>
      
        <content type="html"><![CDATA[<h1 id="问题的提出"><a class="markdownIt-Anchor" href="#问题的提出"></a> 问题的提出</h1><p>我们知道，当我们的数据量达到一定数量时，需要将数据表进行水平拆分，从而满足大量数据的存储和查询，保证系统的可用性，但同时会出现另外一个问题就是，如果业务要查询“最近注册的第3页用户”，该如何实现呢？单库上，可以通过简单的sql实现分页查询</p><pre class="highlight"><code class>select * from t_user order by time limit 200,100</code></pre><p>分库分表后变成两个库后，分库依据是user_id，排序依据是time，单个分数据库层失去了time排序的全局视野，如果同样需要实现分页查询时该怎么办呢？</p><h1 id="全局视野法"><a class="markdownIt-Anchor" href="#全局视野法"></a> 全局视野法</h1><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040381.png" alt></p><p>正常来讲，不管哪一个分库的第3页都不一定有全局第3页的所有数据，例如一下三种情况：<br>情况一：两个分库按照时间排序，数据各占一半，则每页取offset和limit的一般数据回来合并就可以了<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040402.png" alt="aaa"></p><p>情况二：所有数据都在一个库上，则取一个库的所有数据回来就可以了<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040384.png" alt="ccc"></p><p>情况三，那么一般情况是，每个分库的数据数据是随机的，但是一定是在全局offset=600之内<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040393.png" alt="bbb"></p><p>由于不清楚到底是哪种情况，所以必须每个库都返回3页数据，所得到的6页数据在服务层进行内存排序，得到数据全局视野，再取第3页数据，便能够得到想要的全局分页数据。</p><p>这种方法缺点是：当查询的页数增大时，每个分库所需返回的数据也越来成倍增加，降低了查询的性能</p><h1 id="业务折中"><a class="markdownIt-Anchor" href="#业务折中"></a> 业务折中</h1><h2 id="第一种折中的方案是"><a class="markdownIt-Anchor" href="#第一种折中的方案是"></a> 第一种折中的方案是</h2><p>对全局视野法的一种优化，即禁用制定页数的分页查询，必须通过下一页来实现分页查询的页数跳转，并且在每次查询下一页时将上一页的最大排序字段的值带上（这里就是时间time）,这样在每个分库查询数据时待上这个条件，可以优化查询速率。</p><h2 id="第二种折中的方案是"><a class="markdownIt-Anchor" href="#第二种折中的方案是"></a> 第二种折中的方案是</h2><p>数据库分库-数据均衡原理</p><p>使用patition key进行分库，在数据量较大，数据分布足够随机的情况下，各分库所有非patition key属性，在各个分库上的数据分布，统计概率情况是一致的。</p><p>例如，在uid随机的情况下，使用uid取模分两库，db0和db1：</p><p>（1）性别属性，如果db0库上的男性用户占比70%，则db1上男性用户占比也应为70%</p><p>（2）年龄属性，如果db0库上18-28岁少女用户比例占比15%，则db1上少女用户比例也应为15%</p><p>（3）时间属性，如果db0库上每天10:00之前登录的用户占比为20%，则db1上应该是相同的统计规律</p><p>利用这一原理，要查询全局100页数据，offset 9900 limit 100改写为offset 4950 limit 50，每个分库偏移4950（一半），获取50条数据（半页），得到的数据集的并集，基本能够认为，是全局数据的offset 9900 limit 100的数据，当然，这一页数据的精度，并不是精准的。</p><p>根据实际业务经验，用户都要查询第100页网页、帖子、邮件的数据了，这一页数据的精准性损失，业务上往往是可以接受的，但此时技术方案的复杂度便大大降低了，既不需要返回更多的数据，也不需要进行服务内存排序了。</p><h1 id="二次查找法"><a class="markdownIt-Anchor" href="#二次查找法"></a> 二次查找法</h1><p>有没有一种方法既能满足业务要求，并且不需要折中，性能还高的方法呢？<br>接下来介绍一种“二次查找法”，不知道能不能讲的明白，我尽量吧。</p><p>为了方便举例，假设一页只有5条数据，查询第200页的SQL语句为select * from T order by time offset 1000 limit 5;</p><p>分五步：</p><h3 id="1-将select-from-t-order-by-time-offset-1000-limit-5-优化成select-from-t-order-by-time-offset-500-limit-5注意这里的5001000分表数量并将这个sql下发至每个分库分表中执行每个分库返回这个sql执行的结果"><a class="markdownIt-Anchor" href="#1-将select-from-t-order-by-time-offset-1000-limit-5-优化成select-from-t-order-by-time-offset-500-limit-5注意这里的5001000分表数量并将这个sql下发至每个分库分表中执行每个分库返回这个sql执行的结果"></a> 1. 将<code>select * from T order by time offset 1000 limit 5;</code> 优化成<code>select * from T order by time offset 500 limit 5</code>,注意这里的500=1000/分表数量，并将这个sql下发至每个分库分表中执行，每个分库返回这个sql执行的结果。</h3><h3 id="2-找到所有分库返回结果的time的最小值"><a class="markdownIt-Anchor" href="#2-找到所有分库返回结果的time的最小值"></a> 2. 找到所有分库返回结果的time的最小值</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040369.png" alt><br>第一个库，5条数据的time最小值是1487501123<br>第二个库，5条数据的time最小值是1487501223</p><p>故，三页数据中，time最小值来自第一个库，time_min=1487501123，这个过程只需要比较各个分库第一条数据，时间复杂度很低</p><h3 id="3-查询二次改写"><a class="markdownIt-Anchor" href="#3-查询二次改写"></a> 3. 查询二次改写</h3><p>第一次改写的SQL语句是select * from T order by time offset 500 limit 5</p><p>第二次要改写成一个between语句，between的起点是time_min，between的终点是原来每个分库各自返回数据的最大值：</p><p>第一个分库，第一次返回数据的最大值是1487501523<br>所以查询改写为select * from T order by time where time between time_min and 1487501523</p><p>第二个分库，第一次返回数据的最大值是1487501699<br>所以查询改写为select * from T order by time where time between time_min and 1487501699</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040363.png" alt></p><p>从上面图片可以看出，DB1比第一次查出来的数据多了两行，应为查询的范围扩大了</p><h3 id="4-计算time_min这条记录在全局的offset"><a class="markdownIt-Anchor" href="#4-计算time_min这条记录在全局的offset"></a> 4. 计算time_min这条记录在全局的offset</h3><p>根据第一步查询的sql<code>select * from T order by time offset 500 limit</code> ,我们知道每个库的offset值了，将DB0中的最小time的数据虚拟到DB1中推算在DB1中的offset值=497<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040525.png" alt><br>从而我们得知time_min这条记录在全局的offset值=500+497=997</p><h3 id="5-根据第二次查询出来的结果集在内存中作排序已知time_min在全局中的offset997那么结果集排序之后也能推算出offset1000所在的记录从而获得sqlselect-from-t-order-by-time-offset-1000-limit-5的分页查询记录图片黄色部分"><a class="markdownIt-Anchor" href="#5-根据第二次查询出来的结果集在内存中作排序已知time_min在全局中的offset997那么结果集排序之后也能推算出offset1000所在的记录从而获得sqlselect-from-t-order-by-time-offset-1000-limit-5的分页查询记录图片黄色部分"></a> 5. 根据第二次查询出来的结果集，在内存中作排序，已知time_min在全局中的offset=997,那么结果集排序之后也能推算出offset=1000所在的记录，从而获得sql<code>select * from T order by time offset 1000 limit 5</code>的分页查询记录（图片黄色部分）</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184040515.png" alt></p><p>总结：可以精确的返回业务所需数据，每次返回的数据量都非常小，不会随着翻页增加数据的返回量。</p>]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后端&amp;架构 </tag>
            
            <tag> 分库分表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>限流相关</title>
      <link href="/hou-duan-jia-gou/xian-liu-xiang-guan/"/>
      <url>/hou-duan-jia-gou/xian-liu-xiang-guan/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a class="markdownIt-Anchor" href="#前言"></a> 前言</h1><p>在大流量场景，秒杀、抢购场景，一般会对网站做一些流量控制，牺牲一部分流量而保护系统而不至于系统直接down机。</p><h1 id="常见限流算法"><a class="markdownIt-Anchor" href="#常见限流算法"></a> 常见限流算法</h1><h2 id="固定计算限流"><a class="markdownIt-Anchor" href="#固定计算限流"></a> 固定计算限流</h2><p>就是统计固定时间内的流量数量，如果超过了就限制。这种很容易实现，利用AutomicLong统计，下一个统计周期后又清零重新计算。<br>这样会有以下问题：</p><ol><li>1s之内的前100ms就已经达到了,那么后900ms就是空闲的。</li><li>如果1s之内的后100ms和下一秒的前100ms,那么在这个前后1s内加起来的流量是限流的两倍，显然这没有达到“在任意1s内流量不超过限制”的控制，很多黑客利用这个缺陷攻击网站，从而拖垮服务器。</li></ol><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184239907.png" alt></p><h2 id="滑动窗口"><a class="markdownIt-Anchor" href="#滑动窗口"></a> 滑动窗口</h2><p>为了解决“计数限流”的缺陷，我们引入“滑动窗口”的计数方法。就是在计数限流的基础之上，将1个限流时间周期内切分成更小的单位计数，使得限制流量更加均分。<br>具体做法如下：</p><ol><li>将1s钟切成更细粒度200ms为计数单位，将请求时间点按取模的方式计算落到对应的计数格中，然后判断从当前计数格往前推1s(也就是5个计数格)的统计数总和当成当前流量的计数，如果超过阈值则限流，否则放行</li></ol><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184239739-1424159.png" alt></p><ol start="2"><li>随着请求时间的推进，计数窗口也会随之往前移动</li></ol><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184239638-20240605150010827.png" alt></p><ol start="3"><li>这样的好处是，优化了“固定计数法”的缺陷，即在任意时刻，都将都以更小粒度的计数方法往前累加计算，防止在单位时间内流量超过限额。如图：</li></ol><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184239708.png" alt></p><h2 id="漏桶算法"><a class="markdownIt-Anchor" href="#漏桶算法"></a> 漏桶算法</h2><p>漏桶算法思路很简单，水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会时，有一定的缓冲能力，超过最大缓冲时将直接拒绝。这个算法的特点就是，不管桶里面是空还是满，都以均匀的速度放行。下面是从网上找的图：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184239739.png" alt></p><h2 id="令牌桶算法"><a class="markdownIt-Anchor" href="#令牌桶算法"></a> 令牌桶算法</h2><p>令牌桶算法（Token Bucket）：是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。令牌桶算法示意图如下所示：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184239758.png" alt></p><p>令牌桶算法与漏桶算法的区别在于如果在一段时间内都没有流量，而桶中的令牌数有随着时间流逝匀速增加，那么桶中将会缓冲一定数量的令牌，即使后面流量突然增加超过了限额，也会由于还有可用的令牌直接放行，无需要等待。以下是令牌桶算法相对于漏斗算法的一些优势：</p><ol><li><strong>突发流量的处理</strong>：令牌桶算法允许一定程度的突发流量，因为当令牌桶中有足够的令牌时，流量可以以超过平均速率的速度通过一段时间。这在实际网络环境中是有用的，因为网络流量往往是突发性的。相比之下，漏斗算法对流量的控制更为严格，流量以恒定的速率通过，不允许突发流量。</li><li><strong>灵活性和可配置性</strong>：令牌桶算法提供了更多的灵活性，因为可以独立调整令牌的生成速率和桶的容量，以适应不同的流量需求和网络条件。漏斗算法的配置相对简单，主要是固定的漏斗出口速率，这可能不足以适应复杂的网络环境和多样化的流量模式。</li><li><strong>性能</strong>：在高速网络环境中，令牌桶算法通常能够提供更好的性能，因为它允许在令牌可用时快速传输数据包，而不是强制每个数据包都以固定的速率通过。这意味着令牌桶算法可以更有效地利用可用的带宽，从而提高整体的网络性能。</li></ol><p>总的来说，令牌桶算法相对于漏斗算法的优势在于它对突发流量的支持、更高的灵活性和可配置性，以及在高速网络环境中更好的性能表现。这些特点使得令牌桶算法在实际应用中更受欢迎，特别是在需要处理突发流量和动态调整流量控制策略的场景中。</p><h1 id="限流实现"><a class="markdownIt-Anchor" href="#限流实现"></a> 限流实现</h1><h2 id="guava的ratelimiter实现"><a class="markdownIt-Anchor" href="#guava的ratelimiter实现"></a> Guava的RateLimiter实现</h2><p>在Guava的工具包中，<code>RateLimiter</code>就是居于<code>令牌桶算法</code>实现的内存限流。<br>其构造有如下几个：</p><pre class="highlight"><code class> //构造方法1  @VisibleForTesting  static RateLimiter create(SleepingTicker ticker, double permitsPerSecond) {    //实现类是Bursty    RateLimiter rateLimiter = new Bursty(ticker, 1.0 /* maxBurstSeconds */);    //根据permitsPerSecond每秒令牌数计算，每个令牌产生的毫秒数    rateLimiter.setRate(permitsPerSecond);    return rateLimiter;  }  //构造方法2 static RateLimiter create(      SleepingTicker ticker, double permitsPerSecond, long warmupPeriod, TimeUnit unit) {    //实现类是一个平滑预热限流，就是如果流量突然暴增，即使有足够的令牌，也不会一下子全部放下，会加一些线性等待时间平滑过渡    RateLimiter rateLimiter = new WarmingUp(ticker, warmupPeriod, unit);    rateLimiter.setRate(permitsPerSecond);    return rateLimiter;  }</code></pre><p>获取令牌</p><pre class="highlight"><code class>  public double acquire(int permits) {    checkPermits(permits);    long microsToWait;    //获取全局锁    synchronized (mutex) {        //根据当前时间算出还需要等待的时间        microsToWait = reserveNextTicket(permits, readSafeMicros());    }    ticker.sleepMicrosUninterruptibly(microsToWait);    return 1.0 * microsToWait / TimeUnit.SECONDS.toMicros(1L);  }</code></pre><p>下面是令牌桶算法的核心</p><pre class="highlight"><code class>  private long reserveNextTicket(double requiredPermits, long nowMicros) {    //根据当前时间算出可用令牌数及要出来这么多令牌的时间点    resync(nowMicros);    //看下还需要等多久    long microsToNextFreeTicket = nextFreeTicketMicros - nowMicros;    //看下当前要立即花费多少令牌    double storedPermitsToSpend = Math.min(requiredPermits, this.storedPermits);    //还剩多少令牌需要等待    double freshPermits = requiredPermits - storedPermitsToSpend;    //根据不同的实现，Bursty或者WarmingUp，返回额外需要等待的时间    long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend)        + (long) (freshPermits * stableIntervalMicros);    //重置获取这么多令牌要等到啥时候    this.nextFreeTicketMicros = nextFreeTicketMicros + waitMicros;    //更新下还剩多少可用令牌    this.storedPermits -= storedPermitsToSpend;    //返回还需要等待的时间    return microsToNextFreeTicket;  }</code></pre><p>可以看到这个实现，并不是根据算法图一个生产者不断的往一个数组中添加令牌，一个消费者不断的取令牌，而是以时间线的方式，计算出当前获取令牌需要花费的时间及算出当前时间以设定的速度能够无产生多少令牌的方式实时计算的，简单并且没有额外的轮询操作，非常高效节省资源。</p><h2 id="使用semphore进行并发流控"><a class="markdownIt-Anchor" href="#使用semphore进行并发流控"></a> 使用Semphore进行并发流控</h2><p><code>Semphore</code> 是JUC里面的并发信号量实现，Semaphore可以控制某个资源可被同时访问的个数，通过 acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。很适合多线程情况对有限资源的抢占控制。</p><h2 id="netflix-hystrix-熔断限流"><a class="markdownIt-Anchor" href="#netflix-hystrix-熔断限流"></a> Netflix Hystrix 熔断限流</h2><p>Spring Clound里的Hystrix能否实现根据一定的访问异常设置，对应用做到降级限流的的控制</p><h2 id="阿里的sentinel实现"><a class="markdownIt-Anchor" href="#阿里的sentinel实现"></a> 阿里的Sentinel实现</h2><p>Sentinel 是阿里中间件团队开源的，面向分布式服务架构的轻量级高可用流量控制组件，主要以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度来帮助用户保护服务的稳定性。<br>GITHUB:<a href="https://github.com/alibaba/Sentinel" target="_blank" rel="noopener">https://github.com/alibaba/Sentinel</a><br>其官方文档中也提到，其受到Guava RateLmiter的启发。</p><p>大家可能会问：Sentinel 和上面提到的Netflix Hystrix 有什么异同呢？<br>其官方文档有专门的说明：<br><a href="https://github.com/alibaba/Sentinel/wiki/Sentinel-%E4%B8%8E-Hystrix-%E7%9A%84%E5%AF%B9%E6%AF%94" target="_blank" rel="noopener">https://github.com/alibaba/Sentinel/wiki/Sentinel-与-Hystrix-的对比</a></p><h2 id="其他实现"><a class="markdownIt-Anchor" href="#其他实现"></a> 其他实现</h2><p>进行限流控制还可以有很多种方法，针对不同的场景各有优劣，例如通过AtomicLong计数器控制、Redis计数，使用MQ消息队列进行流量消峰等等都是可以的。</p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>流量控制在高并发场景是一个对系统保护必不可少的一个手段，能够牺牲一部分流量而保护整个应用的可用性，不止于发生雪崩情况。</p>]]></content>
      
      
      <categories>
          
          <category> 后端&amp;架构 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 后端&amp;架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Centos 下Redis 安装以及集群搭建</title>
      <link href="/ruan-jian-bi-ji/centos-xia-redis-an-zhuang-yi-ji-ji-qun-da-jian/"/>
      <url>/ruan-jian-bi-ji/centos-xia-redis-an-zhuang-yi-ji-ji-qun-da-jian/</url>
      
        <content type="html"><![CDATA[<p>1.下载redis安装包</p><pre class="highlight"><code class>cd /root/softwarewget http://download.redis.io/releases/redis-3.2.4.tar.gztar -zxvf redis-3.2.4.tar.gz　</code></pre><p>2.编译安装</p><pre class="highlight"><code class>#先确保安装了make命令#make是gcc的编译器，VPS买来必定要安装#安装：yum -y install gcc automake autoconf libtool make#安装g++:yum install gcc gcc-c++cd redis-3.2.4make &amp;&amp; make install</code></pre><p>3.将 redis-trib.rb 复制到 /usr/local/bin 目录下,能在任意目录访问到此命令</p><pre class="highlight"><code class>cd srccp redis-trib.rb /usr/local/bin/</code></pre><p>4.创建目录存放redis节点的配置文件</p><pre class="highlight"><code class>mkdir /opt/redis-cluster/#redis集群节点至少要6个mkdir 7000 7002 7003 7004 7005#复制redis.conf到各个节点目录cp redis-3.2.4/redis.conf /opt/redis-cluster/7000</code></pre><p>5.然后编辑 redis.conf修改每个节点的配置,修改以下属性</p><pre class="highlight"><code class>port  7000                                        //端口7000,7002,7003        bind 本机ip                                       //默认ip为127.0.0.1 需要改为其他节点机器可访问的ip 否则创建集群时无法访问对应的端口，无法创建集群daemonize    yes                               //redis后台运行pidfile  /var/run/redis_7000.pid          //pidfile文件对应7000,7001,7002cluster-enabled  yes                           //开启集群  把注释#去掉appendonly  yes                           //aof日志开启  有需要就开启，它会每次写操作都记录一条日志　</code></pre><p>6.启动节点</p><pre class="highlight"><code class>redis-server redis_cluster/7000/redis.confredis-server redis_cluster/7001/redis.confredis-server redis_cluster/7002/redis.conf</code></pre><p>检查 redis 启动情况</p><pre class="highlight"><code class>[root@localhost 7005]# ps -ef|grep redisroot     23002     1  0 11:41 ?        00:00:05 redis-server 192.168.10.10:7000 [cluster]root     26165     1  0 11:45 ?        00:00:05 redis-server 192.168.10.10:7001 [cluster]root     26609     1  0 12:03 ?        00:00:04 redis-server 192.168.10.10:7002 [cluster]root     27943     1  0 13:46 ?        00:00:00 redis-server 192.168.10.10:7003 [cluster]root     28008     1  0 13:47 ?        00:00:00 redis-server 192.168.10.10:7004 [cluster]root     28031     1  0 13:48 ?        00:00:00 redis-server 192.168.10.10:7005 [cluster]root     28036 18197  0 13:48 pts/0    00:00:00 grep --color=auto redis</code></pre><pre class="highlight"><code class>#查看端口监听netstat -tnlp | grep redis</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage.png" alt></p><p>7.将redis节点加入集群</p><pre class="highlight"><code class>redis-trib.rb  create  --replicas  1  192.168.10.10:7000 192.168.10.10:7001  192.168.10.10:7002 192.168.10.10:7003 192.168.10.10:7004  192.168.10.10:7005</code></pre><p>运行以上命令时，必须要先安装ruby环境，因为这个命令时ruby写的<br>安装命令如下：</p><pre class="highlight"><code class>yum -y install ruby ruby-devel rubygems rpm-buildgem install redis</code></pre><p>重新运行命令如果出现以下图片则表示集群安装成功，记得中途还需输入yes<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20230213222704158.png" alt></p><p>8.集群验证<br>简单说下redis集群的原理：<br>redis cluster在设计的时候，就考虑到了去中心化，去中间件，也就是说，集群中的每个节点都是平等的关系，都是对等的，每个节点都保存各自的数据和整个集群的状态。每个节点都和其他所有节点连接，而且这些连接保持活跃，这样就保证了我们只需要连接集群中的任意一个节点，就可以获取到其他节点的数据。</p><p>Redis 集群没有并使用传统的一致性哈希来分配数据，而是采用另外一种叫做哈希槽 (hash slot)的方式来分配的。redis cluster 默认分配了 16384 个slot，当我们set一个key 时，会用CRC16算法来取模得到所属的slot，然后将这个key 分到哈希槽区间的节点上，具体算法就是：CRC16(key) % 16384。所以我们在测试的时候看到set 和 get 的时候，直接跳转到了7000端口的节点。</p><p>Redis 集群会把数据存在一个 master 节点，然后在这个 master 和其对应的salve 之间进行数据同步。当读取数据时，也根据一致性哈希算法到对应的 master 节点获取数据。只有当一个master 挂掉之后，才会启动一个对应的 salve 节点，充当 master 。</p><p>需要注意的是：必须要6个或以上的主节点，否则在创建集群时会失败，并且当存活的主节点数小于总节点数的一半时，整个集群就无法提供服务了。</p><p>所以使用redis-cli客户端命令连接redis时，随便指定集群中的任意节点都可以访问到整个集群的数据，运行命令是多加一个<code>-c</code>参数</p><pre class="highlight"><code class>redis-cli -h 192.168.10.10 -c -p 7002</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20230213222711977.png" alt></p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20230213222715529.png" alt></p><p>到此安装完成。</p><h1 id="遇到问题"><a class="markdownIt-Anchor" href="#遇到问题"></a> 遇到问题</h1><p>遇到以下问题时：</p><pre class="highlight"><code class>[root@localhost 7004]# /soft/redis-3.2.4/src/redis-trib.rb  create  --replicas  1  192.168.10.10:7000 192.168.10.10:7001  192.168.10.10:7002 192.168.10.10:7003 192.168.10.10:7004  192.168.10.10:7005&gt;&gt;&gt; Creating cluster[ERR] Node 192.168.10.10:7005 is not empty. Either the node already knows other nodes (check with CLUSTER NODES) or contains some key in database 0.</code></pre><p>解决方法：</p><pre class="highlight"><code class>#查找进程并kill掉[root@localhost 7005]# ps -ef|grep redis                             root     23753     1  0 16:31 ?        00:00:00 /soft/redis-3.2.4/src//redis-server 192.168.10.10:7000 [cluster]root     23758     1  0 16:31 ?        00:00:00 /soft/redis-3.2.4/src//redis-server 192.168.10.10:7001 [cluster]root     23763     1  0 16:31 ?        00:00:00 /soft/redis-3.2.4/src//redis-server 192.168.10.10:7002 [cluster]root     23768     1  0 16:31 ?        00:00:00 /soft/redis-3.2.4/src//redis-server 192.168.10.10:7003 [cluster]root     23778     1  0 16:31 ?        00:00:00 /soft/redis-3.2.4/src//redis-server 192.168.10.10:7005 [cluster]root     23846     1  0 16:34 ?        00:00:00 /soft/redis-3.2.4/src/redis-server 192.168.10.10:7004 [cluster]kill 23846#删除/opt/redis-cluster/7004/下除redis.conf的文件rm -f appendonly.aof  dump.rdb  nodes.conf或者rm -f !(redis.conf)#然后重新启动7004cd /opt/redis-cluster/7004/soft/redis-3.2.4/src/redis-server redis.conf/soft/redis-3.2.4/src/redis-trib.rb  create  --replicas  1  192.168.10.10:7000 192.168.10.10:7001  192.168.10.10:7002 192.168.10.10:7003 192.168.10.10:7004  192.168.10.10:7005</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Idea maven 插件安装</title>
      <link href="/ruan-jian-bi-ji/idea-maven-cha-jian-an-zhuang/"/>
      <url>/ruan-jian-bi-ji/idea-maven-cha-jian-an-zhuang/</url>
      
        <content type="html"><![CDATA[<p>默认idea 是已经安装好了maven插件的，在File&gt;settings&gt;能搜索到maven的相关配置<br>但是有时候它会莫名其妙的不见了或消失<br>检查Plugins是否启用了maven<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183122891.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 8常用转换</title>
      <link href="/ruan-jian-bi-ji/java-8-chang-yong-zhuan-huan/"/>
      <url>/ruan-jian-bi-ji/java-8-chang-yong-zhuan-huan/</url>
      
        <content type="html"><![CDATA[<h1 id="1-list转map"><a class="markdownIt-Anchor" href="#1-list转map"></a> 1. List转Map</h1><pre class="highlight"><code class>/** * List -&gt; Map * 需要注意的是： * toMap 如果集合对象有重复的key，会报错Duplicate key .... *  apple1,apple12的id都为1。 *  可以用 (k1,k2)-&gt;k1 来设置，如果有重复的key,则保留key1,舍弃key2 */Map&lt;Integer, Apple&gt; appleMap = appleList.stream().collect(Collectors.toMap(Apple::getId, a -&gt; a,(k1,k2)-&gt;k1));</code></pre><h1 id="list分组成map"><a class="markdownIt-Anchor" href="#list分组成map"></a> List分组成Map</h1><pre class="highlight"><code class>//List 以ID分组 Map&lt;Integer,List&lt;Apple&gt;&gt;Map&lt;Integer, List&lt;Apple&gt;&gt; groupBy = appleList.stream().collect(Collectors.groupingBy(Apple::getId)); System.err.println(&quot;groupBy:&quot;+groupBy);{1=[Apple{id=1, name='苹果1', money=3.25, num=10}, Apple{id=1, name='苹果2', money=1.35, num=20}], 2=[Apple{id=2, name='香蕉', money=2.89, num=30}], 3=[Apple{id=3, name='荔枝', money=9.99, num=40}]}</code></pre><h1 id="3-map转list"><a class="markdownIt-Anchor" href="#3-map转list"></a> 3. Map转List</h1><pre class="highlight"><code class>List&lt;Long&gt; skuIdList = order.getItemList().stream().map(OrderItemDTO::getSkuId).collect(Collectors.toList());</code></pre><h1 id="4-统计求和"><a class="markdownIt-Anchor" href="#4-统计求和"></a> 4. 统计求和</h1><pre class="highlight"><code class>//计算 总金额BigDecimal totalMoney = appleList.stream().map(Apple::getMoney).reduce(BigDecimal.ZERO, BigDecimal::add);System.err.println(&quot;totalMoney:&quot;+totalMoney);  //totalMoney:17.48</code></pre><h1 id="5-最大值-最小值"><a class="markdownIt-Anchor" href="#5-最大值-最小值"></a> 5. 最大值、最小值</h1><pre class="highlight"><code class>Optional&lt;Dish&gt; maxDish = Dish.menu.stream().      collect(Collectors.maxBy(Comparator.comparing(Dish::getCalories)));maxDish.ifPresent(System.out::println); Optional&lt;Dish&gt; minDish = Dish.menu.stream().      collect(Collectors.minBy(Comparator.comparing(Dish::getCalories)));</code></pre><h1 id="6-过滤map"><a class="markdownIt-Anchor" href="#6-过滤map"></a> 6. 过滤Map</h1><pre class="highlight"><code class>//Map -&gt; Stream -&gt; Filter -&gt; MAPMap&lt;Integer, String&gt; collect = map.entrySet().stream().filter(x -&gt; x.getKey() == 2).collect(Collectors.toMap(x -&gt; x.getKey(), x -&gt; x.getValue()));</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java开发环境准备</title>
      <link href="/ruan-jian-bi-ji/java-kai-fa-huan-jing-zhun-bei/"/>
      <url>/ruan-jian-bi-ji/java-kai-fa-huan-jing-zhun-bei/</url>
      
        <content type="html"><![CDATA[<p>JDK下载地址：<br><a href="https://github.com/frekele/oracle-java/releases" target="_blank" rel="noopener">https://github.com/frekele/oracle-java/releases</a></p><p>idea激活：<br><a href="https://juejin.im/post/5df8a5a5e51d4557f0460990" target="_blank" rel="noopener">https://juejin.im/post/5df8a5a5e51d4557f0460990</a></p><p>maven环境变量配置：<br><a href="https://www.cnblogs.com/tanjiyuan/p/11010998.html" target="_blank" rel="noopener">https://www.cnblogs.com/tanjiyuan/p/11010998.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java bean的Getter Setter 自动编译生成工具Lombok</title>
      <link href="/ruan-jian-bi-ji/java-bean-de-getter-setter-zi-dong-bian-yi-sheng-cheng-gong-ju-lombok/"/>
      <url>/ruan-jian-bi-ji/java-bean-de-getter-setter-zi-dong-bian-yi-sheng-cheng-gong-ju-lombok/</url>
      
        <content type="html"><![CDATA[<h2 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h2><p>我们在开发过程中，通常都会定义大量的JavaBean，然后通过IDE去生成其属性的构造器、getter、setter、equals、hashcode、toString方法，当要对某个属性进行改变时，比如命名、类型等，都需要重新去生成上面提到的这些方法，那Java中有没有一种方式能够避免这种重复的劳动呢？答案是有，lombok插件</p><h2 id="idea插件安装lombok"><a class="markdownIt-Anchor" href="#idea插件安装lombok"></a> Idea插件安装lombok</h2><ol><li>File &gt; Settings &gt; Plugins &gt; Browse repositories… &gt; Search for “lombok” &gt; Install Plugin</li><li>在使用项目中引入lombok 的类库</li></ol><pre class="highlight"><code class>&lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;        &lt;version&gt;1.16.10&lt;/version&gt;        &lt;scope&gt;provided&lt;/scope&gt;    &lt;/dependency&gt;</code></pre><h2 id="使用"><a class="markdownIt-Anchor" href="#使用"></a> 使用</h2><p><strong>@Getter / @Setter</strong></p><p>可以作用在类上和属性上，放在类上，会对所有的非静态(non-static)属性生成Getter/Setter方法，放在属性上，会对该属性生成Getter/Setter方法。并可以指定Getter/Setter方法的访问级别。</p><p><strong>@EqualsAndHashCode</strong></p><p>默认情况下，会使用所有非瞬态(non-transient)和非静态(non-static)字段来生成equals和hascode方法，也可以指定具体使用哪些属性。</p><p><strong>@ToString</strong></p><p>生成toString方法，默认情况下，会输出类名、所有属性，属性会按照顺序输出，以逗号分割。</p><p><strong>@NoArgsConstructor, @RequiredArgsConstructor and @AllArgsConstructor</strong></p><p>无参构造器、部分参数构造器、全参构造器，当我们需要重载多个构造器的时候，Lombok就无能为力了。</p><p><strong>@Data</strong></p><p>@ToString, @EqualsAndHashCode, 所有属性的@Getter, 所有non-final属性的@Setter和@RequiredArgsConstructor的组合，通常情况下，我们使用这个注解就足够了。<br>  <br>  ## 原理<br>  该插件的原理是在编码过程中屏蔽bean的getter/setter 方法，在编译成class的时候插件自动根据注解生成对应的gettter/setter 方法，我们通过发编译源码发现</p><pre class="highlight"><code class>@Datapublic class Test {    private String id;    private String name;    public void test(){        this.getId();    }}</code></pre><p>编译后等价于</p><pre class="highlight"><code class>public class Test {    private String id;    private String name;    public void test() {        this.getId();    }    public Test() {    }    public String getId() {        return this.id;    }    public String getName() {        return this.name;    }    public void setId(String id) {        this.id = id;    }    public void setName(String name) {        this.name = name;    }    public boolean equals(Object o) {        if(o == this) {            return true;        } else if(!(o instanceof Test)) {            return false;        } else {            Test other = (Test)o;            if(!other.canEqual(this)) {                return false;            } else {                String this$id = this.getId();                String other$id = other.getId();                if(this$id == null) {                    if(other$id != null) {                        return false;                    }                } else if(!this$id.equals(other$id)) {                    return false;                }                String this$name = this.getName();                String other$name = other.getName();                if(this$name == null) {                    if(other$name == null) {                        return true;                    }                } else if(this$name.equals(other$name)) {                    return true;                }                return false;            }        }    }    protected boolean canEqual(Object other) {        return other instanceof Test;    }    public int hashCode() {        boolean PRIME = true;        byte result = 1;        String $id = this.getId();        int result1 = result * 59 + ($id == null?43:$id.hashCode());        String $name = this.getName();        result1 = result1 * 59 + ($name == null?43:$name.hashCode());        return result1;    }    public String toString() {        return &quot;Test(id=&quot; + this.getId() + &quot;, name=&quot; + this.getName() + &quot;)&quot;;    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis批量删除命令</title>
      <link href="/ruan-jian-bi-ji/redis-pi-liang-shan-chu-ming-ling/"/>
      <url>/ruan-jian-bi-ji/redis-pi-liang-shan-chu-ming-ling/</url>
      
        <content type="html"><![CDATA[<h2 id="写一个python脚本将output目录下所有_rewritten_md文件捞出来遍历内容提取title和content-在头部加入加入以下模板内容并将文件命名为titlemd输出到指定的目录下配置"><a class="markdownIt-Anchor" href="#写一个python脚本将output目录下所有_rewritten_md文件捞出来遍历内容提取title和content-在头部加入加入以下模板内容并将文件命名为titlemd输出到指定的目录下配置"></a> 写一个python脚本，将output目录下所有_rewritten_*.md文件捞出来，遍历内容，提取title和content. 在头部加入加入以下模板内容，并将文件命名为${title}.md，输出到指定的目录下(配置)：</h2><p>title:  ${title}<br>date: ${md文件创建时间}<br>author: okeeper<br>top: false<br>toc: true<br>categories: 人工智能<br>tags:</p><ul><li>人工智能</li><li>AI</li></ul><hr><p>${content}</p><blockquote><p>Redis中有指定多个key批量删除的命令,却没有指定模糊key批量删除命令</p></blockquote><p>批量删除多个key</p><pre class="highlight"><code class>del key1 key2</code></pre><p>通过通配符&quot;*&quot;模糊匹配删除的lua脚本命令</p><pre class="highlight"><code class># 模糊删除eval &quot;local keys = redis.call('keys', ARGV[1]) for i=1,#keys,5000 do redis.call('del', unpack(keys, i, math.min(i+4999, #keys))) end return #keys&quot; 0 'key_*'</code></pre><p>其中<code>key_*</code>就是要模糊匹配的key</p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Selenium</title>
      <link href="/ruan-jian-bi-ji/selenium/"/>
      <url>/ruan-jian-bi-ji/selenium/</url>
      
        <content type="html"><![CDATA[<h1 id="selenium安装环境搭建"><a class="markdownIt-Anchor" href="#selenium安装环境搭建"></a> Selenium安装环境搭建</h1><p><a href="https://www.zybuluo.com/mwumli/note/222253" target="_blank" rel="noopener">https://www.zybuluo.com/mwumli/note/222253</a></p><h2 id="遇到问题"><a class="markdownIt-Anchor" href="#遇到问题"></a> 遇到问题</h2><p>报-13权限问题时</p><pre class="highlight"><code class>sudo npm install --unsafe-perm -g polymer-cli</code></pre><p>adb找不到设备时</p><pre class="highlight"><code class>adb kill-serveradb start-serveradb devices</code></pre><h1 id="元素定位"><a class="markdownIt-Anchor" href="#元素定位"></a> 元素定位</h1><p>find_element_by_android_uiautomator<br><a href="https://blog.csdn.net/weixin_30824277/article/details/95229071" target="_blank" rel="noopener">https://blog.csdn.net/weixin_30824277/article/details/95229071</a></p><h1 id="三种等待方式详解"><a class="markdownIt-Anchor" href="#三种等待方式详解"></a> 三种等待方式详解</h1><p><a href="http://blog.csdn.net/ping523/article/details/53419622" target="_blank" rel="noopener">http://blog.csdn.net/ping523/article/details/53419622</a></p><p><a href="http://www.cnblogs.com/BigFishFly/p/6380024.html" target="_blank" rel="noopener">http://www.cnblogs.com/BigFishFly/p/6380024.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker ES安装</title>
      <link href="/ruan-jian-bi-ji/docker-es-an-zhuang/"/>
      <url>/ruan-jian-bi-ji/docker-es-an-zhuang/</url>
      
        <content type="html"><![CDATA[<p>参考docker安装Elasticsearch官方文档<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html</a></p><h1 id="获取镜像"><a class="markdownIt-Anchor" href="#获取镜像"></a> 获取镜像</h1><pre class="highlight"><code class>docker pull docker.elastic.co/kibana/kibana:7.16.0</code></pre><h1 id="docker-compose启动"><a class="markdownIt-Anchor" href="#docker-compose启动"></a> docker-compose启动</h1><h2 id="新建docker-composeyml文件"><a class="markdownIt-Anchor" href="#新建docker-composeyml文件"></a> 新建docker-compose.yml文件</h2><pre class="highlight"><code class>version: '2.2'services:  es01:    image: docker.elastic.co/elasticsearch/elasticsearch:7.16.0    container_name: es01    environment:      - node.name=es01      - cluster.name=es-docker-cluster      - discovery.seed_hosts=es02,es03      - cluster.initial_master_nodes=es01,es02,es03      - bootstrap.memory_lock=true      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;#      - http.port=9200#      - node.master=true#      - node.data=true#      - node.ingest=true    ulimits:      memlock:        soft: -1        hard: -1    volumes:      # - /Users/yue/data/elasticsearch-cluster/es01/config/elasticsearch.yml:/usr/share/elasticsearch/elasticsearch.yml      - /Users/yue/data/elasticsearch-cluster/es01/data:/usr/share/elasticsearch/data       - /Users/yue/data/elasticsearch-cluster/es01/logs:/usr/share/elasticsearch/logs#      - /Users/yue/data/elasticsearch-cluster/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml    ports:      - 9200:9200    networks:      - elastic  es02:    image: docker.elastic.co/elasticsearch/elasticsearch:7.16.0    container_name: es02    environment:      - node.name=es02      - cluster.name=es-docker-cluster      - discovery.seed_hosts=es01,es03      - cluster.initial_master_nodes=es01,es02,es03      - bootstrap.memory_lock=true      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;#      - http.port=9201#      - node.master=true#      - node.data=true#      - node.ingest=true    ulimits:      memlock:        soft: -1        hard: -1    volumes:      # - /Users/yue/data/elasticsearch-cluster/es02/config/elasticsearch.yml:/usr/share/elasticsearch/elasticsearch.yml      - /Users/yue/data/elasticsearch-cluster/es02/data:/usr/share/elasticsearch/data       - /Users/yue/data/elasticsearch-cluster/es02/logs:/usr/share/elasticsearch/logs #     - /Users/yue/data/elasticsearch-cluster/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml    ports:      - 9201:9200    networks:      - elastic  es03:    image: docker.elastic.co/elasticsearch/elasticsearch:7.16.0    container_name: es03    environment:      - node.name=es03      - cluster.name=es-docker-cluster      - discovery.seed_hosts=es01,es02      - cluster.initial_master_nodes=es01,es02,es03      - bootstrap.memory_lock=true      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;#      - http.port=9202#      - node.master=true#      - node.data=true#      - node.ingest=true    ulimits:      memlock:        soft: -1        hard: -1    volumes:      # - /Users/yue/data/elasticsearch-cluster/es03/config/elasticsearch.yml:/usr/share/elasticsearch/elasticsearch.yml      - /Users/yue/data/elasticsearch-cluster/es03/data:/usr/share/elasticsearch/data       - /Users/yue/data/elasticsearch-cluster/es03/logs:/usr/share/elasticsearch/logs#      - /Users/yue/data/elasticsearch-cluster/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml    ports:      - 9202:9200    networks:      - elastic  kib01:    image: docker.elastic.co/kibana/kibana:7.16.0    container_name: kib01    ports:      - 5601:5601    environment:      ELASTICSEARCH_URL: http://es01:9200      ELASTICSEARCH_HOSTS: '[&quot;http://es01:9200&quot;,&quot;http://es02:9200&quot;,&quot;http://es03:9200&quot;]'    networks:      - elastic  cerebro:    image: lmenezes/cerebro:latest    container_name: cerebro    ports:      - &quot;9000:9000&quot;    command:      - -Dhosts.0.host=http://es01:9200      - -Dhosts.1.host=http://es02:9200      - -Dhosts.2.host=http://es03:9200    networks:      - elasticvolumes:  data01:    driver: local  data02:    driver: local  data03:    driver: localnetworks:  elastic:    driver: bridge</code></pre><h2 id="启动"><a class="markdownIt-Anchor" href="#启动"></a> 启动</h2><pre class="highlight"><code class>docker-compose -f ./docker-compose.yml up d</code></pre><blockquote><p>有可能报错’failed to resolve host [es01] ’<br>This sample docker-compose.yml file uses the ES_JAVA_OPTS environment variable to manually set the heap size to 512MB. We do not recommend using ES_JAVA_OPTS in production. See Manually set the heap size.<br>解决办法，如果你用的市Mac左面版的docker,docker虚拟机内存默认是2G是不够的，调整到4G以上这个问题解决<br>![](…/images/docker ES安装/getImage-20220825184627503.png)</p></blockquote><h1 id="elasticsearch运维常用api"><a class="markdownIt-Anchor" href="#elasticsearch运维常用api"></a> elasticsearch运维常用api</h1><h2 id="查看实例健康状态"><a class="markdownIt-Anchor" href="#查看实例健康状态"></a> 查看实例健康状态</h2><pre class="highlight"><code class>http://localhost:9200/_cat/health?v</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20230213222744486.png" alt></p><h2 id="查看集群健康状态"><a class="markdownIt-Anchor" href="#查看集群健康状态"></a> 查看集群健康状态</h2><pre class="highlight"><code class>http://localhost:9200/_cluster/health?pretty</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184627531.png" alt></p><h2 id="查询分片状态"><a class="markdownIt-Anchor" href="#查询分片状态"></a> 查询分片状态</h2><pre class="highlight"><code class>http://localhost:9200/_cat/shards/test*?v</code></pre><h1 id="elasticsearch的console常用api"><a class="markdownIt-Anchor" href="#elasticsearch的console常用api"></a> Elasticsearch的console常用api</h1><pre class="highlight"><code class></code></pre><h1 id="安装cerebro"><a class="markdownIt-Anchor" href="#安装cerebro"></a> 安装cerebro</h1><p>cerebro是Elasticsearch的可视化运维工具</p><p>docker 镜像获取</p><pre class="highlight"><code class> docker pull lmenezes/cerebro</code></pre><p>启动</p><pre class="highlight"><code class> docker run -d --name cerebro -p 9000:9000 045d7f40bf06</code></pre><p>cerebro可以看到每index的分片分布情况</p><p>浏览器打开：<a href="http://localhost:9000/" target="_blank" rel="noopener">http://localhost:9000/</a></p><h1 id="附件"><a class="markdownIt-Anchor" href="#附件"></a> 附件</h1><h2 id="问题一如果出现docker-容器假死需要强制stop时"><a class="markdownIt-Anchor" href="#问题一如果出现docker-容器假死需要强制stop时"></a> 问题一：如果出现docker 容器假死需要强制stop时</h2><pre class="highlight"><code class>停止所有的容器 docker stop $(docker ps -q)强制移除此容器 docker rm -f mysql1最后一招，强制重启docker服务service 方式重启docker服务sudo service docker restart关闭dockersudo service docker stop</code></pre><p>如果是Docker-Destop左面版，可以在设置中重启</p><h2 id="问题二elk出现unassigned_shards查看及删除"><a class="markdownIt-Anchor" href="#问题二elk出现unassigned_shards查看及删除"></a> 问题二：ELK出现unassigned_shards查看及删除</h2><p>ES的data节点异常关闭，会导致副本出现unassigned shard，致使索引状态变为yellow，甚至是red。</p><h3 id="解决办法1"><a class="markdownIt-Anchor" href="#解决办法1"></a> 解决办法1：</h3><pre class="highlight"><code class># 查询所有分片数据GET _cat/shards# 或者查询集群健康状态GET _cluster/health出现unassigned_shards大于0时表示有异常分片数据</code></pre><p>如果运气不好，遇到了主分片异常，上面的方法不管用，可以先用重试的方法尝试恢复</p><pre class="highlight"><code class>/_cluster/reroute?retry_failed=true</code></pre><p>一般data节点异常退出，该方法都能解决。</p><h3 id="解决办法2"><a class="markdownIt-Anchor" href="#解决办法2"></a> 解决办法2：</h3><p>若不起作用，可以尝试重新分配主分片，不过可能会有部分数据丢失。</p><pre class="highlight"><code class>POST /_cluster/reroute?pretty{    &quot;commands&quot; : [ {        &quot;allocate_stale_primary&quot; :            {              &quot;index&quot; : &quot;test&quot;,               &quot;shard&quot; : 3,              &quot;node&quot; : &quot;192.168.1.1_9200&quot;,              &quot;accept_data_loss&quot; : true            }        }    ]}</code></pre><h3 id="解决办法3"><a class="markdownIt-Anchor" href="#解决办法3"></a> 解决办法3：</h3><p>删除问题索引</p><pre class="highlight"><code class>curl -XDELETE localhost:9200/索引名称</code></pre><p>解决办法4：出现以上问题的原因除了同步异常外，还有一个原因可能是磁盘空间使用率大于85%。<br>es中有个配置<code>cluster.routing.allocation.disk.watermark.low</code>默认是85%，系统磁盘空间使用率大于85%将出现此问题</p><p>解决办法要么调整这个配置，要么清理磁盘</p><pre class="highlight"><code class>PUT /_cluster/settings{    &quot;transient&quot; : {        &quot;cluster.routing.allocation.disk.watermark.low&quot; : &quot;90%&quot;    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker命令笔记</title>
      <link href="/ruan-jian-bi-ji/docker-ming-ling-bi-ji/"/>
      <url>/ruan-jian-bi-ji/docker-ming-ling-bi-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="制作自己的镜像"><a class="markdownIt-Anchor" href="#制作自己的镜像"></a> 制作自己的镜像</h1><p>从互联网拉取镜像</p><pre class="highlight"><code class>docker pull centos:7</code></pre><p>启动容器</p><pre class="highlight"><code class>docker run -it -d centos:7 /bin/bash</code></pre><p>进入启动容器</p><pre class="highlight"><code class>docker exec -it -v /data/soft:/data/soft centos:7 /bin/bash</code></pre><p>在容器中安装jdk</p><pre class="highlight"><code class>yum -y list java*docker yum -y java-11-openjdk.x86_64</code></pre><p>将容器提交到镜像仓库</p><pre class="highlight"><code class>docker commit centos:7 okeeper:centos7  #将正在运行的容器打包为镜像</code></pre><p>将镜像导出为文件</p><pre class="highlight"><code class>docker save -o ./okeeper-centos7.tar okeeper:centos7</code></pre><h1 id="在java项目中配置maven自动构建镜像"><a class="markdownIt-Anchor" href="#在java项目中配置maven自动构建镜像"></a> 在java项目中配置maven自动构建镜像</h1>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git重命名的坑</title>
      <link href="/ruan-jian-bi-ji/git-chong-ming-ming-de-keng/"/>
      <url>/ruan-jian-bi-ji/git-chong-ming-ming-de-keng/</url>
      
        <content type="html"><![CDATA[<p>如果使用git命令进行仅涉及大小写的重命名,git 默认是把你的动作忽略的，所以当你删掉本地代码，重新pull代码时，你会发现文件还是重命名之前的,神奇吧，记下这个坑，等着你们踩着坑来这看吧，坏笑/</p><p>解决方法如下：</p><ul><li>设置git库为大小写敏感（不建议）</li></ul><pre class="highlight"><code class>git config core.ignorecase false</code></pre><p>用这种方法进行重命名，用git status就可以识别出修改了，但是不推荐用这种方式，因为在更新这种修改的时候会有麻烦。</p><ul><li>使用git mv命令（仅当core.ignorecase为true时可用）</li></ul><pre class="highlight"><code class>$ git mv ABC.java Abc.java$ git status......renamed: ABC.java -&gt; Abc.java</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>idea 突然闪退，内存溢出</title>
      <link href="/ruan-jian-bi-ji/idea-tu-ran-shan-tui-nei-cun-yi-chu/"/>
      <url>/ruan-jian-bi-ji/idea-tu-ran-shan-tui-nei-cun-yi-chu/</url>
      
        <content type="html"><![CDATA[<p>解决办法：到安装路径C:\Program Files (x86)\JetBrains\IntelliJ IDEA 15.0.4\bin<br>找到idea.exe.vmoptions配置修改Xmx 为合适大小1024/2048，然后启动此路径下的idea.exe</p><pre class="highlight"><code class>-Xms128m-Xmx1024m-XX:MaxPermSize=350m-XX:ReservedCodeCacheSize=240m-XX:+UseConcMarkSweepGC-XX:SoftRefLRUPolicyMSPerMB=50-ea-Dsun.io.useCanonCaches=false-Djava.net.preferIPv4Stack=true-XX:+HeapDumpOnOutOfMemoryError-XX:-OmitStackTraceInFastThrow</code></pre><p>** 如果你的系统是64位的，则就需要修改idea64.exe.vmoptions这个配置，然后启动idea64.exe**</p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>iterm2 rz sz 安装</title>
      <link href="/ruan-jian-bi-ji/iterm2-rz-sz-an-zhuang/"/>
      <url>/ruan-jian-bi-ji/iterm2-rz-sz-an-zhuang/</url>
      
        <content type="html"><![CDATA[<p>一、本地rz sz安装<br><a href="https://github.com/aikuyun/iterm2-zmodem" target="_blank" rel="noopener">https://github.com/aikuyun/iterm2-zmodem</a></p><p>二、服务器端rz sz安装<br>yum install lrzsz</p><p>rz：从本地上传文件至服务器<br>sz filename：从服务器下载文件至本地</p><p>三、iTrm2配置<br>参考这里：<a href="https://github.com/aikuyun/iterm2-zmodem" target="_blank" rel="noopener">https://github.com/aikuyun/iterm2-zmodem</a></p><p>二、使用#<br>2.1 sz 命令发送文件到本地#<br>sz filename<br>2.2 rz 命令本地上传文件到服务器#<br>rz</p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>maven 包冲突 解决</title>
      <link href="/ruan-jian-bi-ji/maven-bao-chong-tu-jie-jue/"/>
      <url>/ruan-jian-bi-ji/maven-bao-chong-tu-jie-jue/</url>
      
        <content type="html"><![CDATA[<pre class="highlight"><code class>mvn dependency:tree -Dverbose -Dincludes=org.slf4j</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Jmeter进行Dubbo接口压测</title>
      <link href="/ruan-jian-bi-ji/shi-yong-jmeter-jin-xing-dubbo-jie-kou-ya-ce/"/>
      <url>/ruan-jian-bi-ji/shi-yong-jmeter-jin-xing-dubbo-jie-kou-ya-ce/</url>
      
        <content type="html"><![CDATA[<h1 id="软件准备"><a class="markdownIt-Anchor" href="#软件准备"></a> 软件准备</h1><h2 id="一-下载jmeter31"><a class="markdownIt-Anchor" href="#一-下载jmeter31"></a> 一、下载Jmeter3.1</h2><p>下载地址：<a href="https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-3.1.zip" target="_blank" rel="noopener">https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-3.1.zip</a><br>其他版本：<a href="https://archive.apache.org/dist/jmeter/binaries/" target="_blank" rel="noopener">https://archive.apache.org/dist/jmeter/binaries/</a></p><p>更高版本的Jmeter 5+好像有点问题，建议还是用这个版本吧</p><h2 id="二-下载dubbo官方的jmeter插件"><a class="markdownIt-Anchor" href="#二-下载dubbo官方的jmeter插件"></a> 二、下载dubbo官方的jmeter插件</h2><p>下载地址：<a href="https://gitee.com/ningyu/dist-jmeter-plugins-for-apache-dubbo/raw/master/2.7.7/jmeter-plugins-dubbo-2.7.7-jar-with-dependencies.jar" target="_blank" rel="noopener">https://gitee.com/ningyu/dist-jmeter-plugins-for-apache-dubbo/raw/master/2.7.7/jmeter-plugins-dubbo-2.7.7-jar-with-dependencies.jar</a><br>官方用户指南：<a href="https://github.com/thubbo/jmeter-plugins-for-apache-dubbo/wiki/%E7%94%A8%E6%88%B7%E6%8C%87%E5%8D%97" target="_blank" rel="noopener">https://github.com/thubbo/jmeter-plugins-for-apache-dubbo/wiki/用户指南</a></p><h2 id="三-解压jmeter"><a class="markdownIt-Anchor" href="#三-解压jmeter"></a> 三、解压Jmeter</h2><p>将jmeter-plugins-dubbo-2.7.7-jar-with-dependencies.jar放到<code>${JMETER_HOME}\lib\ext.</code>中</p><h2 id="四-启动jmeter"><a class="markdownIt-Anchor" href="#四-启动jmeter"></a> 四、启动Jmeter</h2><p><code>${JMETER_HOME}\jmeter.bat</code></p><h1 id="五-使用jmeter进行订单接口压测"><a class="markdownIt-Anchor" href="#五-使用jmeter进行订单接口压测"></a> 五、使用Jmeter进行订单接口压测</h1><h2 id="在测试计划中右键添加一个线程组设置压测的线程数及并发数"><a class="markdownIt-Anchor" href="#在测试计划中右键添加一个线程组设置压测的线程数及并发数"></a> 在测试计划中右键添加一个线程组，设置压测的线程数及并发数</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182246944.png" alt><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182247846.png" alt></p><h2 id="添加一个dubbo-simple测试任务"><a class="markdownIt-Anchor" href="#添加一个dubbo-simple测试任务"></a> 添加一个Dubbo Simple测试任务</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182248427.png" alt></p><p>将被测试的dubbo api加入<code>${JMETER_HOME}\lib\ext.</code>中，否则paramType将找不到类，paramValue填入入参DTO的json对象，注意不能有格式，否则解析不出来，这是个坑<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182248165.png" alt></p><h2 id="添加请求查看树方便查询每个请求的出入参线程组添加监听器查看结果树"><a class="markdownIt-Anchor" href="#添加请求查看树方便查询每个请求的出入参线程组添加监听器查看结果树"></a> 添加请求查看树，方便查询每个请求的出入参；线程组&gt;添加&gt;监听器&gt;查看结果树</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182248034.png" alt></p><h2 id="添加测试结果汇总报告线程组添加监听器summary-report"><a class="markdownIt-Anchor" href="#添加测试结果汇总报告线程组添加监听器summary-report"></a> 添加测试结果汇总报告；线程组&gt;添加&gt;监听器&gt;Summary Report</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182247230.png" alt></p><h2 id="开始压测点击启动"><a class="markdownIt-Anchor" href="#开始压测点击启动"></a> 开始压测，点击启动</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182248268.png" alt></p><h2 id="结果查看压测过程中可以看到请求参数压测完之后可以压测结果一般需要经过多次压测且压测的线程和并发数多一点"><a class="markdownIt-Anchor" href="#结果查看压测过程中可以看到请求参数压测完之后可以压测结果一般需要经过多次压测且压测的线程和并发数多一点"></a> 结果查看，压测过程中可以看到请求参数，压测完之后可以压测结果，一般需要经过多次压测且压测的线程和并发数多一点</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182247269.png" alt></p><h1 id="六-dubbo服务器状态查看"><a class="markdownIt-Anchor" href="#六-dubbo服务器状态查看"></a> 六、dubbo服务器状态查看</h1><ol><li>使用telnet进入dubbo的console界面</li></ol><pre class="highlight"><code class>telnet 192.168.1.131 32101后回车</code></pre><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182247523.png" alt><br><code>status -l</code> 查看线程状态<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182247961.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Maven命令指定上传打包到私库</title>
      <link href="/ruan-jian-bi-ji/shi-yong-maven-ming-ling-zhi-ding-shang-chuan-da-bao-dao-si-ku/"/>
      <url>/ruan-jian-bi-ji/shi-yong-maven-ming-ling-zhi-ding-shang-chuan-da-bao-dao-si-ku/</url>
      
        <content type="html"><![CDATA[<p>我们一般在pom.xml中加入<code>distributionManagement</code></p><pre class="highlight"><code class>&lt;distributionManagement&gt;    &lt;repository&gt;      &lt;id&gt;internal.repo&lt;/id&gt;      &lt;name&gt;MyCo Internal Repository&lt;/name&gt;      &lt;url&gt;Host to Company Repository&lt;/url&gt;    &lt;/repository&gt;  &lt;/distributionManagement&gt;</code></pre><p>来指定setting.xml中的server私库地址，然后通过<code>mvn clean install deploy</code>打包上传</p><hr><p>但是为了子类不必要的应用，我们可以用<code>-DaltDeploymentRepository</code>来指定打包到私服的参数</p><pre class="highlight"><code class>mvn deploy -DaltDeploymentRepository=releases::default::http://198.11.174.75:8081/nexus/content/repositories/releases/</code></pre><p>上传本地jar到私库</p><pre class="highlight"><code class>mvn deploy:deploy-file -DgroupId=com.xy.Oracle -DartifactId=ojdbc14 -Dversion=10.2.0.4.0 -Dpackaging=jar -Dfile=E:\ojdbc14.jar -Durl=http://localhost:9090/nexus-2.2-01/content/repositories/thirdparty/ -DrepositoryId=thirdparty#上传小米push 到私有仓库mvn deploy:deploy-file -DgroupId=com.xiaomi -DartifactId=MiPush_SDK_Server -Dversion=2.2.18 -Dpackaging=jar -Dfile=lib/MiPush_SDK_Server_2_2_18.jar -Durl=http://198.11.174.75:8081/nexus/content/groups/public/</code></pre><p>单独构建上传模块 pingjuan-web，同时会构建上传 pingjuan-web</p><pre class="highlight"><code class>mvn clean install deploy -pl trade-center-api -ammvn clean install deploy -DaltDeploymentRepository=releases::default::http://198.11.174.75:8081/nexus/content/repositories/releases/ -pl trade-center-api -am</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>护眼神器Dark Reader</title>
      <link href="/ruan-jian-bi-ji/hu-yan-shen-qi-dark-reader/"/>
      <url>/ruan-jian-bi-ji/hu-yan-shen-qi-dark-reader/</url>
      
        <content type="html"><![CDATA[<p>在google应用市场中搜索Dark Reader，可以在网页中进行反色护眼<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825182956835.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>抓包工具Charles安装、破解及使用</title>
      <link href="/ruan-jian-bi-ji/zhua-bao-gong-ju-charles-an-zhuang-po-jie-ji-shi-yong/"/>
      <url>/ruan-jian-bi-ji/zhua-bao-gong-ju-charles-an-zhuang-po-jie-ji-shi-yong/</url>
      
        <content type="html"><![CDATA[<p>Charles是一款抓包必备的工具，支持Windows、Mac、手机的抓包测试，还能对https的SLL加密内容进行解密。</p><h1 id="下载安装"><a class="markdownIt-Anchor" href="#下载安装"></a> 下载安装</h1><ol><li>进入官网下载地址：<a href="http://www.charlesproxy.com/%EF%BC%8C%E7%82%B9%E5%87%BB%E9%93%BE%E6%8E%A5%E4%B8%8B%E8%BD%BD30%E5%A4%A9%E5%85%8D%E8%B4%B9%E8%AF%95%E7%94%A8%E7%89%88%E6%9C%AC%E3%80%82" target="_blank" rel="noopener">http://www.charlesproxy.com/，点击链接下载30天免费试用版本。</a><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183037795.png" alt></li><li>在线破解：<br><a href="https://www.zzzmode.com/mytools/charles/" target="_blank" rel="noopener">https://www.zzzmode.com/mytools/charles/</a></li></ol><h1 id="基本使用"><a class="markdownIt-Anchor" href="#基本使用"></a> 基本使用</h1><h2 id="电脑抓包"><a class="markdownIt-Anchor" href="#电脑抓包"></a> 电脑抓包</h2><ol><li><p>打开Charles，默认是开启抓包代理的，可以看到电脑http请求的内容,你也可以将电脑的抓包代理给关掉，在Proxy&gt;enable MacOs proxy 勾选去掉<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183037940.png" alt></p></li><li><p>设置https证书代理抓包，<br>安装证书：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038586.png" alt><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183037648.png" alt><br>打开百度<a href="https://www.baidu.com" target="_blank" rel="noopener">https://www.baidu.com</a> 测试，发现全是乱码：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038645.png" alt><br>鼠标点击右键添加Enable SLL Proxy,从新刷新页面，Google Chrome 默认把这个当成不安全证书了，使用FireFox浏览器可以添加例外强制打开：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038204.png" alt><br>可以看到Charles已经将https的内容通过Charles 证书加代理的方式能够看到明文请求信息了。<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038795.png" alt></p></li></ol><h1 id="手机抓包"><a class="markdownIt-Anchor" href="#手机抓包"></a> 手机抓包</h1><ol><li><p>设置网络代理<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038117.png" alt><br>通过上面菜单找到Charles的代理服务器IP和端口<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038169.png" alt><br>保证你的手机和你的电脑是在同一个局域网内，打开手机的WLAN配置，ip为上图的30.117.52.174，端口为：12345<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038566.png" alt></p></li><li><p>如果想看到https的请求内容，还是得和电脑一样安装Charles证书，通过safari打开<a href="https://chls.pro/ssl" target="_blank" rel="noopener">https://chls.pro/ssl</a> 下载证书<br>手机–setting–&gt;General—&gt;Profiles &amp; Device Management —&gt;Charles Proxy CA…<br>将设置为信任。如图：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183038687.png" alt></p></li><li><p>接着就可以查看到手机上的网络请求数据了，如果是https点击右键Enable SLL Proxy，在重新刷新下就可以看到了。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>磁盘空间满处理</title>
      <link href="/ruan-jian-bi-ji/ci-pan-kong-jian-man-chu-li/"/>
      <url>/ruan-jian-bi-ji/ci-pan-kong-jian-man-chu-li/</url>
      
        <content type="html"><![CDATA[<h1 id="查看当前目录磁盘使用情况"><a class="markdownIt-Anchor" href="#查看当前目录磁盘使用情况"></a> 查看当前目录磁盘使用情况</h1><pre class="highlight"><code class>df -lh</code></pre><h1 id="统计当前目录下的目录及文件磁盘使用从大到小排序"><a class="markdownIt-Anchor" href="#统计当前目录下的目录及文件磁盘使用从大到小排序"></a> 统计当前目录下的目录及文件磁盘使用从大到小排序</h1><pre class="highlight"><code class>du -h --max-depth=1</code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自行搭建v2ray科学上网工具，支持mac、ios、windows</title>
      <link href="/ruan-jian-bi-ji/zi-xing-da-jian-v2ray-ke-xue-shang-wang-gong-ju-zhi-chi-mac-ios-windows/"/>
      <url>/ruan-jian-bi-ji/zi-xing-da-jian-v2ray-ke-xue-shang-wang-gong-ju-zhi-chi-mac-ios-windows/</url>
      
        <content type="html"><![CDATA[<h1 id="服务器搭建"><a class="markdownIt-Anchor" href="#服务器搭建"></a> 服务器搭建</h1><ol><li><p>购买海外VPS/ECS, 我这里用的是vultr，它家可以随时换IP、换服务器位置，无须另外收费，比较适合新手</p></li><li><p>安装v2ray服务端，有一键安装脚本，傻瓜式安装，安装时如果用的是shadowrocket客户端方式连接，安装时询问时这一步选择是即可</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/v2ray%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%856.png" alt="img"></p></li></ol><p>详细步骤参考网上文章进行一键安装：</p><p><a href="https://xiaoheicn.top/v2ray%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC-233boy%E5%A4%A7%E7%A5%9E%E7%89%88%E6%9C%AC-%E5%8D%95%E7%94%A8%E6%88%B7/" target="_blank" rel="noopener">https://xiaoheicn.top/v2ray一键安装脚本-233boy大神版本-单用户/</a></p><h1 id="客户端下载"><a class="markdownIt-Anchor" href="#客户端下载"></a> 客户端下载</h1><p>因政策原因，国内apple id无法下载ssr的客户端。为了在你的iphone/ipad上下载可用的ss客户端，你需要一个境外apple id登录app store，然后再下载需要的软件。境外apple id请参考：<a href="https://v2xtls.org/%E5%A2%83%E5%A4%96apple-id%E4%BF%A1%E6%81%AF%E6%B1%87%E6%80%BB/" target="_blank" rel="noopener">境外apple id信息汇总</a>，切换apple id下载软件请参考：<a href="https://v2xtls.org/%E5%88%87%E6%8D%A2apple-id%E4%B8%8B%E8%BD%BD%E5%85%B6%E5%AE%83%E5%9B%BD%E5%AE%B6%E5%92%8C%E5%9C%B0%E5%8C%BA%E7%9A%84%E5%BA%94%E7%94%A8/" target="_blank" rel="noopener">切换apple id下载其它国家和地区的应用</a>。</p><p>app store中， <strong>免费</strong>的ssr ios客户端有：</p><ul><li>Mume（图标是一朵梅花，有红梅/黑梅两个版本，黑梅免费且内置免费节点）</li><li>Potatso Lite</li><li>NetShuttle(网际飞梭)</li><li>FastSocks</li><li>Sockswitch（没有中文界面）</li><li>shadowrock</li></ul><p><strong>免费ssr ios客户端个人推荐使用Mume和Potatso lite</strong>，简洁好用。</p><p><strong>付费</strong>的SSr ios客户端有：</p><ul><li>Shadowrocket（俗称小火箭，注意不是shadowrocket VPN）</li><li>pepi</li><li>Potasto 2</li><li>surge pro</li></ul><p><strong>付费的ssr ios客户端个人推荐Shadowrocket和pepi</strong>，两个应用都支持包括SS/SSR/V2Ray在内的等多种协议，功能强大且好用。</p><p>注意：有些shadowsocksr客户端已经下架，但app store中存在同名的应用，请注意区分，例如Waterdrop、MUME。</p><p>注意：上述列出的仅是客户端，安装后需要配置服务端信息才能科学上网。获取服务端信息请参考：<a href="https://v2xtls.org/%E8%8E%B7%E5%8F%96%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E6%9C%8D%E5%8A%A1%E7%AB%AF%E4%BF%A1%E6%81%AF/" target="_blank" rel="noopener">获取科学上网服务端信息</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>靠谱的maven仓库地址</title>
      <link href="/ruan-jian-bi-ji/kao-pu-de-maven-cang-ku-di-zhi/"/>
      <url>/ruan-jian-bi-ji/kao-pu-de-maven-cang-ku-di-zhi/</url>
      
        <content type="html"><![CDATA[<pre class="highlight"><code class>#阿里云maven&lt;mirror&gt;    &lt;id&gt;alimaven&lt;/id&gt;    &lt;name&gt;aliyun maven&lt;/name&gt;    &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;    &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;/mirror&gt;#开源中国maven&lt;mirror&gt;      &lt;id&gt;nexus-osc&lt;/id&gt;      &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;      &lt;name&gt;Nexus osc&lt;/name&gt;      &lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt;  &lt;/mirror&gt;</code></pre><blockquote><p>简单点来说，repository就是个仓库。maven里有两种仓库，本地仓库和远程仓库。远程仓库相当于公共的仓库，大家都能看到。本地仓库是你本地的一个山寨版，只有你看的到，主要起缓存作用。当你向仓库请求插件或依赖的时候，会先检查本地仓库里是否有。如果有则直接返回，否则会向远程仓库请求，并做缓存。你也可以把你做的东西上传到本地仓库给你本地自己用，或上传到远程仓库，供大家使用。<br>远程仓库可以在工程的pom.xml文件里指定，楼上两位已经列的很清楚了。如果没指定，默认就会把下面这地方做远程仓库，即默认会到<a href="http://repo1.maven.org/maven2%E8%BF%99%E4%B8%AA%E5%9C%B0%E6%96%B9%E5%8E%BB%E8%AF%B7%E6%B1%82%E6%8F%92%E4%BB%B6%E5%92%8C%E4%BE%9D%E8%B5%96%E5%8C%85%E3%80%82" target="_blank" rel="noopener">http://repo1.maven.org/maven2这个地方去请求插件和依赖包。</a></p></blockquote><p>Xml代码</p><pre class="highlight"><code class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">repository</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">snapshots</span>&gt;</span>          <span class="hljs-tag">&lt;<span class="hljs-name">enabled</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">enabled</span>&gt;</span>        <span class="hljs-tag">&lt;/<span class="hljs-name">snapshots</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>central<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>Maven Repository Switchboard<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">url</span>&gt;</span>http://repo1.maven.org/maven2<span class="hljs-tag">&lt;/<span class="hljs-name">url</span>&gt;</span>  <span class="hljs-tag">&lt;/<span class="hljs-name">repository</span>&gt;</span>  </code></pre><p>本地仓库默认在你本地的用户目录下的.m2/repository目录下。</p><p>mirror就是镜像，主要提供一个方便地切换远程仓库地址的途径。比如，上班的时候在公司，用电信的网络，连的是电信的仓库。回到家后，是网通的网络，我想连网通的仓库，就可以通过mirror配置，统一把我工程里的仓库地址都改成联通的，而不用到具体工程配置文件里一个一个地改地址。<br>mirror的配置在.m2/settings.xml里。如：</p><pre class="highlight"><code class>&lt;mirrors&gt;    &lt;mirror&gt;      &lt;id&gt;UK&lt;/id&gt;      &lt;name&gt;UK Central&lt;/name&gt;      &lt;url&gt;http://uk.maven.org/maven2&lt;/url&gt;      &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;    &lt;/mirror&gt;  &lt;/mirrors&gt;  </code></pre><p>这样的话，就会给上面id为central的远程仓库做了个镜像。以后向<code>central</code>这个仓库发的请求都会发到<code>http://uk.maven.org/maven2</code>而不是<code>http://repo1.maven.org/maven2</code>了。<br><code>&lt;mirrorOf&gt;central&lt;/mirrorOf&gt;</code>里是要替代的仓库的id。如果填*，就会替代所有仓库。</p><p>参考资料：<br><a href="http://maven.apache.org/guides/introduction/introduction-to-repositories.html" target="_blank" rel="noopener">http://maven.apache.org/guides/introduction/introduction-to-repositories.html</a><br><a href="http://maven.apache.org/guides/mini/guide-mirror-settings.html" target="_blank" rel="noopener">http://maven.apache.org/guides/mini/guide-mirror-settings.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 软件笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软件笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>软件开发方法</title>
      <link href="/ruan-kao/ruan-jian-kai-fa-fang-fa/"/>
      <url>/ruan-kao/ruan-jian-kai-fa-fang-fa/</url>
      
        <content type="html"><![CDATA[<blockquote><p>前言：软件开发方法是软件开发的方法学，旨在提供软件的质量，降低开发成本</p></blockquote><h1 id="1-软件生命周期"><a class="markdownIt-Anchor" href="#1-软件生命周期"></a> 1 软件生命周期</h1><ol><li>可行性研究和规划：通过可行性分析确认原件的必要性，价值点，初步确认软件的目标、范围、风险和开发成本等内容。</li><li>需求分析：需求分析是开发过程的重要阶段，初步确认软件开发的目标和范围，之后则要对软件的需求进行细致分析，确认最终要做成什么样子。这个过程极其重要，如果这个阶段出现分析错误和偏差将导致后续开发过程偏离真实需求越远，修正的成本越大。</li><li>概要设计：是程序员开发过程中的蓝图，包括确认系统架构、各个子系统依赖关系、数据库模型、编码规范、接口规约等内容</li><li>详细设计：详细设计师开发之前的最后设计，是在概要设计的基础上进行进行细化，如类设计。详细设计不是必要过程，在规模较小，功能结构简单的系统中可以省略。</li><li>实现：针对设计的单元模块进行开发，如一个过程、方法、函数，包括实现单元模块的单元测试</li><li>集成测试：对单元模块进行组装联调测试</li><li>确认测试：系统开发完后，需要验证是否和需求预期一致</li><li>软件使用和维护：软件投入试运行，并不断对过程中出现的问题进行维护修正，软件维护郭晨会贯穿整个软件的使用郭晨直至软件自然消亡。</li></ol><h1 id="2-软件开发模型"><a class="markdownIt-Anchor" href="#2-软件开发模型"></a> 2 软件开发模型</h1><p>计算机刚刚诞生的年代，是一种只有天才才能掌握的巩固，人们对软件知识的认知仅仅停留在程序层面。随着技术发展，软件复杂度的提高，意识到必须遵循一定的开发方法才能取得成功，于是出现了模式化的开发方法称为开发模型。</p><h2 id="21-瀑布模型"><a class="markdownIt-Anchor" href="#21-瀑布模型"></a> 2.1 瀑布模型</h2><p>特点：</p><ol><li>软件过程要经过需求分析、总体设计、详细设计、编码、调试、集成测试和系统测试阶段，开发阶段划分明确</li><li>再每一个阶段结算后都有不定的文档或者程序流入下一个阶段</li><li>每个阶段在发现问题时可以反馈给上一个阶段进行修正<br>适用场景：需求明确、稳定时</li></ol><h3 id="211-瀑布v模型"><a class="markdownIt-Anchor" href="#211-瀑布v模型"></a> 2.1.1 瀑布V模型</h3><p>同标准瀑布模型一样，保持了瀑布模型的阶段式文档驱动的特点，但是更强调软件产品的验证工作，即需求分析的记过将作为系统测试的标准，能够在设计初期得到验证，以此类推，总体设计对应了集成测试，详细设计对应了单元测试。</p><h3 id="212-瀑布模型的缺点"><a class="markdownIt-Anchor" href="#212-瀑布模型的缺点"></a> 2.1.2 瀑布模型的缺点</h3><ol><li>需求分析是一切活动的基础，如果需求分析出现偏差，将导致后续活动放大这个偏差。但事实是，由于用户、开发者立场、经验不同、知识领域不同，对同一事物的表述不同造成的理解偏差难于避免，导致后期维护工作繁重</li><li>难于适应需求变化，一旦需求变更要重头再来</li><li>从需求提出到最后看到产品是一个相当长的过程，不能及时给用户反馈，并验证是否是能够满足客户需求的软件。</li><li>瀑布模型是面向文档的开发模型，过程中将产生大量文档，大部分对客户没有意义，但却工作量繁重</li></ol><h2 id="22-演化模型"><a class="markdownIt-Anchor" href="#22-演化模型"></a> 2.2 演化模型</h2><p>演化模型是在瀑布模型难以一次性完全理解用户需求的基础上，对整个过程进行若干次的“瀑布模型”迭代，做到不断渐进、不断深入的过程</p><h2 id="23-螺旋模型"><a class="markdownIt-Anchor" href="#23-螺旋模型"></a> 2.3 螺旋模型</h2><p>螺旋模型是在瀑布模型和演化模型结合的基础上，还强调其他模型忽略的风险分析。<br>特点：</p><ol><li>螺旋模型对每一期都包含需求定义、风险分析、工程实现、和评审4个阶段，对整个过程进行螺旋式迭代</li><li>支持用户需求的动态变化，为用户参与软件开发的所有关键决策提供方便，降低软件开发风险</li></ol><p>缺点：</p><ol><li>螺旋模型的风险评估需要具有丰富风险评估经验和专业知识的人，否则将造成重大损失</li><li>过多的迭代次数会增加开发成本，延迟提交时间</li></ol><h2 id="24-增量模型"><a class="markdownIt-Anchor" href="#24-增量模型"></a> 2.4 增量模型</h2><p>演化模型是另外一种增量模型的形式。在系统架构成熟、风险较低时，可采用增量方式进行系统开发，可提前进行基础测试和系统测试，缩短出事版本的发布周期，提高用户对系统的可见度。<br>特点：</p><ol><li>增量模型，做好系统的分析和设计，对系统划分为若干不同的版本，每一个版本都是完成可用的系统，后一个版本是前一个版本的基础进行开发，扩展前一个版本的功能，同时保证每个版本增量均匀。</li><li>原型法，每一次发布都经历完成的生命周期，当用户需求很多不明确或者技术架构中很多不可知因素时，可采用原型增量法。在初始版本的原型并不考虑需求的合理性和系统稳定性，只为精准获取用户需求，一般会在后面的开发中抛弃这个原型进行完成的系统实现。</li></ol><h2 id="25-构件组装模型"><a class="markdownIt-Anchor" href="#25-构件组装模型"></a> 2.5 构件组装模型</h2><p>将系统划分为一组构件的集合，明确构件之间的关系。每个构件可以独立开发、自包容，可以是自己开发设计，也可以是第三方购买整合。最后进行构件组装的一个开发模型。<br>构件组装优点：</p><ol><li>构件自包容让系统扩展变得更加容易</li><li>良好的构件更容易重用，降低开发成本</li><li>构件力度较整个系统更小，更容易开发设计及安排工作更加灵活</li></ol><p>缺点：</p><ol><li>对构件设计需要经验丰富的架构设计师，设计不良的构件难以实现他的优点</li><li>考虑重用度是，往往会对其他方面设计做出让步，比如性能</li><li>构件组装应用是，要求程序员熟悉掌握构件，增加了开发人员的学习成本</li><li>第三方构件质量难以把控，将影响软件的质量。</li></ol><h1 id="3-统一过程模型"><a class="markdownIt-Anchor" href="#3-统一过程模型"></a> 3 统一过程模型</h1><p>统一过程（Unified Process, UP）是一种优秀的软件开发模型，可以有效地降低软件开发过程中的风险。这个开发模型的特点是每一个阶段的工作都不是绝对的，都是相互交叠配的的，但是每一个阶段都有侧重点。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183846811.png" alt></p><p>整个过程大致分为</p><ol><li>初始阶段，刚刚接入系统开发工作，侧重工作是明确系统目的，业务建模和需求工作</li><li>细化阶段，抽象软件逻辑模型，设计架构，侧重是分析设计工作</li><li>构件阶段，完成系统的构件，使之成为一个完整的实体，并进行测试和部署</li><li>交付阶段，软件系统需求已经完成，重点工作是对软件进行重构、修改、测试和部署</li></ol><p>整个工作内容整体包括：业务建模、需求、分析设计、实施、测试、部署、配置与变更管理、项目管理、环境。</p><p>其中“环境”是相对于其他工作难以理解的。环境工作很重要，也称之为环境管理。在软件开发过程中，需要为各种工作准备相应的工作环境，在工作环境中包含必须的工具、活动指南、活动流程规范、工作产品模板、基本的开发设施等。环境管理应该在工作流中得到应有的重视，每个开发团队都有自己的特点和活动准则规范，这种准则和规范是团队协作的基础，万万不能少，否则开发活动就会使放养式的管理。</p><p>** UP的生命周期**<br>分为4个里程碑</p><ol><li>目标里程碑。明确系统的目标和范围时达到这个里程</li><li>架构里程碑。当开发者确定稳定系统的架构时达到这个里程</li><li>能力里程碑。当系统已经足够稳定和成熟并完成了Alpha测试之后达到这个里程碑</li><li>发布里程碑。当完成系统的测试、完成系统的发布和用户培训工作之后达到这个里程碑</li></ol><p>UP的特点：</p><ol><li>UP是一个迭代的二维开发模型，每个生命后期都可以进行需求、设计、开发等</li><li>采用不同的迭代方式的UP可以演变为演化模型或增量模型</li><li>UP的迭代特点使得更容易控制开发风险</li><li>Up是迭代开发模型，但不属于敏捷开发模型。一般未经过裁剪的Up是一个重载过程</li><li>实际应用可根据具体问题进行UP的裁剪，从而使用各种规模的软件和开发团队</li></ol><p>架构师在UP活动中的作用<br>架构师除了需要建立系统的架构模型外，在UP活动中承担非常重要的角色，例如：</p><ol><li>同需求人员和项目管理人员密切协作</li><li>细化软件架构</li><li>保持整个架构的概念完整性，具体地说就是定义设计方法、设计指南、编码规范、平舌工作<br><strong>因此有人称UP是一个已加购书为中心的开发模型。</strong></li></ol><h1 id="4-敏捷开发方法"><a class="markdownIt-Anchor" href="#4-敏捷开发方法"></a> 4 敏捷开发方法</h1><p>2001年，17位“无政府主义者”共同发表了《敏捷软件开发宣言》：</p><blockquote><ol><li>尽早地、持续地向客户交付有价值的软件对开发人员来说是最重要的。</li></ol></blockquote><ol start="2"><li>拥抱变化，即使在开发的后期。敏捷过程能够驾驭变化，保持客户的竞争力。</li><li>经常交付可工作的软件，从几周到几个月，时间范围越小越好。</li><li>在整个项目中，业务人员和开发者紧密合作。</li><li>围绕士气高昂的团队进行开发，为团队成员提供适宜的环境，满足他们的需要，并给予<br>足够的信任。</li><li>在团队中，最有效率的、也是效果最好的沟通方式是面对面地交流。</li><li>可以工作的软件是进度首要的度量方式。</li><li>可持续地开发。投资人、开发团队和用户应该保持固定的节奏。</li><li>不断追求优秀的技术和良好的设计有助于提高敏捷性。</li><li>要简单，尽可能减少工作量。减少工作量的艺术是非常重要的。</li><li>最好的架构、需求和设计都来自于一个自我组织的团队。</li><li>团队要定期地总结如何能够更有效率，然后相应地自我调整</li></ol><p>这份宣言就是敏捷开发方法的灯塔</p><h2 id="41-敏捷开发方法实践之极限编程extreme-programming"><a class="markdownIt-Anchor" href="#41-敏捷开发方法实践之极限编程extreme-programming"></a> 4.1 敏捷开发方法实践之极限编程（eXtreme Programming）</h2><p>极限编程（XP）是一种轻量（敏捷）、高效、低风险、柔性、可预测、科学而且充满乐趣的软件开发方法。特点如下：</p><ol><li>在更短的周期内，更早地提供具体、持续的反馈信息。</li><li>迭代地进行计划编制。在最开始迅速形成总体计划，然后开发过程中不断迭代发展它</li><li>依赖自动化测试程序来监控开发进度，尽早地铺货缺陷</li><li>依赖口头交流、测试和源程序进行沟通</li><li>倡导持续的、演化式的设计</li><li>依赖于开发团队内部的紧密协作</li><li>尽可能达到程序员的短期利益和长期利益的平衡。即关注短期程序员的自主设计和参与感，同时帮助程序员长期的成长</li></ol><p>四大价值观：沟通、简单、反馈、勇气</p><ol><li>沟通。通常，程序员相对内向，不善言谈，项目中的许多问题都发生在缺乏良好的沟通上。而传统的开发方法中并不太在意这种口头的沟通，而是希望通过完善的流程和面面俱到的文档、报表、计划来代替，这同时就引入了效率不高的问题，往往一个小问题通过漫长的流程下来被放大。而XP方法认为，如果小组内成员无法做到持续的、无间断的交流，协作就无从谈起，XP鼓励大家进行口头的面对面交流快速解决问题，提高效率。</li><li>简单。XP方法的工作中秉承“够用即好”，实现尽可能简单化，不要过度设计。这一点看上去容易，但要做到其实很淡，因为在传统的开发过程中需要开发人员对未来做一些预先的规划，以便后续做扩展预留空间，这是一个平衡的过程，并不是一点都不考虑未来的可扩展性，所以比较难做到</li><li>反馈。传统的开发过程中缺乏对客户必要的反馈，整个开发过程像一个“黑盒子”，过程漫长，完全看不到效果和进度。容易造成最终偏离用户需求的系统软件。XP注重反馈的作用，通过持续的、明确的反馈来暴露软件当前的状态和问题，尽早地纠正一些可以避免的错误。</li><li>勇气。在XP方法中，要有勇气面对每时每刻的变化带来的挑战。由于提倡良好的沟通，会有更多的需求调整；由于提倡系统保持简单，需求变更导致的重构；由于提倡尽早反馈，更多地发现问题并纠正。而面对这些带来的挑战，我们更需要为之提高勇气。因为相比于沟通、简单和反馈带来的挑战，更多的我们是得到了良好的信息同步，尽早地发现了问题，更清晰地理解了用户需求，以及更简单地实现了系统软件。</li></ol><p>XP的四大价值观之下，隐藏着一种更深刻的东西，那就是尊重，对人的尊重。因为这一切都是建立在团队成员之间的相互关系、相互理解的基础之上。</p><h3 id="411-极限编程的十二个最佳实践"><a class="markdownIt-Anchor" href="#411-极限编程的十二个最佳实践"></a> 4.1.1 极限编程的十二个最佳实践</h3><ol><li><p>计划游戏。主要思想是先快速制定一份概要计划，然后随着项目细节的不断清醒，在逐步完善这份计划。“客户负责业务决策，开发负责计算决策”，也就是说系统的范围、下一次迭代发布的时间、用户股市的优先级应有客户决定，而每个用户故事所需的而开发时间、技术成本、如何组件团队、以及开发顺序应有开发团队决定。</p><blockquote><p>计划游戏开始，客户和开发同坐一屋子，每个人准备一支笔、一些用于记录用户需求的纸片，再准备一个白板就可以开始了。</p><ol><li>客户编写需求故事：由客户谈论系统应该完成什么功能，然后用自然语言词汇写在卡片上</li><li>开发人员进行评估：有客户按优先级将故事需求标注为必须有、希望有、如果有三类，然后又开发人进行估算，优先级由高到低。如果估算的时候感到故事需求太大，不容易估算或者超过2人/周，那么应该进行分解在进行评估</li><li>确定迭代周期：根据用户期望的需求优先级、期望发布的时间结合开发现有资源与用户协商，筛检出能够实现的需求，形成初步的需求计划。</li></ol></blockquote></li><li><p>小型发布。XP方法秉承“持续集成，小步快走”的哲学思维，也就是说每次发布的版本尽可能肖，当然前提是每个版本都有发布的商业价值，值得发布。</p></li><li><p>隐喻。相对而言，隐喻这个令人费解，什么时隐喻呢，字面意思是用来暗示字面意义不相似的事物之间相似的东西。对应到开发过程中就是，需要寻求共识，对系统理解、目标价值以等；还有就是发明共享词汇，通过规范项目中常用通用的业务专有名词，减少不必要的沟通；描述体系结构；并不是每一种情况都能找到合适的隐喻，没必要强求，而是顺其自然。</p></li><li><p>简单设计。强调简单的价值观，引出简单性假设原则。这里说的简单设计并不是忽略设计而是设计不应该一次完成，因为随着业务的变化，可能当时设想的可预知的未来根本就是不存在的，留有适当的扩展设计并满足现有需求的简单设计原则。</p></li><li><p>测试先行。是指注重测试用例程序的编写，不能因为没有时间，工作紧张为由忽略测试工作，这样就会由于没有良好的测试用例而化大把的时间在后续的联调维护阶段，实际上这个整体上市大大降低产能、效率埂底下的做法。</p></li><li><p>重构。重构是一种对待吗进行重写而不影响功能实现的的技术，XP要求在开发人员“问到代码的坏味道”时，就有重构代码的勇气。重构的目的是让代码降低因变化引起的风险、使得代码更加易于维护和阅读。</p></li><li><p>结对编程。一开始虽然会牺牲一些速度，但慢慢的，开发速度会逐步加快，究其原因是结对编程大大降低了沟通成本，提高了工作的质量，具体表现在：</p><ol><li>所有的设计决策确保不是一个人做出来的</li><li>系统的任何部分至少有2个人以上熟悉</li><li>不能能同时2个人都忽略测试项</li><li>阶段的动态性，是一个去也知识管理的好途径</li><li>代码总是能够保证评审通过</li><li>XP方法集成的吉他最佳实践能够是的结对编程更加容易进行</li><li>编码标准能够消除一些无谓的分歧</li><li>隐喻可以帮助结对伙伴更好沟通</li><li>简单设计能够是的伙伴更了解他们所从事的工作</li></ol><p>结对编程技术被誉为XP保持工作质量、强调人文主义的一个典型实践，能够是的开发团队之间的协作更加流畅、知识交流更加频繁、团队更加稳定。</p></li><li><p>集体代码所有制。有XP方法鼓励团队进行结对编程，而且编程组是动态搭配的，每个人会遇到不同的代码，代码所有制就不是局限于某一个人，而是集体所有制，团队中的每个人都有进行修改的权利，每个人都拥有全部代码，也都需要对全部代码负责。同时XP强调代码是谁该坏的就应该有谁来修复。</p></li><li><p>持续集成。持续集成是最佳实践的基本支撑条件。</p></li><li><p>每周工作40小时。这是一个让开发者开心、管理者反对的一个最佳实践。加班早已成为开发人员的家常便饭，也是管理者最常用的一种策略。而XP方法认为，加班会扼杀团队的积极性，最终导致项目失败，这也体现了XP方法是关注人的因素比关注过程的因素更多一些。这里说的40小时不是绝对的额，是指根据团队公司合理的工作时长。提倡追求有效的、高效的工作时间，而不是绝对的时长。</p></li><li><p>现场客户。为了保证开发出来的结果与客户的预想接近，XP方法认为最重要的是将客户请到现场，保持和客户的现场沟通，并让客户参与到开发决策中来。</p></li><li><p>编码标准。拥有编码标准可以避免团队无关细节的争论。不过这个标准不是越细越好，而是要能够确保代码清晰，便于交流的一个指导方针。</p></li></ol><p>XP方法最大价值在于项目中融会贯通地运用这12个最佳实践，而非单独使用。当然可以使用其中一些实践，单并不意味这就应用了XP方法。</p><h2 id="42-特征驱动开发方法"><a class="markdownIt-Anchor" href="#42-特征驱动开发方法"></a> 4.2 特征驱动开发方法</h2><p>FDD也是一个迭代的开发模型。FDD每一步都强调质量，不断地交付可运行的软件，并以很小的开发提供准确的项目进度报告和状态信息。同敏捷开发一样，FDD弱化了过程在软件开发的地位。</p><h3 id="421-fdd的角色定义"><a class="markdownIt-Anchor" href="#421-fdd的角色定义"></a> 4.2.1 FDD的角色定义</h3><p>FDD认为，有效的软件开发不可或缺的三个要素是：人、过程和技术。软件开发不能没有过程，也不能没有技术，但最重要的还是人。定义了6中关键角色：</p><ol><li>项目经理。项目开发的组织者，是团队的保护屏障，提供一个适宜的开发环境。</li><li>首席架构设计师。负责系统的架构设计</li><li>开发经理。负责团队日常的开发工作的安排，解决开发过程中的技术问题和资源冲突</li><li>主程序员。主程序员将带领小组完成特征的详细设计和构件工作，一般要求主程序员具有一定的工作经验，并能够带动小组工作。</li><li>程序员。若干个程序员在主程序员带领下完成小组的开发，按照特征开发疾患完成开发</li><li>领域专家。领域专家是指对业务精通的人，一般有客户、系统分析师担当。</li></ol><h3 id="422-fdd的最佳实践"><a class="markdownIt-Anchor" href="#422-fdd的最佳实践"></a> 4.2.2 FDD的最佳实践</h3><p>FDD最佳实践包括：领域对象建模、根据特征进行开发、类的个体所有、组成特征小组、审查、定期构造、配置管理、结果的可见性<br>其中最有特色的是个体所有，激活所有的而开发模型都是代码共有。但在FDD中，将类分配给特定的任何小组，分配给A小组的代码只能由A来维护，除A外的角色都不能修改它，只能使用它。<br>优点是：</p><ol><li>这个类的支配感会促使开发人员产生自豪感，从而更出色地完成任务。不过FDD也提到了类q</li><li>审查也是FDD中很具特设的一项实践。不少人认为审查是非常严格的软件过程特有的，然而FDD中明确将审查作为一项最佳实践。审查是一种很有效的发现缺陷的手段，但经常被忽视，国内的软件组织中很少有严格的审查制度保障软件质量。在开发阶段的代码审查机制能够很好的避免潜在的问题。</li></ol><p>缺点：</p><ol><li>项目依赖关系增强，形成代码黑盒，除了负责人没人能修改。</li></ol><h2 id="43-scrum"><a class="markdownIt-Anchor" href="#43-scrum"></a> 4.3 Scrum</h2><p>Scrum是一个用于开发和维护复杂产品框架，是一个增量的、迭代的开发过程。由若干个迭代周期组成，一个短的迭代周期成为Sprint,每个Sprint的建议周期在2到4周。在Scrum中，使用产品的Backlog来管理产品的需求，产品Backlog是一个按商业价值拍下的需求列表。<br>Scrum团队重产品的Backlog中挑选优先级最高的需求进行开发。<br>挑选的需求在sprint的计划会议上进行讨论、分析和估算得到相应的任务列表，称之为Sprint backlog.</p><h3 id="431-scrum的5个活动"><a class="markdownIt-Anchor" href="#431-scrum的5个活动"></a> 4.3.1 Scrum的5个活动</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183846916.png" alt></p><ol><li><p>产品待办事项的梳理——Prodct Backlog. 产品待办事项通常会很多，也很宽泛，而且想法会变来变去、优先级也会变化，所以产品待办事项列表的梳理是一个贯穿整个Scrum项目的活动。梳理包括：整理需求、优先级排序、事项分解、归并以及商业价值分析等。待办事项的梳理最好是所有团队成员参与，因为有可能需要其他技术或者团队的参与，而不是单单产品经理。</p></li><li><p>Sprint计划会议。每个Sprint工作周期以Sprint计划会议作为开始，让团队共同选择和理解即将到来的Sprint工作事项. Sprint计划会议的成功十分依赖产品待办事项列表的质量。Sprint计划会议工作内容有两部分：</p><ol><li>需要完成那些工作：产品负责人介绍排好序的代办事项，让整个Scrum团队共同理解这些工作。而产品待办事项的数目完全有开发团队决定，开发团队要考虑当天产品的增量状态，团队过去的工作情况，当前生产力等，产品负责人不能强加更多的工作量。</li><li>如何完成工作：开发团队根据当前的“完成的定义”一起决定如何实现一个产品增量，进行任务分解，前几天的工作分解成小单元，每个单元不超过一天，之后的任务可以稍微大一些，以后再对它进行分解。总之产品和开发团队一起考虑斌讨论产品待办事项，确保每个人对事项的理解一致，最终产出待办事项列表就是“Sprint 待办事项列表”，称之为Sprint Backlog</li></ol></li><li><p>每日Scrum会议。开发团队自组织，通过每日Scrum会议来确认他们任然可以实现Sprint的目标，每个人说下三点内容：上一个工作日完成了什么、当前工作日计划完成什么、有什么阻碍或风险。一般不超过15分钟。</p></li><li><p>Sprint评审会议。一个Sprint周期结束时，Scrum团队和相关人员一起评审Sprint的产出，Sprint评审会议向每个人展示当前的产品增量情况，帮助大家了解我们目前的进度到哪里，讨论他们在Sprint过程中看到了什么、有什么想法，并一起探讨下一步如何更好的推进。</p></li><li><p>Sprint回顾会议。每个Sprint周期结束之后，Scrum团队开回顾会议，目的是回顾一下团队在流程人际关系及工作方面做得如何，识别出团队中做得好的与不好的，并找潜在可以改进的事项，为将来的Sprint提供改进的计划</p></li></ol><h3 id="432-scrum的5大价值观"><a class="markdownIt-Anchor" href="#432-scrum的5大价值观"></a> 4.3.2 Scrum的5大价值观</h3><ol><li>承若——愿意对目标负责</li><li>专注——把你的心思和能力都用到你承诺的工作上去</li><li>开放——Scrum把项目中的一切开放给每个人看，做到信息透明</li><li>尊重——每个人都有他独特的背景和经验，尊重每个人的特点</li><li>勇气——有勇气做出承诺，履行程度，接受别人的尊重</li></ol><h2 id="44-水晶方法"><a class="markdownIt-Anchor" href="#44-水晶方法"></a> 4.4 水晶方法</h2><p>水晶方法有七大体系特征：</p><ol><li>经常交付。没过一段时间或者几个月向用户交付可测试运行的代码，让用户有机会发现原来需求是否是他真正想要的，有机会将结果反馈到开发中。</li><li>反思改进。开发过程中难免会遇到一些技术难题、各种烦心事，会影响项目进度，所以我们应该经常在迭代中及时地进行反思和改进，从慌乱的日常开发中，抽一点时间来思考更为行之有效的方法。</li><li>渗透式交流。渗透式交流就是信息交流在团队成员中形成背景听觉，使得成员就像通过渗透一样获取相关信息。团队通过在一个共同的工作空间内，若其中一个成员提出问题，其他成员可以选择关注或不关注，也可以随时加入到讨论中来，选择性地获取相关交流的信息。</li><li>个人安全。当你勇敢指出了困扰你的问题时，你可以不用担心受到报复，应该有保护机制，鼓励大家发现和改正自身的缺点，而不是知而不言，这样就会对团队造成损害，不利于整个团队的协作和稳定。</li><li>焦点。也叫聚焦，明确知道要做什么，然后再安排时间，确保团队成员都清楚地了解他们自己最重要的任务是什么，确保他们能够充分利用时间去完成这些任务。</li><li>与专家用户简历方便的联系。与专家用户简历方便的联系能够给团队提供很好的帮助，例如对业务的专业理解，成品的质量和快速罚款，设计理念和需求背景，用户最新的需求等。</li><li>自动化测试。自动化测试是在开发在修改代码之后能够进行自动化测试，以便发现一些bug，让开发能够及时地进行修复，节省了整体的开发时间，提高效率。</li></ol><h2 id="45-其他敏捷方法开放式源码"><a class="markdownIt-Anchor" href="#45-其他敏捷方法开放式源码"></a> 4.5 其他敏捷方法——开放式源码</h2><p>开放式源码——是指以开放源码的方式运作，特别的就是开发人员可能地域分布很广，这和其他的敏捷方法不同，开放源码的一个好处就是排错的高度并行性，任何人都可以发现错误并修改代码提交给维护者。这里面体现的价值观就是猜测、合作和学习。</p><h1 id="5-软件重用"><a class="markdownIt-Anchor" href="#5-软件重用"></a> 5 软件重用</h1><p>软件产品和其他的产品不同，是抽象的，一旦产生就可以无限地复制，因此重复利用软件产品意义重大，可以节约大量的人力物力。软件重用包括：软件产品、源代码、文档、设计思想甚至领域知识。<br>常见的重用形式：</p><ol><li>源代码重用。这是简单最常见的重用形式，由于软件系统的复杂性，很难大规模地重用已有代码</li><li>架构重用。这个重用也很常见，随着软件架构风格和设计模式的推广和应用，架构重用已经对软件开发产生了重大影响</li><li>应用框架的重用。随着技术的发展，应用框架的重用变得越来越普遍，如AOP、EJB、Spring等应用框架技术</li><li>商业建模的重用。虽然软件领域各有不同，但是人们可以总结出常用的领域建模的方法，重用这些领域建模可以降低不确定性因素风险。</li><li>文档及过程的重用。有效地重用已有的文档有助于提高开发的效率</li><li>构件的重用。如第三方的组件，中间件等</li><li>软件服务的重用。随着web服务的提出，人们越来越关注服务的重用。例如SOA架构就是一个服务重用的实践，让一类功能收归到一个服务做不同业务软件的重用服务。</li></ol><h1 id="6-基于架构的软件设计"><a class="markdownIt-Anchor" href="#6-基于架构的软件设计"></a> 6 基于架构的软件设计</h1><p>基于架构的软件设计（Architecture-Based Software Design,ABSD）是一种架构驱动的设计方法，这种方法有3个基础：</p><ol><li>功能分解。在功能分解中，ABSD方法使用已有的基于模块内聚和耦合技术</li><li>通过选择架构风格来实现质量和业务需求</li><li>软件模板的使用。软件模板利用了一些软件系统的结构。</li></ol><p>ABSB模型是吧整个过程划分为：架构需求、设计、文档化、复审、实现和演化</p><h2 id="61-absb方法与生命周期"><a class="markdownIt-Anchor" href="#61-absb方法与生命周期"></a> 6.1 ABSB方法与生命周期</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183846654.png" alt></p><h2 id="62-基于架构的软件开发模型"><a class="markdownIt-Anchor" href="#62-基于架构的软件开发模型"></a> 6.2 基于架构的软件开发模型</h2><p>基于架构的软件开发模型（Architecture-Based Software Design Model，ABSDM）把整个基于架构的软件过程划分为架构需求、架构设计、架构文档化、架构复审、架构实现和架构演化6个子过程：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825183846024.png" alt></p><ol><li>机构需求。是指用户对目标软件在系统功能、行为、性能、设计约束方面的期望。通过用户的需求，架构师根据技术环境和架构师经验标注出所需要的构件，最后进行需求的评审。必要时“需求获取——标识构件——需求评审”之间进行迭代。</li><li>架构设计。根据架构需求提出架构的模型、映射构件、分析构件相互作用、产生架构、设计评审</li><li>架构文档化。绝大多数架构都是抽象的，有一些概念的构件组成。为了开发人员更好地理解和实现架构，必须把架构进行文档化描述</li><li>架构复审。架构设计完成之后要安排一次由外部人员（用户和领域专家）参与的复审，其目的是识别潜在的风险，及早发现架构设计中的缺陷和错误，包括架构能否满足需求、质量需求是否得到体现、是否清晰、构件是否划分合理、文档标识是否明确、以及构架设计是否满足功能和性能要求等等</li><li>架构实现。开发人员根据复审后的架构文档，分析和实现其中的构件，然后组装测试的一个过程。</li><li>架构演化。在架构开发中，用户的需求可能变动，在开发完成正常运行后，也可能发生需求变化。那么就要相应地调整架构以适应新的软件需求。主要过程包括这7个步骤：需求变动归类、架构演化计划、构件变动、更新构件的相互作用关系、构件组装和测试、技术评审、技术评审，最后得出演化后的架构设计。</li></ol><h1 id="7-形式化方法"><a class="markdownIt-Anchor" href="#7-形式化方法"></a> 7 形式化方法</h1><p>形式化方法是指采用严格的数据方法对软件的描述、开发和验证的过程进行严格规约的一种方法，通过这种方式可以需求和定义人员与开发人员的理解偏差，避免模糊性和二义性。通过形式化描述进行需求分析的质量大大提高，很多自然语言描述无法避免的缺陷在需求分析阶段就会被发现并等到解决，从而降低了后期的开发和维护的成本。形式化描述可以通过计算计算进行自动处理（一些专业软件），进行一致性检查和证明。<br>一般一些安全要求较高的，如地铁、高铁、航空、核电等软件会考虑使用这种开发方法来保证系统的安全和可靠性。</p>]]></content>
      
      
      <categories>
          
          <category> 软考 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 软考 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统原理——初识操作系统</title>
      <link href="/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-chu-shi-cao-zuo-xi-tong/"/>
      <url>/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-chu-shi-cao-zuo-xi-tong/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是操作系统"><a class="markdownIt-Anchor" href="#什么是操作系统"></a> 什么是操作系统</h1><p>操作系统是提供计算机用不与计算机硬件之间的使用接口，并能够管理计算机软件和硬件资源的一个复杂的系统软件，为用户的应用程序提供直接可用的运行环境，是应用程序的开发变得简单、高效。<br>试想一下如果没有操作系统，你将怎样写代码？<br>例如你要写一个实现<code>printf(&quot;hello world&quot;)</code>的功能，你要怎么实现呢？<br>无操作系统的环境下，你只能使用汇编语言直接操作硬件接口</p><pre class="highlight"><code class>xor ah,ah;//对ah、dl清零xor dl,dl;//软驱复位int13h;//BIOS功能调用int 13h中断... //此处省略n行代码mov cl,ah;//其实扇区号送cl寄存器mov dh,al;</code></pre><p>可以看出一个简单的功能，要实现一大段的代码，并且没有的计算机资源做统一的管理，极大的降低程序运行的效率和开发效率。</p><h1 id="操作系统的发展历史"><a class="markdownIt-Anchor" href="#操作系统的发展历史"></a> 操作系统的发展历史</h1><h2 id="无操作系统时代"><a class="markdownIt-Anchor" href="#无操作系统时代"></a> 无操作系统时代</h2><p>第一代计算机（1945~1955年）使用电子管作为主要电子器件，用插件版的链接先或穿孔片表示程序，没有用来存储程序的内存，无操作系统的。<br>我们熟知的那个庞然大物——人类第一台计算机&quot;艾尼阿克&quot;（ENIAC）就是这样的计算机，最初只能完成5000每秒的计算，耗电量在150千万每小时。程序的编程只能通过改变电路的链接方式来表示不同的算法，程序的运行与退出都需要人工的干预，这就是我们人类最初的计算机<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20230213223503151.png" alt></p><h2 id="单道批量处理计算机"><a class="markdownIt-Anchor" href="#单道批量处理计算机"></a> 单道批量处理计算机</h2><p>从第一代计算机开始大概经过了10年的发展，开始使用磁性存储设备，程序员在磁带上录入多批次的作业，交给计算机操作人员，放入计算机中批量载入计算机，计算机会一个一个计算并将结果输出到另外一个磁性设备。这一时期的操作系统就是单到批处理系统，内存红能主流移到用户作业，cup和内存资源被用户作业独占。程序是指令的集合，程序执行是cpu的依次、逐条执行指令的过程。相比于上一代计算机，减少了等待人工操作的时间，但是作业进行I/O时，CPU只能等待I/O完成而无事可做，cpu资源得不到充分利用</p><h2 id="多道批处理系统的特点"><a class="markdownIt-Anchor" href="#多道批处理系统的特点"></a> 多道批处理系统的特点</h2><p>为了解决上一代计算机的问题，有发展到了多道批处理系统。<br>与单道批处理系统相比，躲到批处理系统支持多道程序驻留内存，cpu不在因为某个进程等待I/O而空闲，而是可以去执行其他进程。</p><h2 id="分时操作系统"><a class="markdownIt-Anchor" href="#分时操作系统"></a> 分时操作系统</h2><p>分时操作系统运行多个用户通过终端同时使用计算机。分时操作系统需要解决的两个关键问题是及时接收和及时处理。分时操作系统为例保证每个用户终端的相应时间，使所有的用户任务直接进入内存，并在很短的时间内快速切换让每个任务都运行一遍，达到多个用户任务并行处理的目的。</p><h2 id="实时操作系统"><a class="markdownIt-Anchor" href="#实时操作系统"></a> 实时操作系统</h2><p>实时操作系统主要用户实时控制和实时信息处理领域。与分时系统相比，它具有多路性、独立性、及时性、交互性、可靠性几个特点。<br>实时系统比分时系统要求有更高的可靠性，必须能够在任务能够容忍的时间范围内处理完，否则可能带来巨大的经济损失设置生命安全。批处理系统、分时系统和实时系统是三种基本的草鞋系统类型，实时操作系统可能兼有三者货主其中两者的功能特征.</p><p>#操作系统的五大功能</p><h2 id="内存管理"><a class="markdownIt-Anchor" href="#内存管理"></a> 内存管理</h2><p>内存管理主要是为多道程序运行提供良好的环境，方便用户使用内存，提高内存的利用率，已经从逻辑上扩充内存以实现虚拟存储。包括内存分配、内存保护、地址映射、内存扩充功能。</p><h3 id="内存分配"><a class="markdownIt-Anchor" href="#内存分配"></a> 内存分配</h3><p>内存分配可分为静态分配和动态分配，静态是指按程序所需分配固定大小后不再变化，动态分配是指在系统运行中，根据进程的骑牛分配内存大小，是可以在运行时变化的。<br>为了实现内存分配，需要实现以下几个功能：</p><ol><li>适用于内存分配的数据结构，包含内存的使用情况，内存的空闲区大小，空闲区的起始地址，未内存分配实现提供依据。</li><li>内存分配功能。系统安装一定的内存分配算法分配内存空间。</li><li>内存回收。系统需要回收被释放的内存空间。</li></ol><h3 id="内存保护"><a class="markdownIt-Anchor" href="#内存保护"></a> 内存保护</h3><p>内存保护的任务：一是是操作系统内核的空间不会被用户随意访问，以保证系统的稳定安全。二是是没道用户程序都在自己的内存空间中运行，相对独立互不干扰。</p><h3 id="地址映射"><a class="markdownIt-Anchor" href="#地址映射"></a> 地址映射</h3><p>cpu执行程序的过程中，需要把程序的逻辑地址转变成物理地址，这个转换过程称为地址映射。</p><p>逻辑地址：是指一个程序编译后，通常会形成若干个目标程序，这些程序再经过链接而形成可装载的程序。这些程序中的指令和数据的地址都是相对于编译链接后的机器代码程序的起始地址计算的。称之为逻辑地址。</p><h3 id="内存扩充"><a class="markdownIt-Anchor" href="#内存扩充"></a> 内存扩充</h3><p>为了满足程序的更大内存需求，就要为其从逻辑上扩充更大的内存，需要实现以下功能：</p><ol><li>请求调入功能。运行系统在装入一部分用户程序是就启动该程序的运行，若在程序运行过程中发现要执行的指令货主要访问的数据没有载入内存，通过请求调入装入内存。</li><li>置换功能。在请求调入是，若发现内存空间不足，需要系统将内存中一部分内存换到外存中，以便腾出内存空间载入当前需要的内容。</li></ol><h2 id="进程管理"><a class="markdownIt-Anchor" href="#进程管理"></a> 进程管理</h2><p>进程管理主要包括：经常的组织和描述、进程的控制、进程的同步、进程同学及进程调度。例如进程的创建、销毁、唤醒、阻塞等操作。</p><h2 id="设备管理"><a class="markdownIt-Anchor" href="#设备管理"></a> 设备管理</h2><p>设备管理主要完成用户的I/O请求，未用户分配I/O设备。为了完成这些任务，设备管理需要具备以下功能：</p><ol><li>缓冲管理。</li><li>设备分配。分配用户I/O所需的设备。</li><li>设备处理。由设备驱动程序来实现cpu与设备控制之间的通讯。</li><li>设备独立性和虚拟设备。设备独立性功能是应用程序独立于物理设备。例如，用高级程序设计语言打印图形程序。</li></ol><h2 id="文件管理"><a class="markdownIt-Anchor" href="#文件管理"></a> 文件管理</h2><p>文件存储空间的管理、文件目录的管理、文件读写</p><h2 id="提供用户接口"><a class="markdownIt-Anchor" href="#提供用户接口"></a> 提供用户接口</h2><p>为了方便用户使用操作系统，操作系统向用户提供命令行和图形用户接口，向程序员提供应用程序与操作系统之间的接口。</p><h1 id="操作系统的体系结构"><a class="markdownIt-Anchor" href="#操作系统的体系结构"></a> 操作系统的体系结构</h1><p>操作系统的体系结构是一个复杂软件系统的高层结构，未软件系统提供了一个结构、行为和属性的高级抽象，包括系统元素的结构、元素拣的相互关系，以及指导元素集成的模式和约束。</p><h2 id="简单的监控程序模型"><a class="markdownIt-Anchor" href="#简单的监控程序模型"></a> 简单的监控程序模型</h2><p>最初的计算机并不存在操作系统这个概念，所有的任务都是直接运行与硬件上，程序员直接操作硬件系统。随着控制语言的出现，产生了简单的监控程序，能够保证任意时刻系统只能运行一个任务，保证对系统信息的互斥访问。</p><h2 id="单体结构模型"><a class="markdownIt-Anchor" href="#单体结构模型"></a> 单体结构模型</h2><p>在单体结构模型中，多有的软件和数据结构防止在一个逻辑模块中，对外出的用户程序提供一个完成的内核界面——系统调用。整个系统有若干个功能独立的子程序组成，运行任意一子程序调用其他子程序，因此它的特点是结构简单，便于理解和实现，而且系统所有的部分都集中在一个内核中，效期较高，缺点也很明显，各个子程序之间可以相互调用，系统结构关系复杂，容易引起循环调用和死锁。</p><h2 id="层次结构模型"><a class="markdownIt-Anchor" href="#层次结构模型"></a> 层次结构模型</h2><p>层次结构的基本思想是讲操作系统分解为多个晓得容易理解的层，系统功能被隔离在不同的层中，每一层提供对系统功能的部分抽象。在操作系统的层次结构中，各个模块都有相对固定的位置、相对固定的层次。层与层之间有间隔的接口定义，每一次值依赖于它下层提供的服务而工作，不能夸层随意访问。不过出于效率的考虑，有些系统运行夸层乡下调用。</p><h2 id="客户服务器模型与微内核结构"><a class="markdownIt-Anchor" href="#客户服务器模型与微内核结构"></a> 客户/服务器模型与微内核结构</h2><p>它的核心思想是功能外迁，即吧传统操作系统内核中的一些组成部分（如文件系统、网络、驱动程序等内核功能）放到内核之外作为一个独立的服务进程来实现，在微内核中只保留了操作系统最基本的功能，包括处理器调度、存储管理和消息通道等。</p><h2 id="动态可扩展结构模型"><a class="markdownIt-Anchor" href="#动态可扩展结构模型"></a> 动态可扩展结构模型</h2><p>采用UPCALL和DOWNLOAD技术。它试图将所有的传统操作系统内核中提供的抽象转移到用户控件，以操作系统库的形式提供服务，内核层只负责对物理设备的控制。应用程序可以从用户层库中得到并控件内核抽象，从而实现了操作系统的动态扩展。</p><h1 id="指令的执行"><a class="markdownIt-Anchor" href="#指令的执行"></a> 指令的执行</h1><h2 id="取指令和执行指令"><a class="markdownIt-Anchor" href="#取指令和执行指令"></a> 取指令和执行指令</h2><ol><li>取指令，在每个指令周期开会时，处理器从存储器中读取一条指令，在典型的固定长度指令处理器中，程序计数器（PC）保存有下一次要取的指令地址，每次取指令后都对PC作递增，使它能够按顺序读取吓一条指令，即位于下一个高端存储器地址的指令。</li><li>执行指令，取到指令被防止在处理器的指令寄存器IR中。指令中包含确定处理器将要采取动作的位，处理器解释指令并执行要求的动作，这些动作可分为4类：<br>2.1 处理器与存储器之间的指令或数据传送操作。<br>2.2 处理器与I/O设备质检的指令或数据传送操作<br>2.3 算数运算操作或逻辑运算操作<br>2.4 控制操作，即修改指令的执行顺序的操作。</li></ol><h2 id="小结"><a class="markdownIt-Anchor" href="#小结"></a> 小结</h2><p>程序执行过程是反复取指令和执行指令的过程。PC使用存有下一条指令的地址。指令的执行结果就是使寄存器或内存单元的值发生变化，指令执行的过程也就是存储体内容不断变化的过程。取指令和执行指令是有硬件完成的，不同硬件的体系结构支持不同的指令集合，为某一种硬件平台开发的操作系统不能直接在另外一中体系结构的硬件上运行。</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统原理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统原理——内存</title>
      <link href="/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-nei-cun-guan-li/"/>
      <url>/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-nei-cun-guan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="内存管理的目标"><a class="markdownIt-Anchor" href="#内存管理的目标"></a> 内存管理的目标</h1><ol><li>实现内存分配、内存回收等操作</li><li>提高内存的利用率和内存的访问速度<br>即充分利用现有的内存资源，为应用程序提供方便的内存使用方式和一个快速、安全且充分大的存储器</li></ol><h1 id="程序的链接和装入"><a class="markdownIt-Anchor" href="#程序的链接和装入"></a> 程序的链接和装入</h1><p>链接要解决的问题是将编译后的目标模块装配成一个可执行的程序，分为静态链接和动态链接</p><h3 id="1-程序链接"><a class="markdownIt-Anchor" href="#1-程序链接"></a> 1. 程序链接</h3><p><strong>静态链接</strong>：在程序运行之前，用链接程序将目标模块连接成一个完整的转入模块，任务：一是对逻辑地址进行修改，二是转换外部调用符号<br>优点：运行速度快 缺点：可执行文件较大，占用空间大，系统开销大，程序开发不够灵活，修改一个模块会导致整个程序重新连接</p><p><strong>动态链接</strong><br>可将某些目标模块的链接推迟到这些模块中的函数要被调用时再进行。<br>优点：节省内存和外存空间，方便程序开发<br>缺点：增加了运行时的开销，是程序运行时速度变慢</p><h3 id="2程序的装入"><a class="markdownIt-Anchor" href="#2程序的装入"></a> 2.程序的装入</h3><p>装入方式：绝对装入方式、可重定位装入（静态装入方式）和动态运行时装入方式</p><p><strong>绝对装入方式</strong>：编译程序已知程序在内存中的位置，编译时产生物理地址的目标代码，转入程序按照装入模块的物理地址将程序和数据装入内存<br><strong>可重定位装入方式</strong>：编译时不知道程序在内存中的位置，那么编译时就必须生成可重定位的代码，其中的地址都是逻辑地址，在程序转入内存时，再把逻辑地址映射为物理地址。程序装入时对目标称重的指令和数据地址修改的过程称之为重定位转入</p><p>静态装入方式的特点：1)编译程序使目标模块的地址从0开始<br>2) 程序装入时，装入程序根据内存的使用情况将装入模块的装入内存的某个位置，并对模块进行重定位。物理地址=有效的逻辑地址+程序在内存中的其实位置</p><p>动态运行时装入：当一个进程在被换出之前的内存地址与后来被从外存调入时的位置不同，这是地址映射延迟到进程执行时再进行。</p><h2 id="3连续分配的存储管理方式"><a class="markdownIt-Anchor" href="#3连续分配的存储管理方式"></a> 3.连续分配的存储管理方式</h2><ol><li>单一连续去分配方式<br>适合于单用户单任务系统，内存分为系统区和用户区</li><li>固定分区分配<br>将用户内存空间分配成若干固定大小的区域，每个区域运行一道用户程序；分区的数量固定的，大小也是固定的<br>每个分区大小相等的分配方式缺点是：内存利用率低，主要用于一个计算机去控制多个相同对象的场合，如冶炼炉<br>在一些实时系统中，固定分区的分配方式还是简单而有效的</li><li>动态分区分配方式<br>用户分区的数量和大小都是动态变化的<br>分配原理：系统初始只有一个大的空闲分区，当进程请求内存资源时，系统根据请求资源的大小分配一片空闲区域给进程，当运行一段时间后，空闲分区可能散布在不连续的区域，这时候系统会维护一个记录当前空闲分区的数据接口，当进程请求内存时，系统从所有空闲分区中找到一个合适大小的空间给进程。<br>数据结构：空闲分区表和空闲分区链<br>空闲分区链可以动态为每个分区建立一个节点，每个节点包括分区大小、分区起始地址、指向前一个空闲分区节点的指针、指向后一个空闲分区节点的指针。每一个节点占用的内存动态分配、动态回收。</li></ol><p><strong>动态分区分配算法</strong></p><ol><li>首次适应算法FF<br>要求空闲分区链以地址递增的顺序进行连接，每次从链首开始查找，低地址空间可能会被反复划分 缺点：造成空间浪费，内存碎片</li><li>循环首次适应算法NF<br>不在每次从链首开始查找，而是从上一次查找的空闲分区的下一个分区开始查找，每次应设置一个起始查找指针，指示下一次查找的分区</li><li>最佳适应算法BF<br>为了方便查找，把所有空闲区，按照空闲大小递增的顺序进行排列，总是把大小和进程请求的内存空间大小接近的空间分配给进程。<br>优点：避免了大材小用，提高了内存的利用率<br>缺点：容易留下难以使用的小空闲区</li></ol><h2 id="4-基于分页存储的管理方式"><a class="markdownIt-Anchor" href="#4-基于分页存储的管理方式"></a> 4. 基于分页存储的管理方式</h2><p>把进程的存储在内存中的物理地址不连续的区域，这种内存管理方式称为离散内存管理方式。<br>离散内存管理分配内存空间的管理方式有：<strong>分页存储管理，分段存储管理、段也式存储管理</strong></p><p><strong>页</strong>：将一个进程的逻辑地址空间分为若干个大小相等的片，，称之为页<br><strong>页框</strong>：将物理内存地址分成与页大小相同的若干个存储块，称之为页框</p><p><strong>业内碎片</strong>：进程的最后一页一般装不满一个叶框，而形成了不可利用的碎片称为页内碎片。</p><p><strong>页表</strong>：实现页号到页框的映射，在基本的分页制度中，每个进程有一个页表，进程的每一页在页表中有一个对应的页表项，页表在内存中连续存放。</p><p><strong>分页管理方式的地址结构</strong><br>页的存储结构：<br>页号P   页内偏移量W<br>若用m位标识逻辑地址，页大小为2的n次方，则用低n位表示页内偏移量w,用高位m-n位表示P</p><p>分页地址变换：实现逻辑地址到物理地址的转换<br>公式:物理地址=页框号x页框大小 + 页内偏移量</p><p>为了减少cpu在有效访问内存时间上的开销，提高内存的速度，引入了快表机制<br><strong>快表</strong>:也称转换后的缓冲是为了提高访问内存速度而采用的专用缓存，存放最近访问过的页表项。</p><h2 id="4-基于两级页表和多级页表的管理方式"><a class="markdownIt-Anchor" href="#4-基于两级页表和多级页表的管理方式"></a> 4. 基于两级页表和多级页表的管理方式</h2><p>页表再分页，就形成了两级或者多级页表<br>两级页表：将页表再分页，使得每个页表分页的大小与内存页框的大小相同<br>页目录号实际是一个索引值，根据p1从也木勒表项中找到页表所在的页框号，页号p2是页表中的偏移量，根据p2可以知道应该从也飙中的第p2项找到进程页所在的页框号。</p><h2 id="5-基于分页虚拟存储的系统"><a class="markdownIt-Anchor" href="#5-基于分页虚拟存储的系统"></a> 5. 基于分页虚拟存储的系统</h2><p>虚拟存储技术实现的基本思想是：只把进程的一部分装入内存，在进程执行的过程中，cpu访问内存如果发现所访问的内容不再内存中，则通过异常处理将所需的内容从外存调入内存。<br>虚拟存储技术的好处：</p><ol><li>提高内存的利用率</li><li>提高多道程序度</li><li>把逻辑地址空间和物理地址空间分开，程序员不用关心物理内存的容量对编程的限制。</li></ol><p><strong>虚拟存储技术的特征</strong></p><ol><li>离散性</li><li>多次性</li><li>对换性</li></ol><h2 id="6-页的分配策略"><a class="markdownIt-Anchor" href="#6-页的分配策略"></a> 6. 页的分配策略</h2><p>最少页框数：是指保证进程正常运行所需的最少页框数。操作系统为进程分配的页应该大于或者等于最少页框数</p><p>页分配策略：固定分配策略和可变分配策略<br>页置换策略：局部置换和全局置换。1)局部置换发生置换时，只从请求置换的进程本身的内存页中选择淘汰页，腾出内存空间 2)全局置换是指发生置换时，从所有进程的内存页中选择淘汰的页。<br>也有局部置换和全局置换组合的策略：1)固定分配局部置换 2可变分配局部置换 3)可变分配全局置换</p><p><strong>分配算法</strong></p><ol><li>平均分配算法n进程m页框，则分配INT[m/n]个页框，余数放入缓冲</li><li>按比例分配算法，为进程分配的页框数=进程页数/所有进程页数总和 * 总页框数</li><li>优先权的分配算法</li></ol><h2 id="7页调入策略"><a class="markdownIt-Anchor" href="#7页调入策略"></a> 7.页调入策略</h2><ol><li>系统可以在进程需要时将页调入内存，有利于内存的使用率，但是对系统的时间性能不利</li><li>采用预先调入页的策略，将预计不久后会被访问的页预先调入内存</li></ol><h2 id="8页置换算法"><a class="markdownIt-Anchor" href="#8页置换算法"></a> 8.页置换算法</h2><ol><li>最佳置换算法ORA:该算法选择以后永远不会被访问的页或者长时间不会被访问的页作为换出页</li><li>先进先出置换算法FIFO：最简单。当选择换出页时，选择进入内存时间最早的页（用指针指示当前调入新页时，应当淘汰的那个也在队列中的位置，换出后，指针指向下一个应该淘汰的页）</li><li>最久未使用的LRU置换算法：性能较好的算法，该算法是选择最久未使用的页换出。</li><li>其他置换算法：附件引用位算法、简单clock算法、改进型clock算法、最少使用置换算法、页缓冲算法</li></ol><h2 id="9分段存储管理"><a class="markdownIt-Anchor" href="#9分段存储管理"></a> 9.分段存储管理</h2><p>引入分段机制的优点是方便编程、分段共享、分段保护、动态链接以及存储空间的动态增长</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统原理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统原理——进程调度与死锁</title>
      <link href="/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-jin-cheng-diao-du-yu-si-suo/"/>
      <url>/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-jin-cheng-diao-du-yu-si-suo/</url>
      
        <content type="html"><![CDATA[<h1 id="一-进程调度"><a class="markdownIt-Anchor" href="#一-进程调度"></a> 一、进程调度</h1><p>进程的调度室指按照某种策略或算法从就绪进程中为当前空闲的cpu选择在其上运行的新进程</p><h1 id="二-进程的调度算法"><a class="markdownIt-Anchor" href="#二-进程的调度算法"></a> 二、进程的调度算法</h1><p>##1. 时间概念<br><strong>周转时间</strong>是指从作业开始提交给系统开始，到作业完成为止系统的<br><strong>平均周转时间T</strong>=N各种作业的周转时间之和除以n<br><strong>带权周转时间</strong>=作业的周转时间/系统为它提供服务时间<br><strong>响应时间</strong>=用户从提交一个请求开始至系统首次响应的时间为止的一段时间<br><strong>截止时间</strong>=是指某个人物必须开始执行的最迟时间，或者必须完成的最迟时间</p><h2 id="2-调度算法优劣的准则"><a class="markdownIt-Anchor" href="#2-调度算法优劣的准则"></a> 2. 调度算法优劣的准则</h2><ul><li>周转时间短</li><li>响应时间快</li><li>截止时间保证</li><li>系统吞吐量高</li><li>CPU利用率好</li></ul><h2 id="3-调度算法"><a class="markdownIt-Anchor" href="#3-调度算法"></a> 3. 调度算法</h2><ol><li><p>先来先服务(FCFS),从就绪队首选择最先到达就绪队列的进程<br>优缺点：FCFS适合长进程，不利于短进程，适合CPU繁忙型的进程，不适合IO繁忙型的进程</p></li><li><p>短进程调度优先(SPF)，短进程优先算法有效降低进程的平均等待时间，提高系统的吞吐量</p></li><li><p>调度算法优先(SPL),分为非抢占式优先调度算法，抢占式优先权调度；优先权的调度类型：静态优先权和动态优先权</p></li><li><p>时间片轮转调度算法(RR),时间片大小确认考虑的因素：</p><ol><li>系统对响应时间的要求，响应时间越短，时间片取值应该越小。</li><li>就绪队列中的进程数</li><li>系统的处理能力</li></ol></li><li><p>多级队列调度，不同的队列优先权不同，调度算法也可能不同</p></li><li><p>多级反馈队列调度，队列优先权越高，时间片越短，时间片通常成倍增长。</p></li></ol><p>##实时系统中的调度</p><ol><li>提供必要的调度信息</li><li>系统处理能力强</li><li>采用抢占式调度机制</li><li>具有快速切换机制</li></ol><h2 id="死锁"><a class="markdownIt-Anchor" href="#死锁"></a> 死锁</h2><p>死锁是由于多个进程竞争共享资源引起的进程不能向前推进的僵死状态</p><p>产生死锁的原因：竞争死锁资源且分配资源的顺序不当<br>产生死锁的必要条件：</p><ol><li>互斥</li><li>请求保持</li><li>不剥夺</li><li>环路等待</li></ol><p>处理死锁的防范：</p><ol><li>预防死锁</li><li>避免死锁，资源分配的状态分为安全和不安全状态，不安全状态不一定产生死锁，但是系统进入安全状态一定不会产生死锁，这样就可以避免死锁的产生，银行家算法就是一种系统避免系统死锁的一种检测算法，其基本思想是：一个进程提出资源请求后，系统进行资源的试分配。然后检测此次分配是否处于安全状态，若安全则按分配方案分配资源，否则不进行分配资源。</li><li>检测并解除死锁</li><li>忽略死锁</li></ol><p>某系统中有3个并发进程，都需要同类资源4个，试问该系统保证不会发生死锁的最少资源数是______<br>如果一个进程有m个资源它就能够结束，不会使自己陷入死锁中。因此最差情况是每个进程有m-1个资源并且需要另外一个资源。如果留下有一个资源可用，那么其中某个进程就能够结束并释放它的所有资源，使其它进程也能够结束。所以避免死锁的条件是：r≥p(m-1)+1。带入上述条件公式：<em><em>r≥3</em>(4-1)+1=10</em>*。所以答案为10个。</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统原理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统原理——进程管理</title>
      <link href="/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-jin-cheng-guan-li/"/>
      <url>/cao-zuo-xi-tong-yuan-li/cao-zuo-xi-tong-yuan-li-jin-cheng-guan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="一-进程的概念"><a class="markdownIt-Anchor" href="#一-进程的概念"></a> 一、进程的概念</h1><ol><li>进程是允许并发的程序在某个数据集合上运行的过程</li><li>进程是<strong>正文段</strong>、<strong>用户数据段</strong>和<strong>进程控制块</strong>共同组成的执行环境。</li></ol><h1 id="二-进程与程序的区别"><a class="markdownIt-Anchor" href="#二-进程与程序的区别"></a> 二、进程与程序的区别</h1><ol><li>程序是静态的，进程是动态的</li><li>程序是永久的，进程是暂时存在的</li><li>程序和进程存在的实体不同。程序是指令的集合，进程是由正文段、用户数据段、进程控制块组成</li></ol><h1 id="三-进程与程序的关系"><a class="markdownIt-Anchor" href="#三-进程与程序的关系"></a> 三、进程与程序的关系</h1><p>进程是程序的一次执行，进程总是对于一个特定的程序，一个程序可以对于多个进程</p><h1 id="四-进程的组成部分"><a class="markdownIt-Anchor" href="#四-进程的组成部分"></a> 四、进程的组成部分</h1><h2 id="正文段"><a class="markdownIt-Anchor" href="#正文段"></a> 正文段</h2><p>正文段存放被执行的激情指令</p><h2 id="用户数据"><a class="markdownIt-Anchor" href="#用户数据"></a> 用户数据</h2><p>用户数据段存放进程在执行时要操作的用户数据</p><h2 id="进程控制块"><a class="markdownIt-Anchor" href="#进程控制块"></a> 进程控制块</h2><p>是操作系统管理进程所使用的数据结构<br>进程控制块是实体的一部分，是操作系统重要的数据结构，进程控制块中记录了操作系统所需要的，用户描述进程情况以及控制运行所需要的全部信息，进程控制块是操作系统感知进程存在的唯一标志。</p><h1 id="五-进程管理"><a class="markdownIt-Anchor" href="#五-进程管理"></a> 五、进程管理</h1><ol><li>进程的状态信息：就绪态、执行态、阻塞态</li><li>进程的组织方式：链接方式、索引方式、进程队列</li><li>进程的控制：进程的创建—阻塞—唤醒—终止</li><li>进程的创建条件：1) 用户登录 2)作业调度 3)提供服务 4)应用请求</li><li>阻塞条件： 1)请求系统服务 2)数据尚未到达 3)无工作可做 4)启动某种操作</li></ol><h2 id="操作系统内核"><a class="markdownIt-Anchor" href="#操作系统内核"></a> 操作系统内核</h2><p>操作系统内核是指系统与硬件密切相关、执行频率高的模块，一般常驻内存。</p><h3 id="操作系统内核的功能"><a class="markdownIt-Anchor" href="#操作系统内核的功能"></a> 操作系统内核的功能</h3><ol><li><p>支持功能<br>支撑功能包括：中断处理、时钟管理和原语操作，其中原语操作是一组在执行过程中不能中断的操作</p></li><li><p>资源管理功能<br>资源管理功能包括：进程的管理、存储器管理和设备管理</p></li></ol><p>####中断</p><p>中断时改变计算机执行指令的顺序的一种事件，这种事件与cpu芯片内外部硬件电路参数的电信号对应。</p><p><strong>中断的目的</strong>：能够有效提高cpu的利用率，改善系统性能，支持系统的异步性。例如在引用中断机制之前，采用的是发福轮询的方式来检测本次I/O是否结束。</p><p><strong>中断的类型</strong>：</p><ol><li>同步中断：当指令执行时由cpu控制段元产生的，如除法出错，调试、溢出、浮点出错等</li><li>异步中断（外部中断）：是由其他硬件设备随机产生的，可分为外部可屏蔽中断（I/O设备产生）和外部不可屏蔽中断(紧急事件产生，硬件故障等)</li></ol><p><strong>引起中断的原因</strong>：1)人为设置中断 2)程序性事故 3)I/O设备 4)硬件故障 5)外部事件</p><h2 id="时钟管理"><a class="markdownIt-Anchor" href="#时钟管理"></a> 时钟管理</h2><p>计算机很多活动都是有定时测量来控制的，两种定时测量 1) 保存当前的系统事件和日期 2)维持定时器，操作系统依靠时钟硬件和时钟驱动程序完成上述两种测量</p><p><strong>时钟硬件</strong>：按照指定时间间隔产生时钟中断，测量逝去的时间，并触发与时间有关的操作<br><strong>时钟软件</strong>：维护日期和时间，递减当前进程在一个时间片内的剩余执行时间，对cpu的使用情况记账，递减报警计算器</p><p><strong>时钟源</strong>：实时时钟（RTC/CMOS）/OS时钟</p><h2 id="系统调用与一般函数"><a class="markdownIt-Anchor" href="#系统调用与一般函数"></a> 系统调用与一般函数</h2><p>系统调用是一群实现定义好的模块，他们提供一条管道让应用程序或用户能由此得到核心程序的服务。系统调用时系统程序与用户程序之间的接口。</p><p>系统调用与一般函数的区别：</p><ol><li>系统调用运行在系统态，一般函数运行在用户态</li><li>系统调用与一般函数的执行过程不同，系统调用中断时，有系统找到对于的系统调用子程序</li><li>系统调用要进行[中断处理],比一般函数多一些系统开销</li></ol><h2 id="进程同步"><a class="markdownIt-Anchor" href="#进程同步"></a> 进程同步：</h2><p>操作系统同步机制的主要任务就是保证在多任务共享系统资源的情况下，程序能够得到正确的结果。同时，同步机制需要解决进程执行的协调问题。</p><p>进程同步有两个作用</p><ol><li>对具有共享资源的进程，保住以互斥的方式访问临界资源。临界资源必须以互斥的方式访问共享资源</li><li>对具有相互合作关系的进程，要保证相互合作的各个进程协调执行</li></ol><p><strong>同步机制遵循的准则</strong>： 1)空闲让进 2)忙则等待 3)有限等待 4) 让权等待</p><h2 id="信号量机制"><a class="markdownIt-Anchor" href="#信号量机制"></a> 信号量机制</h2><p>信号量机制对不同共享资源设置称之为信号量的变量，用信号量的取值标识资源的使用情况，或某种事件的发生</p><h3 id="整形信号量机制"><a class="markdownIt-Anchor" href="#整形信号量机制"></a> 整形信号量机制</h3><p>用整形来标记资源的使用情况。若整形量&gt;0,说明有资源可用；若整形量&lt;=0，说明资源忙，进程必须等待。</p><h3 id="记录型信号量机制"><a class="markdownIt-Anchor" href="#记录型信号量机制"></a> 记录型信号量机制</h3><p>除了用整形来标记资源的使用情况外，额外使用一个记录进程队列来存储等待资源的进程。这样就不存在“忙等”，而是通过有可用资源时的回调触发</p><h3 id="and型信号量的机制"><a class="markdownIt-Anchor" href="#and型信号量的机制"></a> AND型信号量的机制</h3><p>基本思想是将进程在整个运行过程中所需要的所有资源一次性的全部分配给进程，待进程使用完后再一起释放。</p><h1 id="六-线程"><a class="markdownIt-Anchor" href="#六-线程"></a> 六、线程</h1><p>在操作系统中，进程是进行资源分配和独立执行的基本单位，为了进一步提高程序的并发性，减少系统的开销，在操作系统中引入了线程的概念。<br>线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程在运行中断性，也有就绪、执行、阻塞三种状态。</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统原理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 操作系统原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>高性能无锁阻塞队列——Disruptor</title>
      <link href="/xue-xi/gao-xing-neng-wu-suo-zu-sai-dui-lie-disruptor/"/>
      <url>/xue-xi/gao-xing-neng-wu-suo-zu-sai-dui-lie-disruptor/</url>
      
        <content type="html"><![CDATA[<p>这是我年初在公司内部技术分享讲Disruptor的PPT,整理下放到博客里面。</p><h1 id="什么是disruptor"><a class="markdownIt-Anchor" href="#什么是disruptor"></a> 什么是Disruptor</h1><p>Disruptor 是一个用于在线程间通信的高效低延时的消息组件，它像个增强的队列，能够在无锁的情况下实现异步并发操作,它是纯内存组件。</p><p>它的特点如下：</p><ul><li>高性能、无锁，实现每秒千万级别的异步业务处理能力</li><li>它除了能实现队列基本功能，还能实现顺序消费，或者复杂的并行和依赖结合的消费方式</li><li>能实现一对多、多对一、多对多的广播或抢占试消费</li></ul><h1 id="为什么高性能快速"><a class="markdownIt-Anchor" href="#为什么高性能快速"></a> 为什么高性能，快速？？？</h1><ul><li>使用RingBuffer数据结构，实现内存复用，减少重新分配空间带来的时间空间损耗</li><li>使用CPU底层CAS（Compare And Swap :比较并交换）指令和内存屏障实现读写无锁化，并使用读写指针序列缓存行补齐方式达到真正的读写分离</li><li>阻塞等待策略，使用Busy Spin(疯狂死循环)，是多核架构最快的通讯方式，同时也是最耗cpu的通讯方式，典型的牺牲硬件来换取速率</li></ul><h1 id="disruptor数据结构"><a class="markdownIt-Anchor" href="#disruptor数据结构"></a> Disruptor数据结构</h1><p>Disruptor底层是一个固定大小的环形数组，每个读或写线程自己维护一个可读可写序列对象Sequence,并保证每个序列在不同的内存缓存行中（cache line）,避免伪共享，实现真正的无锁的读写分离，如图：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184418757.png" alt><br>假设环形数组长度为L=8</p><p>当生产者写入一个元素时，对应写的Sequence下标w++;<br>当消费者读取一个元素时，对应读的Sequence下标r++;<br>当且r &lt; w &lt; r+L时，数组正常写入及消费<br>当且w=r时，数组为空，消费者阻塞，生产者可以从w+1%L的位置开始重复写入<br>当且w=r+L时，数组写满，生产者阻塞，消费者可以从r+1%L的位置开始读取</p><blockquote><p>关于<strong>缓存行伪共享</strong><br>我们知道CPU为了加快访问内存数据，设置了很多CPU高速缓存，当CPU要访问一个内存数据时，先从主内存中缓存一个Cache Line(缓存行，CPU高速缓存存取数据的最小单位是一个缓存行，Hotspot JVM最小单位是64字节，而有的是128字节，不同虚拟机对此处理不一样)，而当一个缓存内的某个变量值改变时，其他缓存了此变量相邻的变量也将将失效，因为它们在一个缓存行中。这就是所谓的内存伪共享，虽然两个线程引用的变量不同，但是由于使用的是同一个缓存行的变量，也将受影响，从而影响CPU的执行速率。<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184418828.png" alt><br>在Disruptor中，为了实现真正的读写分离互不影响，也就是用于读写分离的两个Sequence对象使用缓存行填充的“笨方法”来避免这种伪共享。实现的方法就是将一个Sequence对象填充满一个缓存行，而避免其他无关的对象变量影响其使用速率。<br>实现原理：<br>我们知道一个在Java中一个对象的在内存中的大小取决于这个对象的成员变量大小，如下<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184418735.png" alt><br>需要使用一个long类型的成员变量value，一个long类型是8个字节，除了这个long类型value的下标外，定义14个long类型的变量p1、p2…p15，再加上一个对象的对象头大小是8字节,所以最终一个对象在在内存中的大小刚好是128字节，如果是64字节的 Line Cache就占用两个缓存行，128字节的Line cache就占用一个缓存行，在多线程情况下，排除了无关对象对这个Sequence对象的更新缓存失效影响。由于JDK7开始JVM会对对象的无效变量（未使用的变量）作优化处理，这里使用继承的方式，否则这种方式的缓存行填充是无效的，从JDK8开始已经原生支持缓存行填充，只需要一个注解:</p></blockquote><pre class="highlight"><code class>@Contendedpublic class VolatileLong {    public volatile long value = 0L;  }</code></pre><blockquote><p>并且在java启动参数中设定<code>XX:-RestrictContended</code>，<code>@Contended</code>注释才会生效。</p></blockquote><h1 id="disruptor的其他特性"><a class="markdownIt-Anchor" href="#disruptor的其他特性"></a> Disruptor的其他特性</h1><h2 id="disruptor-并行消费的结果依赖等待"><a class="markdownIt-Anchor" href="#disruptor-并行消费的结果依赖等待"></a> Disruptor 并行消费的结果依赖（等待）</h2><p><img src="https://leanote.com/api/file/getImage?fileId=5a27e543ab644163f00002e7" alt></p><p>从中图可以看出需求是介样子的：生产者生产数据经过C1,C2处理完成后再到C3。<br>假设如下场景：<br>1、交易网关收到交易(P1)把交易数据发到RingBuffer中，<br>2、负责处理增值业务的消费者C1和负责数据存储的消费者C2负责处理交易<br>3、负责发送JMS消息的消费者C3在C1和C2处理完成后再进行处理。<br>使用以下代码就可以实现：</p><pre class="highlight"><code class>disruptor.handleEventsWith(new EventHandleOne(),new EventHandleTow()).then(new EventHandleThree());</code></pre><h1 id="disruptor与arrayblockingqueue-linkedblockingqueue的比较"><a class="markdownIt-Anchor" href="#disruptor与arrayblockingqueue-linkedblockingqueue的比较"></a> Disruptor与ArrayBlockingQueue、LinkedBlockingQueue的比较</h1><table><thead><tr><th>-----</th><th>Disruptor</th><th>ArrayBlockingQueue</th><th>LinkedBlockingQueue</th></tr></thead><tbody><tr><td>实现原理</td><td>固定大小的环形的ringbuffer存放元素</td><td>固定大小的数组存放元素，通过插入、取出两个下标协同循环使用数组</td><td>用链表存放元素，大小不固定</td></tr><tr><td>锁</td><td>无锁，多生产者之间有sequence竞争，采用比锁轻量的CAS操作</td><td>有锁，且读和写是同一个锁，锁粒度最大</td><td>有锁，读锁和写锁分开</td></tr><tr><td>gc</td><td>元素重用，gc较少</td><td>元素重用，gc较少</td><td>元素不重用，gc较多</td></tr><tr><td>其他</td><td>考虑cpu cacheline，避免false sharing，多种等待策略，可根据具体情况选用。比如自旋、wait、自旋一定时间然后wait等。</td><td>等待时线程wait，条件满足时，notify，线程切换较多</td><td>等待时线程wait，条件满足时，notify，线程切换较多</td></tr><tr><td>适用场景</td><td>1、性能最好2、消费者其实是一种广播的方式，即每个元素，每个消费者都要消费</td><td>1、多并发时性能不好。2、典型消费者-生产者模式，一个元素只给一个消费者消费</td><td>1、并发性比ArrayBlockingQueue好，但gc较多。2、典型消费者-生产者模式，一个元素只给一个消费者消费</td></tr><tr><td>一对一消费</td><td>16,355,904 tps/sec</td><td>4,641,233 tps/sec</td><td>4,633,706 tps/sec</td></tr><tr><td>三对一消费</td><td>15,499,070 tps/sec</td><td>8,055,421 tps/sec</td><td>5,997,361 tps/sec</td></tr><tr><td>10对一消费</td><td>17,624,251 tps/sec</td><td>4,310,716 tps/sec</td><td>5,670,863 tps/sec</td></tr><tr><td>100对一消费</td><td>16,952,026 tps/sec</td><td>537,634 tps/sec</td><td>5,701,254 tps/sec</td></tr><tr><td>10000对1消费</td><td>10,060,362 tps/sec</td><td>84,906 tps/sec</td><td>5,252,101 tps/sec</td></tr></tbody></table><p>大家感兴趣可以运行测试代码，Disruptor 性能测试代码：<a href="https://github.com/okeeper/disruptorTest.git" target="_blank" rel="noopener">https://github.com/okeeper/disruptorTest.git</a></p><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><p>凡事都不是选最好的，而是要选适合自己的。<br>同样，我们系统也要根据我们业务需要选择适合的技术。Disruptor，总结就是：如果非业务性能特殊需要，无必要使用Disruptor，如每秒600万订单处理，大多时候我们的JDK5的java.util.concurrent包已经够我们使用了，因为Disruptor会增加我们的成本（学习成本、维护成本以及硬件资源消耗）。</p><p>参考文章:<a href="http://www.importnew.com/19896.html" target="_blank" rel="noopener">剖析Disruptor为什么会这么快(2)：神奇的缓存行填充</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习 </tag>
            
            <tag> Disruptor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dubbo源码学习</title>
      <link href="/xue-xi/dubbo-yuan-ma-xue-xi/"/>
      <url>/xue-xi/dubbo-yuan-ma-xue-xi/</url>
      
        <content type="html"><![CDATA[<h1 id="dubbo-provider暴露源码分析"><a class="markdownIt-Anchor" href="#dubbo-provider暴露源码分析"></a> Dubbo Provider暴露源码分析</h1><p>Dubbo服务端的服务暴露及初始化</p><ol><li><code>org.apache.dubbo.config.spring.ServiceBean#afterPropertiesSet</code> 开始spring 容器初始化好属性后，回调这个方法开始初始化Provider</li><li>前面一堆是初始化<code>ApplicationConfig</code>、<code>Module</code>、<code>Registry</code>(注册中心)、<code>ConfigCenter</code>(配置中心)、<code>Monitor</code>（监控中心）、<code>Metrics</code>(监控项)、<code>Service</code>(服务bean)</li><li>接着找到<code>org.apache.dubbo.config.ServiceConfig#doExportUrls;</code><ol><li>主要看 <code>org.apache.dubbo.config.ServiceConfig#doExportUrlsFor1Protocol</code></li><li>这个方法主要是构建Invoker代理，然后用<code>Exporter&lt;?&gt; exporter = protocol.export(wrapperInvoker);</code> 通过SPI加载默认<code>DubboProtocol</code>.</li><li>进入<code>org.apache.dubbo.rpc.DubboProtocol#export</code>之后我们看到一个<code>openServer</code>调用,初始化一个Server</li><li>进入<code>org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol#openServer</code>，主要调用<code>createServer</code></li><li>进入<code>org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol#createServer</code>,调用了一个静态方法<code>Exchangers#bind()</code></li><li>进入<code>org.apache.dubbo.remoting.exchange.Exchangers#bind</code>,入参是当前要暴露服务的URL和一个<code>requestHandler</code>, requestHandler实现在 <code>org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol#requestHandler</code>里</li><li>进入<code>Exchangers#bind</code>,调用了 <code>org.apache.dubbo.remoting.exchange.Exchangers#getExchanger(org.apache.dubbo.common.URL)</code>获取当前暴露服务URL的个性化<code>Exchanger</code>配置，默认加载<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchanger</code></li><li>进入<code>HeaderExchanger</code>,有两个方法实现分别为<code>bind</code>和 <code>connect</code>,看样子一个事用于Server端暴露服务，一个事用于Client来请求服务</li><li>主要看<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchanger#bind</code>,调用了<code>Transporters#bind()</code>，这里吧requestHandler进行包装成了一个<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeHandler#HeaderExchangeHandler</code></li><li>进入<code>org.apache.dubbo.remoting.Transporters#bind()</code>，看到默认加载的是nett4的<code>org.apache.dubbo.remoting.transport.netty4.NettyTransporter#bind()</code>,而这个实现主要是new了一个<code>org.apache.dubbo.remoting.transport.netty4.NettyServer#NettyServer</code>,到此一个Provider的Invoker代理就绑定到NettyServer里可以对外提供服务了</li><li>在<code>NettyServer</code>的构造方法中，调用了<code>org.apache.dubbo.remoting.transport.dispatcher.ChannelHandlers#wrap</code>,将HeaderExchangeHandler进行一个<code>Dispatcher</code>的分发，默认实现是<code>org.apache.dubbo.remoting.transport.dispatcher.all.AllDispatcher</code>,除此之外还有<code>ConnectionOrderedDispatcher</code>、<code>DirectDispatcher</code>、<code>ExecutionDispatcher</code>、<code>MessageOnlyDispatcher</code>，这里不做展开</li><li>在AllDispatcher中的dispatch实现是<code>AllChannelHandler</code>,所有类型的请求都可以接受处理</li><li>进入<code>org.apache.dubbo.remoting.transport.dispatcher.all.AllChannelHandler#received</code>,我们看到它将接收到的请求丢到一个<code>ExecutorService</code>线程池中异步处理，这里就是Dubbo线程处理的核心了</li><li>我们回到第6步，这里说到默认的handler是<code>org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol#requestHandler</code>, 这个requestHandler被6.3包装成了<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeHandler#HeaderExchangeHandler</code></li><li>进入<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeHandler#HeaderExchangeHandler</code>,这是NIO请求的处理handler,我们了解NIO的Channel是双向通信的，所以当接收到请求时和响应时都会进入到<code>received</code>,当出现异常时进入<code>caught</code><ol><li>我们先来看<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeHandler#received</code>,主要判断是请求还是响应，如果是请求判断是否是否有响应，如果是<code>towWay</code>通信，即有响应结果的请求，进入<code>org.apache.dubbo.remoting.exchange.support.header.HeaderExchangeHandler#handleRequest</code></li><li>在这里调用了一开始传入的requestHandler#reply,实在在<code>org.apache.dubbo.remoting.exchange.support.ExchangeHandlerAdapter</code>，这里就是具体调用找到具体要请求的Provider的Invoker，异步请求并返回一个Feature，然后在当前received方法中进行异步等待，等待响应结果完成send进channel进行响应</li></ol></li></ol></li><li>发布到注册中心</li></ol>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dubbo </tag>
            
            <tag> 学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP及HTTPS的理解</title>
      <link href="/xue-xi/http-ji-https-de-li-jie/"/>
      <url>/xue-xi/http-ji-https-de-li-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="http"><a class="markdownIt-Anchor" href="#http"></a> HTTP</h1><p>HTTP全称叫超文本传输协议(HyperText Transfer Protocol),是用于WWW(万网)服务器与浏览器客户端的一种通讯协议</p><h2 id="tcpip"><a class="markdownIt-Anchor" href="#tcpip"></a> TCP/IP</h2><p>关于计算机通讯，需要了解的一些背景知识，TCP/IP.<br>我们经常说TCP/IP，为什么要一起说，因为这两者有着密切的关系，其实它包含两个协议：</p><ul><li>TCP: TCP 负责将数据包在数据传送之前将它们分割为 IP 包，然后在它们到达的时候将它们重组</li><li>IP：负责将TCP分隔的IP包发送传输到指定ip的机器上，IP包之间的传输不保证顺序性，在TCP重组时才还原数据顺序</li></ul><p>所以说TCP/IP是传输协议的上下层关系。</p><h2 id="关于http"><a class="markdownIt-Anchor" href="#关于http"></a> 关于HTTP</h2><p>而HTTP则是在TCP/IP基础上的进一步封装的协议，属于应用层协议.网络传输的协议关系图如下：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184529465.png" alt></p><p>网络传输的协议，两边刚好是相反的:<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184529221.png" alt></p><h2 id="http原理"><a class="markdownIt-Anchor" href="#http原理"></a> HTTP原理</h2><p>HTTP请求主要分为以下几个步奏：</p><ol><li>域名解析，查找对应DNS服务器域名解析找到对应的IP</li><li>封装TCP/IP通讯数据包，建立连接（3三次握手协议），HTTP是比TCP更高层次的应用层协议，根据规则，只有低层协议建立之后才能，才能进行更层协议的连接</li><li>封装HTTP请求数据包，请求头信息，请求参数等。</li><li>等待服务器响应，服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号、一个成功或错误的代码</li><li>一般情况下，一旦Web服务器向浏览器发送了请求数据，它就要关闭TCP连接，然后如果浏览器或者服务器在其头信息加入了这行代码<br>Connection:keep-alive<br>TCP连接在发送后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求，这就是长连接的原理</li></ol><p>关于HTTP的超时时间，<code>connectTimeout</code>、<code>requestConnectTimeout</code>、<code>readTimeout</code>、<code>socketTimeout</code></p><ul><li><code>connectTimeout</code> 是指上面的第2步，建立TCP/IP连接的超时时间</li><li><code>requestConnectTimeout</code> 是指上面第3步，发送请求头发送http请求的超时时间</li><li><code>readTimeout</code> 是指从发送http请求开始等待响应内容的总超时时间,指上面步骤的第4步</li><li><code>socketTimeout</code> 响应内容有可能是分成几个socket数据包传输的，而这个socketTimeout的意思就是每个socket传输的超时时间</li></ul><p>例如下图：<br>readTimeout设为6s,socketTimeout设为4秒，发送http报文之后响应<br>时间超时为6s,响应内容abc分三次socket传输,每次间隔超时时间为4s，所以总共花费6s是不会抛出<code>socket timeout</code><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184529343.png" alt></p><h2 id="java中使用http"><a class="markdownIt-Anchor" href="#java中使用http"></a> JAVA中使用http</h2><p>Java 访问http通过</p><h1 id="https"><a class="markdownIt-Anchor" href="#https"></a> HTTPS</h1><p>HTTPS简单的说就是，http的安全版</p><h2 id="https基本原理"><a class="markdownIt-Anchor" href="#https基本原理"></a> HTTPS基本原理</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825184528912.png" alt></p><p>过程大致如下：</p><ol><li>SSL客户端通过TCP和服务器建立连接之后（443端口），并且在一般的tcp连接协商（握手）过程中请求证书。<br>即客户端发出一个消息给服务器，这个消息里面包含了自己可实现的算法列表和其它一些需要的消息，SSL的服务器端会回应一个数据包，这里面确定了这次通信所需要的算法，然后服务器向客户端返回证书。（证书里面包含了服务器信息：域名。申请证书的公司，公共秘钥）。</li><li>Client在收到服务器返回的证书后，判断签发这个证书的公共签发机构，并使用这个机构的公共秘钥确认签名是否有效，客户端还会确保证书中列出的域名就是它正在连接的域名。</li><li>如果确认证书有效，那么生成对称秘钥并使用服务器的公共秘钥进行加密。然后发送给服务器，服务器使用它的私钥对它进行解密，这样两台计算机可以开始进行对称加密进行通信。</li></ol><p>参考文章：<br>HTTPS介绍：<a href="https://imququ.com/post/how-to-decrypt-https.html" target="_blank" rel="noopener">https://imququ.com/post/how-to-decrypt-https.html</a><br><a href="http://blog.csdn.net/hguisu/article/details/8680808" target="_blank" rel="noopener">http://blog.csdn.net/hguisu/article/details/8680808</a></p>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习 </tag>
            
            <tag> HTTP </tag>
            
            <tag> HTTPS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于Unicode  UTF-8 、UTF-16字符集编码的理解</title>
      <link href="/xue-xi/guan-yu-unicode-utf-8-utf-16-zi-fu-ji-bian-ma-de-li-jie/"/>
      <url>/xue-xi/guan-yu-unicode-utf-8-utf-16-zi-fu-ji-bian-ma-de-li-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="最近学习nio文件读写的时候就生成了一个疑问程序怎么知道文件使用了什么编码因为底层程序看到的都是二进制的字节码如"><a class="markdownIt-Anchor" href="#最近学习nio文件读写的时候就生成了一个疑问程序怎么知道文件使用了什么编码因为底层程序看到的都是二进制的字节码如"></a> 最近学习NIO文件读写的时候，就生成了一个疑问，程序怎么知道文件使用了什么编码，因为底层程序看到的都是二进制的字节码如：</h1><pre class="highlight"><code class>中文 | utf-8二进制编码人   | 11100100 10111010 10111010 </code></pre><p>程序怎么知道通过这是一个通过3个字节编码的<code>人</code>字呢，于是查询了相关资料：</p><p>要解释这个问题，我们先来了解下ASCII码、GB2312、GBK、Unicode编码的关系和定义</p><h1 id="1-asscii码见ascii码对照表"><a class="markdownIt-Anchor" href="#1-asscii码见ascii码对照表"></a> 1. ASSCII码,见<a href="http://tool.oschina.net/commons?type=4" target="_blank" rel="noopener">ASCII码对照表</a></h1><p>是一种使用一个字节(8位二进制)表示字母、数字和字符的一种编码，如字母<code>A</code>表示为使用十进制值为<code>65</code>的表示，转换为二进制就是<code>1000001</code>,我们知道，在计算机内部，所有的信息最终都表示为一个二进制的字符串。每一个二进制位（bit）有0和1两种状态，因此八个二进制位就可以组合出256种状态，这被称为一个字节（byte）。也就是说，一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从0000000到11111111。<br>上个世纪60年代，美国制定了一套字符编码，对英语字符与二进制位之间的关系，做了统一规定。这被称为ASCII码，一直沿用至今。<br>ASCII码一共规定了128个字符的编码，比如空格&quot;SPACE&quot;是32（二进制00100000），大写的字母A是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的1位统一规定为0。</p><h1 id="2-gb2312-全称是gb2312-80信息交换用汉字编码字符集-基本集是中国标准化组织发布的见gb2312编码规则"><a class="markdownIt-Anchor" href="#2-gb2312-全称是gb2312-80信息交换用汉字编码字符集-基本集是中国标准化组织发布的见gb2312编码规则"></a> 2. <code>GB2312</code> ，全称是GB2312-80《信息交换用汉字编码字符集 基本集》，是中国标准化组织发布的，见<a href="http://www.qqxiuzi.cn/zh/hanzi-gb2312-bianma.php" target="_blank" rel="noopener">GB2312编码规则</a></h1><p>在计算机只有英文的时代，可能使用<code>ASCII</code>码就已经够了，但是随着计算机的普及和全球化，别国的语言肯定也是要计算机编码化的，所以就出现了<code>GB2312</code>编码规则。<code>GB2312</code>是使用固定两个字节来表示简体中文和英文、数字、中文符号、英文符号的一种编码规则。所以如果使用<code>GB2312</code>编码时，英文也是使用两个字节来编码的，这无疑是一种浪费</p><p>而<code>GBK</code>则是在<code>GB23312</code>的基础上添加了繁体中文的扩展</p><h1 id="3-unicode"><a class="markdownIt-Anchor" href="#3-unicode"></a> 3. <code>Unicode</code></h1><p>正如上一节所说，世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。因此，要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。为什么电子邮件常常出现乱码？就是因为发信人和收信人使用的编码方式不一样。<br>可以想象，如果有一种编码，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是Unicode，就像它的名字都表示的，这是一种所有符号的编码。</p><p>再次强调一下,Unicode只是为全世界的每一个文字符号都定义了一个数值对照</p><h1 id="4-utf-8"><a class="markdownIt-Anchor" href="#4-utf-8"></a> 4. <code>UTF-8</code></h1><p>为什么会有<code>UTF-8</code>编码，我们来看下<code>Unicode</code>编码的定义和存在的问题：</p><p>需要注意的是，Unicode只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。<br>比如，汉字&quot;严&quot;的unicode是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。<br>那么第一个问题：怎么样使用二进制的表示来存储我们的编码呢，是和GBK一样使用固定的字节来存？如果这样的话就必须以最长的字节表示为单位，那么应为字母、数字都得使用3个字节或者4个字节来存储，这显然是不能够接受的，这对存储空间是极大的浪费。<br>根据第一个问题，我们是否能够使用变长的存储方式来存unicode编码呢，如果可以，怎么在读取的时候区分一个字符是使用一个字节表示（比如字母、数字），还是使用3个字节表示的中文呢？</p><p>所以最初期，由于存在Unicode存在这些问题的存在<br>它们造成的结果是：1）出现了Unicode的多种存储方式，也就是说有许多种不同的二进制格式，可以用来表示Unicode。<br>2）Unicode在很长一段时间内无法推广，直到互联网的出现。</p><p>我们来看下<code>UTF-8</code>是怎么实现unicode编码的。<br>UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。<br>UTF-8的编码规则很简单，只有二条：<br>1）对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。<br>2）对于n字节的符号（n&gt;1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。</p><pre class="highlight"><code class>Unicode符号范围 | UTF-8编码方式(十六进制) | （二进制）--------------------+---------------------------------------------0000 0000 ~ 0000 007F | 0xxxxxxx0000 0080 ~ 0000 07FF | 110xxxxx 10xxxxxx0000 0800 ~ 0000 FFFF | 1110xxxx 10xxxxxx 10xxxxxx0001 0000 ~ 0010 FFFF | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx</code></pre><p>跟据上表，解读UTF-8编码非常简单。如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。<br>下面，还是以汉字&quot;严&quot;为例，演示如何实现UTF-8编码。<br>已知&quot;漲&quot;的unicode是<code>\u6f32</code>,6f32二进制为<code>110111100110010</code>，根据上表，可以发现4E25处在第三行的范围内（0000 0800 ~ 0000 FFFF），因此&quot;漲&quot;的UTF-8编码需要三个字节，即格式是<code>1110xxxx 10xxxxxx 10xxxxxx</code>。然后，从<code>漲</code>的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，&quot;漲&quot;的UTF-8编码是1110<code>0110</code> 101<code>11100</code> 10<code>110010</code>，转换成十六进制就是<code>e6bcb2</code>。<br>所以理论上讲UTF-8 可以表示2^31个字符，所以还有很多符号表情可以开发编入unicode中。</p><p><em>其他实现方式还包括UTF-16（字符用两个字节或四个字节表示）和UTF-32（字符用四个字节表示），不过在互联网上基本不用。重复一遍，这里的关系是，UTF-8是Unicode的实现方式之一。</em></p><p>#5. 使用java打印出所有中文代码</p><pre class="highlight"><code class>   下标         中文    unicode          unicode十进制值           unicode二进制      utf-8编码二进制            utf-8十六进制      长度字节数    0          葦     \u6f32                28466                110111100110010    11101000 10010001 10100110           e891a6          3    1          葧     \u6f33                28467                110111100110011    11101000 10010001 10100111           e891a7          3    2          葨     \u6f34                28468                110111100110100    11101000 10010001 10101000           e891a8          3    3          葩     \u6f35                28469                110111100110101    11101000 10010001 10101001           e891a9          3    4          葰     \u6f36                28470                110111100110110    11101000 10010001 10110000           e891b0          3    5          葱     \u6f37                28471                110111100110111    11101000 10010001 10110001           e891b1          3    6          葲     \u6f38                28472                110111100111000    11101000 10010001 10110010           e891b2          3    7          葳     \u6f39                28473                110111100111001    11101000 10010001 10110011           e891b3          3    8          葴     \u6f3a                28474                110111100111010    11101000 10010001 10110100           e891b4          3    9          葵     \u6f3b                28475                110111100111011    11101000 10010001 10110101           e891b5          3</code></pre><p>java代码如下：</p><pre class="highlight"><code class>  @Test    public void writeAllChinese() {        int start = 0x6f32;        int index = 0;        System.out.printf(&quot;%5s %10s %10s %20s %20s %15s %20s %10s\n&quot;,&quot;下标&quot;,&quot;中文&quot; ,&quot;unicode&quot; ,&quot;unicode十进制值&quot; ,&quot;unicode二进制&quot; , &quot;utf-8编码二进制&quot;, &quot;utf-8十六进制&quot; ,&quot;长度字节数&quot;);        while (start &lt; 0x6f32 + 10) {            String unicode = &quot;\\u&quot; + Integer.toHexString(start);            char c = (char) Integer.parseInt((start+&quot;&quot;),16);            String chinese = String.valueOf(c);            byte[] bytes = chinese.getBytes();            System.out.printf(&quot;%5s %10s %10s %20s %30s %30s %15s %10s\n&quot;,index,chinese ,unicode ,start ,Integer.toBinaryString(start) , getBinaryString(bytes), Integer.toHexString(Integer.valueOf(getBinaryString(bytes).replace(&quot; &quot;,&quot;&quot;),2)) ,bytes.length);            start++;            index++;        }    }    public static String getBinaryString(byte bytes[]) {        String s = &quot;&quot;;        for(byte b : bytes) {            /**             * 由于java 虚拟机为了方便整数的加减，使用了补码(反码+1)来表示,方便数值的符号直接参与二进制的加减，这样省去了很多计算步骤             * 所以在java中使用String#getBytes()返回的字节数值是反码的表示方法；             * 又由于Int 在java中表示是4个字节32位的，在控制台进行输出的时候，jvm把11001111之前进行了补补全然后再取补码，等到的就是11111111111111111111111110111110             * 所以需要在使用 与 运算将取 反码  0xff = 11111111             */            s = s + Integer.toBinaryString(b &amp; 0xff) +  &quot; &quot;;            //s = s + Integer.toBinaryString(b) +  &quot; &quot;;        }        return s;    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习 </tag>
            
            <tag> Unicode </tag>
            
            <tag> 字符集 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>动态壁纸接口</title>
      <link href="/2019-11-28-dong-tai-bi-zhi-jie-kou/"/>
      <url>/2019-11-28-dong-tai-bi-zhi-jie-kou/</url>
      
        <content type="html"><![CDATA[<h1 id="新浪动态壁纸接口"><a class="markdownIt-Anchor" href="#新浪动态壁纸接口"></a> 新浪动态壁纸接口</h1><p>说明：<a href="https://www.nulltm.com/tag/%E9%9A%8F%E6%9C%BA" target="_blank" rel="noopener">随机</a>图片<a href="https://www.nulltm.com/tag/%E5%A3%81%E7%BA%B8" target="_blank" rel="noopener">壁纸</a><a href="https://www.nulltm.com/tag/api" target="_blank" rel="noopener">api</a>，调用的是<a href="https://www.nulltm.com/tag/%E6%96%B0%E6%B5%AA" target="_blank" rel="noopener">新浪</a>api，速度不用担心，图片资源也很多</p><p>电脑动漫图片：<a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/?lx=dongman" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/?lx=dongman</a></p><p>电脑美女图片：<a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/?lx=meizi" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/?lx=meizi</a></p><p>电脑随机动漫妹子：<a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/?lx=suiji" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/?lx=suiji</a></p><p>手机动漫图片：<a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/?lx=m_dongman" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/?lx=m_dongman</a></p><p>手机美女图片：<a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/?lx=m_meizi" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/?lx=m_meizi</a></p><p>手机随机动漫妹子：<a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/?m_lx=suiji" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/?m_lx=suiji</a></p><p>手机电脑自动判断，电脑显示适合电脑的壁纸，手机显示适合手机的壁纸 <a href="https://www.nulltm.com/go/?url=http://api.btstu.cn/sjbz/zsy.php" target="_blank" rel="noopener">http://api.btstu.cn/sjbz/zsy.php</a></p><p>api现在已经有几千张图了，每天都在增加，大家可以玩玩</p><h1 id="必应动态壁纸接口"><a class="markdownIt-Anchor" href="#必应动态壁纸接口"></a> 必应动态壁纸接口</h1><p>必应在国内的名气不是很大，很多人不知道。必应是美国微软的搜索引擎，类似与百度。不过，有个地方很有趣，必应的首页背景图，每日一换，从不重复。都是团队精选的世界各地的风景、人文类的美图，配有相关文字描述。还是挺有意思的，不过好像只能保存近10多日的数据，超期就无法访问了。</p><p>首先，第一个接口：<a href="http://cn.bing.com/HPImageArchive.aspx?format=js&amp;idx=0&amp;n=1" target="_blank" rel="noopener">http://cn.bing.com/HPImageArchive.aspx?format=js&amp;idx=0&amp;n=1</a></p><p>可以获得当日的必应壁纸无水印高清图片的路径以及版权等信息。具体返回格式如下：</p><pre class="highlight"><code class="json"><span class="hljs-punctuation">{</span>    <span class="hljs-attr">&quot;images&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">{</span>        <span class="hljs-attr">&quot;startdate&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;20181118&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;fullstartdate&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;201811181600&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;enddate&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;20181119&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;url&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/az/hprichbg/rb/NarrowsZion_ZH-CN9686302838_1920x1080.jpg&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;urlbase&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/az/hprichbg/rb/NarrowsZion_ZH-CN9686302838&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;copyright&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;锡安国家公园内的维尔京河，美国犹他州 (© Justinreznick/Getty Images)&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;copyrightlink&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;http://www.bing.com/search?q=%E9%94%A1%E5%AE%89%E5%9B%BD%E5%AE%B6%E5%85%AC%E5%9B%AD&amp;form=hpcapt&amp;mkt=zh-cn&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;quiz&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/search?q=Bing+homepage+quiz&amp;filters=WQOskey:%22HPQuiz_20181118_NarrowsZion%22&amp;FORM=HPQUIZ&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;wp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;hsh&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;a2d2b96a5c113e78bc7a0f8a508cbf73&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;drk&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;top&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;bot&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;hs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span>    <span class="hljs-punctuation">}</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;tooltips&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>        <span class="hljs-attr">&quot;loading&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;正在加载...&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;previous&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;上一个图像&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;next&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;下一个图像&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;walle&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;此图片不能下载用作壁纸。&quot;</span><span class="hljs-punctuation">,</span>        <span class="hljs-attr">&quot;walls&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;下载今日美图。仅限用作桌面壁纸。&quot;</span>    <span class="hljs-punctuation">}</span><span class="hljs-punctuation">}</span></code></pre><p>在url的路径上，拼上域名即可拿到图片：</p><p><a href="https://cn.bing.com/az/hprichbg/rb/NarrowsZion_ZH-CN9686302838_1920x1080.jpg%EF%BC%88%E5%A6%82%E6%9E%9C%E8%BF%99%E4%B8%AA%E6%89%93%E4%B8%8D%E5%BC%80%EF%BC%8C%E8%AF%B7%E8%AE%A4%E7%9C%9F%E9%87%8D%E8%AF%BB%E7%AC%AC%E4%B8%80%E6%AE%B5%E6%9C%80%E5%90%8E%E5%87%A0%E5%8F%A5%E3%80%82%EF%BC%89" target="_blank" rel="noopener">https://cn.bing.com/az/hprichbg/rb/NarrowsZion_ZH-CN9686302838_1920x1080.jpg（如果这个打不开，请认真重读第一段最后几句。）</a></p><p>值得注意的是，接口里的idx=后面的数字为0是今日的壁纸数据，1 2  3  4  5…依次是昨日、前日…   数字是-1是明日的数据。</p><pre class="highlight"><code class="json"><span class="hljs-punctuation">{</span>    <span class="hljs-attr">&quot;date&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;November 19&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;title&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;峡谷秘境&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;attribute&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;美国，锡安国家公园&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;para1&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;今天是美国犹他州锡安国家公园成立99周年的日子，一直以来，它是美国访问量最大的国家公园之一。这里到处都是令人惊叹的西南风景，包括锡安峡谷。壁纸中的地方叫做纳罗斯水道，它是一条穿过峡谷十分狭窄的小径，有的地方甚至只能勉强过一个人，而且有时需要淌着水行走。虽然这个时候水有点冷，但是这里的景色，一个转弯一个惊喜。&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;para2&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;provider&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;© Justinreznick/Getty Images&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;imageUrl&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;http://hpimges.blob.core.chinacloudapi.cn/coverstory/watermark_narrowszion_zh-cn9686302838_1920x1080.jpg&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;primaryImageUrl&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;http://hpimges.blob.core.chinacloudapi.cn/coverstory/watermark_narrowszion_zh-cn9686302838_1920x1080.jpg&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;Country&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;美国&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;City&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;锡安国家公园&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;Longitude&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;-112.946625&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;Latitude&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;37.306900&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;Continent&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;北美洲&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;CityInEnglish&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Zion National Park&quot;</span><span class="hljs-punctuation">,</span>    <span class="hljs-attr">&quot;CountryCode&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;US&quot;</span><span class="hljs-punctuation">}</span></code></pre><p>如果在后面加?d=20181111则是提取2018年11月11日的壁纸故事。这个时间可以从20140501-至今.</p><p><a href="https://cn.bing.com/cnhp/coverstory?d=20181118" target="_blank" rel="noopener">https://cn.bing.com/cnhp/coverstory?d=20181118</a></p><p>有了这些，你就可以搭建一个壁纸站了，每日抓取官方壁纸数据展示，个人觉得，把这些保存下来还是挺有意义的。我前几日借用这两个接口写了一个简单的壁纸站，如果你实在懒得去弄的话，可以随时访问下载哦！最后留个链接，点击这里吧！必应壁纸</p><p>附：</p><p>如果你的网站想要每天更换壁纸壁纸，又不想写接口。下面这几个我写的接口就适合你了！</p><p><a href="https://api.neweb.top/bing.php" target="_blank" rel="noopener">https://api.neweb.top/bing.php</a>   -----必应当日壁纸</p><p><a href="https://api.neweb.top/bing.php?type=future" target="_blank" rel="noopener">https://api.neweb.top/bing.php?type=future</a>   ------必应明日壁纸</p><p><a href="https://api.neweb.top/bing.php?type=rand" target="_blank" rel="noopener">https://api.neweb.top/bing.php?type=rand</a>   -----近7日随机壁纸</p><p>图片demo：（分别是明天、今天、随机的必应壁纸）</p><p>使用方法：</p><pre class="highlight"><code class="html"><span class="hljs-tag">&lt;<span class="hljs-name">img</span> <span class="hljs-attr">src</span>=<span class="hljs-string">&quot;https://api.neweb.top/bing.php&quot;</span> <span class="hljs-attr">alt</span>=<span class="hljs-string">&quot;必应壁纸&quot;</span>&gt;</span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 分享 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分享 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从零开始使用Solidity编写以太坊智能合约并使用Nodejs SDK访问以太坊网络</title>
      <link href="/qu-kuai-lian/cong-ling-kai-shi-shi-yong-solidity-bian-xie-yi-tai-fang-zhi-neng-he-yue-bing-shi-yong-nodejs-sdk-fang-wen-yi-tai-fang-wang-luo/"/>
      <url>/qu-kuai-lian/cong-ling-kai-shi-shi-yong-solidity-bian-xie-yi-tai-fang-zhi-neng-he-yue-bing-shi-yong-nodejs-sdk-fang-wen-yi-tai-fang-wang-luo/</url>
      
        <content type="html"><![CDATA[<h1 id="nodejs安装"><a class="markdownIt-Anchor" href="#nodejs安装"></a> Nodejs安装</h1><p>Nodejs 版本建议8.0以上<br>官网：<a href="https://nodejs.org/en/" target="_blank" rel="noopener">https://nodejs.org/en/</a><br>官网下载安装包:<a href="https://nodejs.org/dist/v8.12.0/node-v8.12.0-x64.msi" target="_blank" rel="noopener">https://nodejs.org/dist/v8.12.0/node-v8.12.0-x64.msi</a><br>安装参考：<a href="https://blog.csdn.net/qq_26562641/article/details/72235585" target="_blank" rel="noopener">https://blog.csdn.net/qq_26562641/article/details/72235585</a></p><p>配置淘宝镜像：</p><pre class="highlight"><code class>npm config set registry https://registry.npm.taobao.org</code></pre><h1 id="新建一个hello-world只能合约的访问"><a class="markdownIt-Anchor" href="#新建一个hello-world只能合约的访问"></a> 新建一个Hello World只能合约的访问</h1><ol><li><p>使用IDEA安装nodejs插件，在插件列表搜索</p></li><li><p>新建一个node工程项目，File&gt;New Project 选择Node.js and NPM<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825155544126.png" alt><br>默认有很多其他的目录，我们删除其他目录，只保留如下的目录：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825155543961.png" alt><br>或者使用<code>npm init</code>命令初始化一个nodejs工程</p></li><li><p>安装solidity编译器依赖，用于编译Solidity，才能被nodejs使用到</p><pre class="highlight"><code class>npm install --save solc</code></pre></li><li><p>安装以太坊的访问SDK web3.js</p><pre class="highlight"><code class>npm install --save web3</code></pre><p>报错解决：</p><blockquote><ol><li>报<code>gyp ERR! configure error gyp ERR! stack Error: Command failed: C:\Users\yan6\AppData\Local\Programs\Pytho n\Python37-32\python.EXE -c import sys; print &quot;%s.%s.%s&quot; % sys.version_info[:3];</code><br>原因：安装脚本中用到了Python2的语法，你的环境变量中配置的Python3所以报这个错<br>解决：修改python的环境变量，将Python3改成Python2，如果没有到官网下载一个Python2</li><li>报<code> error MSB3428: 未能加载 Visual C++ 组件“VCBuild.exe”。要解决此问题，1)</code></li></ol><pre class="highlight"><code class>MSBUILD : error MSB3428: 未能加载 Visual C++ 组件“VCBuild.exe”。要解决此问题，1) 安装 .NET Framework 2.0 SDK；2) 安装 Microsoft VisualStudio 2005；或 3) 如果将该组件安装到了其他位置，请将其位置添加到系统路径中。 [D:\workspace\idea_workspace\blockchian1\node_modules\scrypt\build\binding.sln]MSBUILD : error MSB3428: 未能加载 Visual C++ 组件“VCBuild.exe”。要解决此问题，1) 安装 .NET Framework 2.0 SDK；2) 安装 Microsoft VisualStudio 2005；或 3) 如果将该组件安装到了其他位置，请将其位置添加到系统路径中。 [D:\workspace\idea_workspace\blockchian1\node_modules\scrypt\build\binding.sln]</code></pre><p>解决办法,按装全局windows相关组件：</p><pre class="highlight"><code class>npm install --global --production windows-build-tools </code></pre></blockquote></li><li><p>安装ganache,ganache是用来在本地测试用的测试以太坊网络</p><pre class="highlight"><code class>npm install -g ganache-cli</code></pre></li><li><p>新建一个Solidity脚本，<code>Hello.sol</code></p><pre class="highlight"><code class>pragma solidity ^0.4.17;contract Hello {    string public name;    function Hello(string _name) public {        name = _name;    }    function setName(string _name) public {        name = _name;    }    function getName() public view returns(string ) {        return name;    }}</code></pre></li><li><p>编写一个solidity的编译脚本compile.js</p><pre class="highlight"><code class>const path = require('path');const  fs = require('fs');const solc = require('solc');const srcpath = path.resolve(__dirname,'contracts', 'Hello.sol');const source = fs.readFileSync(srcpath, 'utf-8');//console.log(source);const result = solc.compile(source,1);//console.log(result);module.exports = result.contracts[':Hello'];</code></pre></li><li><p>在tests下新建一个本地Hello World测试类,<code>Web3Test.test.js</code></p><pre class="highlight"><code class>const  assert = require('assert');//约定规范，如果变量是大写const Web3 = require('web3');//内存里面的以太坊测试环境const  ganache = require('ganache-cli');const web3 = new Web3(ganache.provider());//执行编译脚本，并将编译结果引入进来const {interface,bytecode} = require('../compile');/** * 测试一个Hello World智能合约 * @returns {Promise.&lt;void&gt;} */testGetSet = async ()=&gt; {    let accounts = await web3.eth.getAccounts();    //部署也是一个交易命令，所以需要花gas    const abi = JSON.parse(interface);    const contract = new web3.eth.Contract(abi);    const result = await contract.deploy({        data:bytecode,        arguments:['Hello World']    }).send({        from:accounts[0],        gas: 1500000,        gasPrice: '30000'    });    console.log('deploy success:' + result.options.address);    //测试查询    assert.equal(await result.methods.getName().call(),'Hello World');    await result.methods.setName('hahaha').send({        from:accounts[0],        gas:100000    });    assert.equal(await result.methods.getName().call(),'hahaha');    console.log('测试智能合约成功');}/** * 测试以太坊转账 * @returns {Promise.&lt;void&gt;} */testTrade = async ()=&gt; {    let accounts = await web3.eth.getAccounts();    let b0 = await web3.eth.getBalance(accounts[0]);    let b1 = await web3.eth.getBalance(accounts[1]);    //发送交易    console.log('开始转账：account0:' + b0 + ' account1:' + b1);    await web3.eth.sendTransaction({        from:accounts[0],        to:accounts[1],        value:'1000000000000000'    });    b0 = await web3.eth.getBalance(accounts[0]);    b1 = await web3.eth.getBalance(accounts[1]);    //发送交易    console.log('转账成功：account0:' + b0 + ' account1:' + b1);}testGetSet();testTrade();</code></pre></li></ol><blockquote><p>以上代码<code> const {interface,bytecode} = require('../compile');</code><br>这句话的意思是将Hello.sol编译后的导入到当前的node上下文，interface就是编译后的一些方法定义，bytecode就是最终部署到以太坊网络的二进制数据</p></blockquote><ol start="9"><li>测试运行<pre class="highlight"><code class>node `Web3Test.test.js</code></pre>运行结果：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825155544126-1414144.png" alt></li></ol><h1 id="将代码提交到以太坊rankeby测试网络"><a class="markdownIt-Anchor" href="#将代码提交到以太坊rankeby测试网络"></a> 将代码提交到以太坊rankeby测试网络</h1><ol><li><p>安装truffle-hdwallet-provider<br>组件官方文档：<a href="https://www.npmjs.com/package/truffle-hdwallet-provider" target="_blank" rel="noopener">https://www.npmjs.com/package/truffle-hdwallet-provider</a></p><pre class="highlight"><code class> npm install truffle-hdwallet-provider</code></pre></li><li><p>使用truffle-hdwallet-provider：</p><pre class="highlight"><code class>//线上的测试环境var HDWalletProvider = require(&quot;truffle-hdwallet-provider&quot;);var mnemonic = &quot;这里是你的以太坊钱包私钥助记词&quot;; // 12 word mnemonic//使用infura在线的providervar provider = new HDWalletProvider(mnemonic, &quot;https://rinkeby.infura.io/v3/02b9371103e54ed6bb4ccb91651497f5&quot;);const web3 = new Web3(provider);</code></pre><blockquote><p>上面用到的provider_url：<a href="https://rinkeby.infura.io/v3/02b9371103e54ed6bb4ccb91651497f5%E6%98%AFinfura%E7%9A%84%E5%9C%A8%E7%BA%BFurl,%E5%88%B0https://rinkeby.infura.io%E6%B3%A8%E5%86%8C%E4%B8%80%E4%B8%AA%E8%B4%A6%E5%8F%B7%E5%B9%B6%E6%B7%BB%E5%8A%A0%E4%B8%80%E4%B8%AArinkeby%E7%9A%84%E6%B5%8B%E8%AF%95PROJECT%E5%B0%B1%E5%8F%AF%E4%BB%A5%E5%BE%97%E5%88%B0%E4%B8%80%E4%B8%AA%E6%B5%8B%E8%AF%95provider_url%E4%BA%86%EF%BC%8C%E7%BD%91%E7%BB%9C%E4%B8%8D%E5%A5%BD%E5%8F%AF%E8%83%BD%E9%9C%80%E8%A6%81%E7%BF%BB%E5%A2%99" target="_blank" rel="noopener">https://rinkeby.infura.io/v3/02b9371103e54ed6bb4ccb91651497f5是infura的在线url,到https://rinkeby.infura.io注册一个账号并添加一个rinkeby的测试PROJECT就可以得到一个测试provider_url了，网络不好可能需要翻墙</a></p></blockquote></li><li><p>新增一个测试代码进行测试交易,<code>EtherOnlieRinkebyTest.test.js</code></p><pre class="highlight"><code class>//约定规范，如果变量是大写const Web3 = require('web3');//线上的测试环境var HDWalletProvider = require(&quot;truffle-hdwallet-provider&quot;);var mnemonic = &quot;这里是你的以太坊钱包私钥助记词&quot;; // 12 word mnemonic//使用infura在线的providervar provider = new HDWalletProvider(mnemonic, &quot;https://rinkeby.infura.io/v3/02b9371103e54ed6bb4ccb91651497f5&quot;);const web3 = new Web3(provider);/** * 测试web3 */testSend = async ()=&gt; {        let accounts = await web3.eth.getAccounts();        console.log(accounts);        let account0 = accounts[0];        let account1 = '0x5828eb46D40795Da76429553845DfA622F062CB2';        let b0 = await web3.eth.getBalance(account0);        let b1 = await web3.eth.getBalance(account1);        console.log('开始转账：address0:' + account0 + ' :' + b0 + ' address1:'+account1 + ' account1:' + b1);        const tx = web3.eth.sendTransaction({            from:account0,            to:account1,            value: web3.utils.toWei('1', 'ether'),            data: web3.utils.toHex('I love you ,xiao man ju')        },async (err,address)=&gt;  {            console.log(&quot;转账成功,address:&quot; + address);            b0 = await web3.eth.getBalance(account0);            b1 = await web3.eth.getBalance(account1);            let tx = await web3.eth.getTransaction(address);            console.log('tx:'+ JSON.stringify(tx) +' 转账成功：address0:'+account0+':' + b0 + ' address1:'+account1+' account1:' + b1);        });       }testSend();</code></pre></li><li><p>使用nodejs运行测试代码</p><pre class="highlight"><code class>node EtherOnlieRinkebyTest.test.js</code></pre><p>输出结果如下：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220825155544225.png" alt></p></li></ol><p>到此从开发到上传到访问以太坊rinkeby测试网络已经完成。</p><h1 id="nodejs测试框架"><a class="markdownIt-Anchor" href="#nodejs测试框架"></a> Nodejs测试框架</h1><p>上面我们测试一个node脚本是直接使用node命令直接运行，对于实际开发应用中如果想做到自动化测试用例的运行，需要用到类型java里面Junit测试框架的东西，这个东西在node里面叫Mocha</p><ol><li><p>安装mocha</p><pre class="highlight"><code class>npm install --save mocha</code></pre></li><li><p>修改<code>package.json</code>，将scripts.test改成<code>mocha</code></p><pre class="highlight"><code class>{  &quot;name&quot;: &quot;blockchian1&quot;,  &quot;version&quot;: &quot;1.0.0&quot;,  &quot;description&quot;: &quot;&quot;,  &quot;main&quot;: &quot;app.js&quot;,  &quot;directories&quot;: {    &quot;test&quot;: &quot;test&quot;  },  &quot;dependencies&quot;: {    &quot;mocha&quot;: &quot;^5.2.0&quot;,    &quot;solc&quot;: &quot;^0.4.25&quot;  },  &quot;devDependencies&quot;: {},  &quot;scripts&quot;: {    &quot;test&quot;: &quot;mocha&quot;  },  &quot;author&quot;: &quot;&quot;,  &quot;license&quot;: &quot;ISC&quot;}</code></pre><blockquote><p>配置了scripts.test 为mocha命令，<code>npm run test</code>访问的就是mocha的测框架</p></blockquote></li><li><p>mocha测试，<code>MochaTest.test.js</code>, describe就是基本的mocha测试骨架，it是测试用例</p><pre class="highlight"><code class>const assert = require('assert');/** * ecs6 mocha测试 */class Test {    say() {        return 'hello';    }    happy() {        return 'haha';    }}//开始写mocha测试框架let dog;beforeEach(()=&gt;{    dog = new Test();})describe('第一个mocha测试用例',()=&gt; {    it('测试hello()',()=&gt;{        //const  dog = new Test();        let say = dog.say();        console.log(say);        assert.equal(say,'hello');    })    it('测试happy()',()=&gt;{        let happy = dog.happy();        console.log(happy);        assert.equal(happy,'haha');    })})</code></pre></li></ol><blockquote><p>以上用到了assert组件，这个类似java里面的Assert断言，默认在node上下文已将安装，直接依赖使用即可</p></blockquote><ol start="4"><li>运行测试用例<pre class="highlight"><code class>npm run test</code></pre>这个test访问的就是我们之前修改的<code>package.json</code>里面的test命令mocha，类似maven构建时的测试，它将运行项目上下文中的所有实现了mocha的测试用例</li></ol>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>区块链技术之比特币运作原理</title>
      <link href="/qu-kuai-lian/qu-kuai-lian-ji-zhu-zhi-bi-te-bi-yun-zuo-yuan-li/"/>
      <url>/qu-kuai-lian/qu-kuai-lian-ji-zhu-zhi-bi-te-bi-yun-zuo-yuan-li/</url>
      
        <content type="html"><![CDATA[<h1 id="什么是比特币"><a class="markdownIt-Anchor" href="#什么是比特币"></a> 什么是比特币</h1><p>点对点的传输的一个去中心化的电子现金系统。每个节点都共同维护一个区块链形式存储的交易记录，每个比特币节点遵守同一个比特币网络协议，并基于密码学原理加密每一笔交易记录和区块，实现每一笔交易不可逆、防篡改、去中心化的、数据可监管溯源的电子现金交易系统。</p><h2 id="比特币特点"><a class="markdownIt-Anchor" href="#比特币特点"></a> 比特币特点</h2><ul><li>比特币最初由中本聪2008年发明</li><li>比特币发行和交易不依赖中央机构</li><li>比特币的发行总量不会超过2100万个</li><li>只要能够联网，安装比特币客户端，任何人都能接入到这个比特币网络</li><li>比特币的账户地址是匿名的</li><li>任何国家或者机构无法监管或者操纵这个比特币网络</li><li>比特币是基于现代密码学实现的点对点交易的分布式超级账本</li></ul><h1 id="比特币行情"><a class="markdownIt-Anchor" href="#比特币行情"></a> 比特币行情</h1><p>比特币从诞生以来已经翻了好几万倍了，比特币的第一笔交易是一个程序员用50btc买了披萨，第一批持有比特币的人估计早已经是千万富翁，但是神奇的比特币之父中本聪的创始区块及它的账户的其他比特币都还没有发生转账交易。<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508680.png" alt></p><h1 id="区中心化的比特币网络"><a class="markdownIt-Anchor" href="#区中心化的比特币网络"></a> 区中心化的比特币网络</h1><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage.png" alt></p><p>这个比特币网络大致是这个样子的，节点分为以下几类：</p><ul><li>全数据节点：保存了完整的区块链所有交易信息</li><li>矿工节点：负责打包新的交易数据制作新的区块</li><li>轻客户端节钱包节点：只保留自己关心交易数据</li></ul><h1 id="什么是区块链"><a class="markdownIt-Anchor" href="#什么是区块链"></a> 什么是区块链</h1><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508350.png" alt><br>区块链有以下几个特点：</p><ul><li>区块链本质是一个分布式的超级账本，整个比特币网络各个节点仅仅认可和维护记录一样且长度最长的区块链</li><li>每个区块由区块头（上一个区块的hash值，当前区块的高度，出块的时间等）+ 交易记录列表 组成</li><li>所有经过验证符合比特币协议的交易记录都会被“矿工”打包进新的区块，然后广播给所有其它节点。</li></ul><p>每一个新的区块的都有一个指向上一个区块的hash值，所以这条链被形象的称之为<strong>区块链</strong></p><h1 id="什么是挖矿"><a class="markdownIt-Anchor" href="#什么是挖矿"></a> 什么是挖矿</h1><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508575.png" alt><br>上图是传统的煤矿挖矿的矿工，比特币的“挖矿”当然不是这个挖矿。<br>比特币的挖矿是指：将接收到全网的交易记录打包制作到一个新区块并广播至其它节点的过程，由于这个过程通常不是那么容易，需要不停的hash计算符合标准的随机数才能生效新区块，平均全网每10分钟才能有计算出这样的随机数，所以形象的形容为比特币的“挖矿”</p><h2 id="挖矿的原理"><a class="markdownIt-Anchor" href="#挖矿的原理"></a> 挖矿的原理</h2><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508972.png" alt><br>挖矿的过程如下：</p><ol><li>每个矿工节点都共同监听最新的交易数据，并做合法性校验，将符合校验的交易打包进新的区块中</li><li>在新的区块中添加给矿工账户转账的一笔交易，给矿工自己加上相应的比特币奖励和交易记录收取的手续费</li><li>最后一步用新区块的所有内容+一个随机数做SHA-256计算出hash值，使得这个hash值的二进制数符合一定规则，才能向全网广播这个新的区块</li></ol><p>那么接下来我们思考下以下三个问题：</p><ol><li>整个网络那么多矿工谁都有打包制作的权利，怎么解决并发问题？</li><li>这种“苦力活”如果没人做怎么办？</li><li>如果这个矿工“不老实”怎么办？</li></ol><h3 id="1-整个网络那么多矿工谁都有打包制作的权利怎么解决并发问题"><a class="markdownIt-Anchor" href="#1-整个网络那么多矿工谁都有打包制作的权利怎么解决并发问题"></a> 1. 整个网络那么多矿工谁都有打包制作的权利，怎么解决并发问题？</h3><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508157.png" alt><br>在比特币的协议中规定，给挖矿过程增加了一定的难度，使得矿工挖矿并不是那么容易，一般是全网的所有矿工节点的所有算力一起计算10分钟才能制作出一个合法的新区块。<br>有了这个规定，这个比特币网络就有充足的时间让大部分节点同步最新的区块数据，而减少并发问题。这个挖矿的难度在比特币中就叫工作量证明机制（Proof-of-Work，PoW）。</p><p>刚刚提到的10分钟，为什么是10分钟，是怎么保证的？</p><p>先来回答下为什么是10分钟，而不是15分钟、2分钟、8分钟，中本聪在设计比特币机制时，考虑到新区块数据在全世界节点的广播同步有一定的网络延迟，于是为了尽量避免“矿工A和矿工B在不知道对方都计算出结果的情况下同时发送计算结果”的事情，规定了制作新区款的难度，这个难度难到平均每个矿工需要花10分钟挖出一个区块，于是设计了一个这样的值：理论平均出块时间=10分钟。至于为什么是10分钟，那总得取一个值吧，综合考量就定了10分钟。</p><p>是怎么保证全网的平均出块时间一直保证在10分钟，不会随着计算能力的提升，就不需要10分钟了吗？</p><p>比特币规定，每挖完2016个区块，数学题的难度会自动的根据这2016个区块的实际挖出时间，动态地做出调整。</p><p>也就是说，每2016个区块的难度都是一样的，接下来的2016个区块的难度，根据前2016个区块的难度以及前2016个区块的整体实际挖矿时间综合决定，这里有个计算公式如下：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508078.png" alt><br>可以看出10分钟不是绝对值，有的矿工可能运气好一些、3分钟、5分钟就能找到符合标准的新区块，有的矿工运气差一些，可能需要20分钟、30分钟才能找到符合标准的新区块，由于有了这个标准的动态调整，总能保证全网的平均出块时间在10分钟左右。<br>具体这个难度是什么，我们看下面公式：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508135.png" alt><br>而上面的这个目标值b就是和挖矿难度系数有关的值，目前的难度就是SHA-256【制作新区款的所有内容+一个随机数】的hash值的二进制值至少前72位为零，也就是最坏的结果是至少需要计算2^72次才能找到这个随机数，你可以认为这个72就是一个难度系数值</p><p>有了这个工作量证明机制就能保证一定全网在同一时刻只有一个矿工制作成符合标准的新区块吗，答案是否定的，那么如果出现这个情况，比特币网络是怎么处理的？</p><p>E矿工和F矿工分别基于d区块制作出了新的区块并广播至其他节点，如下图：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508546.png" alt></p><p>同时收到e区块和f区块的节点会先同时保留这些区块，直到下一个区块基于其中一个区块制作出更长的区块链</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508291.png" alt></p><p>比特币协议规定只保留最长的区块链，较短的支链中的交易记录重新变为待确认交易重新发送至矿工节点作确认</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508312.png" alt></p><p>如果下一个区块碰巧又分别有两个新的区块基于e区块和f区块制作新区块，比特币网络的做法和上面的是一样的，先同时保留这些支链，直到最长的区块链出现，较短的区块的交易记录变为待确认交易重新发送至别人矿工节点。</p><h3 id="2-这种苦力活如果没人做怎么办"><a class="markdownIt-Anchor" href="#2-这种苦力活如果没人做怎么办"></a> 2. 这种“苦力活”如果没人做怎么办？</h3><p>比特币网络规定每成功生成一个新的区块，给相应的BTC给矿工账号作为奖励，并将新区块中的交易的手续费也归矿工所有，通过这个奖励机制大家就很乐意去干这个“苦力活”了。</p><p>这个奖励最初是50比特币，今后每产生21万个区块，比特币数量都会依次减半。直到第33次减半时，每个块产生0.0021个新比特币直接减为0个，最终比特币总量维持在2100万个。我们知道比特币大约每10分钟产生一个区块，而21万个10分钟接近4年。<br>最终这个比特币网络的矿工只能通过收取交易的手续费来维持他们的成本和收益<br>这个交易的手续费是可以交易方自己定的<br>但是矿工有权利优先选择手续费较高的记账或者拒绝，只要矿工们达成共识。</p><h2 id="挖矿工具矿机"><a class="markdownIt-Anchor" href="#挖矿工具矿机"></a> 挖矿工具——矿机</h2><p>挖矿的矿机从最初的使用PC个人电脑挖矿到专业的挖矿矿池，算力变得越来越强，挖矿的成本也越来越高，门槛越来越高。<br><strong>CPU挖矿→GPU挖矿→专业矿机挖矿→矿池挖矿</strong><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508408.png" alt><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508413.png" alt><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508512.png" alt><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508831.png" alt></p><h1 id="比特币是如何进行交易的"><a class="markdownIt-Anchor" href="#比特币是如何进行交易的"></a> 比特币是如何进行交易的</h1><p>比特币交易符合以下几个特点：</p><ul><li>交易数据包含交易输入和交易输出，其中交易输入的金额总和必须&gt;=输出金额总和</li><li>挖矿奖励属于一个特殊的交易（称为coinbase交易），可以没有输入。</li><li>在比特币没有余额概念，只有分散到区块链里的UTXO（未花费交易记录）</li><li>UTXO是交易的基本单元，不能在分割。</li></ul><h2 id="比特币转账"><a class="markdownIt-Anchor" href="#比特币转账"></a> 比特币转账</h2><p>比特币的交易记录主要由以下几部分组成：</p><ul><li>交易的输入，是指向上一笔交易的hash值</li><li>交易的输入解锁脚本，能够证明这笔钱你有权动用</li><li>交易的输出，交易的输出对方账户</li><li>交易输出的加锁脚本，是的对方必须提供证明是转给他的，才有权动用</li></ul><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508663.png" alt><br>上表格中：<br>记录1是个特殊的交易记录，是比特币矿工的奖励记录，给A账户转账10BTC，所以没有交易输入，这个交易记录叫coinbase<br>记录2:A使用记录1转给他的钱用来支付给B,并加锁这个转账<br>记录3：B收到这个转账时，提供自己的签名和公钥，证明确实是转给他的，B再用这笔转账支付10BTC给C</p><p>从上面的交易得知，<strong>我们把以上交易记录中可以用来当下一笔交易的未使用记录，称之为未花费记录（UTXO）</strong></p><p>我们再来看下面这个记录：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120509067.png" alt></p><p>记录2中A需要支付5BTC给B，但是交易输入记录1是10BTC的，所以将自己的账户添加到交易输出中找回5BTC</p><p>记录4由于A需要支付10BTC，所以交易输入是两笔5BTC的交易记录。</p><p>从上面的交易可以看出,<strong>比特币系统中没有账户的概念，只有交易记录，一笔未花费交易记录不能拆开使用，如果要只需花费一部分，通过在交易输出添加一笔给自己转账的记录，类似现金找零。</strong></p><h3 id="如何防止同一笔前用两次"><a class="markdownIt-Anchor" href="#如何防止同一笔前用两次"></a> 如何防止同一笔前用两次</h3><p>A账号用【记录1】当做输入支付给10BTC给“B账号”，接着又用【记录1】当做输入支付给10BTC给“C账号”,<br>相当于10BTC用了两次。如下图：<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508784.png" alt></p><p>我们分情况来看同一笔交易输入支付给了不同的人：<br>**情况1：**两条交易记录打包在同一个区块中：那么以先收到的交易是合法的，后收到的交易是非法的<br>**情况2：**两条交易记录先后被打包进不同区块的同一主链中：那么当矿工验证交易合法性时，是从以往合法的所有区块的所有交易中查找验证的，先收到的交易是合法的，后收到的是非法的<br>**情况2：**两条交易记录先后被打包进不同区块的不同支链中：<br>A矿工在之前主链基础上制作新区款，先收到交易1；<br>B矿工在之前主链基础上制作新区款，先收到交易2。<br>那么矿工在做合法性验证时都认为是合法的，此时比特币网络发生分叉，随着之后新区款制作，根据比特币协议规定，将保留区块长度最长的链，较短的支链将丢弃，其中的交易记录重新变为未确认交易等待下一个新区块的合法性校验，此时校验不通过的交易将丢弃。</p><h2 id="真实的比特币交易数据的结构"><a class="markdownIt-Anchor" href="#真实的比特币交易数据的结构"></a> 真实的比特币交易数据的结构</h2><pre class="highlight"><code class>{   &quot;lock_time&quot;:0,   &quot;size&quot;:259,   &quot;version&quot;:1,   &quot;vin_sz&quot;:1,   “hash”:“2514161c059ac18bf2eff1e05c4628e322d846e930fd6dd4b24805ea59dc4913”,//这笔交易的ID   &quot;vout_sz&quot;:2,   “inputs”:[//这笔交易的的来源交易，也称输入交易，可能有多个      {         &quot;prev_out&quot;:{“hash”:“4f40655c4ab1a029bc41bc547f79556a0dc48d22df7202778fad592791c77fcd”,//上一笔交易的交易ID“index”:0 //在上一笔交易的输出列表的下标位置         },         “script”:“493046022100cd6795ebcd1b6b87833a4ad812733d3804065d34bafee24da181a770892272b902210088cd2484952ad2572f9bfb2874643dbb4b3c492b749e79d8177a14eb4a3bc61a014104bbf2b84900b6f898548687aefba86cc06da6f4656a71e45fa55128b501455b5486cb09705cfa23c1899fe46d4355c9058bb2de4f1a7f1a01ff27e00b306f7356” //解锁上一笔交易输出的参数      }   ],    “out”:[//这笔交易的交易对手方，也称交易输出，也可以有多个      {   //交易输出的锁定脚本，只有交易对方提供正确的自己的签名及公钥才能证明这笔钱是转给他的，才有资格进行下一次的转账交易         “script_string”:“OP_DUP OP_HASH160 f9d49c5cf3e120ad1be60b67d868603a8fc945d2 OP_EQUALVERIFY OP_CHECKSIG”,         &quot;address&quot;:&quot;1PmyxDv5VvGoSAKMr1DQcWB6sHPx1ZbgWe&quot;,         “value”:88994500000,//转多少钱，单位是聪，1亿聪=1BTC         &quot;script&quot;:&quot;76a914f9d49c5cf3e120ad1be60b67d868603a8fc945d288ac&quot;      },      {         &quot;script_string&quot;:&quot;OP_DUP OP_HASH160 088465c1f0c8b3b3da06f7073a921d6b95b22f49 OP_EQUALVERIFY OP_CHECKSIG&quot;,         &quot;address&quot;:&quot;1n31g4rKiEeXnZEZR6VZwm3LggLicEqEC&quot;,         &quot;value&quot;:1000000000,         &quot;script&quot;:&quot;76a914088465c1f0c8b3b3da06f7073a921d6b95b22f4988ac&quot;      }   ]}</code></pre><h2 id="比特币的脚本语言"><a class="markdownIt-Anchor" href="#比特币的脚本语言"></a> 比特币的脚本语言</h2><pre class="highlight"><code class>OP_DUP OP_HASH160 f9d49c5cf3e120ad1be60b67d868603a8fc945d2 OP_EQUALVERIFY OP_CHECKSIG</code></pre><p>上面是比特币交易中的交易输入解锁脚本，输入两个参数：<sig> <pubk> 使得<pubk>的HASH160值等于9d49c5cf3e120ad1be60b67d868603a8fc945d2，接着使用<pubk>验证<sig>签名，验证同步则表示该交易输入合法有效，就像用户名密码一样。</sig></pubk></pubk></pubk></sig></p><p>比特币脚本语言是非图灵完备脚本语言，就是说它不能实现复杂的逻辑。<br>比特币脚本语言的执行是遵循先进后出的原因，即它的变量读取是堆栈式，如下图：</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120509028.png" alt><br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120508906.png" alt></p><h2 id="最终的结构"><a class="markdownIt-Anchor" href="#最终的结构"></a> 最终的结构</h2><p>比特币就是通过每一个区块都有上一个区块的指正，每个区块中包含通过验证的合法交易组成的链式结构，并让所有节点同步这份数据，形成不可逆，串改成本巨大的分布式超级账本，称之为区块链<br><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/getImage-20220824120509220.png" alt></p><h1 id="比特币的价值及存在问题"><a class="markdownIt-Anchor" href="#比特币的价值及存在问题"></a> 比特币的价值及存在问题</h1><p>比特币的价值在于，金融危机发生的时候，货币超发，法币贬值，社会财富缩水；<br>而比特币不依赖中央机构管理，期价值完全由供给关系决定，<br>当旧的法定货币崩溃时，人们便会涌向比特币，把比特币作为新的资产避风港——“21世纪版的黄金”<br>比特币是目前区块链技术落地最成功的项目，虽然比特币目前实际用的更多的是黑产（赌博、洗钱、黑客敲诈、传销），但是开创了人们对区块链技术无限探索和想象；</p><p>但同样存在着问题：</p><ul><li>由于有新区块难度限制，每秒处理交易数不足7/sec，交易确认时间长大几小时甚至几天交易确认时间长大几小时甚至几天</li><li>巨大的能源消耗（这也是比特币防篡改的代价）</li><li>随着计算机算力的提升，构建数字货币的密码学可能会被攻破</li><li>投机性强，泡沫大</li><li>算力集中，随着挖矿难度增加，只有少数几个矿池能够维持挖矿成本，失去去中心化初衷</li></ul><h1 id="区块链的应用"><a class="markdownIt-Anchor" href="#区块链的应用"></a> 区块链的应用</h1><p>基于区块链的记录不可逆、去中心化、全民监管的特点来构建一个信任网络，降低<br>社会协同合作成本，主要应用如下：</p><ul><li>企业融资：企业可以通过发行代币的方式对投资者承诺未来能够通过代币购买</li><li>公共实物：居于区块链上的登记的信息不可篡改，能够很方便的证明你的信息合法性</li><li>公益：在当前大环境下，听到慈善、公益，心里就不是滋味——信息不透明、 监督困难；利用区块链技术能够追踪每一笔善款的去向</li><li>供应链：结合物联网实现对物品信息的区块链管理，做到每个每个商品从生产到消费者的每一个环节，做到正品溯源；</li><li>供应链金融：代理商可以低成本的通过货物抵押向供应商赊账，并利用区块链智能合约技术保证物品出售时自动回款给供应商</li><li>物流：通过区块链技术做到CP间的信息信任，较少物流环节的信息交换成本，并通过区块链加密技术做到信息的保护。</li></ul><h1 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h1><ul><li>区块链为信息时代的去中心化信息交易提供了良好的解决思路</li><li>区块链只是一种解决问题的技术，一定是结合实际场景落地才能有好的未来，否则就是技术人和投机者的一场狂欢。</li><li>炒币有风险，入市需谨慎</li></ul><h1 id="了解区块链的一些网站"><a class="markdownIt-Anchor" href="#了解区块链的一些网站"></a> 了解区块链的一些网站：</h1><p>区块链相关导航：<a href="https://www.feixiaohao.com/daohanglist/" target="_blank" rel="noopener">https://www.feixiaohao.com/daohanglist/</a><br>比特币富豪排行榜：<a href="http://bitop.top/" target="_blank" rel="noopener">http://bitop.top/</a><a href="http://bitop.top/" target="_blank" rel="noopener">http://bitop.top/</a>)</p>]]></content>
      
      
      <categories>
          
          <category> 区块链 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 区块链 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RokectMQ 和Kafka对比</title>
      <link href="/xue-xi/rocketmq-vs-kafka/"/>
      <url>/xue-xi/rocketmq-vs-kafka/</url>
      
        <content type="html"><![CDATA[<h1 id="rokectmq-和kafka对比"><a class="markdownIt-Anchor" href="#rokectmq-和kafka对比"></a> RokectMQ 和Kafka对比</h1><table><thead><tr><th>对比项</th><th>Kafka</th><th>RocketMQ</th><th>总结</th></tr></thead><tbody><tr><td>部署架构</td><td><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1562836313289_5.png" alt="img"></td><td><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1562836232412_3.webp" alt="img"></td><td>1. Zookeeper对应NameServer,NameServer没有用强一直的watch来监听各个节点可靠性，而是使用心跳机制。<br>2. RocketMQ没有用ZK做高可用负载，原因是Broker在RocketMQ中就是物理概念，一台机器就是一个broker,Broker-Master和Broker-Slave关系在部署初始化是确认，运行过程中无需负载的选主切换，当然RMQ也就不支持在Broker-Master挂掉是自主选主Slave为master,需要手动切换。</td></tr><tr><td>行3架构拓扑图</td><td><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1562837115046_7-1574933554003.png" alt="img"></td><td><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1562837123812_9.png" alt="img"></td><td>1.kafka的partition对应rmq的queue<br>2.都可以为topic指定对应的分区数量<br>3.通过topic创建命令来说明topic、partition和broker<br>(Master/Slave)的关系<br>kafka:<br> <em>sh bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 3 --topic mytopic</em> <br>roketmq:<br> <em>sh /root/rocketmq/bin/mqadmin updateTopic -c defaultCluster -readQueueNums/writeQueueNums 3 -t mytopic</em> <br>可以看出不一样的是kafka需要指定<br>–replication-factor来说明这个topic一个master需要几个slave，而rmq不需要，因为这个Master/slave拓扑结构是在配置写死的<br>4. Kafka的Master/slave是逻辑结构，可以是同一台机器，而rmq不行，必须在初始化时就在配置文件中写死，要么是不同机器，要么是同一机器的不同进程（可以是端口不一样），是对应的物理结构。kafka可实现在通过zk自动Slave升级成Master<br>5. Rmq之所以没有用zk做主备自动切换，也是为了简化整个系统的复杂度，无需过多的关心选主和一致性的问题，同时也为了保证消息的不乱序消费，造成业务异常。</td></tr><tr><td>消息存储</td><td><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1562838493614_11.jpeg" alt="img"></td><td><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/1562838500422_13.jpeg" alt="img"></td><td>1.kafka和rmq都是用文件形式来持久化消息2. kafka为每个partiion单独文件存储；而rmq不是所有的topic的所有queue的数据存储在commitlog中（默认按1G大小存储，超过时新建一个文件，按文件大小偏移量命名），并每个topic的每个queue用consumerqueue小文件存储消费位点信息，可以通过消费位点到commitlog快速定位到对应的数据行。rocketmq这样做的好处是：文件顺序写，小文件随机读。优化了kafka当topic较多时的性能问题。那么rmq是怎么做到的：<br> - producer消息先投递到commitlog,异步最终一致写入consumerqueue - 由于是一个文件，根据linux文件写入缓存页批量写的机制，写入非常迅速，因为没有多个文件的资源竞争<br>- 随机读，因为cosumerqueue中的数据非常少，能够一次性读取很多数据，访问速度和内存相当，通过预读取机制这部分性能可以忽略不计，对于commitlog这个大文件虽然是随机读，但是整体是有序的，还是可以充分利用PageCache的性能，再加上文件内存映射技术，很好的保障了在很多topic下的读写性能。</td></tr><tr><td>性能</td><td>单机写入TPS约在百万条/秒，消息大小10个字节</td><td>RocketMQ单机写入TPS单实例约7万条/秒，单机部署3个Broker，可以跑到最高12万条/秒，消息大小10个字节</td><td>1. Kafka的TPS跑到单机百万，主要是由于Producer端将多个小消息合并，批量发向Broker <br> 2. RocketMQ为什么没有这么做？Producer通常使用Java语言，缓存过多消息，GC是个很严重的问题Producer调用发送消息接口，消息未发送到Broker，向业务返回成功，此时Producer宕机，会导致消息丢失，业务出错Producer通常为分布式系统，且每台机器都是多线程发送，我们认为线上的系统单个Producer每秒产生的数据量有限，不可能上万。缓存的功能完全可以由上层业务完成。</td></tr><tr><td>数据可靠性</td><td>Kafka使用异步刷盘方式，异步Replication</td><td>RocketMQ支持异步实时刷盘，同步刷盘，同步Replication，异步Replication</td><td>1.RocketMQ的同步刷盘在单机可靠性上比Kafka更高，不会因为操作系统Crash，导致数据丢失。在强可靠性要求场景可用 2.另外Kafka的Replication以topic为单位，支持主机宕机，备机自动切换，但是这里有个问题，由于是异步Replication，那么切换后会有数据丢失，且会有消息乱序的风险。</td></tr><tr><td>消费失败重试</td><td>Kafka消费失败不支持自动重试</td><td>RocketMQ消费失败支持定时重试，每次重试间隔时间顺延</td><td>1. kafka如果需要实现消息重试，需要自己实现取出消息重新发送一遍。</td></tr><tr><td>消息顺序</td><td>Kafka支持消息顺序，但是一台Broker宕机后，就会产生消息乱序</td><td>RocketMQ支持严格的消息顺序，在顺序消息场景下，一台Broker宕机后，发送消息会失败，但是不会乱序</td><td>当broker的leader挂掉瞬间，旧的leader对client可见，所以可能存在多个消费者消费不同的broker情况，造成消息乱序消费。</td></tr><tr><td>定时消息消费</td><td>Kafka不支持定时消息</td><td>RocketMQ支持</td><td>开源版本RocketMQ仅支持定时Level阿里云ONS支持定时Level，以及指定的毫秒级别的延时时间</td></tr><tr><td>事物消息</td><td>不支持</td><td>支持但是没有超时回查机制</td><td>阿里内部版本支持完整实物消息</td></tr><tr><td>消息回溯</td><td>可以按照Offset来回溯消息</td><td>支持按照时间来回溯消息，精度毫秒，例如从一天之前的某时某分某秒开始重新消费消息</td><td>典型业务场景如consumer做订单分析，但是由于程序逻辑或者依赖的系统发生故障等原因，导致今天消费的消息全部无效，需要重新从昨天零点开始消费，那么以时间为起点的消息重放功能对于业务非常有帮助。</td></tr><tr><td>消息消费并行度</td><td>Kafka的消费并行度依赖Topic配置的分区数，如分区数为10，那么最多10台机器来并行消费（每台机器只能开启一个线程），或者一台机器消费（10个线程并行消费）。即消费并行度和分区数一致</td><td>顺序消费方式并行度同Kafka完全一致<br> 乱序方式并行度取决于Consumer的线程数，如Topic配置10个队列，10台机器消费，每台机器100个线程，那么并行度为1000。</td><td>RoketMQ在不要求顺序消费时，并行度可以很高</td></tr><tr><td>开发语言</td><td>Scala</td><td>Java</td><td>分布式系统中，Java的语言生态更好</td></tr><tr><td>消息堆积能力</td><td>非常好，上亿级</td><td>非常好，上亿级</td><td>消息堆积能力都非常好</td></tr><tr><td>商业支持</td><td>LinkIn开源</td><td>Alibaba开源</td><td></td></tr><tr><td>成熟度</td><td>Kafka在日志领域比较成熟</td><td>RocketMQ在阿里集团内部有大量的应用在使用，每天都产生海量的消息，并且顺利支持了多次天猫双十一海量消息考验，是数据削峰填谷的利器。</td><td>商业场景RocketMQ更加适合，并且更符合开发习惯</td></tr></tbody></table><h1 id="qa"><a class="markdownIt-Anchor" href="#qa"></a> QA</h1><h2 id="为什么使用消息队列消息队列的作用是什么"><a class="markdownIt-Anchor" href="#为什么使用消息队列消息队列的作用是什么"></a> 为什么使用消息队列?消息队列的作用是什么?</h2><p>异步化、解耦、消除峰值</p><h2 id="kafka-的-topic-和分区内部是如何存储的有什么特点"><a class="markdownIt-Anchor" href="#kafka-的-topic-和分区内部是如何存储的有什么特点"></a> Kafka 的 Topic 和分区内部是如何存储的，有什么特点?</h2><p>新建topic时指定分区数量，并为每个分区维护消息数据存储文件，随着topic数量增加，文件数量增加，读写性能下降。</p><h2 id="与传统的消息系统相比kafka-的消费模型有什么优点"><a class="markdownIt-Anchor" href="#与传统的消息系统相比kafka-的消费模型有什么优点"></a> 与传统的消息系统相比，Kafka 的消费模型有什么优点?</h2><ol><li>Kafka是一个分布式系统，易于向外扩展。</li><li>它同时为发布和订阅提供高吞吐量。</li><li>它支持多订阅者，当失败时能自动平衡消费者。</li><li>消息的持久化。</li></ol><h2 id="kafka-如何实现分布式的数据存储与数据读取"><a class="markdownIt-Anchor" href="#kafka-如何实现分布式的数据存储与数据读取"></a> Kafka 如何实现分布式的数据存储与数据读取?</h2><p>日志形式存储，并生成索引文件，能够通过offset下标快速定位数据行</p><h2 id="kafka-为什么比-rocketmq-支持的单机-partition-要少"><a class="markdownIt-Anchor" href="#kafka-为什么比-rocketmq-支持的单机-partition-要少"></a> Kafka 为什么比 RocketMQ 支持的单机 Partition 要少?</h2><p>数据存储形式决定，kafka为每个分区都生成存储文件，当较多的Parition时，随机写冲突加大，性能下降</p><h2 id="为什么需要分区也就是说主题只有一个分区难道不行吗"><a class="markdownIt-Anchor" href="#为什么需要分区也就是说主题只有一个分区难道不行吗"></a> 为什么需要分区，也就是说主题只有一个分区，难道不行吗?</h2><p>分区是为了尽可能的减少资源竞争，增加处理并行度</p><h2 id="日志为什么需要分段"><a class="markdownIt-Anchor" href="#日志为什么需要分段"></a> 日志为什么需要分段?</h2><p>方便快速清理无用数据，提高磁盘利用率</p><h2 id="kafka-是依靠什么机制保持高可靠高可用"><a class="markdownIt-Anchor" href="#kafka-是依靠什么机制保持高可靠高可用"></a> Kafka 是依靠什么机制保持高可靠，高可用?</h2><p>利用zk实现Master/Slave主备切换</p><h2 id="消息队列如何保证消息幂等"><a class="markdownIt-Anchor" href="#消息队列如何保证消息幂等"></a> 消息队列如何保证消息幂等?</h2><p>利用消息的唯一标识，在业务系统中做好幂等，消息中间件本身无需保证幂等</p><h2 id="让你自己设计个消息队列你会怎么设计会考虑哪些方面"><a class="markdownIt-Anchor" href="#让你自己设计个消息队列你会怎么设计会考虑哪些方面"></a> 让你自己设计个消息队列，你会怎么设计，会考虑哪些方面?</h2><ul><li>消息的持久化</li><li>分布式可靠性</li><li>消息堆积能力</li><li>消息重试</li></ul><blockquote><p>参考文章：<br><a href="https://cloud.tencent.com/developer/news/306092" target="_blank" rel="noopener">分布式消息队列RocketMQ与Kafka架构上的巨大差异</a><br><a href="https://zl378837964.iteye.com/blog/2421888" target="_blank" rel="noopener">RocketMQ与Kafka对比</a><br><a href="https://github.com/javahongxi/whatsmars/wiki/RocketMQ%E5%90%90%E8%A1%80%E6%80%BB%E7%BB%93" target="_blank" rel="noopener">RocketMQ吐血总结</a><br><a href="https://www.cnblogs.com/xiaodf/p/5075167.html" target="_blank" rel="noopener">RocketMQ原理介绍最透彻的文章</a></p></blockquote>]]></content>
      
      
      <categories>
          
          <category> RocketMQ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RocketMQ </tag>
            
            <tag> Kafka </tag>
            
            <tag> MQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客搭建的介绍</title>
      <link href="/blog-introduce/"/>
      <url>/blog-introduce/</url>
      
        <content type="html"><![CDATA[<h1 id="介绍"><a class="markdownIt-Anchor" href="#介绍"></a> 介绍</h1><p>这是我修改自<a href="https://github.com/godweiyang/hexo-matery-modified" target="_blank" rel="noopener">hexo-theme-matery</a>的个性化hexo博客模板，主要修改了一些个性化配置，为了方便大家直接搭建使用。</p><p><img src="https://okeeper-blog-images.oss-cn-hangzhou.aliyuncs.com/images/image-20191128160144163.png" alt="image-20191128160144163"></p><h1 id="我的博客演示"><a class="markdownIt-Anchor" href="#我的博客演示"></a> 我的博客演示</h1><p><a href="https://okeeper.com">https://okeeper.com</a></p><h1 id="快速方法"><a class="markdownIt-Anchor" href="#快速方法"></a> 快速方法</h1><h2 id="1-下载主题源码"><a class="markdownIt-Anchor" href="#1-下载主题源码"></a> 1. 下载主题源码</h2><p>为了减小源码的体积，我将插件目录<code>node_modules</code>进行了压缩，大家下载完后需要解压。另外添加水印需要的字体文件我也删除了，大家可以直接从电脑自带的字体库中拷贝。</p><ul><li>首先运行<code>git clone git@github.com:godweiyang/hexo-matery-modified.git</code>将所有文件下载到本地。</li><li>解压<code>node_modules.zip</code>，然后删除<code>node_modules.zip</code>和<code>.git</code>文件夹。</li><li>还缺一个字体（为图片添加水印需要用到），去<code>C:\Windows\Fonts</code>下找到<code>STSong Regular</code>，复制到<code>hexo-matery-modified</code>文件夹下。</li></ul><h2 id="2-环境准备"><a class="markdownIt-Anchor" href="#2-环境准备"></a> 2. 环境准备</h2><h3 id="21-安装nodejs"><a class="markdownIt-Anchor" href="#21-安装nodejs"></a> 2.1 安装Node.js</h3><p>首先下载稳定版Node.js，我这里给的是64位的。<br>安装选项全部默认，一路点击Next。</p><p>最后安装好之后，按Win+R打开命令提示符，输入<code>node -v</code>和<code>npm -v</code>，如果出现版本号，那么就安装成功了。</p><p>添加国内镜像源<br>如果没有梯子的话，可以使用阿里的国内镜像进行加速。</p><pre class="highlight"><code class>npm config set registry https://registry.npm.taobao.org</code></pre><h3 id="22-安装hexo"><a class="markdownIt-Anchor" href="#22-安装hexo"></a> 2.2 安装hexo</h3><pre class="highlight"><code class>npm i hexo-cli -ghexo -vhexo init# 安装必要组件npm install# 生成静态文件hexo g#启动服务器hexo s</code></pre><h2 id="3-修改配置_configyml"><a class="markdownIt-Anchor" href="#3-修改配置_configyml"></a> 3. 修改配置<code>_config.yml</code></h2><pre class="highlight"><code class="properties"><span class="hljs-comment"># 修改git配置，当执行 `hexo d` 时, 将自动提交到这个git地址</span><span class="hljs-attr">deploy</span>:<span class="hljs-string"></span><span class="hljs-attr">-</span> <span class="hljs-string">type: git</span>  <span class="hljs-attr">repository</span>: <span class="hljs-string">https://github.com/okeeper/okeeper.github.io.git</span>  <span class="hljs-attr">branch</span>: <span class="hljs-string">master</span><span class="hljs-comment"># 修改标题和关键字</span></code></pre><h2 id="4-在github中添加你的博客项目"><a class="markdownIt-Anchor" href="#4-在github中添加你的博客项目"></a> 4. 在github中添加你的博客项目</h2><p>一般为 {你的id}.github.io, 这样后续就可以直接通过 {你的id}.github.io访问到你的blog</p><h2 id="5-编译发布"><a class="markdownIt-Anchor" href="#5-编译发布"></a> 5. 编译&amp;发布</h2><pre class="highlight"><code class># 编译source目录下的文章生成public静态文件hexo g# 提交到你的blog仓库hexo d</code></pre><blockquote><p>hexo部署到github时，提示typeError [ERR_INVALID_ARG_TYPE]: The “mode“ argument must be integer. Receive…<br>出现这个问题的原因是node版本较高</p></blockquote><blockquote><p>解决方法</p></blockquote><pre class="highlight"><code class>$ hexo -vhexo: 3.9.0hexo-cli: 4.3.0os: darwin 22.3.0 13.2.1node: 21.1.0acorn: 8.10.0</code></pre><p>hexo 版本才3.9.0,</p><p>而node 版本已经是14.17.5了</p><p>更换版本<br>使用nvm命令</p><pre class="highlight"><code class>查看可用node版本nvm list#使用低版本的nodenvm use v12.14.0# 再试一下hexo dhexo d</code></pre><h1 id="个性化"><a class="markdownIt-Anchor" href="#个性化"></a> 个性化</h1><h3 id="1-添加水印"><a class="markdownIt-Anchor" href="#1-添加水印"></a> 1. 添加水印</h3><p>为了防止别人抄袭你文章，可以把所有的图片都加上水印，方法很简单。<br><a href="http://xn--watermark-u75nydvqv95a9iho1p6nr2mn0qbjz0e1uk9i9esl5i.py" target="_blank" rel="noopener">首先在博客根目录下新建一个watermark.py</a>，代码如下：</p><pre class="highlight"><code class="python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><span class="hljs-keyword">import</span> sys<span class="hljs-keyword">import</span> glob<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> ImageDraw<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> ImageFont<span class="hljs-keyword">def</span> <span class="hljs-title function_">watermark</span>(<span class="hljs-params">post_name</span>):    <span class="hljs-keyword">if</span> post_name == <span class="hljs-string">&#x27;all&#x27;</span>:        post_name = <span class="hljs-string">&#x27;*&#x27;</span>    dir_name = <span class="hljs-string">&#x27;source/_posts/&#x27;</span> + post_name + <span class="hljs-string">&#x27;/*&#x27;</span>    <span class="hljs-keyword">for</span> files <span class="hljs-keyword">in</span> glob.glob(dir_name):        im = Image.<span class="hljs-built_in">open</span>(files)        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(im.getbands()) &lt; <span class="hljs-number">3</span>:            im = im.convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)            <span class="hljs-built_in">print</span>(files)        font = ImageFont.truetype(<span class="hljs-string">&#x27;STSONG.TTF&#x27;</span>, <span class="hljs-built_in">max</span>(<span class="hljs-number">30</span>, <span class="hljs-built_in">int</span>(im.size[<span class="hljs-number">1</span>] / <span class="hljs-number">20</span>)))        draw = ImageDraw.Draw(im)        draw.text((im.size[<span class="hljs-number">0</span>] / <span class="hljs-number">2</span>, im.size[<span class="hljs-number">1</span>] / <span class="hljs-number">2</span>),                  <span class="hljs-string">u&#x27;@godweiyang&#x27;</span>, fill=(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>), font=font)        im.save(files)<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(sys.argv) == <span class="hljs-number">2</span>:        watermark(sys.argv[<span class="hljs-number">1</span>])    <span class="hljs-keyword">else</span>:        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[usage] &lt;input&gt;&#x27;</span>)</code></pre><p>字体也放根目录下，自己找字体。然后每次写完一篇文章可以运行python3 <a href="http://watermark.py" target="_blank" rel="noopener">watermark.py</a> postname添加水印，如果第一次运行要给所有文章添加水印，可以运行python3 <a href="http://watermark.py" target="_blank" rel="noopener">watermark.py</a> all</p><h3 id="2-添加快速评论"><a class="markdownIt-Anchor" href="#2-添加快速评论"></a> 2. 添加快速评论</h3><p>注册：<a href="https://leancloud.cn/" target="_blank" rel="noopener">https://leancloud.cn/</a></p><pre class="highlight"><code class="yaml"><span class="hljs-comment"># Valine 评论模块的配置，默认为不激活，如要使用，就请激活该配置项，并设置 appId 和 appKey.</span><span class="hljs-attr">valine:</span>  <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span>  <span class="hljs-attr">appId:</span> <span class="hljs-string">***修改成你自己的appId</span>  <span class="hljs-attr">appKey:</span> <span class="hljs-string">***修改成你自己的appKey</span>  <span class="hljs-attr">notify:</span> <span class="hljs-literal">false</span>  <span class="hljs-attr">verify:</span> <span class="hljs-literal">false</span>  <span class="hljs-attr">visitor:</span> <span class="hljs-literal">false</span>  <span class="hljs-attr">avatar:</span> <span class="hljs-string">&#x27;wavatar&#x27;</span> <span class="hljs-comment"># Gravatar style : mm/identicon/monsterid/wavatar/retro/hide</span>  <span class="hljs-attr">pageSize:</span> <span class="hljs-number">10</span>  <span class="hljs-attr">placeholder:</span> <span class="hljs-string">&#x27;来都来了，不留点啥啊！&#x27;</span> <span class="hljs-comment"># Comment Box placeholder</span></code></pre><h3 id="3-给文章添加背景音乐"><a class="markdownIt-Anchor" href="#3-给文章添加背景音乐"></a> 3. 给文章添加背景音乐</h3><p>在.md的markdown文件的开头添加这段代码</p><pre class="highlight"><code class>&lt;div align=&quot;middle&quot;&gt;&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 src=&quot;//music.163.com/outchain/player?type=2&amp;id=407679465&amp;auto=1&amp;height=66&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;</code></pre><h3 id="4-front-matter-选项详解"><a class="markdownIt-Anchor" href="#4-front-matter-选项详解"></a> 4. Front-matter 选项详解</h3><p><code>Front-matter</code> 选项中的所有内容均为<strong>非必填</strong>的。但我仍然建议至少填写 <code>title</code> 和 <code>date</code> 的值。</p><table><thead><tr><th>配置选项</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td>title</td><td><code>Markdown</code> 的文件标题</td><td>文章标题，强烈建议填写此选项</td></tr><tr><td>date</td><td>文件创建时的日期时间</td><td>发布时间，强烈建议填写此选项，且最好保证全局唯一</td></tr><tr><td>author</td><td>根 <code>_config.yml</code> 中的 <code>author</code></td><td>文章作者</td></tr><tr><td>img</td><td><code>featureImages</code> 中的某个值</td><td>文章特征图，推荐使用图床(腾讯云、七牛云、又拍云等)来做图片的路径.如: <code>http://xxx.com/xxx.jpg</code></td></tr><tr><td>top</td><td><code>true</code></td><td>推荐文章（文章是否置顶），如果 <code>top</code> 值为 <code>true</code>，则会作为首页推荐文章</td></tr><tr><td>cover</td><td><code>false</code></td><td><code>v1.0.2</code>版本新增，表示该文章是否需要加入到首页轮播封面中</td></tr><tr><td>coverImg</td><td>无</td><td><code>v1.0.2</code>版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td></tr><tr><td>password</td><td>无</td><td>文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 <code>password</code> 的值，该值必须是用 <code>SHA256</code> 加密后的密码，防止被他人识破。前提是在主题的 <code>config.yml</code> 中激活了 <code>verifyPassword</code> 选项</td></tr><tr><td>toc</td><td><code>true</code></td><td>是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 <code>config.yml</code> 中激活了 <code>toc</code> 选项</td></tr><tr><td>mathjax</td><td><code>false</code></td><td>是否开启数学公式支持 ，本文章是否开启 <code>mathjax</code>，且需要在主题的 <code>_config.yml</code> 文件中也需要开启才行</td></tr><tr><td>summary</td><td>无</td><td>文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</td></tr><tr><td>categories</td><td>无</td><td>文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类</td></tr><tr><td>tags</td><td>无</td><td>文章标签，一篇文章可以多个标签</td></tr><tr><td>reprintPolicy</td><td>cc_by</td><td>文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个</td></tr></tbody></table><blockquote><p><strong>注意</strong>:</p><ol><li>如果 <code>img</code> 属性不填写的话，文章特色图会根据文章标题的 <code>hashcode</code> 的值取余，然后选取主题中对应的特色图片，从而达到让所有文章都的特色图<strong>各有特色</strong>。</li><li><code>date</code> 的值尽量保证每篇文章是唯一的，因为本主题中 <code>Gitalk</code> 和 <code>Gitment</code> 识别 <code>id</code> 是通过 <code>date</code> 的值来作为唯一标识的。</li><li>如果要对文章设置阅读验证密码的功能，不仅要在 Front-matter 中设置采用了 SHA256 加密的 password 的值，还需要在主题的 <code>_config.yml</code> 中激活了配置。有些在线的 SHA256 加密的地址，可供你使用：<a href="http://tool.oschina.net/encrypt?type=2" target="_blank" rel="noopener">开源中国在线工具</a>、<a href="http://encode.chahuo.com/" target="_blank" rel="noopener">chahuo</a>、<a href="http://tool.chinaz.com/tools/hash.aspx" target="_blank" rel="noopener">站长工具</a>。</li><li>您可以在文章md文件的 front-matter 中指定 reprintPolicy 来给单个文章配置转载规则</li></ol></blockquote><p>以下为文章的 <code>Front-matter</code> 示例。</p><pre class="highlight"><code class="yaml"><span class="hljs-meta">---</span><span class="hljs-attr">title:</span> <span class="hljs-string">typora-vue-theme主题介绍</span><span class="hljs-attr">date:</span> <span class="hljs-number">2018-09-07 09:25:00</span><span class="hljs-attr">author:</span> <span class="hljs-string">赵奇</span><span class="hljs-attr">img:</span> <span class="hljs-string">/source/images/xxx.jpg</span><span class="hljs-attr">top:</span> <span class="hljs-literal">true</span><span class="hljs-attr">cover:</span> <span class="hljs-literal">true</span><span class="hljs-attr">coverImg:</span> <span class="hljs-string">/images/1.jpg</span><span class="hljs-attr">password:</span> <span class="hljs-string">8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92</span><span class="hljs-attr">toc:</span> <span class="hljs-literal">false</span><span class="hljs-attr">mathjax:</span> <span class="hljs-literal">false</span><span class="hljs-attr">summary:</span> <span class="hljs-string">这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</span><span class="hljs-attr">categories:</span> <span class="hljs-string">Markdown</span><span class="hljs-attr">tags:</span>  <span class="hljs-bullet">-</span> <span class="hljs-string">Typora</span>  <span class="hljs-bullet">-</span> <span class="hljs-string">Markdown</span><span class="hljs-meta">---</span></code></pre><h1 id="搭建教程请参考"><a class="markdownIt-Anchor" href="#搭建教程请参考"></a> 搭建教程请参考</h1><p><a href="https://godweiyang.com/2018/04/13/hexo-blog/" target="_blank" rel="noopener">https://godweiyang.com/2018/04/13/hexo-blog/</a></p><h1 id="写文章-发布文章"><a class="markdownIt-Anchor" href="#写文章-发布文章"></a> 写文章、发布文章</h1><p>然后输入<code>hexo new post &quot;article title&quot;</code>，新建一篇文章。</p><p>然后打开<code>source\_posts</code>的目录，可以发现下面多了一个文件夹和一个<code>.md</code>文件，一个用来存放你的图片等数据，另一个就是你的文章文件啦。</p><p>编写完markdown文件后，根目录下输入<code>hexo g</code>生成静态网页，然后输入<code>hexo s</code>可以本地预览效果，最后输入<code>hexo d</code>上传到github上。这时打开你的github.io主页就能看到发布的文章啦。</p><h1 id="结合typora的markdown编辑器"><a class="markdownIt-Anchor" href="#结合typora的markdown编辑器"></a> 结合Typora的markdown编辑器</h1><p>有强迫症的人适合当程序员，应为容不得半点不舒服</p><p>对比了市面上的主流markdown编辑器，兼顾以下几个点的，好像只有Typora了</p><ul><li>即时预览，当你输入markdown关键字时自动变换预览格式</li><li>截图直接粘贴生成图片存入指定目录，设置见文件-&gt;偏好设置&gt;图像&gt;路径配置</li><li>简洁并支持主题自定义</li><li>开源免费</li></ul>]]></content>
      
      
      <categories>
          
          <category> 分享 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Blog </tag>
            
            <tag> typora-vue-theme </tag>
            
            <tag> hexo </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
